[{"title":"Binary Sort-二分查找","url":"/2025/07/10/Algorithm/Binary%20Search/","content":"二分查找典型特征\n原数组是有序的, 或者改变原数组顺序不影响答案\n我们要找出来一个数字在数组中的位置(标准二分查找题目)\n\n一般化特征\n我们能一次性排除解空间中的一半解\n我们要找出来解空间中的某一个解的位置\n\n解题通法-红蓝染色法我们能将数组依照单调性分成两部分, 以我们要找出target为例\nnum &gt;&#x3D; target的部分染成蓝色, num &lt; target为红色, 我们需要染色的区间是[left, right]或者(left-1, right+1)…\n\n[left, right]要染色的区间的含义就是我们现在没有染色也就是不知道其中的元素和target之间的关系\n\n循环不变量(以两端闭区间举例)\n\nleft - 1始终是红色\nright + 1始终是蓝色\n\n思考顺序\n首先确定我们怎么确定答案, 这种方式一定是要利用原数组在找到答案方面的单调性, 我们一定能一次性排除一半的解空间\n确定下来红蓝染色情况\n确定下来没有染色区间的开闭选择(一般是双开区间)\n\n典型例题及实现找到第一个大于等于target的值\n闭区间private int lower_bound(int[] nums, int target) &#123;    int left = 0;    int right = nums.length - 1;    // [left, right], left == right + 1 区间为空    // left - 1始终 &lt; target    // right + 1始终 &gt;= target    while (left &lt; right + 1) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid + 1;        else             right = mid - 1;    &#125;    return right + 1;&#125;\n\n开区间private int lower_bound(int[] nums, int target) &#123;    int left = -1;    int right = nums.length;    // (left, right), left + 1 == right 区间为空    // left 始终 &lt; target    // right 始终 &gt;= target    while (left + 1 &lt; right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid;        else             right = mid;    &#125;    return right;&#125;\n\n左开右闭private int lower_bound(int[] nums, int target) &#123;    int left = -1;    int right = nums.length - 1;    // (left, right], left == right 区间为空    // left 始终 &lt; target    // right + 1始终 &gt;= target    while (left &lt; right) &#123;        int mid = left + (right - left + 1) / 2;        if (nums[mid] &lt; target)             left = mid;        else             right = mid - 1;    &#125;    return right + 1;&#125;\n\n这里会有个额外的问题是mid向下取整, 会在left &#x3D; -1, right &#x3D; 0的时候取到-1, 所以我们需要调整成向上取整, 在left &#x3D; -1, right &#x3D; 0的时候取整到0, 就会不落到区间外面了\n左闭右开private int lower_bound(int[] nums, int target) &#123;    int left = 0;    int right = nums.length;    // [left, right), left == right 区间为空    // left - 1始终 &lt; target    // right 始终 &gt;= target    while (left &lt; right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid + 1;        else             right = mid;    &#125;    return right;&#125;\n\n题单典型题目35. 搜索插入位置\n74. 搜索二维矩阵\n34. 在排序数组中查找元素的第一个和最后一个位置\n非典型题目33. 搜索旋转排序数组\n153. 寻找旋转排序数组中的最小值\n参考链接灵茶山艾府-红蓝染色法\n","categories":["Algorithm","Binary sort"],"tags":["Algorithm","Binary Sort"]},{"title":"Java基础面试问题","url":"/2025/07/10/Interview/Java%20Base/","content":"Java基础a &#x3D; a + b 与 a +&#x3D; b 的区别+&#x3D; 隐式的将加操作的结果类型强制转换为持有结果的类型。如果两个整型相加，如 byte、short 或者 int，首先会将它们提升到 int 类型，然后在执行加法操作。\nbyte a = 127;byte b = 127;b = a + b; // error : cannot convert from int to byteb += a; // ok\n\n(因为 a+b 操作会将 a、b 提升为 int 类型，所以将 int 类型赋值给 byte 就会编译出错)\n为什么需要泛型？适用于多种数据类型执行相同的代码\n引入泛型，它将提供类型的约束，提供编译前的检查\n泛型方法泛型方法创建\n\n泛型方法使用\n\n泛型方法创建的时候需要使用&lt;T&gt;来声明这是一个泛型方法, 在传入的参数中需要有Class&lt;T&gt; c参数来指明传入的参数的类型, 然后在方法中通过反射newInstance方法来创建一个新的对象\n使用泛型方法的时候, 可以通过Class.forName(“全限定类名”)来获取Class类\n泛型的上限和下限？在使用泛型的时候，我们可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。\n上限\nclass Info&lt;T extends Number&gt;&#123;    // 此处泛型只能是数字类型\n\n下限\npublicstaticvoidfun(Info&lt;? super String&gt; temp)&#123;// 只能接收String或Object类型的泛型，String类的父类只有Object类System.out.print(temp +&quot;, &quot;);&#125;\n\n如何理解Java中的泛型是伪泛型？泛型中类型擦除 Java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型, 同时这里是会擦除成下限类型），就像完全没有泛型一样。\n注解元注解，元注解是用于定义注解的注解，包括@Retention、@Target、@Inherited、@Documented\n\n@Retention用于标明注解被保留的阶段\n@Target用于标明注解使用的范围\n@Inherited用于标明注解可继承\n\nJava异常类层次结构?\nThrowable\n 是 Java 语言中所有错误与异常的超类。 \n\nError 类及其子类：程序中无法处理的错误，表示运行应用程序中出现了严重的错误。\nException 程序本身可以捕获并且可以处理的异常。Exception 这种异常又分为两类：运行时异常和编译时异常。\n\n\n\n\n\n运行时异常\n\n都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。\n运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。\n\n非运行时异常 （编译异常）\n\n是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。\n可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）区别？\n可查异常（编译器要求必须处置的异常）：\n\n正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。\n除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。\n\n不可查异常(编译器不要求强制处置的异常)\n\n包括运行时异常（RuntimeException与其子类）和错误（Error）\n什么是SPI机制？SPI（Service Provider Interface），是JDK内置的一种 服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，MySQL和PostgreSQL都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是 解耦。\nSPI整体机制图如下：\n\n当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader。\nSPI机制的应用？\nSPI机制 - JDBC DriverManager\n\n在JDBC4.0之前，我们开发有连接数据库的时候，通常会用Class.forName(“com.mysql.jdbc.Driver”)这句先加载数据库相关的驱动，然后再进行获取连接等的操作。而JDBC4.0之后不需要用Class.forName(“com.mysql.jdbc.Driver”)来加载驱动，直接获取连接就可以了，现在这种方式就是使用了Java的SPI扩展机制来实现。\n\nJDBC接口定义\n\n首先在java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商来提供的。\n\nmysql实现\n\n在mysql的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。\n\npostgresql实现\n\n同样在postgresql的jar包postgresql-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是postgresql对Java的java.sql.Driver的实现。\n\n使用方法\n\n上面说了，现在使用SPI扩展来加载具体的驱动，我们在Java中写连接数据库的代码的时候，不需要再使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动了，而是直接使用如下代码：\nString url = &quot;jdbc:xxxx://xxxx:xxxx/xxxx&quot;;Connection conn = DriverManager.getConnection(url,username,password);.....","categories":["Interview","Java","JavaBase"],"tags":["Java","Interview","JavaBase"]},{"title":"Java JUC-并发编程面试问题","url":"/2025/07/11/Interview/Java%20JUC/","content":"并发编程问题\n","categories":["Interview","Java","JUC"]},{"title":"Java Colletion-集合框架面试问题","url":"/2025/07/10/Interview/Java%20Collection/","content":"&#x2F;&#x2F; TODO\n","categories":["Interview","Java","Collection"],"tags":["Java","Interview","Collection"]},{"title":"Spring AI 测试文件","url":"/2025/07/10/Java/JUC/JUC%20test/","content":"JUC测试文件\n","tags":["JUC"]},{"title":"MySQL 锁机制","url":"/2025/07/16/MiddleWare/MySQL/MySQl%20%E9%94%81/","content":"\n参考:\n\nhttps://relph1119.github.io/mysql-learning-notes/#/mysql/25-%E5%B7%A5%E4%BD%9C%E9%9D%A2%E8%AF%95%E8%80%81%E5%A4%A7%E9%9A%BE-%E9%94%81 \nhttps://xiaolincoding.com/mysql/lock/how_to_lock.html\n\n\nMySQL锁机制详解快照读与锁定读MySQL中读可以分作两类\n\n快照读: 也就是普通的select, 读-读场景不需要额外的机制保证并发安全, 而读-写场景通过MVCC来实现隔离级别\n锁定读: 会加锁的读, 是select ... for update或者select ... lock in share mode , 在MySQL中update, delete操作会分成两部分, 读取阶段和写入(删除)阶段, 前一阶段就属于锁定读\n\n共享锁(S)和互斥锁(X)共享锁: 如果一个事务给一个表(记录)加了S锁, 其他事务能再获取这个S锁, 但是该事务和其他事务都不能再获取这个表(记录)的X锁\n互斥锁: 独占锁, 如果有一个事务给一个表(记录)加了X锁, 其他事务不能再从这个表(记录)上获取锁了(无论XS), 同时也不能给已经上锁了的表(记录)加上X锁\n\n\n\n兼容性\n共享锁S\n互斥锁X\n\n\n\n共享锁S\n兼容\n不兼容\n\n\n互斥锁X\n不兼容\n不兼容\n\n\n类似于读-读并发安全, 所以不需要额外处理, 也就是S锁能兼容, 其他的情况都存在并发安全问题, 所以不能兼容\n表锁表级锁锁上整张表的锁, 分有X和S两种\n什么时候会加上表级锁: MySQL InnoDB引擎中因为有更细粒度的行级锁, 所以其实表级锁应用场景极其有限(没啥用)\n但是现在有个问题就是, 如果我们要对某个表加X锁或者S锁, 有个问题就是, 我们需要确保现在这个表是没有不兼容的行锁的\n\n我们要加上表级S锁的时候, 就需要保证表内没有X锁\n我们要加上表级X锁的时候, 就需要保证表内没有锁\n\n这种时候很明显我们不能遍历每行来看是不是有加锁, Innodb引入了意向锁的机制\n意向锁IS锁: 共享意向锁, IX锁: 互斥意向锁\n什么时候会加上意向锁: 现在在加锁前, 我们会现在表级上加上一个意向锁, 比如我们要加上一个互斥X锁, 我们就会先在表上加一把IX, IS同理\n在有了意向锁以后, 我们就能通过判断表上有没有持有IS和IX锁来快速判断现在我们能不能加表锁\nIS, IX是表级锁, 它们的出现仅仅是为了在之后加表级锁的时候快速判断表中是不是存在加锁的记录, IS锁和IS锁之间是兼容的,  IX和IX之间是兼容的\n\n\n\n兼容性\nX\nIX\nS\nIS\n\n\n\nX\n不兼容\n不兼容\n不兼容\n不兼容\n\n\nIX\n不兼容\n兼容 兼容的\n不兼容\n兼容 兼容的\n\n\nS\n不兼容\n不兼容\n兼容 兼容的\n兼容 兼容的\n\n\nIS\n不兼容\n兼容 兼容的\n兼容 兼容的\n兼容 兼容的\n\n\nMDL锁Meta Data Lock: 元数据锁, 是针对DDL操作的锁, 防止在存在事务还在执行的时候变更表结构\n什么时候会加上MDL: \n\n对一张表CRUD的时候, 加上MDL读锁\n修改表结构的时候, 加上MDL写锁\n\nMDL写锁的获取会阻塞MDL读锁的获取, 也就是如果有一个事务在修改表结构获取MDL写锁的时候阻塞了, 后续的CRUD操作都会被阻塞住\nMDL在事务提交后才会释放\nAUTO-INC锁是用于处理AUTO_INCREAMENT自增字段的自增的锁, 如果并发地向一张表中插入记录, 就可能会导致自增字段值重复\n有两种锁来解决并发自增问题\n\nAUTO-INC锁: 在执行插入语句的时候, 会加上一个表级的AUTO_INC锁, 然后分配自增属性的值, 在插入语句执行结束后将锁释放掉, 以此将插入时生成自增值串行化\n轻量级锁: 在执行插入语句的时候, 获取这个轻量级锁, 在生成自增属性的值以后就将锁释放掉\n\n如果我们的插入语句在执行前就知道要插入多少条数据, 就会采用轻量级锁\n\nTIP：设计InnoDB的大佬提供了一个称之为innodb_autoinc_lock_mode的系统变量来控制到底使用上述两种方式中的哪种来为AUTO_INCREMENT修饰的列进行赋值，当innodb_autoinc_lock_mode值为0时，一律采用AUTO-INC锁；当innodb_autoinc_lock_mode值为2时，一律采用轻量级锁；当innodb_autoinc_lock_mode值为1时，两种方式混着来（也就是在插入记录数量确定时采用轻量级锁，不确定时使用AUTO-INC锁）。不过当innodb_autoinc_lock_mode值为2时，可能会造成不同事务中的插入语句为AUTO_INCREMENT修饰的列生成的值是交叉的，在有主从复制的场景中是不安全的。\n\n行锁行锁在MySQL中是InnoDB独有的更加细粒度的锁\n记录锁Record Lock: 记录锁, 有S锁和X锁之分, 是针对一条记录上加的锁, 也就是对某一行加上的锁\n什么时候加锁: 在执行锁定读的时候会对遍历到的行加上, 往往是以next-key lock的组成部分的形式被加上\n间隙锁Gap Loc: 间隙锁, 有S锁和X锁, 但是没有分别, 实际上是都是S锁的行为, 多个事务可同时获取一个间隙的Gap Lock, 是对一个开区间的锁, 用于解决可重复读隔离级别下的幻读现象的\n\n在id范围(3, 5)的间隙锁以后, 其他事务就无法再插入id &#x3D;4的记录了\n什么时候加锁: 和记录锁是一样的, 执行锁定读的时候会对遍历到的行加上, 往往是以next-key lock的组成部分的形式被加上\nNext-Key LockNext-Key Lock &#x3D; Record Lock + Gap Lock, 锁定一个范围, 并且锁定记录本身\n因为Next-Key Lock是包含Record Lock的, 所以是分X锁和S锁的\n插入意向锁是在insert前会对某个记录加上锁, 用于提高插入的并发效率, 只要插入位置不同, 想插入的事务间不会相互阻塞, 只有当多个事务尝试插入相同位置时才会产生冲突\n什么时候加锁: 在执行插入操作的时候需要判断这个位置上有没有间隙锁, 如果有, 插入操作就会被阻塞, 然后生成一个插入意向锁(is_wait &#x3D; true), 在这个间隙锁被释放掉以后, 插入意向锁就会被真正获取到, 执行插入操作\n有插入意向锁（当前机制）：\ncss复制索引：[1] [4] [7] [10]事务A：INSERT 5  → 在(4,7)设置插入意向锁事务B：INSERT 6  → 在(4,7)设置插入意向锁结果：两个事务可以并发执行 ✓\n\n没有插入意向锁（假设情况）：\ncss复制索引：[1] [4] [7] [10]事务A：INSERT 5  → 在(4,7)设置间隙锁事务B：INSERT 6  → 等待事务A释放间隙锁结果：事务B被阻塞，必须等待 ✗\n","categories":["Middleware","MySQL","Lock"]},{"title":"工作流-Chain Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/1.%20Workflow-ChainWorkflow/","content":"工作流-lian’shi\n参考\n\nhttps://www.anthropic.com/engineering/building-effective-agents\n\n\n流程说明对于链式工作流, 整体的呈现效果就是用户输入userInput以后, 这个userInput在输入以后会链式的向下执行, 在每个节点携带上一个节点的回答和使用当前节点的prompt来和LLM对话\n\n填充systemPrompts数组, 在这种情况下, Chain Workflow也被称作Prompts Chain工作流\n遍历每个prompt\n将上一轮的回答和现在的prompt组成一个新的input\n对话获取response\n\n\n输出最后的response\n\n\n代码\n代码\n\npublic String chain(String userInput) &#123;    String response = usertInput;        for (String promt : systemPrompts) &#123;        String input = String.format(&quot;&#123;%s&#125;\\n &#123;%s&#125;&quot;, prompt, response);        String response = chatClient.prompt(input).call().conmtent();                if(!check(response)) &#123;            return this.errorResponse;        &#125;    &#125;    return response;&#125;\n\n\n系统prompt示例\n\n// Step 1    &quot;&quot;&quot;    Extract only the numerical values and their associated metrics from the text.    Format each as&#x27;value: metric&#x27; on a new line.    Example format:    92: customer satisfaction    45%: revenue growth&quot;&quot;&quot;,// Step 2    &quot;&quot;&quot;    Convert all numerical values to percentages where possible.    If not a percentage or points, convert to decimal (e.g., 92 points -&gt; 92%).    Keep one number per line.    Example format:    92%: customer satisfaction    45%: revenue growth&quot;&quot;&quot;,// Step 3    &quot;&quot;&quot;    Sort all lines in descending order by numerical value.    Keep the format &#x27;value: metric&#x27; on each line.    Example:    92%: customer satisfaction    87%: employee satisfaction&quot;&quot;&quot;,// Step 4    &quot;&quot;&quot;    Format the sorted data as a markdown table with columns:    | Metric | Value |    |:--|--:|    | Customer Satisfaction | 92% | &quot;&quot;&quot;\n\n\n\n使用场景此工作流非常适合于任务可以轻松明晰地分解成多个固定子步骤的场景. 用延迟换取更高的准确性\n\n原文: \nWhen to use this workflow: This workflow is ideal for situations where the task can be easily and cleanly decomposed into fixed subtasks. The main goal is to trade off latency for higher accuracy, by making each LLM call an easier task.\n\n举例说明: \n\n撰写文章大纲, 检查大纲是否符合某些标准, 然后根据大纲完成文档\n从MCP中获取应用监控数据, 提取出来关键信息, 捕捉其中的异常, 推送给管理者\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Parallelization Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/3.%20Workflow-ParallelizationWorkflow/","content":"工作流-并行工作流流程说明\n用户输入input数组对应需要并行执行一系列任务, 适用于所有的任务的prompt, 以及线程池的数量\n将每个input并行化运行LLM\n等待所有的运行完毕后返回\n\n代码public List&lt;String&gt; parallel(String prompt, List&lt;String&gt; inputs, int nWorks) &#123;    ExecutorService executor = Executors.newFixedThreadPool(nWorkers);        try &#123;        List&lt;CompletableFuture&lt;String&gt;&gt; futures = input.stream()            .map(input -&gt; CompletableFuture.supplyAsync(() 0&gt; &#123;                try&#123;                    return chatClient.prompt(prmopt + &quot;\\nInput: &quot; + input).call().content();                &#125; catch (Exception e) &#123;                    throw new RuntimeException(&quot;Failed to process input: &quot; + input, e);                &#125;            &#125;, executor))            .collect(Collectors.toList());                // 等待所有的任务结束        CompletableFuture&lt;Void&gt; allFutures = CompletableFuture.allof(        \t\t\tfutures.toArray(CompletableFuture[]::new));        allFutures.join();                return futures.stream()            .map(CompletableFuture::join)            .collec(Collectors.toList());    &#125;&#125;\n\n适用场景当拆分后的子任务可以并行化以提高速度的时候, 或者需要多个视角或尝试来获取更高置信度的结果的时候. 涉及到多方面考量的复杂任务的时候, 每个考量都由单独的LLM调用处理, LLM的表现会更好\n\n原文:\nWhen to use this workflow: Parallelization is effective when the divided subtasks can be parallelized for speed, or when multiple perspectives or attempts are needed for higher confidence results. For complex tasks with multiple considerations, LLMs generally perform better when each consideration is handled by a separate LLM call, allowing focused attention on each specific aspect.\n\n\n投票场景, 多次运行相同的任务来获得不同的输出\n切分: 将并行化的任务交给不同的LLM来执行, 比如自动评估的时候, 或者防护机制, 一个LLM处理用户的查询, 另一个模型沙宣不适当的请求和内容\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Routing Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/2.%20Workflow-RoutingWorkflow/","content":"工作流-路由工作流流程说明用户输入userInput和可行的路由Map&lt;String, Object&gt; String是对这个路由的简介, Object就是实际的路由内容\n这里以角色分配, 将不同的任务分配给不同的promt角色的使用方式举例\n\n用户输入初始的userInput和Map&lt;String, String&gt;\n根据userInput和Map的keySet让LLM决策当前任务使用的prompt角色, 给出原因和选择, 使用结构化的输出到RoutingResponse中\n使用对应的prompt角色, 输出最后的结果\n\n\n代码\nroute方法\n\npublic String route(String userInput, Map&lt;String, Object&gt; routes, String mode) &#123;    RoutingResponse routingResponse = determineRoute(input, routes.keySet);        Object select = routes.get(routingResponse.getSelect());    \tswitch (mode) &#123;        case &quot;prompts&quot;:            // 选择不同的prompt解决这个问题            return chatClient.prompt((String) select + &quot;\\nInput: &quot; + userInput).call().content();        case &quot;modelChoose&quot;:            // 选择不同的client解决这个问题            return (chatClient) select.prompt(userInput).call().content();    &#125;&#125;\n\n\ndetermineRoute方法\n\nprivate String determineRoute(String input, Iterable&lt;String&gt; availableRoutes) &#123;\tString selectorPrompt = String.format(&quot;&quot;&quot;                Analyze the input and select the most appropriate support team from these options: %s                First explain your reasoning, then provide your selection in this JSON format:                \\\\&#123;                    &quot;reasoning&quot;: &quot;Brief explanation of why this ticket should be routed to a specific team.                                Consider key terms, user intent, and urgency level.&quot;,                    &quot;selection&quot;: &quot;The chosen team name&quot;                \\\\&#125;                Input: %s&quot;&quot;&quot;, availableRoutes, input);                                              RoutingResponse routingResponse = chatClient.prompt(selectorPrompt).call().entity(RoutingResponse.class);    return routingResponse.selection();&#125;\n\n适用场景适合处理存在不同的分类, 分别处理的复杂任务\n\n原文:\nWhen to use this workflow: Routing works well for complex tasks where there are distinct categories that are better handled separately, and where classification can be handled accurately, either by an LLM or a more traditional classification model&#x2F;algorithm.\n\n\n将简单&#x2F;常见问题路由到较小的模型（如 Claude 3.5 Haiku），将困难&#x2F;不寻常的问题路由到功能更强大的模型（如 Claude 3.5 Sonnet），以优化成本和速度。\n将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具中。\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Orchestrator-workers","url":"/2025/07/18/Project/AI%20Agentic%20System/4.%20Workflow-Orchestrator-workers/","content":"工作流-编排器-工人工作流流程说明这个工作流可以看作是ParallelizationWorkflow的自动分配任务版本\n中央LLM动态分解任务, 并将其委派给工作者LLM, 并综合结果\n\n用户输入任务描述input\n将用户的任务和编排器prompt输入给LLM用于划分任务\n将划分后的任务集合和工人prompt输入给LLM用于执行划分后的任务\n返回所有的执行结果\n\n代码\n执行代码, process\n\npublic FinalResponse process(String taskDescription) &#123;    // 获取编排器的编排结果    OrchestratorResponse orchestratorResponse = this.chatClient.prompt()        .user(u -&gt; u.text(this.orchestratorPrompt))        \t\t\t.param(&quot;task&quot;, taskDescription)        .call()        .entity(OrchestratorResponse.class);        // 执行每个任务    List&lt;String&gt; workerResponse = orchestratorResponse.tasks().stram().map(task -&gt; this.chatClient.prompt()     .user(u -&gt; u.text(this.workerPrompt)          .param(&quot;original_task&quot;, taskDescription)          .param(&quot;task_type&quot;, task.type())          .param(&quot;task_description&quot;, task.description())      ))      .call()      .content().toList();        return new FinalResponse(orchestratorResponse.analysis(), workerResponse);&#125;\n\n\n\n\norchestrator prompt\n\n&quot;&quot;&quot;Analyze this task and break it down into 2-3 distinct approaches:Task: &#123;task&#125;Return your response in this JSON format:\\\\&#123;&quot;analysis&quot;: &quot;Explain your understanding of the task and which variations would be valuable.Focus on how each approach serves different aspects of the task.&quot;,&quot;tasks&quot;: [\\\\&#123;&quot;type&quot;: &quot;formal&quot;,&quot;description&quot;: &quot;Write a precise, technical version that emphasizes specifications&quot;\\\\&#125;,\\\\&#123;&quot;type&quot;: &quot;conversational&quot;,&quot;description&quot;: &quot;Write an engaging, friendly version that connects with readers&quot;\\\\&#125;]\\\\&#125;&quot;&quot;\n\n\nworker\n\n&quot;&quot;&quot;Generate content based on:Task: &#123;original_task&#125;Style: &#123;task_type&#125;Guidelines: &#123;task_description&#125;&quot;&quot;&quot;\n\n适用场景非常适合无法预测所需子任务的复杂任务, 在拓扑结构上和并行化类似, 和并行化的关键区别是在于灵活性-子任务不需要预先定义, 而是由编排器根据具体的输入确定\n\n原文:\nWhen to use this workflow: This workflow is well-suited for complex tasks where you can’t predict the subtasks needed (in coding, for example, the number of files that need to be changed and the nature of the change in each file likely depend on the task). Whereas it’s topographically similar, the key difference from parallelization is its flexibility—subtasks aren’t pre-defined, but determined by the orchestrator based on the specific input.\n\n\n每次对多个文件进行复杂更改的编码产品\n搜索任务涉及从多个来源搜集和分析信息以获取可能相关的信息\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Evaluator-optimizer","url":"/2025/07/19/Project/AI%20Agentic%20System/5.%20%20Workflow-Evaluator-optimizer.md/","content":"工作流-评估优化器流程说明在评估-优化器中, 一个LLM调用生成响应, 另一个在循环中提供评估和反馈\n\n用户输入task\nLLM生成第一轮的回复\n对LLM的回复生成评估\n检查评估的结果是不是PASS, 如果是, 直接返回最终结果\n\n\n将所有的历史memory都添加到上下文中, 以及将回复评估添加到上下文中\n进行下一次循环\n\n代码\nloop\n\nprivate RefinedResponse loop(String task, String context, List&lt;String&gt; memory,                             List&lt;Generation&gt; chainOfThought) &#123;    Generation generation = generate(task, context);    memory.add(generation.response());    chainOfThought.add(generation);    EvaluationResponse evaluationResponse = evalute(generation.response(), task);    if (evaluationResponse.evaluation().equals(EvaluationResponse.Evaluation.PASS)) &#123;        // Solution is accepted!        return new RefinedResponse(generation.response(), chainOfThought);    &#125;    // Accumulated new context including the last and the previous attempts and    // feedbacks.    StringBuilder newContext = new StringBuilder();    newContext.append(&quot;Previous attempts:&quot;);    for (String m : memory) &#123;        newContext.append(&quot;\\n- &quot;).append(m);    &#125;    newContext.append(&quot;\\nFeedback: &quot;).append(evaluationResponse.feedback());    return loop(task, newContext.toString(), memory, chainOfThought);&#125;\n\n\ngenerate\n\nprivate Generation generate(String task, String context) &#123;    Generation generationResponse = chatClient.prompt()        .user(u -&gt; u.text(&quot;&#123;prompt&#125;\\n&#123;context&#125;\\nTask: &#123;task&#125;&quot;)              .param(&quot;prompt&quot;, this.generatorPrompt)              .param(&quot;context&quot;, context)              .param(&quot;task&quot;, task))        .call()        .entity(Generation.class);    System.out.println(String.format(&quot;\\n=== GENERATOR OUTPUT ===\\nTHOUGHTS: %s\\n\\nRESPONSE:\\n %s\\n&quot;,                                     generationResponse.thoughts(), generationResponse.response()));    return generationResponse;&#125;\n\n\nevalute\n\nprivate EvaluationResponse evalute(String content, String task) &#123;    EvaluationResponse evaluationResponse = chatClient.prompt()        .user(u -&gt; u.text(&quot;&#123;prompt&#125;\\nOriginal task: &#123;task&#125;\\nContent to evaluate: &#123;content&#125;&quot;)              .param(&quot;prompt&quot;, this.evaluatorPrompt)              .param(&quot;task&quot;, task)              .param(&quot;content&quot;, content))        .call()        .entity(EvaluationResponse.class);    System.out.println(String.format(&quot;\\n=== EVALUATOR OUTPUT ===\\nEVALUATION: %s\\n\\nFEEDBACK: %s\\n&quot;,                                     evaluationResponse.evaluation(), evaluationResponse.feedback()));    return evaluationResponse;&#125;\n\n\n\n\nGenerator prompt\n\n&quot;&quot;&quot;Your goal is to complete the task based on the input. If there are feedbackfrom your previous generations, you should reflect on them to improve your solution.CRITICAL: Your response must be a SINGLE LINE of valid JSON with NO LINE BREAKS except those explicitly escaped with \\\\n.Here is the exact format to follow, including all quotes and braces:&#123;&quot;thoughts&quot;:&quot;Brief description here&quot;,&quot;response&quot;:&quot;public class Example &#123;\\\\n    // Code here\\\\n&#125;&quot;&#125;Rules for the response field:1. ALL line breaks must use \\\\n2. ALL quotes must use \\\\&quot;3. ALL backslashes must be doubled: \\\\4. NO actual line breaks or formatting - everything on one line5. NO tabs or special characters6. Java code must be complete and properly escapedExample of properly formatted response:&#123;&quot;thoughts&quot;:&quot;Implementing counter&quot;,&quot;response&quot;:&quot;public class Counter &#123;\\\\n    private int count;\\\\n    public Counter() &#123;\\\\n        count = 0;\\\\n    &#125;\\\\n    public void increment() &#123;\\\\n        count++;\\\\n    &#125;\\\\n&#125;&quot;&#125;Follow this format EXACTLY - your response must be valid JSON on a single line.&quot;&quot;&quot;\n\n\nEvaluator prompt\n\n&quot;&quot;&quot;Evaluate this code implementation for correctness, time complexity, and best practices.Ensure the code have proper javadoc documentation.Respond with EXACTLY this JSON format on a single line:&#123;&quot;evaluation&quot;:&quot;PASS, NEEDS_IMPROVEMENT, or FAIL&quot;, &quot;feedback&quot;:&quot;Your feedback here&quot;&#125;The evaluation field must be one of: &quot;PASS&quot;, &quot;NEEDS_IMPROVEMENT&quot;, &quot;FAIL&quot;Use &quot;PASS&quot; only if all criteria are met with no improvements needed.&quot;&quot;&quot;\n\n适用场景在有清晰的评估标准, 并且迭代改进提供可衡量的价值. 良好契合的两个标志是\n\n当人类清晰地表达反馈时, LLM的答案可以得到显著的改进\nLLM能表达这种反馈\n\n\n原文:\nWhen to use this workflow: This workflow is particularly effective when we have clear evaluation criteria, and when iterative refinement provides measurable value. The two signs of good fit are, first, that LLM responses can be demonstrably improved when a human articulates their feedback; and second, that the LLM can provide such feedback. This is analogous to the iterative writing process a human writer might go through when producing a polished document.\n\n\n复杂的搜索任务需要多轮搜索和分析才能收集全面的信息, 评估人员是否需要进一步搜索\n生成代码的自优化\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"Spring AI 测试文件","url":"/2025/07/10/Spring/Spring%20AI/Spring%20AI-test/","content":"Spring AI 测试文件\n","categories":["Spring","Spring AI"],"tags":["Spring AI"]}]