[{"url":"/2025/07/08/Computer_Science/Algorithm/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/","content":""},{"url":"/2025/07/08/Computer_Science/Computer_network/Chapter4-Network-layer/","content":"网络层: 数据平面4.1 导论转发从合适的端口从哪个端口出\n\n是个局部的功能\n类比于旅行是决定了单个路口我该怎么走\n\n路由由算法决定分组从发送主机到目标接收主机的路径\n\n是个全局的功能\n规划了从源地点到目的地的整体的路径\n\n数据平面\n本地, 每个路由器的功能\n通过路由表得出输入端口到达的分组该如何转发到输出端口\n转发功能\n传统方法 : 基于目标的地址ip + 转发表实现\nSDN方式 : 基于多个字段 + 流表 &#x3D;&gt; 能对分组做出的行为是更多的, 转发, 泛洪, 阻塞, 修改某些字段等动作\n流表则由远程服务器实现, 通过SDN方式, 网络变得可编程了\n\n\n\n\n\n控制平面\n网络范围内的逻辑\n计算出来的路由表的是控制平面\n传统的控制平面, 路由器算法是在路由器内实现\nSDN方式(software-defined networking)\n\n\n\n\n\n传统方式下, 控制平面和数据平面紧耦合在一台设备上, 同时是分布式的, 每个路由器独立完成工作\n很难改动\n\n\nSDN方式 : 逻辑集中的控制平面, 通过远程控制器与本地的控制代理交互 (CAs), 给分组交换器计算出不同的流表, 再让路由器根据流表转发\n集中式且可编程\n\n\n\n\n网络服务模型对单个数据报的服务\n\n可靠传送\n延迟保证, 如少于40ms的延迟\n\n对数据报流的服务\n\n保序\n带宽的保证\n分组之间的延迟差\n\n所以一个网络服务我们可以通过一系列的指标衡量, 以区分出来不同的模型\n\n网络架构, 带宽, 丢失, 保序, 延迟, 拥塞的反馈\n什么都不提供的是 best effort 尽力而为的网络模型\n\n4.2 路由器组成4.3 IP: Internet Protocol数据报格式分片IPv4地址NAT: 网络地址转换IPv64.4 通用转发和SDN"},{"title":"Hello World","url":"/2025/07/08/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"url":"/2025/07/08/Computer_Science/Computer_network/Chapter2-Application-layer/","content":"应用层2.1 应用层原理C&#x2F;S 结构\n\n不对等的结构, S是核心\n\n随着用户的增加, 达到一定阈值后, 性能会有断崖式的下降\n\n\nP2P 结构 -&gt; 对等体\n\n关系是对等\n\n随着用户的增加, 性能会能够维持\n\n\n混合结构\n\n举例说明\n\n注册, 目录等是集中式的\n\n用户的之间的通信是对等的\n\n\n\n在对等体的某次通信中, peer可能是充当服务端, 也可能充当客户端\n\n分布式应用进程需要解决的问题\n\n问题一 : 进程标识 (用于标识你的是唯一的, 这样能保证不会发送错位置), 寻址 (别人该怎么找到你, 相当于找到你的住房的地图)\n问题二 : 应用层的下层传输层是怎么提供服务的, 从而使应用层之间可以传输信息\n问题三 : 怎么定义报文的形式, 接到报文后的行为 -&gt; 协议\n\n\n寻址一个应用进程的三个要素\n\nIP地址\nTCP还是UDP\nTCP或UDP的端口号\n\n\n需要传递的信息\n\n发的什么\n谁发的\n发给谁\n\n\n为了减少层间的信息传输数量, 我们引入了socket, 它在计算计上的物理体现就是一个整数\n\n对于TCP : 就会创建一个整数用于映射 (我的主机ip, 端口号, 对方的主机ip. 端口号) 这个四元组\n对于UDP : 就是一个(对方的IP, 进程端口号) 这个二元组\n这里的机制类似于C语言中传输大型的struct, 比起将整个struct传输进去, 我们更倾向于传输一个地址, 通过这个简短的地址, 我们就能找到那个大的变量\n接下来的收发, 我们都只用传递那个socket值\n\n\nTCP socket : 用于指明应用进程会话的本地显示\n\nUDP socket : 仅代表一个端节点, , 是无连接的, 发送的内容里就必须有对方的ip和端口号\n\n应用对于协议的选择的四个考量因素\n\n数据丢失率\n安全性\n吞吐\n延迟\n举例说明\n文件传输 -&gt; 数据不能有丢失, 对吞吐需求不大, 延迟同样, 安全性可能有要求\n交互式游戏 -&gt; 对延迟敏感, 容忍丢失, 吞吐量小\n直播 -&gt; 容忍丢失, 对吞吐量的要求高, 同时延迟不能超过0.1s\n实时电话 -&gt; 容忍丢失, 对吞吐量要求较高, 延迟要求同上\n\n\n\n\n\nTCP和UDP都是明文传输, 对于安全性没有任何的保证\n\n\n2.2 Web and HTTP : port &#x3D; 80URL\nUniform Resource locator 统一资源定位符\n\n格式 : Prot(协议名) : &#x2F;&#x2F;user:psw@www.someSchool.edu(主机名)&#x2F;someDept(路径名)&#x2F;pic.gitf:port(端口, 因为Web引用有默认的端口号, 一般端口号不需要指定)\n\n\nHTTP协议非持久化的HTTP连接\n非持久化的连接的通讯过程\n\nC -&gt; S 请求建立连接 (TCP)\n\nS -&gt; C 确认建立连接 (TCP)\n\nC -&gt; S 请求对象 (HTTP)\n\nS -&gt; C 返回对象 (HTTP)\n\nC -&gt; S  关闭连接 (TCP)\n\n\n\n\n\n响应时间模型\n往返时间RTT (round-trip-time) : 一个小的分组从客户端到服务器, 再从服务器返回客户端的时间, 因为分组很小, 传输时间可以忽略不计, 但需要记录传播时间\n故一次HTTP通讯, 需要耗费的时间为2 * RTT + 对象的传输时间\n第一个RTT 用来发起TCP连接, 第二个RTT 用来发起HTTP请求, 并等待HTTP响应\n\n\n\n持久化的HTTP连接\n通讯过程\n1. C -&gt; S 请求连接 (TCP)\n\n\nS -&gt; C 确认连接 (TCP)\n\nC -&gt; S 请求获取对象 (HTTP请求报文)\n\nS -&gt; C 发送对象 (HTTP相应报文)\n\nC -&gt; S 请求获取对象2….\n\n\n\n非流水线和流水线方式\n\n非流水线方式 -&gt; uqi, 流水线方式 -&gt; qi\nuqi方式\n是一个对象一个对象获取的, 其中是有阻塞关系的, 下一对象的获取请求需要等待上一个对象获取完毕以后, 才会发送\n举例 :C -&gt; S 请求获取对象AS -&gt; C 返回对象 AC -&gt; S 请求获取对象B\n\n\nqi方式\n分成两部分处理, 首先统一发送所有请求, 再一次接受所有的返回, 实现了并行的收发\n举例 :C -&gt; S 请求获取对象AC -&gt; S 请求获取对象B…S -&gt; C 返回对象AS -&gt; C 返回对象B\n\n\n\n\n\n请求报文\n请求报文示例 :\n\nGET(请求方法) ..URL路径.. HTTP/1.1(协议)Host: www.example.com\t// 请求的服务器域名User-Agent: Mozilla/5.0\t// 客户端信息Accpet: text/html,application/json // 客户端能接受的内容类型Connetion: close\t\t// 连接是否建立一次通讯后就关闭Accept-Language: zh-CN\t// 接受的语言偏好Content-Type: application/json // 传输的内容的类型Content-Length: 128\t\t// 接下来的信息中属于该次请求的内容的长度...&lt;Entity-data&gt; // 请求携带的表单 \n\n\n对于Content-Type的解释 : TCP协议是没有维护着边界数这个数据的, 所以需要更上层的协议或应用规定, 以此来区分在同一次的传输中的庞大内容中属于各自通讯的部分\n举例 : 我发送了两个HTTP请求, 各自的长度是15K, 则在TCP中, 一次性传输了30K的数据, 现在我们就需要这个Length划分边界, 以说明这部分内容是属于哪个请求的\n\n\n提交请求相关的数据的方式 :\nURL方式 : 在URL中写出 (RESTFUL), 例如 : tb.com?username&#x3D;…&amp;password&#x3D;…\n表单方式 : 即提交请求中包含请求体, 常见的有json形式的表单\n\n\n1.1新增的请求方法 : PUT (用于新增数据), DELETE (用于删除数据)\n\n响应报文\n响应报文示例 :HTTP/1.1 200 OK Connection: close\t// 控制连接状态, close表示服务器处理完请求后关闭连接, \t\t\t\t\t// 另一个值是 keep-aliveDate:  Wed, 21 Oct 2024 07:28:00 GMT // 服务器发送响应Server: \t// 服务端的信息Last-Modified:\tWed, 21 Oct 2024 07:28:00 GMT // 用于更新缓存使用, 在接下来的缓存部分会详细说明, 这里显示的是资源最后修改的时间Contenet-Length: \t// 作用与请求报文中的一致Content-Type: \t// 响应报文的类型\n\ncookies\n有状态和无状态\nHTTP是无状态的协议, 服务器不会维护与客户端的通讯历史, 即每一次的交换报文, 都是一次全新的通讯\n带来的问题是, 在像电商平台这种网站上, 我们是有需要维护的状态的, 比如用户信息\n\n\n\n\nCookie就像网站临时给的身份证, 帮助网站记住你是谁, 记住你的偏好设置, 一般会保存在浏览器的某个文件夹下\n\n执行逻辑\n\n第一次访问网站的时候, 请求是不会携带cookie的\n服务器响应的返回中会携带Set-Cookie响应头\n之后的请求中, 都会携带Cookie请求头 (来源于之前获得到的Cookie)\n\n\n举例说明 : (常用但典型的用户信息就不用说明了, 主要说明购物车场景) \n\n用户添加第一个商品到购物车的时候 , 请求 : POST &#x2F; cart&#x2F;add\n服务器返回 : Set-Cookie: cart_id&#x3D;123456\n后续添加商品, 请求自动带上: Cookie: cart_id&#x3D;123456\n\n\nCookie与隐私 : \n\n并不是所有的Cookie都是和上面介绍的一样, 是为了更便捷和传输更少的数据而服务的, 有相当一部分会采集用户的行为数据, Cookie可以算是存放浏览隐私数据的容器\n一般来说, Cookie是不会被跨站使用的\n\n\n\nWeb缓存\n优点 : \n\n能降低返回的时间\n减小服务器的负载\n\n\nWeb缓存的两种方式\n\n本地缓存 : 这个本质上应该算是加载静态资源, 并且保存在本地, 这样就能将以一些常用的数据, 比如Logo保存在本地, 而不是每次访问网站都需要重新获取\n\nproxy代理服务器方式 : \n\n这种缓存方式更为复杂, 它的核心理念是 “二八定律” ,即80%的人访问了20%的内容, 所以我们可以设置一个服务器, 专门用于承载那个20%被经常访问的数据, 这样, 就不用所有的数据都需要走源服务器并且, 这样即使我们不用提高服务器的带宽, 同样能大幅提高响应速度\n\n举例说明 : 以搜索引擎为例, 原本我们收到所有的数据, 执行的逻辑都是发往源服务器, 再执行搜索, 但是这样会导致导向源服务器的数据量需要随着访问的增加, 一直线性地增加, 这样对于带宽的需求变得极大. \n  解决方案 : 将设置proxy服务器, 用于做中间的代理, 其中直接存储了那20%的数据, 则访问者的数据如果 “hit” 中了这20%, 则会走浏览器 -&gt; 代理服务器, 而不会加重源服务器的负担\n\n\n\n缓存与Last-Modified以及If-Modified-since字段之间的关系\n\n本地缓存 : 更加直接, 如果请求头中的If-Modified-since字段和Last-Modified字段的中的时间戳不同, 则会更新本地的数据, 不同时候, 这个请求会返回200, 而在相同的时候则会返回304 Not Modified\n\nproxy代理缓存 : 会变成如图所示的访问路线\nC  -&gt;  proxy  -&gt;  S |       |      | |-请求-&gt; |      | |       |-验证请求-&gt;| |       |&lt;-304响应-| |&lt;-304响应-|      |\n\n那两个首部行的内容都是timestamp -&gt; 时间\n\n\n\n\n\n\n2.3 FTP : port 21, RFC 959\n用于早期的文件共享, 但因为是明文的传输, 后面应该是被替代了的\n\n以TCP作为传输协议\n\n\n通讯流程\n建立TCP连接 : 21端口 -&gt; 控制连接\n身份认证 (用户名, 密码, …)\nC端向客户端发送控制指令查看文件list\n接收到要下载文件的指令, 服务器打开另一个到客户端的20端口的连接, 用于数据传输\n一个文件传输完毕以后, 关闭数据连接\n\n特性\n是带外  ( out of band ) 传送\nFTP协议是有状态的, FTP服务器需要维护用户的状态信息, 当前路径, 用户账户与控制连接对应\n\n命令与响应 : (响应不赘述, 有需要时自行查找)\nUSER username\nPASS password\nLIST 请服务器返回远程主机当前目录的文件列表\nRETR filename 从远程主机当前下载文件\nSTOR filename 向远程主机上传文件\n\n2.4 SMTP : port 25Email的组成\n用户代理 : \n一般是用户的C端, 比如, Gmail就是我和谷歌邮箱服务器之间的用户代理, 使得通讯的过程可以被隐藏而变成面向最终用户的操作端\n\n\n邮件服务器 : 用于收发邮件\n简单的邮件传输协议 : SMTP\n邮件访问协议 : POP3, IMAP, HTTP\n\n邮件的收发的过程举例说明 (A 要向 B发送邮件)\n发送邮件(SMTP) : A 通过用户代理 -&gt; 邮件服务器a\n\n发送邮件(SMTP) : A发送的邮件被邮件服务器a -&gt; 邮件服务器b\n\n接受邮件(POP3…) : B 通过用户代理从服务器b拉取邮件A\n\n\nSMTP协议特性 :\nmessage全部内容都必须是7位的ASCII码, 不遵从这个规定是无法传输的\n是持久连接, 并不是发送了一个邮件就会关闭, 一个TCP连接可以发送多个邮件\n报文内容用CRLF做结尾符\n一次传输的报文里, 是可以有多个对象的, 比如, 我这封邮件里有正文, 还有我的附件, 都会一同传输\n\n文本报文 :\nRFC 822 : 文本报文标准\n\n首部行 : \n\nTo : 收件人\nFrom : 发件人\nSubject :\n\n\n现在就有问题是, 如何只通过ASCII码传输所有内容, 比如有中文, 很容易会出现在ASCII码编码内容之外的内容\n\n解决方法 : 做映射编码, 常见的方式有Base64编码模式\n\n\n\n邮件访问协议我们发送了邮件以后, 另一个人还需要收到和查看邮件, 这个时候就需要用到邮件访问协议\n\n常用的协议 : 均为明文协议\n\nPOP3 : 较简陋的协议, 仅支持本地管理文件夹\n\nIMAP : 对比POP3更复杂, 是有状态的协议, 支持远程管理文件夹\n\nHTTP : 易用\n\n\n\n\nPOP3协议无状态\n通讯过程 : \n1. 用户确认阶段\n- 用户名\n- 密码\n2. 服务器响应\n- +OK\n- -ERR\n3. 事务处理阶段 (拉取邮件的阶段)\n- 客户端 -&gt; 服务器\n- list -&gt; 获取报文号列表\n- retr 报文号 -&gt; 拉取对应报文号的报文\n- dele 报文号 -&gt; 删除对应的报文\n- quit -&gt; 关闭连接\n\n下载并删除与下载并保留\n下载并删除 -&gt;  将邮件下载到客户端以后, 会将服务器上的邮件dele\n能减小服务器的负载\n如果改变了客户机, 就不能阅读邮件了\n\n\n下载并保留 -&gt; 留在云端, 即使下载到本地后, 也不会删除\nPOP3的默认模式是下载并删除, 但是也可以通过设置DELE标志为false, 使得下载并保留\n\nIMAP有状态(会话状态, 邮件的状态和标记, 目录的访问权限)的协议, IMAP服务器会将每个报文和一个文件夹关联起来, 这样就能构建一个远程的文件系统\n, 并通过这个远程的文件系统, 远程的管理邮件\n\n允许用户通过目录组织访问\n允许用户之拉去报文的组件 (只拉取报文的一部分, 比如我只获取这个封邮件中的附件)\n在会话过程中始终保持用户状态, 会维护持续的会话状态, 而POP3每一次的连接都是新会话\n用户名, 邮件ID和目录之间映射\n\n\n\n2.5 DNS提供域名, 并做域名到IP地址之间的转换\n\n如何命名设备\n\n平面化会有重名\n分层式的命名\n\n\n如何做转换\n\n不可能由一台设备集中式解决, 不可行\n分布式的解析\n\n\n对域名的管理, 对域名的维护问题\n\n对域名的增删\n\n\nDNS\n\n除了能提供域名到IP地址的转换, 还有别名到规范名字的转换\n能做到负载均衡\n\n\n问题一 : 层次化树状的结构的命名方法\n\nInternet根被划分为几百个顶级域\n\n通用的(generic)\n.com; .edu; .gov; .int; .mil; .net …. \n\n国家的(countries)\n.cn; .us; .nl; .jp\n\n\n\n根据这种划分方法, 最末端的树叶就是一台主机, 而每条树枝都是一个子域\n\n有13个根名字服务器\n\n域名是从树叶往上走, 用逗点间隔\n\n域的划分是逻辑的, 不是物理的\n\n\n\n分布式解决\n\n一个名字服务器的问题 \n\n可靠性 : 单点故障\n\n拓展性 : 通信容量\n\n维护问题 : 远程维护集中的服务区\n\n\n\n将命名空间划分为若干区域zone\n\n权威\n\nTLD服务器 : 顶级域服务器 : 负责顶级域名和所有国家级的域名\n\n区域名字服务器维护资源记录\n\nDomain_name : 域名\nttl : time to live  生存时间\n可以是长期的 -&gt; 权威记录, 长时间保持不变的记录\n也可以短期的 -&gt; 缓存记录, 缓存下来某个域名和ip之间的对应关系, 缓存 -&gt; 性能, 删除 -&gt; 一致性, 这个对应关系是可能会发生变化的\n\n\nClass : 类别, 互联网中所有都是IN (internet)\nValue : ip地址\nType : \n现在还需要关注提供的服务还有, 机器别名到正规名字的转换, 邮件服务器别名到正规名字的准换 , 域名到IP之间的转换, 下面的子域是怎么划分的\nDNS的资源记录(RR)\nRR的格式 : (name, value, type, ttl)\nType &#x3D; A : Name -&gt; 主机的名字, Value -&gt; IP地址\nType &#x3D; NS  : Name -&gt; 域名, Value -&gt; 域名对应的权威服务器的域名\n用于供上层域找到下层域, 那么就携带两组信息\n子域的命名, 权威服务器的命名\n权威服务器的IP\n\n\n\n\nType &#x3D; CNAME : Name为规范名字的别名, Value为规范名字\nType &#x3D; MX : Value为name对应的邮件服务器的名字\n\n\n\n\n\n\nDNS (Domain Name System) 工作流程\n\n应用 -&gt; 解析器 (resolver)\n\n解析器作为客户 -&gt; Name Server发出查询报文(UDP)\n\nName Server返回响应报文 (name&#x2F;ip)\n\n\n\n递归查询, 从叶向根逐步走\n\n迭代查询\n\nDNS 请求和响应\n\n其中的id用于统一查询和应答\n\n\n维护 -&gt; 新增一个域\n\n简单来说, 就是上层服务器维护一个指针(资源记录的一个组合)\n\n举例, 我现在要新增一个uptopic.com的域名\n\n到注册登记机构注册域名uptopic.com\n\n向该机构提供权威DNS服务器 (基本的, 辅助的) 的名字和IP地址\n\n登记机构在com  TLD服务器插入两条RR记录\n(uptopic.com, dns1.uptopic.com, NS)(dns1.uptopic.com, 212.212.212.1, A)\n\n\n\n在权威服务器中保有\n\n用于web的类型为A的记录\n用于邮件服务器的类型为MX的记录\n\n\n\n\nDNS泄露\n\n\n2. 6 纯P2P架构\n非结构化P2P\n\n将peer视作一个节点, peer和peer之间的会话视作一条边, 那么非结构化的P2P, 则以刚刚的方法构建出来的图是没有任何结构的, 是一个松散的, 随机的图\n\n\nDHT结构化的P2P\n\n采用刚刚的构建方式, 最后构建的图, 形成了树, 环等结构\n\n\nP2P: 集中式的目录\n\npeer节点上线后, 向目录服务器提供ip和自己拥有的资源的目录\npeer可以通过目录服务器检索和找到该去哪下文件\n\n\n完全分布式 :\n\n泛洪式查询 (flooding), 不断向邻居发起查询, 邻居也向它的邻居发送查询\noverlay覆盖式网络的维护\n上线 : 上线后, 通过客户端提供的在线的ip发出ping, 收到的节点返回response, 从而建立起了邻居关系\n下线 : 下线的时候, 向它的邻居发送请求说明自己下线, 邻居再随机获取一个节点作为节点以维持网络强度\n\n\n\n\n混合体 : 存在组长和组员\n\nP2P文件分发 : BitTorrent\n\n将一个文件和一组描述以及hash值关联\n描述用于索引, hash值用于唯一标识文件以定位文件\n\n\n和完全分布式类似, 上下线建立洪流的方式相同\n采用bit map的方式\n假设现在我有诺干个文件块每个256k, 为其建立散列表, 每个peer维护一个bit map, 具有的文件标识为1, 其余的为0\n现在加入了一个新的用户, 这个用户的bit map就全部为0, 这个时候, 开始会随机地向其他节点请求, 在获取四个块之后, 后续就只会请求稀缺的块, 来防止拥有稀缺快的用户下线后, 其他用户难以获取这些稀缺的块\n并且对于一个peer, 它的下载的优先级, 会按照它对这个洪流的贡献分配\n现在有80个人向A发起下载请求, A不可能全部都满足, 他在前两个周期, 会只去查看在之前为他提供了更大贡献的节点发起的请求, 第三个周期会随机获取队列中的节点, 提供一个振荡的机会\n\n\n\n\n结构化的P2P系统\n\n为每个内容计算哈希\n按照哈希值将文件进行排序, 并维持一定的结构(树, 图), 能够一定程度上提高查询的性能, 可以减少副本的数量的同时保障查询的性能\n\n\n\n2.7 CDN\n视频的码率压缩\n\n多媒体流化服务 : DASH\n\n将一段视频, 切分为一个一个块, 并将每一块并行处理成高码率, 中码率, 低码率等份\n给出告示文件, 用于说明某个块的信息 : 码率, URL..\n客户端会根据用户的能力和需求, 动态地变化块的码率\n\n\nCDN -&gt; 加速服务\n\n数量取胜 enter deep : 将CDN服务器深入到许多的接入网\n\n部署非常多的缓存加速节点服务器, 由租用节点的运营商决定将哪些内容缓存在CSN中, 然后用户发起请求的时候, 会做域名的重定向到最近的CDN服务器\n离用户近, 但由于数量多 -&gt; 管理困难\nAkamai\n\n\nbring home \n\n部署在少数关键位置, 如将服务器簇安装于POP附近 (离若干$1^{st}$ISP POP附近)\n利用租用线路将服务器簇连接起来\nLimelight\n\n\n\n\nCDN的流程\n\n应用提供方提前部署内容到CND节点\n\n用户从源服务器获取manifest文件(告示文件) -&gt; 用于指示播放流\n\n用户根据告示文件向提供的URL请求获取IP\n\nicp的权威服务器再返回CDN的权威服务器的域名到本地的DNS服务器, 供其重新解析\n\n重新解析后, 访问向CDN的权威服务器, 其再返回的根据它判断后, 返回一个离用户较近的IP地址\n\n用户从那个IP地址获取视频流\n\n\n\n\n2.8 TCP套接字编程\nTCP -&gt; 可靠的, 字节流的服务, 面向连接\n\nby the stream, 但是保证报文之间的界限\n\n\n运行流程\n\n服务器首先运行\n\n创建欢迎socket -&gt; 一个值\n\n和本地端口捆绑\n\n在欢迎socket上阻塞式等待接收用户的连接 accept()\n\n\n\n客户端主动和服务器建立连接\n\n创建本地客户端的套接字, 隐式捆绑到本地的port\n\n指定服务器进程的IP端口, 和服务器连接\n\n\n\n客户端连接到来的时候\n\n接受来自用户端的请求, 解除阻塞式的等待, 等待的一个新的socket (connection socket)\n\n\n连接API调用有效的时候, 连接的就建立起来了\n\n\n\n数据结构 sockaddr_in : IP地址和port绑定关系的数据结构\nstruct sockadrr_in &#123;    short sin_family; // 地址簇    u_short sin_port; // port    u_long sin_addr; // IP地址    char si n_zero[8]; // 别名&#125;\n\n数据结构 host_ent : 域名和IP地址相对应的数据结构\nstruct hostent &#123;    char *h_name; // 主机的域名    char ** h_aliases; // 主机的别名    int h_length; // 地址的长度    char **h_addr_list; // IP的列表    int h_addrtype; // &#125;\n\n运行流程\n2.9 UDP通信过程\n\n\n​\t\n"},{"title":"计算机网络传输层详解 - TCP与UDP协议原理","url":"/2025/07/08/Computer_Science/Computer_network/Chapter3-Transport-layer/","content":"传输层3.1 概述\n提供的服务是什么 -&gt; 进程到进程之间逻辑上的message的通信\n传输协议运行在端系统上\n发送方 : 将报文会分解为若干报文段, 分段传输给网络层\n接收方 : 将报文段重组为报文, 再提供给应用层\n\n\n传输层怎么将网络层提供的不可靠服务加强, 最后能完成可靠的信息传输\n复用和解复用\n传输层协议的对比 : UDP, TCP\n两个协议都提供了多路复用和解复用的服务\nTCP\n拥塞控制\n流量控制\n建立连接\n\n\nUDP\n没有额外的服务\n\n\n都不提供的服务为\n延迟保证\n带宽保证\n\n\n\n\n\n3.2 多路复用和解复用\n复用的信息是IP, 网络物理链路, 网络带宽等资源, 实现方式简单来说就是通过port来区分\n\n复用的实现 -&gt; socket封装信息与解封装\n\nTCP实现复用的流程\n\n复用\n建立的socket维护了一个六元组, (socket值, 标识连接的四元组(源IP, 源port, 对方IP, 对方port), PID)\n通过socket API发送message给目标主机的对应进程\nsocket API通过维护的六元组表, 查询到当前message应该如何封装, 以传递给下一层\n\n\n解复用\n传输到的目标服务器后\n目标服务器通过传递过来的信息中的四元组, 查询本地的socket映射表, 从而将对应的信息传递给该socket对应的PID\n\n\n这里复用了这个主机的IP, 以及其中的网络物理链路, 使得信息的传递能从端到端, 更细分为进程到进程\n解复用就是一个拆包对应port号再对应进程号的方式\n\n\nUDP实现复用\n\n复用\n和TCP一致, 就是socket标识连接的是二元组(目的IP, 目的端口)\n\n\n解复用\n和TCP一致\n\n\n\n\n两者之间的对比\n\nTCP协议中, 不同的四元组在服务器端查到的socket对应的PID是不同的, 故能精准地区分出来不同来源的报文, 并且会区别他们, 对应到不同的进程\n但是UDP协议中, 只会维护目的IP与port, 无法得知源服务器的IP与port, 無法區分來源, 可能會出現衝突\n\n\n\n3.3 无连接传输 UDP\n可能会有丢失和乱序\n对比IP到IP之间的直接通讯, 提升之处在于能实现进程到进程之间的通讯\n用户数据报协议 : UDP\nUDP报文段的头部 -&gt; 固定8个字节, 分成两个4字节的部分\n源端口号, 目的端口号 (源端口号用于回复)\n长度 校验和(用于校验UDP传输的信息在传输的过程中是否出错, 出错了直接丢失)\n\n\n\n\n校验和计算关系\n检测在被传输报文段中的差错 (如比特反转)\n发送方 : \n将报文段的内容视作16比特的整数\n校验和 : 报文段的加法和\n\n\n接收方\n重新计算校验和\n检查是否相等\n不相等 -&gt; 一定出错了\n相等 -&gt; 会有残存错误, 但是概率很小\n\n\n\n\n\n\n\n3.4 可靠数据传输Rdt2.0\n致命的错误 -&gt; ACK和NAK的信息本身也会出现发送错误\n\nRdt2.1\n引入了一个序号的机制, 对比原来的过程\n\n在R方给出回复以后, 如果不是ACK, S方都重新发送上次需要的内容, 假设是P0\n由于有了信号的标志, R方能检测到出现了重复 -&gt; R方意识到自己给的回复出错 -&gt; 重新回复, 同时把重复的信息丢掉, 防止重复发\n没有序号的时候, 如果采取这个策略 (一直发到有ACK为止), 会出现的问题是, R方会有重复的信息, 因为R方是无状态的, 现在相当一个有状态的通信, 维护了已经成功接受到的信息, 但是给出的回复是错误的情况, 实际维护的内容是发过来的分组信息的序号\n\n\nRdt2.1还是2.0都是 “stop and wait协议”, 发送后停止, 等待接收方返回确认信息, 这种协议下, 我们为分组标号, 只用0和1即可\n\n具体的序号机制, 序号位是一位, 从发送方的角度出发, 会一直发送同样的序号的信息直到接收到ACK, 接收到以后变换序号位\n从接收方的角度 : 如果接收和当前等待的信号位相同的数据包, 则认定为新的消息, 反之为旧的消息\n\n\nACK和NAK作为控制信息, 本身也需要校验和等机制保证可靠\n\n\nRdt2.2\n引入的新机制是NAK free, 以便后续实现流水线的收发\n是一种 “言它策略”, 不再用NAK标识错误, 而是为ACK标号, 给出错误的ACK标号, 则代表错误\n例如, 接收方给的返回本该是的ACK1, 但是给的返回是上一个返回 : ACK0 -&gt; 说明出错了\n当前分组的反向确认, 用前一个分组的正向确认代替\n\n\n\nRdt3.0\n同时有比特反转和分组丢失的问题\n\n解决丢失 : 超时机制, 比如我现在向接收方传递p1, 如果出现了丢失现象 -&gt; 出现死锁\n\n解决方案 :  超时重传 -&gt; 一般时间是一个正常的来回多一点的时间, 无论是数据包丢失还是返回的控制信息丢失, 都采取超时重传, 因为现在重复不是问题\n\n\n超时时间的设置如果不合理 -&gt; 重复收发的问题 -&gt; 效率会降低为原来的50%, 甚至更低, 因为在这次数据包到达并返回控制信息之前, 因为超时时间设置过短, 就重新触发了超时的机制, 会让一个数据包重复收发两次\n\n出现的问题 -&gt; 效率问题 -&gt; 在信道比较长的时候, 一个信道能接受非常多的分组, 如果還是 “stop and wait” , 信道的利用率極低\n\n\n流水线协议 : GBN, SR滑动窗口协议 (slide window)\nsw &#x3D; 1, rw &#x3D; 1 -&gt; stop and wait协议\n\nsw &gt; 1, rw &#x3D; 1 -&gt; GBN\n\nsw &gt; 1, rw &gt; 1 -&gt; SR 选择性重发协议\n\n发送缓冲区 -&gt; 存放那些已经发送但是没有得到确认的分组, 用于检测重发和超时重发, 可发准备发但是未发的也会存储\n\n发送窗口, 发送缓冲区的一个子集, 发送缓冲区的大小是根据物理条件设置的, 而发送窗口是实际的队列, 像是容量和length的区别\n\n每发送一个分组, 前沿向前移动一个单位\n每收到一个分组的确认信息, 后沿向前滑动一个单位\n\n\n给出了意外的返回, 比如现在的发送窗口是从0 ~ 3的, 这个时候接受到了分组4的信息, 这个时候做出的动作\n\n抛弃掉这个乱序分组\n计算出現在的已经给出返回的分组的最高的编号, 比如現在滑动窗口后沿是2, 前沿是3, 那么這個時候, 接受方會給出返回ACK1的確認\n\n\n接收窗口 &#x3D; 接收缓冲区\n\nRW &#x3D; 1的时候 -&gt; 只能顺序接收 &#x3D;&#x3D; 只有0号分组可以接收, 只能从0 ~ n以此接收 &#x3D;&#x3D; GBN\nRW &gt; 1 &#x3D;&gt; 可以乱序接收\nRW &gt; 1的时候, 会有一个和发送窗口一样的接收窗口, 里面放了等待的分组, 哪个分组到来就返回ACK几, 不过, 只有序号在最左边的分组接收了, 窗口的后沿才会向前滑动至没有接收到的分组的位置\n低序号到来的时候, 接收窗口移动\n高序号到来的时候, 缓存但不交付 (不允许失序), 不滑动 \n滑动意味着数据的交付, 交付给上一层\n\n\n\n\n正常情况下, 两个窗口之间的互动\n\n用户的分组发送 -&gt; 发送窗口的前沿向前滑动 -&gt; 接收窗口向前滑动 -&gt; 返回控制信息 -&gt; 发送窗口的后沿向前滑动 -&gt; 新的分组落入发送窗口 -&gt; 循环往返\n\n\n异常情况下的窗口互动\n\n问题 : 发送方的传递的分组在传输的过程中丢失或出错, 接收方的返回出错\n均导致的问题 -&gt; 乱序的发送\nGBN和SR的运行机制, 都会保证最后到达的分组是正确\n但是存在区别, 举例说明 : 成功发送0, 1号分组, 现在我们不断连续发送了2,3,4分组(乱序)\nGBN : 接收端会返回ACK2, 然后3分组和4分组就会被丢弃掉, 而发送方只维护着一个超时计时器, 分组3和分组4没有接收到, 超时后, 会重发断点后的所有分组, 也就是go back 到2的位置, 重发接下来的分组3和分组4\n一旦一个分组发送失败了, 接下来要返回发送失败的分组, 重头再发\n\n\nSR : 发送方只需要单独发送超时的分组, 选择性地发送, 不需要返回这个操作, 只需要将发送失败的分组重新发送, 每个分组单独的维护着一个定时器\nGBN : Go back N ; SR : Selective Repeat\n定时器开始和关闭计时的时机 -&gt; 发送的时候开始, 成功接收的时候关闭\n\n\n\n\nGBN和SR的优缺对比\n\n\n\n\nGBN\nSR\n\n\n\n优点\n简单, 所需资源少 (接收方只需要维护一个缓存单元)\n出错时, 代价小\n\n\n缺点\n一旦出错, 回退N步的代价很大\n复杂, 所需要的资源多 (接收方需要创建多个缓存单元)\n\n\n\n使用的范围\n出错率低 : 比较适合GBN, 出错非常罕见, 没有必要用SR\n链路容量大(延迟大, 带宽大) : 比较适合SR而不时GBN, 出错的代价太大了\n\n\n\n\n发送窗口的最大值, 序号空间为$2^n$\n\nSR : $2^{n-1}$\nGBN : $2^n -1$\n用于区分新的数据包和旧的数据包, 这里我们需要引入接收方 “期待” 的数据序号的问题\n举例说明, 现在的序号空间是4, 发送了0, 1, 2, 3向接收方\nGBN : 假设现在的发送空间的大小是4\n全部接收成功的时候, 返回ACK3, 这个时候接收方控制信息回传丢失, 发送方超时重传四个分组\n这个时候, 接收方并不知道这四个分组是新一轮的分组, 还是上一轮重传的分组\n\n\nGBN : 假设现在的发送空间是3\n全部接收成功以后, 返回ACK2\n接下来有两种情况\n发送方成功接收到了ACK2, 那么发送窗口滑动到[3, 0, 1]并发送, 也就是接收方获取到的分组是[3, 0, 1]\n发送方没有接收到ACK2, 那么Go back, 然后超时重传这三个分组[0, 1, 2], 这个时候接收方接收到的分组是[0, 1, 2]\n两种情况下的接收是不一样的, 接收方以此能够分辨出来接收到的分组是超时重传的还是新的一轮的分组\n\n\n\n\nSR : 假设序号是3位的\n发送空间为5的时候, 发送方发送了[0,1,2,3,4]\n发送方成功接收到返回的ACK0 ~ 4, 这个时候, 发送窗口滑动到了[5,6,7,0,1]\n发送方没有接收到其中的ACK0, ACK1, 这个时候, 发送窗口不动[0,1,2,3,4], 超时重传[0,1]\n我们可以发现这两种情况下, 我们会有0,1是重复的, 并且由于SR的乱序确认的, 所以它无法判断传回来的0, 1是超时重传的上一轮次的分组还是新的一轮的分组\n\n\n\n\n\n\n\n\n\n3.5 面向连接协议 : TCP\n点到点之间的服务\n一个进程到一个进程之间的服务\n\n\n需要上层应用自己维护报文之间的界限\nTCP会根据MSS, 将原本的报文切分为一段一段的字节流, 并不维护原本的报文的界限问题\nMSS : 最大报文段大小\n\n\n管道化\n拥塞控制, 流量控制\n\n\n发送和接收的缓存\n因为发送方和接收方的能力是可能是不一样的\n\n\n全双工数据\n同一连接中数据是双向流通的\n\n\n面向连接\n\nTCP报文段的结构\n\n序号 : 在TCP按照MSS为一份的大小将报文切分为一段一段的字节流以后, 这个就是TCP报文段的载荷部分(body), 而body部分, 也就是承载的内容的第一个字节在原报文中的偏移量, 就是需要\n这里我们会规定序号的起始, 并不是总是以0为开始\n举例说明 : 现在我们有一个128字节的报文段, MSS&#x3D;2, 那么原报文就被切分为64段小的字节流, 我们规定起始的序号是X, 那么第0段TCP报文段的序号就是X, 第1段TCP报文段的序号就是X+1*MSS\n\n\n确认号 : 假设这里的数字是551, 说明接受方收到550及以前的所有字节, 需要ACK位置1, 才是有效的\n首部长度, 保留未用\n\n往返延迟(RTT)和超时定时\n超时定时的时间是动态变化的, 根据短时间的情况, 计算出来合适的超时定时\n\nSampleRTT : 发送方维护一个定时器, 在发送一个报文的时候开始计时, 接收到返回的时候停止计时, TCP是流水线协议, 但是同时只会有一个分组的在被定时器计时, 其他的分组的用时情况不会被关注\n\n暴力平均所有的SampleRTT获得到的RTT无法很好的反应当前的网络状况, 故我们采用移动平均值\n\nEstimatedRTT &#x3D; (1 - a)*EstimatedRTT + a*SampleRTT\n\n过去的样本对平均值的贡献为${(1-\\alpha)}^n$ &#x3D;&gt; 呈指数下降\n\n推荐的$\\alpha$的为0.125\n\n指数加权移动平均\n\n设置超时时间除了考虑平均值还需要考虑分散程度(方差),因为我们想尽可能多的包含情况 \n\n$DevRTT &#x3D; (1-\\beta)DevRTT + \\beta\\left\\vert {SampleRTT - EstimatedRTT} \\right\\vert$\n$\\beta$推荐为0.25\n\n\n最终的超时时间设置为EstimatedRTT + 4*DevRTT\n\n\n可靠数据传输\n累计确认 (GBN) , 并且表示的自己的期待\n\n单个重传定时器 (GBN)\n\n是否可以接收乱序是未被规定的事件\n\n触发重传\n\n超时\n快速重传 &#x3D;&gt; 接收到了三个冗余的 确认\n\n\n\nTCP 简化版\n忽略流量控制和拥塞控制\n\n发送方的流程\n\n初始化Seq信号的初始值 &#x3D;&gt; NextSegNum , Sendbase\n接收到了上层传输过来的数据, 创建segment(段)和seg, 这里的seg是下一个要传输的字节段的起始位置\n传递segment给下一层IP\nNextSegNum &#x3D; NextSegNum + length(data) &#x3D;&gt; 类似于发送窗口的前沿向前滑动\nbase ~ next : 发送方已发送但未被确认的字节\n\n\n如果没有计时器开始计时, 开启计时器\n如果超时, 重传base对应的segment, 不会将所有未被确认的都重传一遍, 然后重新计时\nACK recieved, with ACK field value y\nif (BaseSeg &lt; y) &#x3D;&gt; 说明这个时候后沿在现在已经被确认收到的信息之前 &#x3D;&gt; 移动后沿 BaseSeg &#x3D; y\n如果移动后沿以后, 前后沿没有相遇, 重新启动定时器, 因为说明還有已发送但是未被确认的字节\n\n\n\nTCP ACK的建议\n四种情况, 这里需要引入的一个机制是ACK的延迟, 用于减少对发送方的回复, 以减少对发送方的干扰, 这里设定最大等待时间是500ms\n\n第一种情况\n\n事件 : 所期望序号的报文段按序到来, 所期望序号的之前的报文段都被确认\n动作 : 延迟ACK, 接受到一个ACk以后, 等待500ms, 如果这个时间段内第二个TCPseg没有到, 则发送一个ACK\n\n\n第二种情况\n\n事件 : 所期望序号的报文段按序到来, 第二个报文段也到来了\n动作 : 对第一种情况的正向的情况的补充, 即在500ms內, 第二个报文段成功接收到了, 发送ACK\n\n\n第三种情况\n\n事件 : 比期望报文序号更大的报文发送过来了, 即乱序到达, 检测出数据流中的间隔\n动作 : 发送断点位置的ACK, 指明現在期望收到這個斷點位置的TCP段\n\n\n第四种情况\n\n事件 : 能部分填补或完全填补接收数据间隔的报文段到达\n\n动作 : 若這個報文段填補的是gap的低端, 則發送累計後的ACK\n\n\n\n\n\n\n流量控制\n方式 -&gt; 传输的数据中包括缓冲区的剩余大小, 额外的传输成本太高了\npiggybacking &#x3D;&gt; 捎带技术, 在传输的信息中带上缓冲区的大小\n在发送方的TCP段头部的rwnd字段(就是头部的接收窗口)告诉空闲buff的大小\n\n\n\n连接管理三次握手的内容\n前两次握手 &#x3D;&gt; 同意建立连接, 每一方都知道对方愿意建立连接, 为连接准备资源: 缓冲区\n\n第三次握手 &#x3D;&gt; 同意连接参数 : 初始seg的序号\n\n两次握手的失败场景一 : 半连接\n\n请求连接的TCPseg发送到服务器以后, 服务器的确认连接超时回复\n发起端重新发送对连接的请求, 这样服务器端单向维护连接, 同时应对新的连接请求, 建立一个新的连接, 并为连接准备资源, 这些虚假的半连接消耗了很多资源\n\n\n两次握手失败场景二 : 旧数据被当成新数据接受了\n\n客户端发起连接请求但超过定时器设置\n客户端放弃了原先的连接, 发送了新的连接请求\n新的连接完成\n传递data1, 发送超时后以后, 重传data1\n正常通信一段时间以后连接关闭\n\n\n延迟的连接请求和data1到达, 这个时候服务器收到旧的连接请求后会当成新的连接建立\n同时旧的data1也会被当成新的”旧”连接的新数据接收\n\n\n三次握手\n\n第一次 : 选择初始的序号, 发送TCP SYN报文 \nSeq &#x3D; x, SYNbit &#x3D; 1(这是头部的一个bit, 置1的时候说明这是连接建立请求报文)\n\n\n第二次 :  选择初始序号, y发送SYNACK报文, 确认SYN\nSYNbit &#x3D; 1, Seq &#x3D; y, ACKbit &#x3D; 1; ACKNUM&#x3D;x+1\n\n\n第三次 : 确认对方给出的序号, 一般第三次握手和第一次数据传递同时发生\nACKbit &#x3D; 1, ACKnum&#x3D;y+1\n\n\n\n\n\n三次握手是怎么解决二次握手带来的两个问题\n半连接 : 在第二次收到服务器对于延迟的第一次握手请求的回应的握手请求时, 会拒绝第三次握手, 从而拒绝建立连接\n详情 : 客户端现在同樣面對的延遲問題, 但是第一次發出握手請求的時候, 攜帶了第一個seq序列號ISN1(initialize sequence number), 這個請求觸發了超時重傳機制, 重新發起握手請求, 這個時候攜帶的是ISN2\n這個時候服務器在後續的時候回應延遲的握手請求, 返回的ACKnumber是ISN1+1, 而客戶端需要的是ISN2+1\n\n\n旧的数据被当成了新数据\n在三次握手的情况下, 旧数据到达的时候压根就没有建立连接\n\n\n一种诡异的情况 : 现在仍然是出现了数据data传输过程中延迟送达, 在传输的过程中, 连接关闭了, 紧接着, 又开始了新的一次连接, 并且双方使用的端口号等信息和上次一致, 这里就会有个问题, 新的连接会接收老的连接滞留的数据\n这个时候ISN是随机设置的必要性就体现出来了, 这个时候凭借序号空间之间的差异, 就能区分出来老的和新的连接\n但是会极小概率出现连序号空间都是相同的情况, 将ISN和时钟的相关, 取时钟的前32bit作为ISN\n\n\n\n连接的拆除\n对称释放, 并不完美\n\n一端向另一端发送关闭连接的请求, 然后接收到对方给的确认, 然后单边关闭连接, 双边对称进行\n\n关闭请求 : FINbit &#x3D; 1, seq &#x3D; x\n\n确认返回 : ACKbit &#x3D; 1; ACKnum &#x3D; x+1\n\n\n\n经历了对称的释放后, 主动方最后再开启计时器, 如果经历了2*max  segment lifetime(TCP报文在网络中的最大生存时间) , 再无信息传递, 关闭连接, 以有时间处理最后可能的重传, 并且等待时间会清空可能会干扰到下一段连接的报文\n\n\n3.6 拥塞控制原理拥塞的原因和代价 : 场景1\n条件\n\n两个发送端和两个接收端\n\n一个路由器具备无限的缓冲空间 -&gt; 不会有分组丢失\n\n输出链路带宽 : R\n\n没有重传\n\n\n\n假设输入为$\\lambda^{in}$k, 它的值到R&#x2F;2的时候, 连接的吞吐量到达极限, 但是这个时候的流量强度为1, 排队延迟爆增, 进入的速率越接近极限, 排队延迟增长得越快\n\n\n拥塞的原因和代价 : 场景2\n场景\n一个分组路由器, 有限的缓冲 &#x3D;&gt; 有丢失现象\n分组丢失的时候, 重传\n应用层的输入和输出是对等的\n传输层的输入包括了重传 &#x3D;&gt; $\\lambda^{‘’}{in} &gt; \\lambda{in}$\n\n\n发送端知道空闲缓冲区的大小\n随着越来越多的输入, 重传的分组在所有分组的比例越来越大, 随着拥塞程度的增加, 想要输出同样的数量的分组, 代价越来越大\n同时是一个正反馈调节, 随着重传分组的增加, 网路拥塞的速率加速用于, 是非线性增长\n\n\n\n拥塞的原因和代价 : 场景3\n网络拥塞以后, 当分组丢失的时候, 任何”关于这个分组的上游传输能力”都被浪费了\n\n拥塞控制\n网络辅助的拥塞控制 : 网络提供一些是否发送拥塞的显式的信息\n端到端拥塞控制 : 端系统自己判断是否发生拥塞\n\n网络辅助的拥塞控制\nATM ABR 拥塞控制\n传递信息用的是固定长度53byte的信元\n弹性服务\n如果没有发生拥塞的时候 &#x3D;&gt; 发送方可以使用带宽\n发生的时候 &#x3D;&gt; 降低到最低保障速度\n\n\nRM (资源管理) 信元中有对拥塞情况的标志位\nNIbit : 轻微拥塞 &#x3D;. 速率不要增加了\nCIbit : 拥塞了, 降低速率\n\n\nER字段\n每经过一个交换机, 根据能提供的速率设置ER的值, 并且ER &#x3D; min(ER, now)\n发送端因此是最低的可支持速率\n\n\n\n3.7 TCP拥塞控制\n使用端到端的拥塞控制 &#x3D;&gt;\n减少的路由器的负担\n符合网络核心简单的TCP&#x2F;IP架构\n\n\n\n如何检查拥塞\n发送的段超时 &lt;&#x3D; 由于分组被路由器抛出, 但也有误动作 &#x3D;&gt; 可能是收到了干扰, 然后TCP段发生错误, 然后没通过校验从而被抛出, 但是误动作发送的概率比常规情况小太多了\n收到了三个冗余的ACK\n\n控制策略\n速度控制方法 : rate &#x3D; CongWin &#x2F; RTT\nCongWin : 用来控制发送方在收到接收方确认之前能发送的最大的字节数\n超时或者收到了3个冗余的ACK, CongWin下降,\n超时的时候, CongWin降为1MSS, 进入到SS阶段在倍增到CongWin&#x2F;2 (每个RTT), 从而进入CA阶段\n3个重复 &#x3D;&gt; Config &#x3D; Config&#x2F;2, CA阶段\n\n\n否则, CongWin上升\nSS阶段 : 加倍增加(每个RTT)\nCA阶段 : 线性增加\n\n\n\n\n\n联合控制SendWin &#x3D; min{CongWin, RevWin} : 发送窗口的大小为接收窗口可用空间和拥塞窗口的最小值, 这样能同时兼顾流量控制和拥塞控制\n控制流程线性增加, 乘性减\n\n\n\n事件\n状态\nTCP 发送端行为\n解释\n\n\n\n没有被确认的分组收到了ACK\n慢启动 (SS)\nCongWin *&#x3D; 2, 如果这个时候拥塞窗口大于Threshold, 进入CA拥塞避免阶段\n每一个RTT, CongWin加倍\n\n\n没有被确认的分组收到了ACK\n拥塞避免 (CA)\n每一次报文ACK的时候CongWin +&#x3D; MSS*(MSS&#x2F;CongWin),\n每一个RTT, CongWin+1\n\n\n收到了三个重复的ACK, 说明出现了轻微的拥塞\nSS or CA\nThreshold &#x3D; CongWin&#x2F;2, CongWin &#x3D; Threshold + 3, 状态等于CA\n快速重传, 实现乘性的减, CongWin没有直接变为1\n\n\n超时\nSS or CA\nThreshold &#x3D; CongWin&#x2F;2, CongWin &#x3D; 1, 状态变为SS\n进入slow start阶段\n\n\n重复的ACK\nSS or CA\n对被ACK的segment增加重复ACK的技计数\n相当于对于是否出现轻微拥塞情况的等待判断, 期间不需要对Threshold或者CongWin进行变化\n\n\n\n\n使用CongWin +&#x3D; MSS*(MSS&#x2F;CongWin), 而不是在一次RTT结束的时候CongWin +&#x3D; MSS, 能保证不会出现在一次RTT结束后, 如果MSS, 数据量激增的情况, 而是平缓的将其分摊到了RTT过程中每一次ACK上\n\n在TCP拥塞的语境下, RTT的含义是收发完一次CongWin大小的数据, 所以在一次RTT中, 发送并收到了CongWin&#x2F;MSS数量的包\n\n\n\nTCP的吞吐量平均窗口尺寸 &#x3D;&gt; (3&#x2F;4)W\nTCP的公平性有多个主机共用带宽, 采用TCP通讯, 长期来看,  带宽的分配是公平的\n\n两个竞争的TCP会话\n\n加性增加, 斜率为1, 吞吐量增加\n乘性减, 吞吐量比例减少\n\n\n与之相对的, 能从中看出这是一种相对的公平\n\n是从TCP的数量出发的, 如果现在用两台主机竞争一个链路带宽为R的瓶颈, A主机发起了1个TCP会话, B主机发起了9个TCP的会话, 最后分配时, A获取的带宽是1&#x2F;10R, 而B是9&#x2F;10R\n从斜率出发, 如果另一个TCP会话的延迟更小, 在第一个TCP会话线性增加一次的时候, 另一个TCP会话已经线性增加了两次了, 这个时候, 斜率趋向于2\n\n\n并不是完全的平衡, 只是一种相对的平衡\n\n\n","categories":["计算机科学","计算机网络","传输层"],"tags":["传输层","TCP","UDP","可靠传输","流量控制","拥塞控制","多路复用","网络协议","八股文","面试"]},{"url":"/2025/07/08/Computer_Science/Computer_network/ssh/","content":"ssh"},{"title":"操作系统进程与线程基础 - 并发编程核心概念","url":"/2025/07/08/Computer_Science/Operating-System/4.1%20%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86-%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/","content":"进程线程基本知识进程\n对于这种多个程序, 交替运行的想法就是操作系统管理多进程的最初的想法\n对于一个支持多进程的操作系统, 它会在多个进程之间频繁切换, 每个进程执一段时间, 以此造成了多个程序并行执行的错觉但是实际上, 这些程序是并发执行的\n\n并行和并发的区别\n\n\n\n并发是一个处理器让多个任务交替运行, 同时执行多个任务, 是看似并行\n并行是多个处理器分别处理多个任务, 是真正意义上的并行\n\n进程的状态操作系统会切换任务, 在多个任务之间交替运行, 是一种, 运行-暂停-运行的工作状态, 那么在我们这个处理器恢复运行进程的时候, 需要恢复这个进程的状态\n\n\n创建状态 : 进程在创建的时候的状态\n就绪状态 : 可运行的状态, 只是目前被阻塞了, 处理器正在处理其他的进程, 随时能重新运行当前进程\n运行状态 : 进程被调度以后, 就会由就绪状态进入到运行状态, 表示进程正在执行\n结束状态 : 进程运行结束以后, 进程正在从操作系统中消失的时候的状态\n阻塞状态 : 进程在等待某个外部事件的完成, 比如磁盘IO的时候, 会进入阻塞状态, 直到事件完成, 触发中断, 唤醒程序重新回到就绪状态\n阻塞挂起状态 : 在虚拟内存管理的操作系统中, 通常会将阻塞状态的进程的物理内存交换到磁盘中, 以减少这些被挂起的进程占用的物理内存\n就绪挂起状态 : 进程在磁盘中, 但只要进入到内存中, 就会运行, 是在内存中没有足够的空间供当前进程运行的时候, 这个进程就会进入就绪挂起状态\n\n挂起进程的原因\n\n用户手动的挂起, 比如Linux中的Ctrl + z\n内存紧张的时候的内存置换, 也就是swap机制, 进程被kswapd守护进程换入到硬盘中, 这个时候这个被换入的进程就会进入到就绪挂起状态\n内存空间不足以这个进程运行的时候, 这个事件出现的时机有很多种, 比如这个进程被创建以后, 在阻塞挂起状态被唤醒以后, 出现了物理内存空间不足的情况, 都会导致程序进入就绪挂起状态, 等待物理内存有足够的资源的时候再恢复运行\n\n进程的控制结构进程控制结构(Proccess Control Block), 操作系统通过PCB描述一个进程, 也是一个进程存在的唯一标识, 也就是如果一个进程的PCB消失了, 那么这个进程也就消失了, 一个进程存在, 也必然有一个相对应的PCB\n\nPCB包含什么信息呢?\n\n\nCPU相关信息 :\nCPU中的各个寄存器的值, 在被中断执行的时候, 会保存CPU中的各个寄存器的值, 以便在重新运行的时候, 能重新从断点处重新运行, 可以说CPU相关信息就是进程运行的上下文\n\n\n资源分配清单\n打开的文件列表, 使用的I&#x2F;O设备信息,  有关内存地址和虚拟地址的信息\n\n\n进程描述信息\n进程标识符 : 标识进程的唯一ID\n用户标识符 : 标识这个进程属于哪个用户, 记录的应该是用户的唯一ID\n\n\n进程控制和管理信息\n进程当前的状态 : 如创建, 阻塞, 就绪等\n进程优先级 : 进程抢占处理器运行时间的时候的优先级\n\n\n\n\n那么PCB是怎么组织的呢?\n\n通过链表的形式将PCB连接起来, 同时根据PCB的不同进程状态, 不同类的PCB链接到不同的链表上\n同时操作系统还会维护一个PCB的索引表, 来提高查找的性能, 使用链表的原因是, 进程的创建和销毁是件很频繁的事件, 而链表的创建和删除性能很好, - 在Linux中构建索引表是通过建立PID-&gt;PCB的哈希表\n进程的控制结合PCB解释我们能控制进程做什么\n创建进程操作系统允许一个进程创建另一个子进程, 并让子进程继承父进程的所有资源\n\n申请一个空白的PCB, 初始化地向里面填入控制和管理管理信息以及进程描述信息\n为该进程分配必要的资源, 比如内存资源\n将PCB插入到就绪队列, 等待被CPU调度运行\n\n终止进程进程被终止方式有三种 : 正常终止, 异常终止, 外界信号干预如果进程有子进程, 在进程被杀死的时候, 如果子进程还存在的时候, 会将子进程视作孤儿线程, 托孤给1号进程(system), 由1号进程对他们完成状态手机工作\n\n查找需要终止的进程的PCB\n检查进程的状态, 如果进程正在运行, 停止进程的运行\n如果进程有子进程, 将子进程变成孤儿线程\n将子进程托孤给1号进程\n\n\n将进程所拥有的所有资源还给操作系统\n删除PCB\n\n阻塞进程当进程需要等待某个事件完成的时候, 可以调用进程阻塞语句, 将自己阻塞, 等待唤醒\n\n找到需要阻塞的线程的PCB\n如果进程是运行状态, 保护现场, 将进程阻塞, 将进程的状态标识为阻塞状态\n将PCB转移到阻塞队列中\n\n唤醒进程在进程被阻塞的时候是无法自己唤醒自己的, 需要发现者进程使用唤醒语句将被阻塞的进程唤醒\n\n找到被阻塞进程的PCB\n如果进程是阻塞状态, 将PCB从阻塞队列中移出, 并标记为就绪状态\n将进程PCB添加到就绪队列, 等待处理器调度\n\n进程的上下文切换\ncpu上下文切换\n\ncpu的上下文是告诉cpu该从哪里加载任务, 从哪里开始执行任务的内容\n\ncpu寄存器\n程序计数器 - 存储的是cpu要执行的指令\n\n在切换任务的时候, 系统内核会保存cpu上下文, 以便在恢复运行的时候重新加载cpu的上下文, 以继续执行上次的任务\n这里的任务主要包括 : 进程, 线程, 中断. 所以对应的cpu的上下文切换也包括进程上下文切换, 线程上下文切换, 中断上下文切换三种\n\n进程上下文切换切换的内容\n\n进程的切换只能发生在内核态进程切换的内容分成内核空间和用户空间\n\n用户空间有堆 栈, 全局变量等用户空间的资源\n内核空间的资源包括内核堆栈, 寄存器等资源\n\n线程","categories":["计算机科学","操作系统","进程管理"],"tags":["八股文","面试","进程","线程","并发","并行","进程状态","进程调度","上下文切换","操作系统"]},{"url":"/2025/07/08/Computer_Science/Operating-System/5.1%E9%9B%B6%E6%8B%B7%E8%B4%9D/","content":"零拷贝"},{"title":"Redis学习任务清单","url":"/2025/07/08/middle_ware/Redis/Redis%20Task/","content":"Redis\n Redis数据库缓存缓存一致性保证\n Redis面试\n Redis面试的后半部分\n Redis面试的前半部分\n 制作复习问题卡片\n\n\n Redis数据结构\n Redis数据类型和常用命令以及场景\n 数据结构\n 制作数据类型的复习问题卡片\n 制作数据结构的复习问题卡片\n\n\n Redis中过期删除策略和内存淘汰策略\n 制作复习问题卡片\n Redis中的过期删除策略和内存淘汰策略\n\n\n 持久化\n AOF\n RDB\n 大key存储对持久化的影响\n 制作复习问题卡片\n\n\n 集群\n 制作复习问题卡片\n 缓存问题 : 缓存击穿, 雪崩, 传透\n 主从复制时怎么实现的\n 哨兵机制\n 为大营销添加上哨兵和主从复制\n 检查大营销中的缓存问题\n\n\n\n","categories":["中间件","Redis","任务清单"],"tags":["Redis","学习计划","面试准备","数据结构","持久化","集群"]},{"url":"/2025/07/08/Computer_Science/Operating-System/%E6%80%BB%E7%BB%93/","content":"磁盘调度算法和读者写者问题其中的核心问题都有\n\n对于饥饿情况的考虑 (公平性)\n\n\n"},{"title":"Java基础知识详解","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E5%9F%BA%E7%A1%80/","content":"Java基础包装缓存机制Byte,Short,Integer,Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据，Character 创建了数值在 [0,127] 范围的缓存数据，Boolean 直接返回 TRUE or FALSE\nShort s1 = 123;Short s2 = 123;s1 == s2 // true\n\n\n如果我们手动创建对象, 这个时候就不会使用缓存中的数据, 返回的就是在堆区的新的对象的地址\n\nInteger i1 = 40; // 发生了自动装箱, 等同于Integer i1 = Integer.valueOf(40);Integer i2 = new Integer(40);i1 == i2; // false\n\n静态方法为什么不能调用非静态成员\n非静态成员的值是在运行时, 创建了这个对象的实例以后才能够访问\n在类的非静态成员还不存在的时候, 静态方法就已经存在了\n所以我们很容易得出结论, 静态成员只能访问静态方法\n\n浅拷贝和深拷贝\n这个问题也是和CPP中的拷贝问题是一样的问题, 只不过在java中拷贝函数使用过implement Cloneable来是实现的\n\n我们将需要被拷贝的类中的所有数据复制一份, 创建一个新的实例, 但是在这个实例中, 因为我们是直接复制的, 浅拷贝会直接复制内部对象的引用地址, 原对象和浅拷贝对象共用一份内部对象\n\n如何解决\n实现Clonebale, 在其中手动将内部对象也clone一份, 这个时候拷贝对象中的内部对象使用的就是新的实例\n\n\n\nhashCode与equals与&#x3D;&#x3D;\n这三个方式, 都能进行相等的判断\n\n\n&#x3D;&#x3D; 比较的是值, 如果比较的对象, 这个时候比较的就是对象的地址\nequals我们默认是这个比较的是对象的值是否相等, 这也是我们往往预期的行为\nhashCode()返回的是对象的hash值, 如果我们需要将对象放在hash集合对象中, 我们必须重写这个方法\n\n\n在Java中, 如果两个对象通过equals判断相等, 那么它们的hashcode也必须相等, 这样才能保证集合的工作不会出现错误\n\n\n如果两个对象的hashcode不同说明两个对象一定不同(同样的值一定能算出来同样的hashcode), 但是hashcode相同两个对象不一定完全相同, 会有hash碰撞\n\n重写hash方法\n\n\n@Override public int hashCode() &#123;     return Objects.hash(name, age); // 根据 name 和 age 生成哈希值 &#125;\nString, StringBuffer, StringBuilder\nString是不可变的, 我们将两个string加起来的操作, 实际上是隐式地调用StringBuilderr的append方法后再toString(), 创建的是一个新的对象\n\nString str1 = &quot;hello&quot;;str1 += &quot;world&quot;;// 代码等同于StringBuilder strbuilder.append(str1).append(world).toString();\n那么如果我们需要频繁修改String对象的时候, 这个时候就会频繁创建StringBuilder对象用于拼接字符串\n\n如果我们需要频繁修改字符串的时候, 或拼接字符串的时候, 使用StingBuilder拼接后再toString()\nStringBuffer相较于StringBuilder是线程安全的, 损失大概15%的性能\n\nString 为什么是不可变的\nString内部有一个char数组用于存储字符串, 这个字符串是private final\n\n\nchar数组是private, 外界无法直接访问, 同时String也没有向外提供修改的接口\nfinal保证了无法通过继承String类来实现对char数组的修改\n子类无法修改父类的final字段的值\n\n\n\n字符串常量池\nJVM中为字符串专门开辟的一块区域, 避免字符串的重复创建\n\n使用和创建一个字符串字面量的时候(比如”hello”和final 字段修饰的String)\n\n检查这个变量在不在字符串常量池中, 在的话会直接返回对应的引用\n如果不在的话就会, 在字符串常量池中创建, 并返回对应的索引, 使用new会在堆区中再新建一个实例\n可以通过intern方法指定获取常量池中的字符串对象\n\nException 和 Error的区别所有的异常类的共同祖先是Throwable类, 这个类的两个重要子类就是Exception和Error\n\nException : 程序本身能处理的异常, 可以通过catch捕获\n可检查的错误, 这类的错误是我们能预料到的错误, 如果受检查异常没有被 catch 或者 throws 出去, 就会无法通过编译\n不可检查错误, 其实就是运行时错误, 这类错误只有运行的时候才会出现, 比如空指针错误, 错误传参等\n\n\nError : 程序无法处理的错误, 不建议使用catch捕获 (如OOM, StackOverFlow这种)\n\n序列化\n序列化用于持久化Java对象或者网络传输Java对象, 序列化的主要目的是通过网络传输对象或者说是将对象存储到文件系统, 数据库, 内存中\n\n\n序列化 : 将数据结构或对象转换成可以存储或传输的形式, 通常是二进制字节流, 也可以是JSON, XML等文本形式\n反序列化 : 将序列化产生的数据转化回对象的过程\n\nJDK自带的序列化手段实现Serializable接口就行了\n@AllArgsConstructor@NoArgsConstructor@Getter@Builder@ToStringpublic class RpcRequest implements Serializable &#123;    private static final long serialVersionUID = 1905122041950251207L;    private String requestId;    private String interfaceName;    private String methodName;    private Object[] parameters;    private Class&lt;?&gt;[] paramTypes;    private RpcMessageTypeEnum rpcMessageTypeEnum;&#125;\n\nserialVersionUID的作用充当版本号的作用, 反序列的时候会检查UID和当前类的UID是否一致, 如果不一致则会抛出InvalidClassException\n\n虽然是static但是这个特殊的变量还是会被写到序列化数据中\n\n让某些字段不被序列化\ntransient关键字修饰\n\n常用的序列化工具\nJDK官方的序列化不支持跨语言的调用, 性能差, 存在安全问题, 一般不使用JDK自带的序列化方式\n\n\nKryo\nProtobuf\n\nJava代理模式\n使用代理对象来代替对真实对象的访问, 这样就能在不修改原目标对象的前提下, 提供额外的功能操作, 拓展目标对象的功能\n\n静态代理创建一个代理类, 让代理类实现被代理的类实现的接口, 然后将被代理类传入代理类, 再重实现对应的接口方法, 增强原来的方法\n动态代理\n静态代理的维护成本太高了, 我们如果修改了被代理类还要重新修改代理类, 过于臃肿\n\n我们不需要针对每个目标类都单独创建一个代理类, 并且也不许要我们必须实现接口, 我们可以通过代理实现类(CGLIB动态代理机制)\n\nJDK动态代理类使用步骤\n\n定义一个接口及其实现类\n自定义 InvocationHandler(接口)并重写invoke方法, 在invoke方法中调用原生方法, 并自定义一些处理逻辑\n通过 Proxy.newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 方法创建代理对象；\n\n\nCGLIB动态代理\n\nJDK动态代理只能代理实现了接口的类\n\n\n\npublic interface MethodInterceptorextends Callback&#123;    // 拦截被代理类中的方法    public Object intercept(Object obj, java.lang.reflect.Method method, Object[] args,MethodProxy proxy) throws Throwable;&#125;\n\nobj : 被代理的对象（需要增强的对象）\nmethod : 被拦截的方法（需要增强的方法）\nargs : 方法入参\nproxy : 用于调用原始方法\n\n\n使用步骤\n自定义一个类\n实现MethodInterceptor并重写intercept方法, intercept用于拦截增加被代理类的方法, 和JDK动态代理中的 invoke 方法类似\n通过Enhancer类的create()创建代理类\n\n\n\npackage github.javaguide.dynamicProxy.cglibDynamicProxy;public class AliSmsService &#123;    public String send(String message) &#123;        System.out.println(&quot;send message:&quot; + message);        return message;    &#125;&#125;\n\n\n实现方法拦截器\n\nimport net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;/** * 自定义MethodInterceptor */public class DebugMethodInterceptor implements MethodInterceptor &#123;    /**     * @param o           被代理的对象（需要增强的对象）     * @param method      被拦截的方法（需要增强的方法）     * @param args        方法入参     * @param methodProxy 用于调用原始方法     */    @Override    public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123;        //调用方法之前，我们可以添加自己的操作        System.out.println(&quot;before method &quot; + method.getName());        Object object = methodProxy.invokeSuper(o, args);        //调用方法之后，我们同样可以添加自己的操作        System.out.println(&quot;after method &quot; + method.getName());        return object;    &#125;&#125;\n\n\n获取代理类\n\nimport net.sf.cglib.proxy.Enhancer;public class CglibProxyFactory &#123;    public static Object getProxy(Class&lt;?&gt; clazz) &#123;        // 创建动态代理增强类        Enhancer enhancer = new Enhancer();        // 设置类加载器        enhancer.setClassLoader(clazz.getClassLoader());        // 设置被代理类        enhancer.setSuperclass(clazz);        // 设置方法拦截器        enhancer.setCallback(new DebugMethodInterceptor());        // 创建代理类        return enhancer.create();    &#125;&#125;\n\nUnsafe类[[unsafe]]\n","categories":["Java","Java进阶","基础知识"],"tags":["面试","Java基础","包装类","缓存机制","静态方法","浅拷贝","深拷贝"]},{"url":"/2025/07/08/Computer_Science/Computer_network/%E8%AE%A1%E7%BD%91%E5%85%AB%E8%82%A1/network%20Task/","content":"\n \nHTTP\n\n \nHTTP\n\n \n缓存\n\n \nHTTPS\n\n \nWebSocket\n\n \nRPC\n\n \n制作复习卡片\n\n \nHTTP2\n\n \nHTTP3\n\n\n\n \nTCP\n\n TCP四次挥手三次握手\n TCP拥塞控制\n QUIC协议 (基于UDP实现可靠的协议)\n 制作复习卡片\n\n\n \nIP\n\n[ ]\n\n\n\n"},{"title":"Redis面试题汇总","url":"/2025/07/08/middle_ware/Redis/redis%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"Redis面试题为什么使用Redis为什么选用Redis作为MySQL数据库的缓存?Redis过期删除与缓存淘汰策略Redis使用的过期删除策略是什么?Redis中可以为key设置过期时间, Redis中有单独的一张表用于记录每个key的过期时间\n对于删除操作, Redis中有 懒惰删除 和 定期删除 两种策略\n\n懒惰删除 : Redis会在下一次使用到这个key的时候, 先去检查这个key是不是再过期时间表中, 如果在并且已经过期了, 就会将这个key删除, 也就是从内存中释放\n优点 : 对CPU时间友好, 占用CPU的时间更少\n缺点 : 对缓存不友好, 没有被使用到的key会一直占用内存, 即使它已经过期了\n\n\n定期删除 : 为了补足上面懒惰删除中某些没有被使用的过期key会一直占用内存的问题, Redis还有定期删除的设置, Redis会定期抽取一定数量的key, 并检查它们是不是过期了, 过期了就删除. 如果(过期的key &#x2F; 所有检查的key) &gt; 25%, 就会立马开启下一轮检查, 因为这个时候说明redis中有很多过期的key. 否则则等待下一轮检查. 同时为了避免这个删除循环过度, 导致线程卡死, redis中对于每一轮还有时间限制, 如果超过最大时间(默认25ms), 也会退出等待下一轮检查\n优点 : 能清理过期的且使用频率低的key, 对内存友好, 同时最大时间的设置, 也能限制这个操作占用过多的cpu时间\n缺点 : 执行的频率和时间难以把握\n\n\n\nRedis持久时, 对过期键会如何处理?对于RDB(Redis Database)文件\n\nRDB文件生成阶段 : 生成的时候会对key进行过期检查, 过期键不会被写入\nRDB文件加载阶段 : 需要从主节点和从节点分情况讨论\n主节点 : 会进行键的过期检查, 如果键过期了, 就不会加载进Redis中\n从节点 : 不会检查, 会将RDB文件中的内容全部重新加载进Redis中, 但是主从节点进行数据同步时候, 从服务器中的数据会被清空, 所以从节点中的过期键也不会造成什么影响\n\n\n\n对于AOF(Append Only)文件\n\nAOF文件生成阶段 : 如果持久化的时候, 数据库中的某个过期键还没有被删除, 就会保留这个键, 等到过期键被删除的时候, 会显式地追加一条DEL删除指令.\nAOF文件重写阶段 : 执行AOF重写的时候, 会对Redis中键进行检查, 已经过期的键不会保存到重写后的AOF文件\n\n主从模式下, Redis怎么处理过期键从服务器不会对过期键做任何处理, 而是在主服务器会对键进行过期检查, 发现键是过期以后, 会在AOF文件中追加一条DEL指令, 同步到所有的从库, 从库通过执行这条DEL指令来删除过期键\n内存淘汰策略有几种在内存满了以后, 会触发Redis的内存淘汰策略, 可以通过设置redis的maxmemory参数设置内存淘汰策略可以大致分为 不进行数据淘汰策略, 进行数据淘汰策略两类\n\n不进行数据淘汰策略 : 就是简单的在内存满了(超过设置的最大内存)以后, 不淘汰任何数据, 不再提供服务, 直接返回错误\n进行数据淘汰的策略 : 又可以再分成两类, 全局淘汰和只在设置了过期时间的键中进行淘汰\n全局淘汰 : allkeys_random : 全局随机淘汰键, allkeys_lru : 全局LRU淘汰, allkeys_lfu : 淘汰整个键值中最少使用的键\n只在设置了过期时间的键中进行淘汰 : volatile_random : 随机淘汰设置了过期时间的键, volatile_lru : 淘汰最久未被使用的键, volatile_lfu : 淘汰使用次数最少的键, volatile_ttl : 淘汰过期时间更早的键\n\n\n\nRedis中的LRU与LFU\nLRU : Least Recently Used : 最近最少使用\n\nLRU最大的问题是需要维护一个所有数据对象大链表, 以及每次在访问数据项的时候都需要移动链表项, 这两个操作的开销都很大所以在Redis中的LRU是一种 近似LRU, 从而减小LRU算法的开销\n\n为每个redis数据对象添加一个时间戳属性, 用于记录数据的, 记录数据 最后一次访问时间\nRedis在执行缓存淘汰策略的时候, 通过 随机采样的方式淘汰数据, 每次随机抽取5个数据(可以配置), 然后淘汰掉其中的时间戳最久远的一个数据项但是LRU无法解决 缓存污染 的问题\n\n\nLFU : Least Frequently Used : 最近最不常用\n\nRedis记录每个数据项的使用次数\n\nlru : 24bit\n\n在LRU算法中, 这个24bit的数据记录最近一次访问的时间戳在LFU算法中, 高16位存储最近访问时间, 低8位存储访问次数\n在redis中, 同一时间内, 只会使用一种方式解释lru属性, 在运行期间一般不会随意切换淘汰策略\n\n如果从LRU -&gt; LFU : 会将redis对象的lru值初始化(一般是5)\n如果从LFU  -&gt; LRU : 会用新的解释策略解释lru的值\n\nRedis缓存设计如何避免缓存雪崩, 缓存击穿, 缓存传透这里是针对使用redis作为数据库的缓存的时候出现的情况, 一个数据请求的请求顺序在有缓存的情况下会是\n\n请求到redis缓存\n命中 -&gt; 直接返回\n没有命中 -&gt; 尝试从数据库中获取数据并更新redis缓存\n\n\n\n\n什么是缓存雪崩?\n\n短时间内大量的key或者是热点数据过期, 导致用户的请求直接跨过redis, 直接请求从数据库中获取数据, 大量的请求直接压垮了数据库. \n这里雪崩的时机是发生在从redis中获取缓存失败, 并且在给redis设置缓存之间发生\n\n怎么解决缓存雪崩?\n\n\n将缓存的过期时间随机分散 : 在原本失效的时间基础上增加1-10分钟, 这样就不会出现大量数据同一时间失效的情况\n设置缓存不过期 : 通过后台程序来设置和更新缓存时间, 避免因为缓存失效带来的缓存雪崩\n\n\n什么是缓存击穿?\n\n缓存击穿是缓存雪崩的一个子情况, 指的是针对于单个热点数据, 在缓存失效的时候, 大量的请求打向了数据库.\n\n怎么解决缓存击穿?\n\n\n互斥锁 : 在缓存没有命中之后, “从数据库中获取数据并更新缓存”这个操作设置互斥锁, 也就是保证同一时间只有一个请求是会被打向数据库, 其他的都会等待重试, 重新尝试从缓存中获取数据\n\nfunction getData(key) &#123;    // 1. 从缓存获取数据    value = redis.get(key)        // 2. 缓存命中,直接返回    if (value != null) &#123;        return value    &#125;        // 3. 缓存未命中,尝试获取锁    if (redis.setnx(&quot;lock:&quot; + key, &quot;1&quot;, expireTime)) &#123;        try &#123;            // 4. 从数据库获取数据            value = db.query(key)                        // 5. 将数据写入缓存并设置过期时间            redis.set(key, value, expireTime)                        return value        &#125; finally &#123;            // 6. 释放锁            redis.del(&quot;lock:&quot; + key)        &#125;    &#125; else &#123;        // 7. 获取锁失败,等待一段时间后重试        sleep(50)        return getData(key) // 递归调用    &#125;&#125;\n\n\n\n\n设置缓存不过期\n\n\n什么是缓存传透?\n\n前两种情况都是数据库中有数据的时候, 还有访问的数据在数据库中不存在的情况, 这个时候, 每个请求都同样会被打向数据库, 这个问题常常是运营方面的配置有问题, 或者有恶意攻击\n\n怎么解决缓存传透问题\n\n\n非法请求的限制: 当有大量恶意请求访问不存在的数据的时候, 在API的入口判断请求参数的合理性\n设置空值或者默认值 : 在线上业务发生缓存传透的现象的时候, 可以针对查询的数据, 在缓存中设置一个空置或者默认值, 后续请求就能识别出来现在发生了缓存传透\n使用布隆过滤器快速判断数据是否存在, 避免通过查询数据库来判断数据是否存在 : 通过布隆过滤器记录存在的数据, 从而快速判断数据是否存在\n\n如何设计一个缓存策略, 可以动态缓存热点数据?用户访问数据也是具有局部性的, 如果我们能动态缓存热点数据, 能有效地增加缓存命中率, 这是一个典型的热点商品缓存管理\n\n通过Redis的Sorted Set创建基于访问时间排序的队列\n系统定期删除队列最后的200个商品, 然后再从数据库中随机读取中200个商品\n每次请求到达的时候, 就会先尝试从队列中获取商品ID, 如果命中了, 就根据ID再从另一个缓存数据结构中获取实际的商品信息\n\n// 初始化function 初始化排序队列():    如果 Redis中不存在&quot;hot_products_queue&quot;:        product_ids = 从数据库中随机获取1000个商品ID        对于每个 product_id in product_ids:            Redis.ZADD(&quot;hot_products_queue&quot;, 当前时间戳, product_id)        如果 Redis中不存在&quot;products_cache&quot;:        products = 从数据库获取所有在&quot;hot_products_queue&quot;中的商品详情        对于每个 product in products:            Redis.HMSET(&quot;products_cache:&quot; + product.id, product的所有字段和值)// 访问商品时更新队列function 访问商品(product_id):    // 更新访问时间戳    Redis.ZADD(&quot;hot_products_queue&quot;, 当前时间戳, product_id)        // 从缓存获取商品信息    product_info = Redis.HGETALL(&quot;products_cache:&quot; + product_id)    如果 product_info为空:        product_info = 从数据库获取product_id的商品信息        Redis.HMSET(&quot;products_cache:&quot; + product_id, product_info的所有字段和值)        返回 product_info// 定期刷新队列function 定期刷新队列():    // 移除排名靠后的200个商品    old_products = Redis.ZRANGE(&quot;hot_products_queue&quot;, 0, 199)  // 获取排名最后的200个    Redis.ZREM(&quot;hot_products_queue&quot;, old_products)        // 从数据库随机获取200个新商品    new_products = 从数据库中随机获取200个不在队列中的商品ID    对于每个 product_id in new_products:        Redis.ZADD(&quot;hot_products_queue&quot;, 当前时间戳, product_id)                // 同时确保这些商品的详情也被缓存        如果 !Redis.EXISTS(&quot;products_cache:&quot; + product_id):            product_info = 从数据库获取product_id的商品信息            Redis.HMSET(&quot;products_cache:&quot; + product_id, product_info的所有字段和值)// 从队列获取热门商品function 获取热门商品(start, end):    // 获取排名靠前的商品ID    product_ids = Redis.ZREVRANGE(&quot;hot_products_queue&quot;, start, end)  // 从高到低排序        products = []    对于每个 product_id in product_ids:        product_info = Redis.HGETALL(&quot;products_cache:&quot; + product_id)        products.append(product_info)        返回 products// 设置定时任务每隔一定时间段(例如1小时):    执行 定期刷新队列()\n\n常见的缓存更新策略Redis数据库和缓存保持一致性详解\n缓存更新策略有三种\n\nCache Aside : 旁路缓存\nRead&#x2F;Write Through : 读穿 &#x2F; 写穿策略\nWrite Back : 写回策略\n\n\n旁路缓存策略\n\n这个策略是业务中主要使用的更新策略\n\n在发生写操作的时候 : 先更新数据库, 再删除缓存中的数据\n在发生读操作的时候 : 先尝试从缓存中获取, 如果没有获取到,  尝试从数据库中获取, 并更新缓存\n\n这个策略中的重点是写操作为什么是先更新数据库后删除缓存?\n\n如果是先更新缓存再更新数据库呢?\n\n现在我们有两个线程都要访问age : 20这个数据, 其中1号线程要修改这个数据为21. 2号线程要读取这个值\n\n对于1号线程 : 执行 1. 删除缓存中的数据 2. 更新库表中的age &#x3D; 21\n对于2号线程 : 从缓存中读取的时候, 发现数据不存在, 这个时候会尝试从数据库中获取, 这个时候读取到的是20(old)\n\n这个时候就出现了偏差, 并且因为更新数据库中的数据的时间是相对较长的, 所以相对也更容易触发这个并发问题, 一致性更差, 因为两个操作之间的空隙很大\n\n那么现在是先更新数据库再删除缓存呢?\n\n同样我们有两个线程都要访问age : 20这个数据, 其中1号线程要修改这个数据为21. 2号线程要读取这个值\n\n对于1号线程 : 执行 1. 更新数据库中的数据 2. 删除缓存\n对于2号线程 : 缓存命中, 读取到20(old)\n\n也出现了缓存一致性的问题, 那么为什么选用这个方案?\n\nredis的写操作相对于数据库的写操作, 速度快得多\n先写数据库再删除缓存这两个操作之间的空隙更小, 更能视作为一个原子操作\n\n不过最后也能看出, 这个方案其实更适合读多写少的情况\n\nWrite&#x2F;Read Through : 写&#x2F;读传透策略\n\n将和数据库的交互交给缓存程序, 用户程序只与缓存打交道, 其实可以看做是旁路缓存的理想情况\n\n写操作 : 将数据更新到缓存中, 然后同步更新到数据库中\n读操作 : 尝试从缓存中读取 ? 返回数据 : 从数据库中读取数据并更新缓存\n\n这个方案在实际开发中并不适用, 因为redis并没有提供管理数据库的功能\n\nWrite Back\n\n和CPU缓存策略中的写回策略是一样的方式, 在缓存中更新数据以后, 将数据打上脏标, 在数据要被移除的时候, 将数据写回到数据库中\n适用于 读少写多 的情况, 但是这个策略会带来数据不是强一致性的问题, 会有数据丢失的风险. 掉电数据就没了\nRedis实战","categories":["中间件","Redis","面试"],"tags":["Redis","持久化","面试题","缓存","过期删除","内存淘汰"]},{"url":"/2025/07/08/Computer_Science/Operating-System/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/3.2%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-malloc%E6%98%AF%E6%80%8E%E4%B9%88%E5%88%86%E9%85%8D%E5%86%85%E5%AD%98%E7%9A%84/","content":"内存管理-malloc是怎么分配内存的Linux中进程的内存分布长什么样子在32位的系统中, 用户空间是3GB, 内核空间是1GB\n在64位的系统中, 两个空间各为128T\n用户内存空间从低到高分别是6种不同的内存段\n\n\n代码段 : 用于存储可执行的二进制代码\n数据段 : 已初始化的静态变量和全局变量\nBSS段 : 未初始化的静态变量和全局变量\n堆段 : 动态分配的内存, 从低地址向高地址增长\n文件映射段 : 动态库, 共享内存等, 从低向高增长\n栈段 : 局部变量的和函数调用的上下文等, 大小是固定的, 一般是8MB\n\n其中堆段和文件映射段的内存是动态分配的.\nmalloc是怎么分配内存的malloc分配的内存的时候会根据分配的内存的大小, 选择调用不同的系统调用分配内存\n\nbrk() : 在分配的内存 &lt; 128KB的时候, 在堆区分配内存\n会将堆顶指针上移指定大小\n但是这个时候分配的并不是物理内存, 而是虚拟内存, 也就是这个时候这个只是移动了堆顶指针, 并没有映射到物理内存, 只有在第一次通过这个虚拟地址在页表上查到查找, 发现这个页没有在物理内存中的时候, 通过缺页中断, 我们才会真正地给这个虚拟内存分配对应的物理内存\n在程序第一次调用malloc的时候, 内存分配器会通过brk()向操作系统请求一大块内存, 后续的malloc()调用通常不会触发系统调用, 而是先尝试从内存池中分配内存, 这个过程是在用户态中发生的, 不需要切换到内核态\n\n\nmmap() : 在分配的内存 &gt;&#x3D; 128KB的时候, 在文件映射段分配内存\n在文件映射区域分配一块内存, 相当于从文件映射区域偷了一块内存\n\n\n\nfree的时候是真的释放了内存吗\n对于堆中的内存, 我们执行free并没有将内存真的从堆中释放, 而是缓存在malloc的缓存池中, 以便下一次申请的时候, 能直接分配\n\nfree会更新内存分配器中的内部数据结构, 将这块数据结构标记为可用\n\n\n而对于通过mmap()从文件映射段中获取的内存, 在free的时候, 是将内存归还给了操作系统\n\n\n为什么不全部使用mmap来分配内存mmap每次执行的时候都会切换到内核态并申请内存, 在free的时候会释放内存回操作系统. 并且mmap申请内存在malloc中没有内存池缓存的机制\n在这样的机制下, 每次通过mmap申请到的内存 都会因为申请内存发生运行态的切换, 还会发生缺页中断(在第一次访问虚拟地址的时候), 这样会导致CPU的消耗较大\n而malloc在通过brk()系统调用申请内存的时候, 因为堆内存是连续的空间, 所以会预先申请更多的内存, 同时释放的时候也并不会将内存真的释放, 而是将缓存在内存池中, 这样在下次申请内存的时候直接从内存池中取出来内存块使用就行, 不需要切换运行态, 也不会触发缺页中断\n为什么不全部使用brk来分配内存申请大的内存块, 很容易导致堆段的内存碎片\n\n"},{"title":"虚拟内存原理详解 - 内存管理核心机制","url":"/2025/07/08/Computer_Science/Operating-System/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/3.1%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","content":"内存管理-为什么要有虚拟内存如果没有虚拟内存如果没有虚拟内存, 也就意味着我们的程序需要直接和物理内存进行交互, 我们需要直接操作物理内存地址, 那么问题来了, 我们怎么保证我们的程序操作的物理内存地址, 别人的程序没有在操作, 这个物理地址是安全可直接操作的?\n虚拟内存虚拟内存就是上面直接操作物理地址会导致的问题的解决方案, 操作系统在物理内存和程序之间提供一个抽象层, 我们将内存虚拟化, 我们让每个程序都看似拥有一整个内存空间, 可以访问可行的所有内存地址, 无关物理内存的大小, 物理内存的地址. 将虚拟内存和物理内存之间的映射交给操作系统管理\n这样我们的程序就不需要再考虑这个内存地址是不是正在被其他的程序使用, 不需要再考虑其他的程序对自己内存的影响, 因为所有的程序都有自己的虚拟内存, 相互独立\n在有了虚拟内存以后, 我们访问一个内存地址的过程会变成\n\nCPU 携带虚拟地址 -&gt; MMU -&gt; 访问到物理地址\n\n\n\n那么操作系统是怎么管理虚拟地址和物理地址之间的关系?\n\n主要通过内存分段和内存分页两种方式\n内存分段内存分段的理念是基于程序是有若干个逻辑分段组成的. 不同的段有不同的属性, 所以就用分段的形式将段分离出来\n\n在分段机制下, CPU是怎么访问一个物理内存地址的?\n\n分段机制下的虚拟地址分为两部分 : 段选择因子, 段内偏移量\n\n段选择因子\n段号 : 用作段表的索引, 最重要的属性\n段表中保存的是这个段的基址, 段的界限, 特权等级等\n\n\n特权等标志位\n\n\n\n\n通过段号 + 段内偏移量, 从段号我们能知道段基址, 再将段基址加上段内偏移量就是物理地址, 以此完成了虚拟地址到物理地址之间的转换分段的方法会导致两个问题\n\n内存碎片\n内部碎片 : 段内分配了比需要的内存更多的内存\n外部内存碎片 : 由于每个段的长度不固定, 在运行的时候, 我们创建和释放段, 就会出现我们有256M的空闲空间, 但是这个256的空间实际上是不连续的, 被分成两个128M, 这个时候我们就无法再创建一个200M的段\n\n\n内存交换的效率低\n在分段方法下, 内存交换的最小单位变成了段, 而段的大小是不确定的, 我们很容易出现需要交换大小很大的段, 磁盘的访问速度比内存慢很多, 最后就会导致机器卡顿(这个交换的过程是阻塞的, 同时内存交换能解决外部内存碎片的问题, 我们可以将内存中的内容swap到磁盘中, 再重新加载到的内存中, 重新加载的时候, 让这些内存连续, 这个时候就能空出256M的连续空间)\n\n\n\n内存分页内存分段的主要问题是外部内存碎片和内存交换的空间太大的问题, 要解决这些问题, 我们就需要有能少出现一些内存碎片的方法 : 内存分页(Paging)\n分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小, 在Linux中的, 每一页的大小为 4KB\n虚拟地址和物理地址之间通过页表映射\n\nCPU -&gt; 虚拟内存 -&gt; 页表(MMU) -&gt; 物理地址\n当进程访问的虚拟地址在页表中查询不到的时候, 就会触发 缺页异常, 进入系统内核态分配物理空间更新进程页表, 再返回用户态, 恢复进程的运行\n也就是说, 实际上分配物理内存的时刻是发生在第一次访问的时候, 而不是申请这块内存的时候\n分页的方式使得我们在加载程序的时候, 不再需要一次性将程序加载到物理内存中, 只建立虚拟内存和物理内存之间的页的映射之后, 在程序运行中, 需要用到对应的虚拟内存页中的指令和数据的时候, 再加载到物理内存中, 实现了按需加载, 而不是预加载\n\n\n\n\n所以分页是怎么解决分段的 [外部内存碎片和内存交换效率低] 的问题的?\n\n因为采用了分页的机制, 而页和页之间是连续紧密排列的, 所以不会有外部内存碎片\n我们swap的最小单位不再是不确定大小的段, 而是页, 更细粒度, 如果内存空间不够, 操作系统会把其他正在运行中的 [最近没有使用] 的内存页面释放出来, 暂时写在硬盘上, 这个过称作 换出. 而一旦有需要, 再从磁盘中加载进来, 这个过程称为 换入. 更加细粒度的交换, 并且是按需和使用频率交换, 能有效提高内存的交换效率\n\n分页机制下, 虚拟地址和物理地址之间是怎么建立映射的?\n\n分页机制下, 虚拟地址分为页号和页内偏移量两部分\n\n查询过程为\n\n通过虚拟页号我们在页表中查询到物理页号\n再将物理页号加上页内偏移量, 得到物理内存地址\n\n\n简单的分页机制有什么缺陷吗?\n\n因为我们给每个程序都制造了他们拥有所有的页的假象, 所以我们需要为每个程序都建立一个页表用于映射虚拟页号和物理页号, 一页的大小是2^12, 4GB是2^32, 也就是有2^20个页, 每个页表项需要4个字节存储, 那么整个4GB的内存空间就需要2^22的内存, 也就是4MB的内存来存储页表\n100个进程, 光是页表就需要400MB的内存, 这个开销过大了, 换成64位的环境, 会变得更糟糕\n多级页表为了解决的上面的我们需要为每个程序创建一个完整的页表的问题, 我们采用多级页表技术\n\n多级页表是怎么解决上面的问题的?\n\n我们将2^20大小的页表分成两级, 每级页表的大小是1KB,  在多级页表的机制下, 我们从虚拟地址访问到物理地址需要\n\n虚拟地址中有一级页号和二级页号\n通过一级页号定位二级页表的地址\n通过二级页表和页内偏移量访问到对应的物理内存地址\n\n看似多级页表机制反而让我们建立页表的开销变得更大了, 现在需要4KB + 4MB的大小存储页表, 但是多级页表最关键的点在于我们能按需创建页表, 而根据空间局部性原理, 程序实际需要访问的内存地址只有很小一部分, 这就导致最后4MB的二级页表只会被创建很小一部分, 就像\n\n我们现在需要去找到一个地方\n单极页表就是一张非常详细的大的地图, 这个地图一次性加载的代价很高\n而多级页表就是开始给了我们一张很粗略的地图只有国家, 我们到了对应的国家以后的, 再申请获取一张更详细的国家地图, 我们再访问对应的更详细的地址(这个申请更详细地图的行为, 是程序向系统发起的)\n\n\n在64位的系统中, 页表不只有两级, 而是被分成了四级\n\n全局页目录项 PGD（Page Global Directory）；\n上层页目录项 PUD（Page Upper Directory）；\n中间页目录项 PMD（Page Middle Directory）；\n页表项 PTE（Page Table Entry）；\n\n\nTLB多级页表虽然解决了空间上的问题, 但是在时间上带了额外的开销, 现在我们要将我们的虚拟地址转化为物理地址, 需要更多的工序\n利用局部性原理, 很轻车熟路地, 我们只需要将我们常用的页表项存储到访问速度更快地硬件上, 所以我们现在又多了一个专门存放程序最常访问地页表项的Cache : TLB\n段页式内存管理将内存分段和内存分页结合起来就是段页式内存管理\n\n段页式内存管理的实现方式\n\n先通过程序的逻辑意义, 将内存分为多个段\n将段分成多个页, 也就是对段划分出来的连续空间再划分成固定大小的页\n\n这样虚拟地址就由段号, 页号, 页内偏移量三部分组成\n\n段页式访问内存的过程\n\n\n通过段号得到对应的页表\n通过虚拟页号, 在页表中查询到物理页号\n物理页号 + 页内偏移量查询到具体的物理地址\n\nLinux内存布局Linux内存主要使用的是内存分页的方式, 但是因为Intel处理器的使用段页式内存管理, Linux不可避免地涉及了段机制\n但是Linux中, 每个段的开始的地址都是0x0, 每个段空间都是整个4GB的虚拟空间(32位的环境下), 这种做法下相当于屏蔽了处理器中的段的概念, 段只被用于访问控制和内存保护\nLinux将虚拟地址空间分为内核空间和用户空间\n\n对于每个进程来说, 用户空间是相互独立的, 但是关联的都是相同的物理空间\n\n总结 - 虚拟内存的三大核心价值\n允许进程使用超过物理内存大小的进程空间 ( 通过交换机制 )\n提供进程间内存隔离, 每个进程拥有独立的内存空间\n通过页表的权限标记实现内存访问控制和保护\n\n","categories":["计算机科学","操作系统","内存管理"],"tags":["八股文","面试","操作系统","虚拟内存","物理内存","MMU","内存映射","页表","内存保护"]},{"url":"/2025/07/08/Computer_Science/Operating-System/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/3.3%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%86%85%E5%AD%98%E6%BB%A1%E4%BA%86,%20%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88/","content":"内存管理-内存满了会发生什么内存分配的过程\n在CPU第一次访问虚拟地址的时候, 发现这个虚拟内存没有映射到实际的物理内存, 这个时候就会触发缺页中断, 将中断交给缺页中断函数处理\n中断函数判断是否有空闲的物理内存\n有则直接分配内存, 并建立物理内存和虚拟内存之间的映射关系\n没有则会开始回收内存的工作\n\n\n后台内存回收 : 唤醒kswapd内核线程来回收内存, 这个过程是 异步 的\n直接内存回收 : 后台异步回收内存跟不上进程内存申请的速度, 就会直接开始回收, 这个回收的过程是同步的, 也就是会阻塞进程的运行\n直接内存回收后, 空闲的物理内存仍然无法满足这次的物理内存的申请, 就会触发 OOM 机制, OOM Killer 机制会根据算法选择一个占用物理内存较高的进程, 并将其杀死, 直到释放足够的内存, 这个时候内存分配函数也会返回失败, 同时在释放的过程中申请内存的进程如果分数过高, 也可能被杀掉\n\n\n可回收的内存类型主要是两类内存\n\n文件页 : 内核缓存的磁盘数据和内核缓存的文件数据都叫做文件页. 将文件页释放是件安全风险很低的事情, 大不了以后再从磁盘中读取就是了. 回收干净页的方式是直接释放内存, 回收脏页的方式是先写回磁盘, 再释放内存\n匿名页 : 没有实际的载体, 是一个程序的上下文, 比如堆, 栈数据等. 这部分数据很可能还要再被访问, 不能直接释放, 不然就丢失数据了, 回收的方式是通过Linux的Swap机制, 会将这些数据写入到磁盘中, 再释放, 下次使用的时候再从磁盘中写回\n\n两类内存的回收都是基于LRU算法,  优先回收不常访问的内存. 具体的实现会在4.5详细说明\n回收内存导致的性能异常的常见处理方式回收内存的性能瓶颈在于磁盘的IO\n调整文件页和匿名页的回收倾向回收文件页触发的磁盘IO次数比匿名页的次数少些, 所以让操作系统队文件页的回收倾向更大, 能减少磁盘的IO次数, 提高一定的性能\nLinux提供了&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;swappiness 的参数来设置回收倾向, 数值越大, 越积极使用swap, 也就是越倾向于回收匿名页; 数值越小, 越消极使用swap, 也就更倾向于回收文件页\n尽早触发kswapd内核异步线程回收内存\n我们该怎么发现现在系统的抖动是直接内存回收导致的?\n\n通过 sar -B 1 命令观察\n\n图中红色框住的就是后台内存回收和直接内存回收的指标，它们分别表示：\n\npgscank&#x2F;s : kswapd(后台回收线程) 每秒扫描的page个数\npgscand&#x2F;s : 应用程序在内存申请过程中每秒直接扫描的page个数\npgsteal&#x2F;s : 扫描的page中每秒被回收的个数 (pgscank + pgscand)\n\n也就是如果系统发生抖动的时候, pgscand的值很大, 那大概率是由 [直接回收内存] 导致的\n解决方式就是尽早触发kswapd内核异步线程回收内存\n\n什么时候会触发kswapd内核线程回收内存呢\n\n内核定义了三个阈值, 来衡量当前剩余内存是否充裕或者紧张\n\n页最小阈值\n页低阈值\n页高阈值\n\n \nkswapd会定期扫描内存的使用情况, 根据剩余内存的情况来进行内存回收的工作\n\n图中橙色部分 : 如果内存剩余在页低阈值和最小阈值之间的时候, 会kswapd0会执行内存回收, 直到剩余内存大于高阈值为止\n图中红色部分 : 说明用户可用内存基本都耗尽了, 此时会触发直接内存回收, 这个时候应用程序就会被阻塞\n\n也就是如果我们想尽早触发kswapd系统异步回收线程, 就需要增大页低阈值, 而页低阈值是通过设置最小阈值间接设置的\npages_min = min_free_kbytespages_low = pages_min*5/4pages_high = pages_min*3/2\n\n页最小阈值能通过内核选项 /proc/sys/vm/min_free_kbytes 设置\n但是增大了以后, 会使得系统预留过多的内存空间空闲, 浪费了内存, 所以在调整之前, 我们需要思考程序更关注什么, 如果更关注延迟, 就能适当增大min_free_kbytes\n如何保护一个进程不会被OOM杀掉呢Linux内核里有一个oom_badness()函数, 会把系统中可以被杀掉的进程都扫描一遍, 并对每个进程进行打分,  得分最高的进程会被首先杀掉\n得分的计算\n// points 代表打分的结果// process_pages 代表进程已经使用的物理内存页面数// oom_score_adj 代表 OOM 校准值// totalpages 代表系统总的可用页面数points = process_pages + oom_score_adj*totalpages/1000\n\noom_score_adj越大, 进程越容易被杀掉, 每个进程中这个参数都默认为0\n\noom_adj的范围是-1000 ~ 1000\n\n在物理内存4G的机器上申请8G的内存会发生什么\n在32位的系统上, 进程理论上最大能申请3 GB大小的虚拟内存, 所以直接申请8GB内存, 会失败\n64位的系统上, 因为进程理论上最大能申请128TB大小的虚拟内存, 即使物理内存4GB, 申请8GB内存也没有问题, 如果这块虚拟内存被访问了, 需要看系统有没有Swap分区\n有分区, 即使4GB, 程序也能正常使用8GB内存, 进程正常运行\n没有分区, 物理空间不够, 进程会被操作系统杀掉, OOM\n\n\n\n"},{"url":"/2025/07/08/Computer_Science/Operating-System/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/3.4%20%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E9%A2%84%E8%AF%BB%E5%A4%B1%E6%95%88%E5%92%8C%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93%E7%9A%84%E9%97%AE%E9%A2%98/","content":"内存管理-如何避免预读失效和缓存污染的问题其实这两个问题都是在问如何改进LRU算法\nRedis通过实现LFU算法来避免缓存污染而导致缓存命中率下降的问题\nMySQL和Linux操作系统通过改进LRU算法来避免预读失效和缓存污染\nLinux和MySQL的缓存机制Linux的page cache和MySQL的Buffer Pool缓存的基本数据单位都是页\nLinux的缓存在应用程序读取文件的数据的时候, Linux操作系统会对读取的文件数据进行缓存, 缓存在文件系统的Page Cache中\nMySQL的缓存读取的数据时, 如果数据存在于Buffer Pool 中时, 客户端会直接读取缓存中的数据, 否则从磁盘中读取\n修改数据的时候, 首先修改Buffer Pool中的数据, 然后将页设置为脏页, 最后由后台线程将脏页写入到磁盘中\n解决预读失效什么是预读机制Linux操作系统为基于Page Cache的读缓存机制提供预读机制\n\n应用程序只想读取磁盘文件A的offset为0 ~ 3KB范围内的数据, 但是磁盘的基本读写单位时block(4KB), 所以操作系统至少会读取0~4KB的内容\n同时操作系统出于空间局部性原理, 会将磁盘块 offset [4KB, 8KB), [8KB, 12KB), [12KB, 16KB)都加载到内存中, 额外申请了3个page\n\n\nMySQL Innodb存储引擎的Buffer Pool也有类似的预读机制, MySQL从磁盘中加载页的时候, 会提前将它相邻的一页一并加载进来\n预读失效会带来什么问题如果预读的时候提前加载进来的页没有被访问, 就是预读失效\n如果使用传统的LRU算法, 就会把预读页放到LRU链表头部, 内存空间不够的时候就将末尾淘汰掉\n如果这些预读页不会被访问到, 就会出现, 不会被访问的预读页却占据了LRU的前排的位置, 而末尾淘汰的页, 可能是热点数据, 这样就大大降低了缓存命中率 \n如何避免预读失效造成的影响让预读页停留在内存里的时间要尽可能的短, 让真正被访问的页才移动到LRU链表的头部, 从而保证真正被读取的热点数据停留在内存里的时间尽可能长\n\nLinux操作系统实现了两个LRU链表, 活跃LRU (active_list), 非活跃LRU(inactive_list)\nMySQL地Innodb存储引擎是在LRU链表上划分来2个区域: young区域和old区域\n\n这两种解决方案都是为了将数据分为冷数据和热数据, 分别LRU\n\nLinux如何避免预读失效带来的影响\n\n\n预读页就会被加入到 inactive list区域的头部\n访问inactive_list中的数据, inactive_list中的数据会升级到active_list的头部, 然后将active_list的末尾数据降级到inactive_list的头部\n\n\nMySQL Innodb如何避免预读失效\n\n其实是基本类似的设计, 只不过Linux分成了两个链表, 而MySQL一个链表, 但是划分成了两部分\n预读的页只加入到old区域的头部, 当页被真正访问的时候, 才会将页插入到young区域的头部, 并将young区域的最后一个元素顺位到old区域的头部\n解决缓存污染什么是缓存污染如果还是使用 [只要数据被访问一次, 就将数据加入到活跃LRU链表头部, 这种方式的话, 就还存在着缓存污染的问题]\n在我们批量读取数据的时候, 由于数据被读取了一次, 这些大量数据都会被加入到[活跃LRU链表]里, 然后真正的热点数据就全被淘汰了, 如果这些大量的数据不是热点数据的话, 那么整个活跃LRU链表都被污染了\n如何解决缓存污染其实我们对于这个问题有个很奇妙的切入点在于, 解决缓存污染的核心在于识别出热点数据, 我们可以通过识别出来这个数据是不是由局部性带来的访问, 而是跨越时间的热点数据\n\nLinux操作系统 : 在内存页被第二次访问的时候, 才将页升级\nMySQL Innodb : 在内存页被第二次访问的时候, 还会进一步判断停留在old区域的时间\n如果第二次访问时间与第一次访问的时间在1s内, 就不会被升级\n如果停留时间超过1s就会升级\n\n\n\n"},{"url":"/2025/07/08/Computer_Science/Operating-System/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/3.5%20%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/","content":"页面置换算法页面置换 swap在发生缺页中断以后, 如果这个时候物理内存已经申请满了, 我们就会触发页面置换, 我们将不常用的页置换到硬盘中, 从而空出申请需要的内存, 这里有个问题是我们怎么选出来不常用的页面呢?\n页面置换算法这就是页面置换算法做得事\n最佳页面置换算法我们计算出来现在被使用的物理页中, 需要经过最长时间才会迎来下一次使用的页, 然后将这个页置换出去\n这个算法是一个理想的算法, 因为我们是无法得知某个页下一次使用的时间\n这个算法也是效率最高的算法, 所以常用来衡量页面置换算法, 页面置换算法离最佳页面置换算法越近, 效率越高\nFIFO先进先出页面置换算法, 维护一个全局队列, 最先被被使用的页, 最先被淘汰\nLRU最近最久未使用置换算法\n使用LRU维护全局链表, 每次淘汰最久不被使用的页\n但是这个实现方法存在着每次访问页都需要更新链表, 成本高, 所以同样不常被作为页面置换算法来实现\nCLOCK时钟页面置换算法就是用来解决上面LRU的问题的\n我们维护一个所有物理页的环形队列, 让一个指针开始的时候指向某个页面, 然后在需要页面置换的时候, \n沿环形队列扫描, 如果这个页面的页表项的访问位是0, 则将这个页面淘汰, 如果是1则置0, 扫描直到碰到0, 然后将它淘汰\nLFU最不常用置换算法\n淘汰使用次数最少的页面, 但是这里需要给每个页面维护一个计数器, 硬件开销成本大\n同时这个算法没有考虑到时间, 如果某个页面在很久以前被使用了非常多次, 就会一直留滞在内存中\n"},{"url":"/2025/07/08/Computer_Science/Operating-System/%E5%86%85%E6%A0%B8/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","content":"OS什么是系统调用 ?\n操作系统为了用户态的程序能过够调用操作系统提供的内核态级别的子功能而创建的接口\n\n\n凡是与系统态级别的资源有关的操作, 都必须通过系统调用方式向操作系统提出服务请求\n文件管理\n进程控制\n内存管理\n\n\n\n系统调用的分类 ?\n设备管理: 完成设备 (输入输出设备和外部存储设备等) 的请求或释放, 以及设备启动等功能\n文件管理: 完成对文件的CRUD\n进程管理: 进程的创建, 撤销, 阻塞, 唤醒, 进程间的通信等功能\n内存管理: 完成内存的分配, 回收以及获取作业占用内存区大小及地址等功能\n\n系统调用的过程了解吗 ?\n用户态的程序发起系统调用, 因为系统调用中涉及到一些特权指令 (只能由操作系统内核态才能运行的指令), 用户态程序权限不足, 因此会中断执行, 也就是Trap (Trap是一种中断)\n中断发生以后, 当前CPU执行的程序会中断, 跳转到中断处理程序. 内核程序开始执行, 也就是开始处理系统调用\n当系统调用处理完毕以后, 操作系统再调用特权指令切换回用户态 (iret, sysret eret), 恢复用户态的上下文, 继续执行用户态程序\n\n"},{"url":"/2025/07/08/Computer_Science/Operating-System/%E5%86%85%E6%A0%B8/%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81/","content":"OS什么是用户态和内核态\n这个概念是以进程访问资源的特点为依据进行的划分, 将进程在操作系统上的运行分为两个级别, 是为了安全和管理而设计\n\n\n用户态(User Mode) : 用户态运行的程序能直接读取用户程序的数据, 拥有较低的权限.\n不能直接访问内核数据和程序\n操作系统在执行用户程序时, 主要工作在用户态, 只有在执行没有权限完成的任务的时候才会切换到内核态\n访客模式\n\n\n内核态(Kernel Mode) : 内核态运行的进程几乎可以访问计算机中的任何资源, 不受控制, 拥有非常高的权限\n可以访问任何有效的地址\n管理员模式\n\n\n\n为什么要区分内核态和用户态\n安全性 : 内核程序和用户程序的运行环境分隔, 有助于防止用户程序对系统造成不可修复的破坏, 会对系统的正常运行造成灾难性的影响.\n这些危险指令智能在内核态运行, 这些只能由操作系统内核执行的指令也被叫做 特权指令\n\n\n稳定性 : 应用程序错误只会影响到该程序本身, 而不会导致整个系统崩坏\n\n用户态和内核态是如何切换的\n系统调用 : 用户态进程 主动 要求切换到内核态的一种方式, 主要是为了使用内核态才能做的事情, 比如读取磁盘资源. \n实现 : 操作系统为用户特别开放了一个中断\n比如用户态程序发起 read() 请求读取硬盘数据, 就会从用户态切换到内核态\n\n\n中断 : 当外围设备完成用户请求的操作后, 会向CPU发出相应的中断信号, 这个时候CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序\n如果之前执行的是用户态, 而中断处理程序执行的内容是内核态的程序, 这个时候, 我们就发生了从用户态到内核态的切换. \n我们完成了对磁盘数据的读取的时候, 操作系统就会向cpu发送一个中断, 让cpu能继续运行原先的等待的用户程序\n\n\n异常 : 当CPU在执行运行在用户态下的程序时, 发生了某些事先不可知的异常, 这时就会触发由当前运行进程切换到处理此异常的内核相关程序中\n比如缺页异常\n\n\n\n"},{"url":"/2025/07/08/Computer_Science/Operating-System/%E7%A1%AC%E4%BB%B6%E7%BB%93%E6%9E%84/1.%20CPU%E6%98%AF%E6%80%8E%E4%B9%88%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F%E7%9A%84/","content":"OS硬件结构中央处理器 (CPU : Central Processing Unit)位数\n常见的cpu有32位和64位的cpu, 这里的位数指的是cpu的带宽\n即cpu一次能计算多少字节的数据\n32bit : 一次可以计算4字节\n64位 : 一次可以计算8字节\n\n\ncpu的位宽越大, 一次性能计算的数据量就能越大\n\n\n那么如果一个32位的CPU只能计算32位的数据吗\n\n\n一个32位的CPU可以计算大于32位的数据\n32位指的是寄存器宽度为32为位, 数据总线位32位, 一次可以处理32位的数字\n可以通过多周期分段算法, 将一个数字分成多个32的片段, 就像串联式的加法器一样实现拓展\n\n\n\n\n这里的32位的数据指的是最后运算结果不能超过32位还是参与运算的数字不能超过32位\n\n\nCPU单次运算中操作数的位宽上限时32位\n操作数长度限制32位\n寄存器宽度限制32位, 超过32位的数据无法一次性处理, 需要拆分为多次计算\n\n\n\n为什么使用寄存器\n已经有了内存了, 为什么我们还需要寄存器存储CPU数据\n\n\n用途上的区别\n\n寄存器 : 临时存放CPU直接处理的数据和指令, 强调快速访问\n内存 : 存储运行时程序及数据, 以及需要长期保留的数据, 强调容量大, 长期保存\n\n\n物理位置上的区别\n\n寄存器距离CPU更近, 能在更短的时钟周期内做出响应\n\n\n数量上的区别\n\n寄存器的数量很少\n\n\n本质原因\n\n使用寄存器, 本质上是因为内存的访问速度远低于CPU的计算速度, 我们需要一个存储区域能匹配CPU的运算速度, 用于储存CPU运算过程中, 产生的大量临时的数据, 提高整体的性能\n\n\n\n寄存器 (了解)1. 通用寄存器\n数据寄存器 (如 AX, BX, CX, DX) \n存储运算过程中的数据, 运算结果, 地址偏移量等\n\n\n\n2. 地址寄存器\n指针寄存器 (SP, BP)\n\nSP (Stack Pointer, 栈指针)\n指示当前栈顶的位置, 用户函数调用时的压栈和出栈操作\n\n\nBP (Base Pointer, 基址指针) \n存放栈中的某个数据区域的起始地址, 通常用于定位栈中的局部变量\n\n\n\n\n变址寄存器（如SI、DI）：\n\nSI（Source Index，源变址寄存器）：\n存储源数据的偏移地址，常用于字符串、数组数据复制。\n\n\nDI（Destination Index，目的变址寄存器）：\n存储目标数据的偏移地址，也用于字符串、数组数据操作。\n\n\n\n\n\n3. 段寄存器（Segment Registers）\nCS（Code Segment，代码段寄存器）：\n存储当前程序执行代码段的起始地址。\n\n\nDS（Data Segment，数据段寄存器）：\n存储程序数据段的起始地址。\n\n\nSS（Stack Segment，堆栈段寄存器）：\n存储堆栈段的起始地址。\n\n\nES（Extra Segment，附加段寄存器）：\n存储附加数据段地址，通常用于额外的数据存储或字符串操作。\n\n\n\n4. 控制寄存器（Control Registers）\nIP（Instruction Pointer，指令指针寄存器）：\n存储下一条要执行的指令的内存地址，CPU 根据 IP 的值依次取指令执行。\n\n\nFLAGS（标志寄存器）：\n存储 CPU 运行状态和运算结果的状态信息，如进位标志（CF）、零标志（ZF）、符号标志（SF）等，用于条件判断、程序流程控制。\n\n\n控制寄存器组（如 CR0、CR3 等）：\n现代 CPU 中的特殊控制寄存器，用于开启或关闭 CPU 特殊功能，如分页、缓存控制、保护模式管理等。\n\n\n\nCPU是怎么利用寄存器来工作的\n现在假设我们计算一个3 + 5 &#x3D; ?\n\n1. 取指令 (IP和CS寄存器)\nCPU首先查看指令寄存器(IP) 知道了下一条要执行的指令是加法\n然后通过代码寄存器(CS), 知道了执行加法运算的指令在哪里\n\n2. 取数据 (DS数据段寄存器, AX, BX通用寄存器)\nCPU把内存中的两个数字取到寄存器中\n把3放在AX中\n把5放在BX中\n\n\nDS寄存器用于告诉CPU数字3和5在内存的哪个位置\n\n3. 执行计算 (ALU算数逻辑单元)\nALU算术逻辑单元直接访问寄存器中的数据进行计算得出计算结果是8\n\n4. 存放结果 (AX)\n计算出来的结果临时存入寄存器内\n\n5. 判断运算的状态 (FLAGS标志寄存器)\n通过这个寄存器判断运算的状态\n结果是否为0 (8 !&#x3D; 0, 所以这个时候的ZF的标志为0)\n是否产生进位 (不进位, CF标志为0)\n\n\n\n6. 将结果返回内存 (DS数据段寄存器)\n将AX中的计算结果返回到内存中\n\n重点寄存器IP&#x2F;PC, 程序计数寄存器\n存放了CPU下一条要执行的指令的地址\n\nIR (Instruction Register) 指令寄存器\n用于暂存当前正在执行的指令的寄存器\n\nCPU从内存中取出指令以后, 会先将这条指令存放在IR寄存器中, 然后再解码并执行\n\n\n能防止指令被干扰\n\n\nIR与CS代码段寄存器\nCS代码段寄存器告诉CPU指令具体在内存哪个段里, CPU再去取出放进IR中\n\n总线\n地址总线, 用于指定CPU将要操作的内存地址\n数据总线, 用于读写内存的数据\n控制总线, 用于发送和接受信号, 比如中断, 设备复位等信号, CPU收到信号后自然进行响应, 也需要控制总线\n\n\nCPU读写内存数据的时候, 一般需要通过下面的三个总线\n\n\n通过 地址总线 来指定内存的地址\n通过 控制总线控制 是读还是写命令\n通过 数据总线 来传输数据\n\n结合总线CPU执行一条命令的全过程\nCPU读取 程序计数器 的值, 这个值是指令的内存地址 -&gt; 控制单元通过地址总线指定需要访问的内存地址 -&gt; 通过内存准备数据 -&gt; 通过数据总线将指令传给CPU -&gt; 将指令数据存进**IR(指令寄存器)**中\n程序计数器 自增, 表示指向下一条指令. 自增的大小由CPU的位宽决定, 如32位的CPU位宽是4字节,  PC就会自增4, 因一条指令是4个字节, 需要4个内存地址存放\nCPU解码指令寄存器中的指令\n计算型指令 -&gt; 交给逻辑运算单元\n存储型指令 -&gt; 控制单元\n\n\n\n指令的类型\n从功能划分, 可以将指令划分为5大类\n\n\n数据传输类型的指令, 比如 store/load 是寄存器与内存间数据传输的指令, mov是将一个内存地址的数据移动到另一个内存地址的指令\n运算类型的指令, 逻辑运算和算数运算指令, 最多只能处理两个寄存器中的数据\n跳转类型的指令, 通过修改程序计数器的值来跳转执行指令的过程, 比如编程中常见的 if-else, switch-case, 函数调用等\n信号类型的指令, 比如发生中断的指令 trap\n闲置类型的指令, 比如指令nop, 执行后CPU会空转一个周期\n\n64位CPU和32位CPU对比\n64位的性能一定比32位高很多吗\n\n\n64位的优势可以从两方面来看\n可以一次性运算超过32位的数字, 但是实际上这么大的数字运算很少发生\n32位的地址总线最大只能是32位, 最大寻址能力是4G, 而64位的cpu有64位,  最大寻址能力是 2^64, 远超于32位CPU的寻址能力\n\n\n\n\n64位的软件和32位的软件之间区别是什么, 64位的操作系统能运行在32位的系统上吗, 反过来能吗\n\n区分32位还是64位的软件, 主要考虑的是指令是64位的还是32位的\n\n32位的指令在64位的机器上运行, 只需要做一套兼容机制就能实现了, 反过来就不行, 32位的寄存器存不下64位的指令\n\n硬件的32位和64位指的是硬件的带宽, 软件的32位和64位指的是指令的位宽\n"},{"url":"/2025/07/08/Computer_Science/Operating-System/%E7%A1%AC%E4%BB%B6%E7%BB%93%E6%9E%84/2.1.%20CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/","content":"CPU Cache\nCPU Cache指的是靠近cpu的SRAM芯片, 电路简单, 访问速度非常快, 同时靠近CPU, 读取速度远快于主存(内存DRAM)\n\n\nCPU Cache的出现主要是为了解决CPU和主存之间的速度不匹配这一问题\n\n解决上面所述的 “内存墙” 问题, 最核心的思路就是减少对内存的访问次数, 这也是CPU Cache生效的关键\n\n\nCPU Cache是怎么减少内存的访问次数\n在有了CPU Cache以后, 访问数据会按照  : L1 缓存 -&gt; L2 缓存 -&gt; L3 缓存 -&gt; 主存 -&gt; 硬盘的顺序, 只有当前层没有, 我们才会访问下一层, 直到获取到我们需要的数据\n\n\n我们要减少主存的访问次数, 也就是保证我们能在CPU高速缓存中获取到我们需要的数据\n局部性原理\n时间局部性 : 最近访问过的数据很可能会被再次访问\n空间局部性 : 访问过某个数据以后, 其附近的数据也很可能会被访问\nCache每次读取都会将整个数据块(Cache Line)一次性加载, 利用空间局部性原理\n\n\n预读技术\n根据访问模式, 预测将要使用的数据, 提前将数据从主存中加载到Cache中\n\n\n\n\n\nCPU 的缓存一致性\nCPU的缓存一致性, 就是需要保证CPU Cache中的数据和主存的中的数据是一致的(保证最终一致性), 允许短时间的不一致, 但是很明显当其他CPU读取到主存中的该数据的时候, 我们需要保证其他CPU读到的数据是Cache中的或许已经被修改后的数据\n\n\n这个问题换个说法 : 我们什么时候该将数据从Cache中写回主存\n\n写直达这个想法也是最直观的, 我们同时将数据写入CPU高速缓存和主存, 具体的写入过程是\n\nCPU写入数据, 这个数据是否在CPU Cache中\n不在 -&gt; 直接写入到主存中\n在 -&gt; 先写入到CPU Cache中, 再写入到CPU的主存中\n\n\n\n\n这个方法的局限性也明显, 不管这个数据在不在CPU高速缓存中, 只要CPU写入了数据, 都需要将数据写回主存中一次\n\n写回既然写直达每次写回操作都会将数据写回到主存中, 为了减少数据写回内存中的频率就出现了写回方法\n在写回机制中, 当写操作发生的时候, 新的数据只会被写入到cpu高速缓存中, 只有当修改过的Cache Block 被替换的时候, 才会触发将数据写回到内存中的操作, 减少了数据写回内存的频率\n\n\n这个方法一言以蔽之, 其实就是在缓存不命中的时候, 才会将被替换的缓存重新写入到主存中\n\n多核下的缓存一致性问题问题的发生\n\n加入我们现在有个变量i &#x3D; 0, 我们A核心和B核心同时运行两个线程, 分别做i++\n按照我们的预期, 最后的结果应该是2\n但是会发生, A核心给自己的缓存中的i + 1 变成1, B核心给自己的缓存中的仍为0的i + 1变成1\n\n如何解决缓存一致性问题只要保证以下两点就能做到缓存一致性\n\n写传播 : 某个CPU核心中的Cache数据更新的时候, 必须要传播到其他的核心中的Cache\n事务串行化 : 串行化也就是和并行化对立, 我们需要让操作按照顺序一一进行, 而不是同步进行, 不然就会发生\n核心A想将i &#x3D; 10, 核心B想将i &#x3D; 20, 如果不能保证事务的串行化, 我们会不知道最后i会等于多少, 因为是并行发生的(事实上是串行发生, 但是这里的并行会让我们不知道这两个操作发生的先后顺序)\n\n\n\n总线嗅探总线嗅探就是写传播的最常见实现方式, 当CPU A修改了L1Cache中的i的值的时候, 会通过总线将这个事件广播通知其他的所有的核心, 每个CPU上的核心都会监听总线上的广播事件, 并检查自己有没有相同的数据在自己的L1 Cache中, 如果有, 就会将该数据也更新到自己的L1Cache中\n\n其他核心将数据更新到自己的Cache上的过程 : 这个过程需要看写传播协议的具体实现, 有写无效协议(MESI协议就是其中之一), 写更新协议\n\n写无效协议 : 会通过总线传播一个让其他CPU将自己缓存中的数据标记的为无效数据, 在下一次访问无效数据的时候, 会发起读请求\n写更新协议 : 这个协议不同于写无效协议的按需更新, 而是推式更新, 在CPU-A发情修改以后, 会通过总线将新数据推送至其他CPU\n\n\nMESIMESI是基于总线嗅探机制实现了CPU缓存一致性的协议, 名字是四个单词的首字符缩写\n\nModified, 已修改, 缓存行被修改, 与主存不一致, 只能存在于当前处理器缓存中\nExclusive, 独占, 缓存行未被修改, 与主存一致, 只存在于当前处理器缓存中 \nShared, 共享, 缓存行未被修改, 与主存一致, 可能存在于多个处理器缓存中\nInvalidated, 缓存行失效, 不能使用\n\nMESI实现写传播机制, 通过写无效协议的方式实现事务串行化通过独占数据, 在执行写操作之前, 获取该缓存行的排他所有权 (E或M状态)\n\n\n\n当前状态\n事件\n行为\n\n\n\nI\nLocal Read\n1. 如果其他CPU中没有这个数据, 则从主存中读取这个数据, 并将数据标记为E2. 如果其他CPU中有这个数据且为M, 则将数据更新到内存中, 本地核心的缓存再从内存中读取, 并将其他CPU和自己的Cache Line都标记为S3. 如果其他核心的Cache中有这个数据, 且状态为S或E, 本地核心的Cache从缓存中读取这个数据并将这些CPU的Cache都标记为S\n\n\nI\nLocal Write\n如果其他CPU Cache中有这个数据并且为M, 则将数据先写回内存中, 再将其他的CPU中的Cache Line标记为I, 从内存中读取这个数据, 再在缓存中更新这个数据, 并将数据标记为M, 如果其他的CPU\n\n\nI\nRemote Read\n状态不变\n\n\nI\nRemote Write\n状态不变\n\n\nE\nLocal Read\n状态不变\n\n\nE\nLocal Write\n修改Cache中的数据, 状态变为M\n\n\nE\nRemote Read\n状态变为S\n\n\nE\nRemote Write\n将数据标记为I\n\n\nM\nLocal Read\n状态不变\n\n\nM\nLocal Write\n修改Cache中的数据, 状态不变\n\n\nM\nRemote Read\n将数据写回内存中, 并将状态变为S\n\n\nM\nRemote Write\n将数据写回到内存中, 并将数据标记为I\n\n\nS\nLocal Read\n状态不变\n\n\nS\nLocal Write\n如果其他CPU Cache中有这个数据, 则将数据都标记为I, 将本地的 Cache中的数据修改并标记为M\n\n\nS\nRemote Read\n状态不变\n\n\nS\nRemote Write\n将数据标记为I\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"url":"/2025/07/08/Computer_Science/Operating-System/%E7%A1%AC%E4%BB%B6%E7%BB%93%E6%9E%84/2.2%20%E4%BC%AA%E5%85%B1%E4%BA%AB/","content":"伪共享分析伪共享问题有两个不同核心的线程1和2, 他们分别要修改物理内存中相邻的变量A和B, 因为A和B在物理内存中是相邻的, 而CPU加载的最小单元是Cache, 这两个变量会被读取到同一个Cache Line中\n\n这个修改过程会是\n\n线程1:\n从内存中读取Cache Line, 变成E状态\n修改A变量, AB所在的Cache Line变成M状态\n\n\n线程2:\n读取Cache Line, 因为线程所在1的CPU Cache中有这个Cache Line, 并且状态是M\n将线程1的Cache Line写回到内存中\n线程2从内存中读取最新的A和B(但其实线程2会用到的B并没有被修改), 变成E状态\n线程1变成I状态\n线程2修改Cache Line中的B, 变成M状态\n\n\n\n我们会发现在这种情况下Cache Line直接失效了, 每次都需要从内存中读取数据, 修改以后需要将数据直接写回到内存中\n如果线程1和线程2交替执行, 我们的Cache 命中率高达0%\n解决伪共享问题很简单地我们让两个变量不要在同一个cache line中就好了, 解决思路就是padding, 我们用冗余的变量直接占满A所在的Cache Line的剩余空间, 最后A和B就会被分配到不同的Cache Line中\n\nlinux中提供了宏来实现这一点, 可以让原本是内存紧凑排列变成cache line紧凑排列\njava中也是通过padding解决\n"},{"url":"/2025/07/08/Computer_Science/Operating-System/%E7%A1%AC%E4%BB%B6%E7%BB%93%E6%9E%84/2.3%20%E8%BD%AF%E4%B8%AD%E6%96%AD/","content":"软中断软中断和硬中断操作系统在响应中断的时候, 会无法处理其他程序, 比如进程的调度, 或者无法处理其他的中断(导致中断丢失), 所以我们需要尽可能减少执行中断处理程序的事件\nLinux中讲中断分成了硬中断和软中断两部分\n\n硬中断: 上半部分直接处理硬件请求, 由硬件触发, 快速执行, 处理耗时短的任务\n软中断: 下半部分由内核触发, 延迟执行, 处理耗时较长的任务\n\n相关的命令可以通过top后按1, 查看其中的si项就能看到软中断的CPU占用\n通过cat /proc/softirqs查看各个类型的软中断的触发次数\n通过watch -d cat/proc/softirqs 看软中断的触发次数的变化速率\n通过ps aux | grep softirq查看软中断线程, 被”[]“括起来的可以一般认为是内核线程, 每个CPU都有一个内核软中断线程[ksoftirqd/x], x是CPU编号\n"},{"title":"Big-Market项目01 - 使用脚手架创建工程和push代码","url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/1.%20%E4%BD%BF%E7%94%A8%E8%84%9A%E6%89%8B%E6%9E%B6%E5%88%9B%E5%BB%BA%E5%B7%A5%E7%A8%8B%E5%92%8Cpush%E4%BB%A3%E7%A0%81/","content":"配置环境\njdk 1.8\nMaven 3.x - xfg使用的是3.8.6\n\n创建工程\n创建仓库并推送至远程仓库测试在1-xfg-app中启动Application, 看是否在8091端口启动成功\n","categories":["项目实战","Big-Market","环境搭建"],"tags":["Java","Maven","脚手架","Git","项目初始化"]},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/10.%20%E6%8A%BD%E5%A5%96%E8%A7%84%E5%88%99%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1/","content":"需求分析\n情景 : 我们原先有rule_lock这个计数锁的抽奖中规则, 现在我们需要加上对于库存的核对, 如果从库存中获取失败, 我们直接返回幸运奖\n使用原先框架的不足, 我们无法动态灵活地配置多种规则流程比如if (A -&gt; TAKE_OVER) -&gt; B else (A -&gt; ALLOW) -&gt; C这种动态且灵活的规则过滤流程\n\n解决方法\n通过决策树实现, 从根节点到叶子节点就是一条完整的规则过滤链\n我们让树的能到达左节点的前提是上一个节点是ALLOW, 达到右节点的前提是TAKE_OVER(暂时这个章节是这样, 因为还涉及RuleLimitType的值的问题)\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/11.%20%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F%E4%B8%B2%E8%81%94%E6%8A%BD%E5%A5%96%E8%A7%84%E5%88%99%20&&%20%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/","content":"需求分析\n在上一节实现了规则树模型的结构的设计, 这节我们在数据库中加上相关的关于规则树的配置的信息, rule_tree, rule_tree_node, rule_tree_node_line三个库表, \n\n\n通过从其中查到的信息构建规则树\n重构抽奖过程, 去掉filter的部分\n\n重构的流程 : 在drawio的图中有详细的描述对于设计模式的总结建造者模式 Builder说明相较于构造模式是更灵活的一种创建一个新对象的方式, 我们能任意选择该类的字段进行创建一个新的对象, 而不再是需要传入全部的参数, 或者只能按照我们有的构造方法创建新的对象\n疑惑但是其实这样的过程等同于使用setter在无参创建以后赋值, 这个设计模式主要是为了简化这个创建然后set的过程吗\n责任链说明\n执行的功能和switch case语句相似, 相当于我们构建一个case组, 并在其中选择性的break(也就是接管), 不break就会进入到下一个case(也就是放行)\n我们会顺次执行链中的事件节点, 并在当前节点判断我们是需要在这个节点就返回结果(TAKE_OVER), 还是放行进入到下一个节点继续进行下一个事件(ALLOW)\n\n对比if else的优势相较于if else肯定是在编码上更加复杂了的, 但是也带来了更多的灵活性以及非侵入式的添加这个”if else”中情况的可能遵守了OCP开闭原则\n\n灵活性 : 我们能通过配置数据库以及添加责任链节点类的实现类来为责任链中添加链结\nOCP与非侵入式 : 我们现在添加一个新的过滤规则, 不再需要修改原先的其他的链节点事件的代码, 只需要添加新的节点的代码, 数据库中的数据\n\n决策树说明\n决策树其实比起说是一个单独的设计模式, 更像是责任链设计模式的上位替代, 在决策树中我们每条从根节点到叶子节点的过滤过程就是一条过滤的责任链\n对于责任链来说, 理论上来说, 能用决策树实现的过滤流程, 我们同样能用多组责任链, 并将其中的链节连接起来的实现\n以及将这些链进行合并我们就能得到一颗树, 只不过这颗树的边只有EQUAL规则, 并且只能构造成一颗二叉树, 因为我们只有放行和接管两种选项\n\n\n\n决策树和责任链\n决策树与责任链相比, 有更灵活的方式选择这个事件现在到下一个事件之间的规则, 也就是决策树是能构建成一颗多叉树的, 因为对于每条边之间我们都能设置什么时候边的入节点才能到达这条边的出节点\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/14.%20%E6%8A%BD%E5%A5%96%E6%B4%BB%E5%8A%A8%E8%AE%A2%E5%8D%95%E6%B5%81%E7%A8%8B%E8%AE%BE%E8%AE%A1/","content":"这节做了什么\n这节主要是创建了活动抽奖的主要框架, 这个框架和strategy那边的框架其实类似\n\n\n创建各个实体类\n创建值对象\n活动状态值对象\n订单状态值对象\n\n\n创建聚合对象\n活动仓储层\n服务层 : 我们主要在这个位置实现业务逻辑\n单一功能接口IRaffleOrder : 创建订单接口\nAbstractRaffleActivity : 用于定义活动抽奖的过程\nRaffleActivityService extends AbstractRaffleActivityService : 实现抽奖的过程中的各个组件\n\n\n\n学到了什么DDD架构下的接口等的编排\n接口定义单一职责的功能 \n抽象类定义某些复杂的过程\n继承抽象类的服务类实现抽象类中的各个组件\n\nDDD中的各种类别的类VO对象\nValue Object 值对象\n\n\n与VO对象相对的就是实体对象, 这两者的核心区别是\nVO对象没有唯一ID, 里面包含了很多通用的信息, 一般来说就是一个枚举类, 相等判断基于所有的值\n不同的Entity即使值相同, 但是唯一ID不同, 也是不一样的实体, 但是但对于VO对象来说就算不是, 相等判断基于ID\n\n\n一般来说, VO对象就是一个enum类\n\nAggregate聚合对象\n用于将一组相关的对象作为一个整体\n\n优点\n\n聚合是一个事务边界, 要么整体成功, 要么整体失败\n保证了成员数据一致性, 能够同意管理一组对象 (TCP请求结构体就是一个聚合对象, 里面有各个部分, 我们使用它只需要将其作为一个整体考虑, 并且这一个整体内是保持了数据一致性)\n\n\n\n\n\n数据一致性\n数据一致性指确保数据在各个系统, 组件或操作之间保持准确, 完整和可靠的状态\n\nSKU\nstock keeping unit : 库存量单位, 代表的是活动商品的唯一标识\n\n\nSKU的作用 \nSKU中有整个活动配置的聚合\nsku\n活动ID\n次数编号\n库存剩余\n库存总量\n创建时间\n更新时间\n\n\n通过这个SKU, 我们能查到这个活动的所有信息\n\n\n同时一个SKU就是一个商品, 这些商品能共享一个活动, 这个表主要是用来解耦商品和活动\n因为我们会出现一个多个商品共享一个活动的情况, 它们共享一套配置, 比如说, 用户通过签到和充值都能获得同一个活动的奖品, 这个时候我们就能灵活地配置\n\n幂等性\n在系统设计中的含义是 : 对同一操作执行一次或者多次, 其结果应该是一样的. 通俗地说, 多次调用对系统产生的影响是一样的, 即对资源的作用是一样的\n\n\n拿数据库举例, mysql就实现了幂等性\n\nSELECT 语句不涉及对数据的变动, 天生就具有幂等性\nUPDATE, DELETE等语句多次执行的结果是一样的, 具备幂等性, (这里指的是绝对值删除, 也就是 id &#x3D; x这种)\n与之相对的, 使用相对值进行UPDATE, DELETE, 就不具备幂等性, 我们多次运行的结果是不一致的\n\n\n在这里我们SKU的设计中, outBusinessNo字段的是业务的单号, 通过这个业务单号, 我们来实现幂等性, 即使我同一个请求发送多遍, 系统也只会处理一次\n\n\n"},{"title":"Big-Market项目 - DDD领域驱动设计总结","url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/14.DDD%E6%80%BB%E7%BB%93/","content":"充血模型什么是充血模型充血模型和贫血模型的区别充血模型的优势值对象与实体对象DTOVO抽象类仓储层六边形","categories":["项目实战","Big-Market","架构设计"],"tags":["DDD","领域驱动设计","充血模型","贫血模型","VO","DTO","仓储层","六边形架构"]},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/15.%20%E6%B4%BB%E5%8A%A8%E6%8A%BD%E5%A5%96%E6%B5%81%E7%A8%8B%E5%AE%9E%E7%8E%B0/","content":"实现了什么\n这节课主要实现了活动抽奖的下单的整个流程\n\n\n为活动抽奖的下单装配了责任链, 用于过滤活动下单动作\n活动的库存时间校验\n活动sku库存\n\n\n为下单这个操作实现了操作的事务一致性, 以及幂等性\n\n学到了什么如何保证一个多部份组成的订单是事务一致的聚合对象\n通过将多部份组合成一整个整体- 聚合对象 - 订单\n我们通过操作和管理, 并通过这个对象进行数据库操作, 保证了成员数据一致性\n\n事务上的一致性\n我们已经传进来了一个订单聚合对象\n\n分库分表上的一致性\n为用户创建路由键\n通过这个路由键, 我们能保证对于一个用户, 他的订单相关的操作都会被路由到同一个数据库中操作, 这样我们就能更方便得保证事务一致性\n而不需要分布式的事务一致性, 分布式的事务一致性的保证是安全度更低, 效率更低的方法\n\n\n\n编程式事务 : TransactionTemplate\nTransactionTemplate 是Spring提供用于事务管理的Bean, 比声明式的(@Transactional) 更加地灵活, 颗粒度更小\n\n\n这个Bean是怎么保证事务一致性的\n\nexecute(status -&gt; &#123;    // 1. 开启事务    // 获取数据库连接    // 设置自动提交为false    // 2. 执行业务逻辑    orderDao.insert();    accountDao.update();    // 3. 提交事务    // 如果没有异常, 则事务管理器自动提交    return true;&#125;) catch(Exception1 e) &#123;    // 4. 回滚事务    status.setRollbackOnly();    throw e;&#125; catch(Exception2 e) &#123;    // 不需要回滚的事务    throw e;&#125;\n\n声明式事务\n这个方式会直接将一个方法都视作一个事务, 灵活度更低, 但是侵入性更弱, 毕竟只用加个注解就行\n\n\n最佳实践\n\n@Servicepublic class OrderService &#123;        // 1. 方法级别注解优先于类级别    @Transactional(rollbackFor = Exception.class)    public void createOrder(OrderDTO orderDTO) &#123;        // 事务操作    &#125;        // 2. 只读事务优化    @Transactional(readOnly = true)    public OrderDTO getOrder(Long orderId) &#123;        return orderDao.selectById(orderId);    &#125;        // 3. 超时设置    @Transactional(timeout = 30)    public void longTimeOperation() &#123;        // 长时间操作    &#125;&#125;\n\n\n\n\n\n\n\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/12.%20%E4%B8%8D%E8%B6%85%E5%8D%96%E5%BA%93%E5%AD%98%E8%A7%84%E5%88%99%E5%AE%9E%E7%8E%B0/","content":"需求说明我们现在需要实现库存的扣减, 同时为了加速, 我们需要将这个扣减的过程放到redis中进行, 并通过锁机制保证不超卖. 同时实现异步的定时地执行数据库中数据更新(延时队列 + 定时任务)\n业务流程\nBefore  将所有奖品的库存数据装配至redis缓存中\n\n一条删减信息在业务中经过的流程redis中删减 -&gt; 删减成功 -&gt; 是否超卖 -&gt; 没有超卖 -&gt; 延迟队列 -&gt; 定时任务数据库修改数据\n\n\nRedis的作用\n缓存\n将库存的信息加载进内存中, 让用户面向的数据实际上是redis缓存中的数据, 这样由磁盘IO变为内存IO, 加快了处理速度\n同时减小了数据库的负载, 不用频繁地获取和释放连接\n\n\n加锁兜底\n对已经执行过获取的奖品在缓存中进行加锁记录(strategyId_awardId_surplus), 这样无论发生了什么会导致数据异常的情况, 我们都不会发生超卖事件.\n已经出现过的surplus剩余数量我们都会记录下来, 哪怕数据错误恢复, 多加了库存数量, 我们在访问到这个库存数量的时候, 也会因为这个库存数量我们已经加过锁, 所以访问失败\n\n\n消息队列\n我们将redis中的延迟队列当成消息队列使用, 让数据库定期从消息队列中获取任务, 执行更新操作, 这样均衡了数据库的负载, 进行了削峰\n\n\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/16.%20%E5%BC%95%E5%85%A5MQ%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8SKU%E5%BA%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/","content":"实现了什么实现的内容\n和前面实现策略奖品扣减一样实现了加锁的在缓存中的扣减库存操作, 同时延迟队列延迟将数据库更新操作加入队列以减轻数据库压力, 数据库定时异步更新\n\n额外加上了MQ, 如果缓存中剩余库存扣减至0, 直接清空队列(延时队列和阻塞队列), 并发送请求将数据库中的剩余库存清空至0 \n对于并发量很高的情况, 比如秒杀这种情景, 通过消息队列能有效减少对数据库的操作数量\n\n\n填充实现了责任链中的具体的过滤逻辑和对于责任链的组装\n\n\n学到了什么库存扣减流程\n算是重温了一遍在第一阶段中的库存扣减操作, 同时加上了MQ额外处理库存变成0的情况\n\n预处理\n预热, 将sku商品的数量加载到redis缓存中\n\n库存扣减\n责任链过滤\n\n用户发送请求扣减库存 -&gt; skuRecahrgeCard实体对象(商品充值实体) -&gt; 责任链过滤请求(确保请求是正确, 需要被响应的请求) -&gt; 活动状态是open -&gt; 在活动时间内 -&gt; 活动sku库存数量 &gt; 0 -&gt; 扣减库存校验责任链 (尝试进行扣减操作, 确保扣减成功, 这种时候才会返回订单号)\n\n\n库存扣减\n\n尝试通过仓储层扣减redis中的库存\n扣减完毕得到扣减后的库存数量 &gt; 0 : 说明是合理的扣减\n检验这个库存是不是扣减过\n没有扣减过 -&gt; 将这个剩余库存加锁 -&gt; 将扣减更新数据库的信息添加到延迟队列中 -&gt;  返回扣减成功 \n扣减过 -&gt; 说明这个库存扣减过, 出现错误, 返回扣减失败\n\n\n\n\n&#x3D;&#x3D; 0 : 说明这个时候刚好将所有的库存扣减完了, 走特殊处理 -&gt; 将Message发布到RabbitTemplate中 -&gt; ActivitySkuStockZeroCustomer监听这个特殊处理的信息 -&gt; 听到以后, 将库存清零, 将队列清空\n\n\n\n\n\n扣减库存中的数据一致性保证\nredis的decr操作本身就带有原子性, 能保证用户扣减缓存中的库存是原子的\n通过给扣减过的库存加锁, 保证了库存不会在运营错误配置的情况下超卖\n异步的数据库同步保证了最终一致性\n\n削峰操作\n该操作主要是为了减少数据库的压力\n\n\n异步的定时数据库IO, 而非实时的更新任务\nMQ消息队列处理为零的特殊情况, 直接一步到位, 只需要设置一次值就完成了延迟队列里的更新任务, 只需要执行一次更新操作\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/17.%20%E7%94%A8%E4%BA%8E%E9%A2%86%E5%8F%96%E6%B4%BB%E5%8A%A8%E5%BA%93%E8%A1%A8%E8%AE%BE%E8%AE%A1/","content":"实现了什么库表设计\n因为账户可用抽奖次数, 为了应对复杂的实际需求, 我们是为一个账户设置了日次数, 月次数, 总次数的限制, 这个时候如果我们在扣减额度的时候是扣减这张账户表中的次数, 则还需要在特定的时间恢复库存\n\n\n这个时候我们还要额外记录我们要恢复的次数数量 (因为这个次数是可能会发生变化的, 比如有什么奖励是增加最大抽奖次数) \n所以我们干脆直接再设置一个表, 用于存储用户可用的次数的表, 我们在这个表中执行扣减, 原先的表就相当于一个镜像表(就像我们记录了最大生命值一样, 然后在新的游戏中扣减生命值, 新的游戏再恢复)\n\nTODO\n扣减额度的库表任务很明显和用户订单需要在一个事务中完成 (通过聚合对象 + 事务实现?)\n获取到订单了以后, 通过抽奖策略计算, 我们得到抽奖奖品\n将抽到的奖品通过发送MQ发送出去\n维护一个task表, 依靠task表的备份, 我们通过定时job扫描task表, 重新发送未成功的MQ消息\n\n\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/18.%20%E9%A2%86%E5%8F%96%E6%B4%BB%E5%8A%A8%E6%89%A3%E5%87%8F%E8%B4%A6%E6%88%B7%E9%A2%9D%E5%BA%A6/","content":"实现了什么service分层将用户抽奖流程分成\n\n用户添加额度 \n领取活动 (扣减互动账户额度)\n执行抽奖策略\n抽奖结果落库\n\n这节课主要实现的是第二个部分, 领取活动, 同时我们将原先实现的进行了分层, 以和领取活动部分进行切分\n\n我们可以将这部分分成两部分\n创建充值订单, 为用户增加抽奖次数, 这里创建的是活动订单记录, 表明有人参与了活动, 获取了额度, 这个时候聚合对象传递的就有添加的次数\n这里的订单更多的是起到的记录的作用, 在数据库中记录用户获取次数额度的获取记录\n同时将额度的增加落库\n\n\n创建用户额度扣减订单, 如果用户有额度创建订单, 创建订单, 这里的订单是执行抽奖的消耗, 是一个下单记录\n\n\n\n账户额度的扣减和恢复\n在之前我们只有一个表的时候, 我们就需要在对应的时间执行恢复额度操作\n现在我们创建了月账户表, 日账户表, 两个表分别对应了用户这个月 &#x2F; 天可用的额度\n那么在这个时候, 如果我们要执行用户账户额度的扣减\n将总账户, 月账户, 日账户, 三个账户中的额度都执行扣减\n总账户的中的镜像月余额和镜像日余额里面的值, 是我们能最多分配给这个月&#x2F;日的额度, 如果这个活动有多个月, 那么下个月, 我们能分配给这个用户的月额度还需要收到总额度的限制, 总账户中的镜像额度就是为了约束这个点, 我们不能每个月都分配给用户相同的额度剩余量\n\n\n\n\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/20.%20%E6%8A%BD%E5%A5%96%E6%B4%BB%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%B8%B2%E8%81%94/","content":"开发需求\n开发内容1；串联整个抽奖流程，提供 API\n开发内容2；提供以活动为主导的，预热装配动作\n开发内容3；抽奖策略模块中，校验账户额度。【之前的一个策略规则，需要根据已经抽奖次数进行解锁】\n开发内容4；存放抽奖结果后，更新用户参与活动时的抽奖单状态为已使用。\n\ncase层\n该层也叫application层用于编排领域来实现新的业务, 提高了领域模块的复用性, 同时能实现更加复杂的功能\n\n\n但是在像我们这样实现目的相对单一的业务. 我们只需要controller编排业务即可\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/19.%20%E5%86%99%E5%85%A5%E4%B8%AD%E5%A5%96%E8%AE%B0%E5%BD%95%E5%92%8C%E4%BB%BB%E5%8A%A1%E8%A1%A5%E5%81%BF%E5%8F%91%E9%80%81MQ/","content":"为什么使用MQ发奖\n对于用户中奖到发奖, 通常来说我们会做异步解耦\n\n\n这里需要做异步解耦的原因是\n因为一些发奖的方法并不都是在抽奖系统, 而是我们需要通过各种RPC&#x2F;HTTP接口来发放\n但是我们需要考虑我们调用这些方法出现异常的时候, 这个时候我们就需要重发\n\n\n\n为什么需要任务补偿机制\n我们需要保证写入记录和发送MQ消息(也就是调用发奖的接口执行发奖)的一致性, 保证这两个必须同时成功或者同时失败, 但是我们是无法通过数据库事务来保证这个事情, MQ消息不是数据库事务\n\n\n引入task表, 用于记录我们需要发送的所有消息, 并在其中标记这条消息的状态\n\ncreate : 还没有被消费\ncomleted : 这条消息已经被消费了 \nfail : 这条消息被尝试消费过, 但是失败了\n\n\n对于创建了但是过了很久还没有被消费的消息, 以及消费失败的消息, 我们执行定时重发\n\n我们通过定时任务, 扫描task表, 找出符合项, 执行重发\n\n\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/21.%20%E6%B4%BB%E5%8A%A8%E4%BF%A1%E6%81%AFAPI%E8%BF%AD%E4%BB%A3%E5%92%8C%E5%8A%9F%E8%83%BD%E5%AE%8C%E5%96%84/","content":"对DDD的新的理解角度 - Maven依赖\n今天在写第21节的时候想在trigger层直接调用dao接口的时候, 突然发现是无法import进来的, 一看pom, 果然里面是没有导入系统模块infrastructure的. 只有types, domain, api层是被导入了的. 为什么要这么设计? 是不是每个pom文件都是这样有限的导入部分系统模块? 这个和DDD之间有什么关系\n\n模块之间的依赖关系\ntrigger\ntypes\ndomain\napi\n\n\ninfrastructure\ndomain\ntypes\n\n\ndomain\ntypes\n\n\napp\ntrigger\ninfrastructure\ntypes\ndomain\napi\n\n\napi \ntypes\n\n\n\n通过pom规定层间的交互模式\n为什么repository的接口放在domain层, 但是实现需要放在infrastructure层?\n\n\n在逻辑上和结构上, xfg之前有说过domain层在这里只定义自己和infrastructure层交互的形式(接口), 但是我一直没有想到的是对于这个理念, 我们也是有实际的约束的\n通过pom文件, 我们规定了每个 层 之间的访问的限制\n\n这样做的好处\n有限的暴露既保证了规范性, 在domain层我们无法直接调用infrastructure层的接口, 只能通过repository中规定的接口, 有限地访问资源\n防止项目扁平化, MVC化, domain想要访问infrastructure层的内容, 必须也只能经由repository, 这样便于项目的管理和后期的拓展维护, 我们想知道我们增加&#x2F;减少一个需求, 我们只需要顺着层次之间自上到下就能修改我们所有的内容\n彻底的职责分离, 上层为下层提供接口, 我想访问什么内容, 下层为上层实现具体的访问, 我该怎么做才能访问到对应的内容\n接口是上层向下层暴露的需求, 作为开发人员, 能在开发该层的过程中不再关心除了该层以外的内容\n\n\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/22.%20MQ%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E5%92%8C%E9%87%8D%E5%8F%91%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93/","content":"为什么我们需要使用MQ\n假设我们现在有个情景是我们买一个东西以后会为我们添加会员积分, 或者是秒杀场景等高并发场景\n\n\n系统解耦\n使用MQ为生产者和消费者之间解耦, 一方面解决了服务之间的强依赖问题(微服务, 分布式系统), 即使消费者宕机, 消息仍然会存储再队列中, 待恢复后消费\n能保证各个服务之间的相对独立, 其中一个崩溃不会导致整个链路都受到影响\n\n\n异步处理\n消费者异步处理任务, 下单以后, 订单系统立即返回成功相应让用户看到自己的订单记录和获取的物品, 但实际上将发奖等操作异步完成\n提高了系统的并发能力, 同时减少了不必要的等待, 我们不必非得等在数据库中将奖品发出去以后, 再让用户看到自己中了什么奖\n\n\n流量削峰\n我们可以将消息存入MQ中, 让消费者根据自己的消费能力进行消费, 为生产和消费之间解耦合\n\n\n\n数据一致性\n因为我们要在两个节点之间同步消息, 那么就会带来数据一致性问题, 消息生产端和消息消费端之间的消息数据一致性问题\n\n会碰到的问题\n消息丢失 : 在本地执行完事务以后, 在发送MQ消息的环节出现问题, 导致消息丢失\n消息重复消费 : 因为网络等原因, MQ在队列中重复存储, 这个时候消费端会重复消费一条消息\n生产者和消费者的事务一致性问题 : 消息发送成功, 但是业务失败, 以及业务成功但消息发送失败\n\n解决方案消息丢失 &amp; 事务一致性问题\n创立一个Task表, 在发送mq之前, 执行业务时, 将消息存入数据库中, 保证业务和消息存入数据库之间的事务一致性, 在数据库中标记这条消息状态为create\n\n事务结束, 发送MQ消息\n\n发送成功, 将数据库中的这条消息标记为completed\n发送失败, 标记消息为fail\n\n\n创建job, 定时扫描task库, 从中获取状态是fail或者是create的消息, 重新发送\n\n\n重复消费\n换个说法就是我们如何保证消费端的幂等性\n为每个订单生成全局唯一ID来保证幂等性\n获取全局ID的方式\n数据库自增主键\nUUID\nRedis\n\n\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/23.%20%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E8%BF%94%E5%88%A9%E7%BB%93%E7%AE%97/","content":"实现的内容\n添加上了用户行为返利的customer, 对库表的设计更清晰了点, 原来RebateConfig里面配置的是这个行为返利返的的东西\n因为返利的是额度, 也就是为用户添加抽奖等额度, 所以过程就是\n监听到的用户的行为 -&gt; 为用户创建充值卡 -&gt; 对应的充值卡ID(类型) 就是 RebateConfig中配置的内容\n使用充值卡为用户充值\n\n\n\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/26.%20%E7%A7%AF%E5%88%86%E9%A2%86%E5%9F%9F%E8%B0%83%E9%A2%9D%E6%9C%8D%E5%8A%A1/","content":""},{"title":"Big-Market项目03 - 设计库表","url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/3.%20%E8%AE%BE%E8%AE%A1%E5%BA%93%E8%A1%A8/","content":"章节内容\n这个章节简单地说明了下核心业务 - 抽奖功能\n\n针对我们抽奖的功能, 创建了三个表\n\n策略总表 strategy : 用于存储抽奖策略的最宏观的信息\n策略奖品 strategy_award : 用于存储某个抽奖策略下的奖品\n抽奖规则 strategy_rule : 用于存储某个什么样的条件能抽中这个奖品这种抽奖规则\n\n库表3.1 策略总表CREATE TABLE `strategy` (`id` bigint(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;自增ID&#x27;,`strategy_id` bigint(8) NOT NULL COMMENT &#x27;抽奖策略ID&#x27;,`strategy_desc` varchar(128) NOT NULL COMMENT &#x27;抽奖策略描述&#x27;,`create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;,`update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;,PRIMARY KEY (`id`),KEY `idx_strategy_id` (`strategy_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;  LOCK TABLES `strategy` WRITE;/*!40000 ALTER TABLE `strategy` DISABLE KEYS */;  INSERT INTO `strategy` (`id`, `strategy_id`, `strategy_desc`, `create_time`, `update_time`)VALUES(1,100001,&#x27;抽奖策略&#x27;,&#x27;2023-12-09 09:37:19&#x27;,&#x27;2023-12-09 09:37:19&#x27;);\n\n3.2 策略奖品CREATE TABLE `strategy_award` (`id` bigint(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;自增ID&#x27;,`strategy_id` bigint(8) NOT NULL COMMENT &#x27;抽奖策略ID&#x27;,`award_id` int(8) NOT NULL COMMENT &#x27;抽奖奖品ID - 内部流转使用&#x27;,`award_title` varchar(128) NOT NULL COMMENT &#x27;抽奖奖品标题&#x27;,`award_subtitle` varchar(128) DEFAULT NULL COMMENT &#x27;抽奖奖品副标题&#x27;,`award_count` int(8) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;奖品库存总量&#x27;,`award_count_surplus` int(8) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;奖品库存剩余&#x27;,`award_rate` decimal(6,4) NOT NULL COMMENT &#x27;奖品中奖概率&#x27;,`rule_models` varchar(256) DEFAULT NULL COMMENT &#x27;规则模型，rule配置的模型同步到此表，便于使用&#x27;,`sort` int(2) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;排序&#x27;,`create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;,`update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;修改时间&#x27;,PRIMARY KEY (`id`),KEY `idx_strategy_id_award_id` (`strategy_id`,`award_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;  LOCK TABLES `strategy_award` WRITE;/*!40000 ALTER TABLE `strategy_award` DISABLE KEYS */;  INSERT INTO `strategy_award` (`id`, `strategy_id`, `award_id`, `award_title`, `award_subtitle`, `award_count`, `award_count_surplus`, `award_rate`, `rule_models`, `sort`, `create_time`, `update_time`)VALUES(1,100001,101,&#x27;随机积分&#x27;,NULL,80000,80000,80.0000,&#x27;rule_random,rule_luck_award&#x27;,1,&#x27;2023-12-09 09:38:31&#x27;,&#x27;2023-12-09 10:58:06&#x27;),(2,100001,102,&#x27;5次使用&#x27;,NULL,10000,10000,10.0000,&#x27;rule_luck_award&#x27;,2,&#x27;2023-12-09 09:39:18&#x27;,&#x27;2023-12-09 10:34:23&#x27;),(3,100001,103,&#x27;10次使用&#x27;,NULL,5000,5000,5.0000,&#x27;rule_luck_award&#x27;,3,&#x27;2023-12-09 09:42:36&#x27;,&#x27;2023-12-09 10:34:24&#x27;),(4,100001,104,&#x27;20次使用&#x27;,NULL,4000,4000,4.0000,&#x27;rule_luck_award&#x27;,4,&#x27;2023-12-09 09:43:15&#x27;,&#x27;2023-12-09 10:34:25&#x27;),(5,100001,105,&#x27;增加gpt-4对话模型&#x27;,NULL,600,600,0.6000,&#x27;rule_luck_award&#x27;,5,&#x27;2023-12-09 09:43:47&#x27;,&#x27;2023-12-09 10:34:26&#x27;),(6,100001,106,&#x27;增加dall-e-2画图模型&#x27;,NULL,200,200,0.2000,&#x27;rule_luck_award&#x27;,6,&#x27;2023-12-09 09:44:20&#x27;,&#x27;2023-12-09 10:34:26&#x27;),(7,100001,107,&#x27;增加dall-e-3画图模型&#x27;,&#x27;抽奖1次后解锁&#x27;,200,200,0.2000,&#x27;rule_lock,rule_luck_award&#x27;,7,&#x27;2023-12-09 09:45:38&#x27;,&#x27;2023-12-09 10:30:59&#x27;),(8,100001,108,&#x27;增加100次使用&#x27;,&#x27;抽奖2次后解锁&#x27;,199,199,0.1999,&#x27;rule_lock,rule_luck_award&#x27;,8,&#x27;2023-12-09 09:46:02&#x27;,&#x27;2023-12-09 12:20:52&#x27;),(9,100001,109,&#x27;解锁全部模型&#x27;,&#x27;抽奖6次后解锁&#x27;,1,1,0.0001,&#x27;rule_lock,rule_luck_award&#x27;,9,&#x27;2023-12-09 09:46:39&#x27;,&#x27;2023-12-09 12:20:50&#x27;);\n\n\n\n3.3 策略规则CREATE TABLE `strategy_rule` (`id` bigint(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &#x27;自增ID&#x27;,`strategy_id` int(8) NOT NULL COMMENT &#x27;抽奖策略ID&#x27;,`award_id` int(8) DEFAULT NULL COMMENT &#x27;抽奖奖品ID【规则类型为策略，则不需要奖品ID】&#x27;,`rule_type` tinyint(1) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;抽象规则类型；1-策略规则、2-奖品规则&#x27;,`rule_model` varchar(16) NOT NULL COMMENT &#x27;抽奖规则类型【rule_random - 随机值计算、rule_lock - 抽奖几次后解锁、rule_luck_award - 幸运奖(兜底奖品)】&#x27;,`rule_value` varchar(64) NOT NULL COMMENT &#x27;抽奖规则比值&#x27;,`rule_desc` varchar(128) NOT NULL COMMENT &#x27;抽奖规则描述&#x27;,`create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;,`update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;,PRIMARY KEY (`id`),KEY `idx_strategy_id_award_id` (`strategy_id`,`award_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;  LOCK TABLES `strategy_rule` WRITE;/*!40000 ALTER TABLE `strategy_rule` DISABLE KEYS */;  INSERT INTO `strategy_rule` (`id`, `strategy_id`, `award_id`, `rule_type`, `rule_model`, `rule_value`, `rule_desc`, `create_time`, `update_time`)VALUES(1,100001,101,2,&#x27;rule_random&#x27;,&#x27;1,1000&#x27;,&#x27;随机积分策略&#x27;,&#x27;2023-12-09 10:05:30&#x27;,&#x27;2023-12-09 12:55:52&#x27;),(2,100001,107,2,&#x27;rule_lock&#x27;,&#x27;1&#x27;,&#x27;抽奖1次后解锁&#x27;,&#x27;2023-12-09 10:16:41&#x27;,&#x27;2023-12-09 12:55:53&#x27;),(3,100001,108,2,&#x27;rule_lock&#x27;,&#x27;2&#x27;,&#x27;抽奖2次后解锁&#x27;,&#x27;2023-12-09 10:17:43&#x27;,&#x27;2023-12-09 12:55:54&#x27;),(4,100001,109,2,&#x27;rule_lock&#x27;,&#x27;6&#x27;,&#x27;抽奖6次后解锁&#x27;,&#x27;2023-12-09 10:17:43&#x27;,&#x27;2023-12-09 12:55:54&#x27;),(5,100001,107,2,&#x27;rule_luck_award&#x27;,&#x27;1,100&#x27;,&#x27;兜底奖品100以内随机积分&#x27;,&#x27;2023-12-09 10:30:12&#x27;,&#x27;2023-12-09 12:55:55&#x27;),(6,100001,108,2,&#x27;rule_luck_award&#x27;,&#x27;1,100&#x27;,&#x27;兜底奖品100以内随机积分&#x27;,&#x27;2023-12-09 10:30:43&#x27;,&#x27;2023-12-09 12:55:56&#x27;),(7,100001,101,2,&#x27;rule_luck_award&#x27;,&#x27;1,10&#x27;,&#x27;兜底奖品10以内随机积分&#x27;,&#x27;2023-12-09 10:30:43&#x27;,&#x27;2023-12-09 12:55:57&#x27;),(8,100001,102,2,&#x27;rule_luck_award&#x27;,&#x27;1,20&#x27;,&#x27;兜底奖品20以内随机积分&#x27;,&#x27;2023-12-09 10:30:43&#x27;,&#x27;2023-12-09 12:55:57&#x27;),(9,100001,103,2,&#x27;rule_luck_award&#x27;,&#x27;1,30&#x27;,&#x27;兜底奖品30以内随机积分&#x27;,&#x27;2023-12-09 10:30:43&#x27;,&#x27;2023-12-09 12:55:58&#x27;),(10,100001,104,2,&#x27;rule_luck_award&#x27;,&#x27;1,40&#x27;,&#x27;兜底奖品40以内随机积分&#x27;,&#x27;2023-12-09 10:30:43&#x27;,&#x27;2023-12-09 12:55:59&#x27;),(11,100001,105,2,&#x27;rule_luck_award&#x27;,&#x27;1,50&#x27;,&#x27;兜底奖品50以内随机积分&#x27;,&#x27;2023-12-09 10:30:43&#x27;,&#x27;2023-12-09 12:56:00&#x27;),(12,100001,106,2,&#x27;rule_luck_award&#x27;,&#x27;1,60&#x27;,&#x27;兜底奖品60以内随机积分&#x27;,&#x27;2023-12-09 10:30:43&#x27;,&#x27;2023-12-09 12:56:00&#x27;),(13,100001,NULL,1,&#x27;rule_weight&#x27;,&#x27;6000,102,103,104,105,106,107,108,109&#x27;,&#x27;消耗6000分，必中奖范围&#x27;,&#x27;2023-12-09 10:30:43&#x27;,&#x27;2023-12-09 12:58:21&#x27;),(14,100001,NULL,1,&#x27;rule_blacklist&#x27;,&#x27;1&#x27;,&#x27;黑名单抽奖，积分兜底&#x27;,&#x27;2023-12-09 12:59:45&#x27;,&#x27;2023-12-09 13:42:23&#x27;);\n\n\n测试验证\n创建完库表以后, 将建表语句导出到 docs&#x2F;dev-ops&#x2F;mysql&#x2F;sql, 如果到处的库表语句没有create创建库可以自己添加\n\nCREATE database if NOT EXISTS `big_market` default character set utf8mb4 collate utf8mb4_0900_ai_ci;use `big_market`;\n\n\n重新执行docker-compose安装, 确保可以自动创建库表, 登录localhost:8899查看, 这一步骤能有利于以后的云服务部署应用\n\n","categories":["项目实战","Big-Market","数据库设计"],"tags":["数据库设计","MySQL","抽奖策略","库表设计"]},{"title":"Big-Market项目04 - 基础层持久化数据配置","url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/4.%20%E5%9F%BA%E7%A1%80%E5%B1%82%E6%8C%81%E4%B9%85%E5%8C%96%E6%95%B0%E6%8D%AE/","content":"章节介绍为持久层建立基本的ORM\n准备工作\n创建新的分支 250217-func-orm\n将新的分支push\n\n1. 创建实体类1.0 常用的快捷键和IDEA对于文件注释的自动生成1.0.1 常用的win快捷键\n通过这些快捷键, 我们能快速从库表中将信息提取出来构建实体类\n\n\nShift + Alt : 选中多列的内容\nAlt + 上下拖动 : 光标选中多列\n\n1.0.2 IDEA对于class文件注释的自动生成\n在Editor的File and Code Templates里面找到class, 添加上\n\n/**  * @ClassName $&#123;NAME&#125;  * @Description TODO  * @Author: func  * @Date $&#123;DATE&#125; $&#123;TIME&#125;  * @Version 1.0  */\n之后就会在创建class文件的时候自动生成文件注释\n1.1 创建Strategy类package com.func.infrastructure.persistent.po;    import lombok.Data;    import java.util.Date;    @Data  public class Strategy &#123;      /**自增ID */      private Long id;      /**抽奖策略ID */      private Long strategyId;      /**策略模型 */      private String ruleModel;      /**抽奖策略描述 */      private String strategyDesc;      /**创建时间 */      private Date createTime;      /**更新时间 */      private Date updateTime;  &#125;\n\n1.2 StrategyAwardpackage com.func.infrastructure.persistent.po;    import lombok.Data;    /**   * @ClassName StrategyAward   * @Description 抽奖策略奖品明细配置 - 概率, 规则   * @Author: func   * @Date 2025/2/17 21:46   * @Version 1.0   */  @Data  public class StrategyAward &#123;        /** 规则模型, rule配置规则记录*/      private String ruleModels;      /** 自增ID*/      private String id;      /** 抽奖策略ID*/      private String strategyId;      /** 抽奖奖品ID*/      private String awardId;      /** 抽奖奖品标题*/      private String awardTitle;      /** 抽奖奖品副标题*/      private String awardSubtitle;      /** 奖品库存总量*/      private String awardCount;      /** 奖品库存剩余*/      private String awardCountSurplus;      /** 中奖概率*/      private String awardRate;      /** 奖品在转盘上的排序*/      private String sort;      /** 创建时间*/      private String createTime;      /** 更新时间*/      private String updateTime;  &#125;\n\n1.3 StrategyRulepackage com.func.infrastructure.persistent.po;    import lombok.Data;    /**   * @ClassName StrategyRule   * @Description 策略规则   * @Author: func   * @Date 2025/2/17 21:52   * @Version 1.0   */  @Data  public class StrategyRule &#123;      /** 自增ID*/      private String id;      /** 策略ID*/      private String strategyId;      /** 抽奖ID*/      private String awardId;      /** 抽奖规则类型 [1-策略类型, 2-奖品类型]*/      private String ruleType;      /** 抽奖规则类型 [rule_lock]*/      private String ruleModel;      /** 抽奖规则比值*/      private String ruleValue;      /** 抽奖规则描述*/      private String ruleDesc;      /** 创建时间*/      private String createTime;      /** 更新时间*/      private String updateTime;  &#125;\n\n1.4 Awardpackage com.func.infrastructure.persistent.po;import lombok.Data;import java.util.Date;/** * @ClassName Award * @Description 奖品的详细信息 - 配置参数, 奖品key, 奖品类型 * @Author: func * @Date 2025/2/17 22:21 * @Version 1.0 */@Datapublic class Award &#123;    /** 自增ID*/    private Long id;    /** 奖品ID*/    private Integer awardId;    /** 奖品描述*/    private String awardDesc;    /** 奖品种类key, 用于匹配奖品种类*/    private String awardKey;    /** 奖品的配置参数, 如奖品模型类型等*/    private String awardConfig;    /** 创建时间*/    private Date createTime;    /** 更新时间*/    private Date updateTime;&#125;\n\n2. 创建Dao层\n比较简单的创建了每个实体pojo类的xml和Dao层mapper\n\n这里不再赘述\n3. 执行测试对每个Dao进行的测试所有的功能\n@RunWith(SpringRuner.class)用于在测试开始的时候创建Spring应用的上下文\n","categories":["项目实战","Big-Market","持久层设计"],"tags":["ORM","MyBatis","持久层","实体类","数据库映射","Big-Market"]},{"title":"Big-Market项目05 - 概率策略装配处理算法实现","url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/5.%20%E6%A6%82%E7%8E%87%E7%AD%96%E7%95%A5%E8%A3%85%E9%85%8D%E5%A4%84%E7%90%86/","content":"1. 需求\n在这章节我们要解决的需求是 : 实现概率抽奖, 也就是我们在库表strategy_award中记录了每个奖品的中奖概率, 那么我们怎么实现这个概率呢?\n\n2. 实现需求的逻辑\n假设我们有3个商品, 它们中奖的概率分别是0.3, 0.5, 0.2\n\n2.1 if-else我们可以写个if-else语句, 抽奖就是获取一个随机数, 让随机数 % 10, 如果随机数是0 ~ 2, 就是中奖了奖品1, 如果是3~7就是中奖了奖品2, 如果是8 ~ 9就是中奖了奖品3\nint rand = repository.getRateRange() % 10;if (rand &lt; 2) // 奖品1else if (rand &lt; 7) // 奖品2else if (rand &lt; 9) // 奖品3\n\n\n但是有限的if-else表达的内容是有限的, 我们不可能未来添加了一个商品, 就再添加一个if-else, 这样维护的成本太高了, 并且如果我们如果修改了之前的某个概率, 那么关于范围又要重新计算\n\n2.2 占位法我们转化下概率问题, 我们创建一个数组, 其中有10格, 那么只要其中的3格记录的是奖品1, 其中的5格是奖品2, 2格奖品3. 那么我们随机获取一个0~9的数字, 将这个数字视作key从这个数组中索引内容, 得到奖品编号, 这样的过程也能保证抽奖的概率\n\n在实际的实现中, 我们将 “数组”放在Redis中缓存, 用于加快访问的速度, 并且我们只需要创建一次映射关系就能全局使用\n\n3. 代码实现框架3.1 关键类\nIStrategyArmory : 策略装配工厂, 负责初始化策略的计算, 将概率数组初始化并存到redis中\nboolean assembleLotteryStrategy(Long strategyId) : 用于初始化策略装配, 将策略缓存到redis中\nInteger getRandomAwardId(Long strategyId); : 执行一次抽奖, 传入策略ID, 返回抽到的奖品号AwardId\n\n\nIStrategyRepository : 策略的仓储接口, 这个类的职责是和Redis和MySQL数据库对接\nList&lt;StrategyAwardEntity&gt; queryStrategyAwardList(Long strategyId); 从Redis中查找这个策略的Id对应的策略奖品实体列表, 如果没有找到则从数据库中重新查找, 并将内容存进Redis中\nvoid storeStrategyAwardRateTables(Long strategyId, Integer rateRange, HashMap&lt;Integer, Integer&gt; shuffleStrategyAwardSearchRateTables); 存储抽奖策略范围值和概率查找表 (进Redis?), 概率查找表\nint getRateRange(Long strategyId);  通过strategyId, 从Redis中查询到独赢的概率范围\nInteger getStrategyAwardAssemble(Long strategyId, int rateKey); 通过StrategyId和rateKey从Redis中查询到的对应的奖品ID\n\n\nIRedisService : 从Redis从存储和查询数据\n\n3.2 类的实现说明3.2.1 StrategyReposityList&lt;StrategyAwardEntity&gt; queryStrategyAwardList(Long strategyId);\n代码流程\n\n\n先尝试从Redis中获取缓存\n判断缓存是否为空, 也就是我们有没有成功地获取缓存, 成功获取了, 则在这个位置返回策略奖品实体\n从数据库中需要的策略ID的对应的策略奖品PO列表, 通过Dao层的queryStrategyAwardByStrategyId方法\n将PO列表转化为DO\n将DO列表存储进Redis中, 返回DO列表\n\n3.2.2 StrategyArmory\n这个类是这个分支的核心代码, 用于实现装配概率的核心逻辑\n\nboolean assembleLotteryStrategy(Long strategyId);\n这个类是其中最核心的方法, 执行了从获取StrategyAwardEntities列表, 并将其转化为概率数组存放进Redis中的过程\n\n\n从策略仓储层查询到这个策略ID对应的策略奖品实体列表 (会调用StrategyRepository中的queryStrategyAwardList方法) \n流式处理从获取到的策略奖品实体列表中获取到最小的概率\n先将List转化为流\n通过map()将StrategyAwardEntity映射为从其中getAwardRate方法获取到的值\n再通过BigDecimal::compareTo方法获取到其中的最小值\n通过orElse如果流为空的时候则返回BigDecimal.ZERO\n\n\n获取概率值的总和\nmap映射为getAwardRate\n通过reduce(BigDecimal::add)方法, 将所有的值加起来\n\n\n用概率总和 &#x2F; 最小概率值, 获取到总共的格子数\n生成概率查找表\n循环遍历每个StrategyAwardEntity, 对于每个Entity, 计算它需要的格子数, 并将它的Id作为格子的内容添加到Map中格子数次\n\n\n对生成的查找表进行乱序处理\n最后生成对应的Map集合\n将Map集合存放到Redis中 (调用repository中的storeStrategyAwardSearchRateTable)\n\n@Slf4j@Servicepublic class StrategyArmory implements IStrategyArmory &#123;    @Resource    private IStrategyRepository repository;    @Override    public boolean assembleLotteryStrategy(Long strategyId) &#123;        // 1. 查询策略配置        List&lt;StrategyAwardEntity&gt; strategyAwardEntities = repository.queryStrategyAwardList(strategyId);        // 2. 获取最小概率值        BigDecimal minAwardRate = strategyAwardEntities.stream()                .map(StrategyAwardEntity::getAwardRate)                .min(BigDecimal::compareTo)                .orElse(BigDecimal.ZERO);        // 3. 获取概率值总和        BigDecimal totalAwardRate = strategyAwardEntities.stream()                .map(StrategyAwardEntity::getAwardRate)                .reduce(BigDecimal.ZERO, BigDecimal::add);        // 4. 用 1 % 0.0001 获得概率范围，百分位、千分位、万分位        BigDecimal rateRange = totalAwardRate.divide(minAwardRate, 0, RoundingMode.CEILING);        // 5. 生成策略奖品概率查找表「这里指需要在list集合中，存放上对应的奖品占位即可，占位越多等于概率越高」        List&lt;Integer&gt; strategyAwardSearchRateTables = new ArrayList&lt;&gt;(rateRange.intValue());        for (StrategyAwardEntity strategyAward : strategyAwardEntities) &#123;            Integer awardId = strategyAward.getAwardId();            BigDecimal awardRate = strategyAward.getAwardRate();            // 计算出每个概率值需要存放到查找表的数量，循环填充            for (int i = 0; i &lt; rateRange.multiply(awardRate).setScale(0, RoundingMode.CEILING).intValue(); i++) &#123;                strategyAwardSearchRateTables.add(awardId);            &#125;        &#125;        // 6. 对存储的奖品进行乱序操作        Collections.shuffle(strategyAwardSearchRateTables);        // 7. 生成出Map集合，key值，对应的就是后续的概率值。通过概率来获得对应的奖品ID        Map&lt;Integer, Integer&gt; shuffleStrategyAwardSearchRateTable = new LinkedHashMap&lt;&gt;();        for (int i = 0; i &lt; strategyAwardSearchRateTables.size(); i++) &#123;            shuffleStrategyAwardSearchRateTable.put(i, strategyAwardSearchRateTables.get(i));        &#125;        // 8. 存放到 Redis        repository.storeStrategyAwardSearchRateTable(strategyId, shuffleStrategyAwardSearchRateTable.size(), shuffleStrategyAwardSearchRateTable);        return true;    &#125;\n\npublic Integer getRandomAwardId(Long strategyId)\n通过StrategyId获取到这个策略对应的rateRange\n然后生成一个0 ~ rateRange - 1范围内的值, 执行并通过repository中的getStrategyAwardAssemble方法传入一个随机数, 执行一次抽奖\n\n","categories":["项目实战","Big-Market","抽奖算法"],"tags":["抽奖策略","Big-Market","概率抽奖","算法设计","随机算法","概率分布"]},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/6.%20%E6%9D%83%E9%87%8D%E8%A3%85%E9%85%8D%E5%A4%84%E7%90%86/","content":"需求说明\n我们需要实现不同等级的人, 他能抽到的奖品种类是不一样的, 这里的分类法则在这里主要体现为已经抽了多少积分, 我们可以理解为, 抽了4000积分以后, 他有一个奖品范围A, 抽了5000积分以后有个新的奖品范围B, 类推\n\n库表在strategy_rule库表的字段rule_model下有条数据是rule_weight, 这行数据的rule_value : 4000:102,103,104,105 5000:102,103,104,105,106,107 6000:102,103,104,105,106,107,108,109\n在strategy库表的字段rule_models下数据中记录了这个策略装载了哪些策略模式\n实现流程0. 怎么实现在特定范围内进行抽奖?\n其实主思路很简单, 先查询获取所有的奖品实体类, 将奖品Id不在范围内的排除掉就好了\n\n1. 将原先的装配概率查找表的函数进一步抽象private void assembleLotteryStrategy(String key, List\\&lt;StrategyAwardEntity&gt; strategyAwardEntities)\n\n这个函数的是我们从public boolean assembleLotteryStrategy(Long strategyId)中抽取出来的函数, 通过我们实现在特定范围内进行抽奖的思路, 我们需要将原先的根据strategyId查询到所有的StrategyAwardEntities装配概率查找表的函数后面的装配概率查找表的部分抽象出来, 这样我们就能根据strategyAwardEntities和key装配一个rateTable进Redis中\n\n\n实际的函数就是将原先的函数中的从第二步开始的步骤抽取成一个函数\n\nprivate void assembleLotteryStrategy(String key, List&lt;StrategyAwardEntity&gt; strategyAwardEntities) &#123;    // 1. 获取最小的概率值    BigDecimal minAwardRate = strategyAwardEntities.stream()            .map(StrategyAwardEntity::getAwardRate)            .min(BigDecimal::compareTo)            .orElse(BigDecimal.ZERO);    // 2. 概率值总和    BigDecimal totalAwardRate = strategyAwardEntities.stream()            .map(StrategyAwardEntity::getAwardRate)            .reduce(BigDecimal.ZERO, BigDecimal::add);    // 3. 计算总共需要多少个格子, 也就是概率范围    BigDecimal rateRange = totalAwardRate.divide(minAwardRate, 0, RoundingMode.CEILING);    // 4. 生成概率奖品查找表    List&lt;Integer&gt; strategyAwardSearchRateTable = new ArrayList&lt;&gt;(rateRange.intValue());    for (StrategyAwardEntity strategyAwardEntity : strategyAwardEntities) &#123;        Integer awardId = strategyAwardEntity.getAwardId();        BigDecimal awardRate = strategyAwardEntity.getAwardRate();        for (int i = 0; i &lt; rateRange.multiply(awardRate).setScale(0, RoundingMode.CEILING).intValue(); i++) &#123;            strategyAwardSearchRateTable.add(awardId);        &#125;    &#125;    // 5. 将查找表乱序    Collections.shuffle(strategyAwardSearchRateTable);    // 6. 将查找表转化为Map集合    Map&lt;Integer, Integer&gt; shuffleStrategyAwardSearchRateTable = new HashMap&lt;&gt;();    for (int i = 0; i &lt; strategyAwardSearchRateTable.size(); i++) &#123;        shuffleStrategyAwardSearchRateTable.put(i, strategyAwardSearchRateTable.get(i));    &#125;    // 7, 将Map集合存入Redis中    repository.storeStrategyAwardRateTables(key, shuffleStrategyAwardSearchRateTable.size(), shuffleStrategyAwardSearchRateTable);\n\n2. 既能装配完整配置, 也能装配权重配置的函数public boolean assembleLotteryStrategy(Long strategyId)\n通过这个函数我们需要实现原先的概率的装配也需要实现权重策略的装配\n\n我们同样需要装配原先的不包含权重的概率查找表, 这个时候的key就是strategy_id\n\n// 1. 查询配置信息List&lt;StrategyAwardEntity&gt; strategyAwardEntities = repository.queryStrategyAwardList(strategyId);assembleLotteryStrategy(String.valueOf(strategyId), strategyAwardEntities);\n\n\n检查当前抽奖策略中有没有权重的配置, 如果没有则不进行配置\n\n// 2. 权重策略配置 - 适用于 rule_weight 权重规则配置StrategyEntity strategyEntity =  repository.queryStrategyEntityByStrategyId(strategyId);String ruleWight = strategyEntity.getRuleWeight();// 如果没有权重策略的配置if (null == ruleWight) return true;\n\n从StrategyRuleEntity中获取到将装配的权重进行了解析后的Map&lt;String, List&lt;Integer&gt;&gt;, 后面的List中存的就是这个权重策略对应的AwardId\n\nStrategyRuleEntity strategyRuleEntity = repository.queryStrategyRule(strategyId, ruleWight);if(null == strategyRuleEntity) &#123;    throw new AppException(ResponseCode.STRATEGY_RULE_WEIGHT_IS_NULL.getCode(), ResponseCode.STRATEGY_RULE_WEIGHT_IS_NULL.getInfo());&#125;Map&lt;String, List&lt;Integer&gt;&gt; ruleWeightValueMap = strategyRuleEntity.getRuleWeightValue();\n\n遍历所有的key, 也就是遍历所有的配置方法, 创建新的策略奖品实体列表副本, 从其中删除不List中的AwardId, 再将这个新的副本传进前面抽象出来的方法中, 创建新的概率搜索表\n\nSet&lt;String&gt; keys = ruleWeightValueMap.keySet();for (String key : keys) &#123;    List&lt;Integer&gt; ruleWeightValues = ruleWeightValueMap.get(key);    ArrayList&lt;StrategyAwardEntity&gt; strategyRuleEntitiesClone = new ArrayList&lt;&gt;(strategyAwardEntities);    strategyRuleEntitiesClone.removeIf(entity-&gt; !ruleWeightValues.contains(entity.getAwardId()));    assembleLotteryStrategy(String.valueOf(strategyId).concat(&quot;_&quot;).concat(key), strategyRuleEntitiesClone);&#125;\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/7.%20%E6%8A%BD%E5%A5%96%E5%89%8D%E7%BD%AE%E8%A7%84%E5%88%99%E8%BF%87%E6%BB%A4/","content":"需求说明我们想实现黑名单这类的风控方法以及我们之前想实现的让用户在消费了一定量的积分以后会变更能抽中的奖品范围这类的抽奖的前置规则配置\n库表中的修改\n在strategy_rule表中rule_model是rule_blacklist的那行数据中, 修改rule_value中为具体的值100:user001,user002,user003\n在award中的添加一个award_id是100的黑名单奖品, 这个奖品就是黑名单用户的积分保底\n\ndrawio\n该章节关于逻辑和类的解释, 通过drawio诠释, 通过文字, 很难表述清楚复杂的交互逻辑和结构性\n\ndraw.io\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/8.%20%E6%8A%BD%E5%A5%96%E4%B8%AD%E7%BD%AE%E8%A7%84%E5%88%99%E8%BF%87%E6%BB%A4/","content":"需求说明\n在上一章节的基础上, 我们已经完成了整个过滤的框架的搭建\n\n这个章节我们主要完成了两件事\n\n在框架上\n加上了中置规则的ddoCheckRaffleLogic\n添加了StrategyRuleModelVO VO对象, 用于解析获取到的奖品rule为之分类\n\n\n在内容上\n增加了中置规则的过滤, 修改了performRaffle()方法\n\n\n\ndrawio抽奖中置规则过滤\n"},{"url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/9.%20%E4%BD%BF%E7%94%A8%E8%B4%A3%E4%BB%BB%E9%93%BE%E5%A4%84%E7%90%86%E6%8A%BD%E5%A5%96%E8%A7%84%E5%88%99/","content":"需求说明\n这个章节主要是使用责任链重构了抽奖前置规则过滤的代码\n\ndrawiodrawio\n"},{"title":"Big-Market项目部署指南 - Docker和环境配置","url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/deployment/","content":"dockerdocker engine部署 - Ubuntusee Docker docs - Ubuntu for more details\n\n设置Docker apt仓库\n\n# Add Docker&#x27;s official GPG key:sudo apt-get updatesudo apt-get install ca-certificates curlsudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.asc# Add the repository to Apt sources:echo \\  &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\  $(. /etc/os-release &amp;&amp; echo &quot;$&#123;UBUNTU_CODENAME:-$VERSION_CODENAME&#125;&quot;) stable&quot; | \\  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get update\n\n\n安装docker 其中只有docker engine, 不包含docker-compose\n\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n\n测试安装\n\nsudo docker run hello-world\n\ndocker-compose部署-Ubuntu需要完成上面的前置步骤\nsee Docker-compose docs for more details\n\n下载和安装Docker Compose standalone\n\ncurl -SL https://github.com/docker/compose/releases/download/v2.35.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose\n\n\n添加可执行权限给docker-compose文件\n\nchmod +x /usr/local/bin/docker-compose\n\n\n添加软链接\n\nsudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\n\ndocker网络代理配置只给bash配置了网络代理是不够的, docker有自己的网络设置, 不会自动使用系统或bash配置中的代理\n\n创建或编辑Docker配置文件 (我喜欢用vim)\n\nsudo vim /etc/docker/daemon.json\n\n\n添加或修改配置\n\n&#123;  &quot;proxies&quot;: &#123;    &quot;http-proxy&quot;: &quot;http://proxy:port&quot;,    &quot;https-proxy&quot;: &quot;http://proxy:port&quot;,    &quot;no-proxy&quot;: &quot;localhost,127.0.0.1&quot;  &#125;&#125;\n\n\n重启docker服务\n\nsudo systemctl restart docker\n\ndocker的一些简单的配置, 更方便的使用see linux-postinstall docs for more details\n如何避免每次都使用sudo在用户中运行docker需要root权限, 需要sudo才能执行\n\n创建docker组\n\nsudo groupadd docker\n\n\n添加当前用户到docker group中\n\nsudo usermod -aG docker $USER\n\n\n激活对于组的变动\n\nnewgrp docker\n\n\n验证现在运行docker不需要sudo了\n\ndocker run hello-world\n\n开机自启动\n开启docker自启动和container自启动\n\nsudo systemctl enable docker.servicesudo systemctl enable containerd.service\n\n\n关闭自启动\n\nsudo systemctl disable docker.servicesudo systemctl disable containerd.service\n\n查看docke的配置信息\n总的信息\n\ndocker info\n\n\n代理信息\n\ndocker info | grep -i proxy\n\n\n\n\n\npotainer一个docker的GUI管理界面\n下载配置好docker engine以后\n\n​\t拉取\n\ndocker pull portainer/portainer\n\n\n安装和启动 ( 阿里云的服务器还需要先执行 docker volume crete portainer_data)\n\ndocker run -d --restart=always --name portainer -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer\n\n接下来就能通过服务器IP:9000访问portainer了 \n文件权限查看文件的权限\n查看当前文件夹下的所有文件的权限\n\nls -la\n\n\n查看某个文件的详细信息\n\nstat &lt;file-name&gt;\n\n\n文件权限信息解读\n\ndrwxr-xr-x 4 simon simon 4096 Apr 11 21:04 .drwxr-xr-x 4 simon simon 4096 Apr 11 21:04 ..-rw-r--r-- 1 simon simon 1460 Apr 11 21:27 docker-compose-app.yml\n\n开头的第一个字符表明这是个目录文件还是个文件文件(d : 目录, - : 文件)\n后面每三个字符为一组, 每组r : 读权限, w : 写权限, x : 执行权限, - : 说明这个权限没有\n三组权限分别是 : 用户权限, 组权限, 其他用户的权限\n第一个名称simon是文件所属的用户名称, 第二个是这个文件所属的组名称\n修改文件的权限不使用root用户登录的时候, 文件的权限问题还是挺让人恼火的\n\n修改文件的所有权\n\nsudo chown user:group &lt;file-name&gt;\n\n\n更改文件的权限\n\nsudo chmod 666# 这个数字是权限的缩写, 第一个数字是user的权限# 第二个数字就是group的权限, 第三个数字是others的权限# 每组权限中# r 表示读权限(read)，数值为4# w 表示写权限(write)，数值为2# x 表示执行权限(execute)，数值为1# - 表示没有对应的权限# 所以666代表的权限就是 rw-rw-rw# 再比如 644 就是权限 rw-r--r--\n\n\n递归修改文件的权限\n\nsudo chmod -R ...\n\n网络配置代理配置\n为当前bash配置代理\n\nexport http_proxy=&quot;http://IP:port&quot;export https_proxy=&quot;https://IP:port&quot;\n\n\n将配置添加到配置文件中, 添加到~&#x2F;.bashrc中即可\n检查配置是否生效\n\ncurl -v www.google.com\n\nJava运行环境配置Java JDK\n查看所有的apt缓存中的JDK版本\n\nsudo apt-cache search jdk\n\n\n选个自己要的版本下载\n\nsudo apt install openjdk-8-jdk -y\n\n\n配置下JAVA_HOME等信息\n\nexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\n\n检测安装\n\njava --version\n\n\n\nmaven因为看了下apt中的maven倒也还挺新的, 就直接用的apt下载\n\n安装\n\nsudo apt install maven -y\n\n\n检测安装\n\nmvn --version\n\n\n\n\n\n\n\n","categories":["项目实战","Big-Market","部署运维"],"tags":["Docker","部署","Ubuntu","docker-compose","环境配置","运维"]},{"title":"Big-Market项目问题记录 - Redis锁解决间隙锁问题","url":"/2025/07/08/Project/Big-Market/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%9C%AA%E7%90%86%E8%A7%A3%E7%9A%84%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","content":"1. 第26节中的redis锁用于避免间隙锁问题- 这里的间隙锁问题到底是什么\n- 这里的redis锁的作用是什么, 解决了什么情景下的什么问题, 没搞懂这\n\nfix : 增加redis锁, 避免产生间隙锁问题问题原来的代码\nraffleActivityOrderDao.insert(raffleActivityOrder);// 2. 更新账户 - 总int count = raffleActivityAccountDao.updateAccountQuota(raffleActivityAccount);// 3. 创建账户 - 更新为0，则账户不存在，创新新账户if (0 == count) &#123;    raffleActivityAccountDao.insert(raffleActivityAccount);&#125;// 4. 更新账户 - 月                    raffleActivityAccountMonthDao.addAccountQuota(raffleActivityAccountMonth);                    // 5. 更新账户 - 日                    raffleActivityAccountDayDao.addAccountQuota(raffleActivityAccountDay);\n\n\n问题\n\n在update失败的时候会因为使用的是非唯一索引, 所以会导致间隙锁的产生, 而间隙锁是一个范围锁, 因为这个范围锁, 我们会出现死锁的情况\n事务A 尝试更新(user_id &#x3D; 4, activity_id &#x3D; 100)的账户, 由于记录不存在, 获取(3,100)到(5, 150)之间的锁\n事务B 尝试更新(user_id &#x3D; 4, activity_id &#x3D; 200) 的账户, 由于记录不存在, 同样获取(3,100)到(5, 150)的间隙锁\n事务A 执行插入操作, 获取插入意向锁, 但被事务B的间隙锁阻塞\n事务B 执行插入操作, 获取插入意向锁, 但被事务A的间隙锁阻塞\n形成了死锁\n\n\n解决方式\n\n先查询, 再执行更新或者插入, 不会产生间隙锁, 通过RLock保证并发情况的原子性\n\n\n\n","categories":["项目实战","Big-Market","问题解决"],"tags":["MySQL","间隙锁","Redis锁","死锁","并发控制","数据库优化"]},{"title":"AI-Agent项目解析01 - 架构概览和Controller层分析","url":"/2025/07/08/Project/ai-agent/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/ai-agent-0/","content":"ai-agent-0自上而下的阅读, 优先理解整个业务框架, 可以看作是对于业务建模的逆推\nController文件夹位置: trigger-http\n比起细读每个controller的实现细节, 这部分在最开始阅读的时候, 我更倾向于关注更宏观的controller实现的功能, 避免在最开始的时候迷失在细节里面, 因为很多要想理解很多细节往往依托于对于整个业务框架的理解\n通过大致理解每个controller的功能, 初步搭建起来整个ai-agent的业务\n这步需要删繁就简, 删去和业务不直接相关的部分\nService-Controller业务核心相关的Controller部分, 这部分同样是不纠结于具体的实现, 我们只关注实现的业务是怎么样的, 这里只有一个Controller(其实在api层里的service就能看出来, 那里也只有一个service接口), 同时不同于CRUD相关的Controller我们是对持久化对象删繁就简, 这里我们是对业务删繁就简, 只留下来核心的处理来串联业务\npreheatpublic Response&lt;Boolean&gt; preheat(@RequestParam(&quot;aiAgentId&quot;) Long aiClientId) &#123;    log.info(&quot;预热装配 AiAgent &#123;&#125;&quot;, aiClientId);    aiAgentPreheatService.preheat(aiClientId);&#125;\n\n根据aiClientId预热指定client的配置, 如果想进一步查看预热的内容, 我们就需要去查看preheat的具体实现\nchatAgent public Response&lt;String&gt; chatAgent(@RequestParam(&quot;aiAgentId&quot;) Long aiAgentId, @RequestParam(&quot;message&quot;) String message) &#123;     log.info(&quot;AiAgent 智能体对话，请求 &#123;&#125; &#123;&#125;&quot;, aiAgentId, message);     String content = aiAgentChatService.aiAgentChat(aiAgentId, message);&#125;\n\n指定AgentId进行对话\nchatStreampublic Flux&lt;ChatResponse&gt; chatStream(@RequestParam(&quot;aiAgentId&quot;) Long aiAgentId, @RequestParam(&quot;ragId&quot;) Long ragId, @RequestParam(&quot;message&quot;) String message) &#123;        log.info(&quot;AiAgent 智能体对话(stream)，请求 &#123;&#125; &#123;&#125; &#123;&#125;&quot;, aiAgentId, ragId, message);        return aiAgentChatService.aiAgentChatStream(aiAgentId, ragId, message);&#125;\n\n指定aiagent并携带rag进行流式对话\nuploadRagFilepublic Response&lt;Boolean&gt; uploadRagFile(@RequestParam(&quot;name&quot;) String name, @RequestParam(&quot;tag&quot;) String tag, @RequestParam(&quot;files&quot;) List&lt;MultipartFile&gt; files) &#123;        log.info(&quot;上传知识库，请求 &#123;&#125;&quot;, name);        aiAgentRagService.storeRagFile(name, tag, files);&#125;\n\n上传知识库文件, 并未rag打上tag和name\nCRUD-Controller其实在实际阅读的时候, 这种CRUD的方法都可以直接跳过, 毕竟不涉及业务逻辑, 大部分也不会什么细节设计, 简单读下注释和@Resource发现只有dao的时候就大概知道可以跳过了, 但是需要在这个地方重点关注CRUD处理的对象, 需要有个印象, 同时删除掉id&#x2F;name&#x2F;createtime之类的属性, 留下来需要重点关注的和业务相关的属性记录下来\nAiAdminAgentClientController\n@RequestMapping(value = &quot;queryAgentClientList&quot;, method = RequestMethod.POST)    public ResponseEntity&lt;List&lt;AiAgentClient&gt;&gt; queryAgentClientList(@RequestBody AiAgentClient aiAgentClient) &#123;        List&lt;AiAgentClient&gt; aiAgentClientList = aiAgentClientDao.queryAgentClientList(aiAgentClient);        return ResponseEntity.ok(aiAgentClientList);    &#125;\n\n方法内部就是简单的根据入参获取所有AI智能体客户端, 根据SQL语句中的查询条件, 可以发现这里是通过传入的aiAgentClient中的有的信息来搜索出来所有满足条件的client, 这里的入参就像是一些软件上的筛选标签, 只有这些tag的结果才会被显示出\n\n通过这个方法能实现根据条件获取所有满足条件的AiAgentClient的业务, 可以通过这个实现最开始的所有的client的展示, 只要入参是空就行, 也就是没有筛选条件\n同时是分页返回(这里因为使用了offset, 会有深度分页的问题, 不过就这个查询体量这个问题还不需要被关心就是了, 不会影响啥性能)\n\n\n剩下的方法就是同样的CRUD, 不额外说明\n\n​     根据ID查询AI智能体客户端关联\n​     根据智能体ID查询客户端关联列表\n​     根据客户端ID查询智能体关联列表\n​     新增AI智能体客户端关联\n​     更新AI智能体客户端关联\n​     删除AI智能体客户端关联\n\n不过这里能发现智能体和客户端之间是有差异的, 同时通过client_id和agent_id连接\n下面是这个Controller CRUD的实体对象的定义\npublic class AiAgentClient extends Page &#123;    private Long id;    private Long agentId;    private Long clientId;    /**     * 序列号(执行顺序)     */    private Integer sequence;    private Date createTime;&#125;\n\n继承Page是为了便于实现分页\npublic class Page &#123;    /**     * 当前页码     */    private int pageNum = 1;    /**     * 每页条数     */    private int pageSize = 10;    /**     * 总条数     */    private long total;    /**     * 总页数     */    private int pages;    public int getOffset() &#123;        return (pageNum - 1) * pageSize;    &#125;    public int getLimit() &#123;        return pageSize;    &#125;&#125;\n\nAiAdminAgentController这个Controller是对于AiAgent持久化对象的CRUD, 内容不赘述\n - 分页查询AI智能体列表\n - 根据channel查询AI智能体列表\n - 根据ID查询AI智能体\n - 新增AI智能体\n - 更新AI智能体\n - 删除AI智能体\n\n需要关注的是AiAgent这个持久化对象的属性\npublic class AiAgent extends Page &#123;    private Long id;    private String agentName;    private String description;    /**     * 渠道类型(agent，chat_stream)     */    private String channel;    /**     * 状态(0:禁用,1:启用)     */    private Integer status;        private Date createTime;    private Date updateTime;&#125;\n\n需要后续重点关注的是channel属性的作用\nAiAdminAgentTaskScheduleControllerCRUD的方法\n\n分页查询AI代理任务调度列表\n\n根据ID查询AI代理任务调度\n\n新增AI代理任务调度\n\n更新AI代理任务调度\n\n删除AI代理任务调度\n\n只留下来的和业务代码高度相关的部分\n\n\npublic class AiAgentTaskSchedule extends Page &#123;        /**     * 任务描述     */    private String description;    /**     * 智能体ID     */    private Long agentId;    /**     * 时间表达式(如: 0/3 * * * * *)     */    private String cronExpression;        /**     * 任务入参配置(JSON格式)     */    private String taskParam;    private Integer status;&#125;\n\n这里看到我们能创建定时task, 定时执行某个agent, 通过cron表达式来设置定时任务的执行频次\nAiAdminClientAdvisorConfigController\n分页查询客户端顾问配置列表\n\n根据ID查询客户端顾问配置\n\n根据客户端ID查询顾问配置列表\n\n新增客户端顾问配置\n\n更新客户端顾问配置\n\n删除客户端顾问配置\n\n智能体顾问的配置对象\n\n\npublic class AiClientAdvisorConfig extends Page &#123;    /**     * 客户端ID     */    private Long clientId;    /**     * 顾问ID     */    private Long advisorId;&#125;\n\n将client和advisor通过id关联起来\nAiAdminClientAdvisorController对AiClientAdvisord的CRUD\nclass AiClientAdvisor extends Page &#123;    /**     * 顾问类型(PromptChatMemory/RagAnswer/SimpleLoggerAdvisor等)     */    private String advisorType;    /**     * 扩展参数配置，json 记录     */    private String extParam;    /**     * 状态(0:禁用,1:启用)     */    private Integer status;&#125;\n\n顾问类型, PromptChatMemory类型的功能应该是预定义了提示词, RagAnswer是前面的结合了Rag知识库的顾问, SimpleLoggerAdvisor是日志分析? 这个暂时不知道\nCRUD的方法\n\n分页查询客户端顾问列表\n根据ID查询客户端顾问\n新增客户端顾问\n更新客户端顾问\n删除客户端顾问\n\nAiAdminClientModelConfigController对AiClientModelConfig的CRUD\npublic class AiClientModelConfig extends Page &#123;    /**     * 客户端ID     */    private Long clientId;    /**     * 模型ID     */    private Long modelId;&#125;\n\n将Client与model绑定起来的config类, 用于持久化这个client使用的模型?\nCRUD的方法\n\n分页查询客户端模型配置列表\n根据ID查询客户端模型配置\n根据客户端ID查询模型配置\n根据模型ID查询客户端模型配置列表\n新增客户端模型配置\n更新客户端模型配置\n删除客户端模型配置\n\nAiAdminClientModelController对AiClientModel的CRUD\nAiClientModel: 标准的模型API配置类, 其中需要额外解释的是completionsPath和embeddingsPath, 同时需要将其与AiClientModelConfig区分开来, 后者只是为了建立model和client的关联关系的对象\n\ncompletionsPath: 用于支持对话功能, 指定AI模型文本生成&#x2F;对话完成功能的API端点路径, 用于构建完整的API请求URL，调用模型的文本生成服务\nembeddingsPath: 用于支持rag功能, 指定AI模型向量嵌入功能的API端点路径, 用于将文本转换为向量表示，支持语义搜索、相似度计算等功能\n\npublic class AiClientModel extends Page &#123;        /**    * 主键ID    */    private Long id;    /**     * 模型名称     */    private String modelName;    /**     * 基础URL     */    private String baseUrl;    /**     * API密钥     */    private String apiKey;    /**     * 完成路径     */    private String completionsPath;    /**     * 嵌入路径     */    private String embeddingsPath;    /**     * 模型类型(openai/azure等)     */    private String modelType;    /**     * 模型版本     */    private String modelVersion;    /**     * 超时时间(秒)     */    private Integer timeout;    /**     * 状态(0:禁用,1:启用)     */    private Integer status&#125;\n\nCRUD的方法\n\n分页查询客户端模型列表\n查询所有的模型的配置\n根据ID查询客户端模型\n新增客户端模型\n更新客户端模型\n删除客户端模型\n\nAiAdminClientSystemPromptController对AiClientSystemPrompt的CRUD\nAiClientSystemPrompt: 提示词持久化对象\npublic class AiClientSystemPrompt extends Page &#123;    /**     * 主键ID     */    private Long id;    /**     * 提示词内容     */    private String promptContent;    /**     * 状态(0:禁用,1:启用)     */    private Integer status;&#125;\n\nCRUD的方法\n\n分页查询系统提示词列表\n查询所有系统提示词列表\n根据ID查询系统提示词\n新增系统提示词\n更新系统提示词\n删除系统提示词\n\nAiAdminClientToolConfigController对AiClientToolConfig的CRUD\nAiClientToolConfig: 用于将tool和client_id关联起来, 同时说明这个工具的类型, 有MCP和function call作为可选项\npublic class AiClientToolConfig extends Page &#123;    /**     * 客户端ID     */    private Long clientId;    /**     * 工具类型(mcp/function call)     */    private String toolType;    /**     * 工具ID(MCP ID/function call ID)     */    private Long toolId;&#125;\n\nCRUD方法\n\n分页查询客户端工具配置列表\n根据ID查询客户端工具配置\n根据客户端ID查询工具配置列表\n新增客户端工具配置\n更新客户端工具配置\n删除客户端工具配置\n\nAiAdminClientToolMcpController对AiClientToolMcp的CRUD\nAiClientToolMcp: 对于MCP工具的配置信息的记录, 其中需要注意的字段是transportType和transportConfig\ntransportType: 传输类型(sse&#x2F;stdio)\n\nSSE(Server-Sent Events): 使用远程MCP服务, 比如百度AI搜索这种, 往往需要有apikey进行验证\n基于HTTP的实时通信协议\n适用于远程MCP服务器\n通过HTTP连接进行数据传输\n\n\nSTDIO: 本地部署的MCP服务\n基于进程间通信\n适用于本地MCP服务器\n通过命令行启动和管理\n\n\n\ntransportConfig: 传输配置, 简单来说就是MCP的一切配置信息\n\n连接参数\nSSE模式：配置远程服务的URL、端点路径、认证信息\nSTDIO模式：配置本地进程的启动命令和参数\n\n\n认证信息\n\n\nAPI密钥、令牌等安全凭证\n支持不同服务商的认证方式\n\n\n服务发现\n\n\n指定具体的MCP服务器地址\n配置服务端点和路径\n\n\n运行环境\n\n\nSTDIO模式下的JVM参数\n进程启动环境变量\n\npublic class AiClientToolMcp extends Page &#123;    /**     * MCP名称     */    private String mcpName;    /**     * 传输类型(sse/stdio)     */    private String transportType;    /**     * 传输配置     */    private String transportConfig;    /**     * 请求超时时间(分钟)     */    private Integer requestTimeout;    /**     * 状态(0:禁用,1:启用)     */    private Integer status;&#125;\n\nCRUD方法\n\n分页查询MCP配置列表\n根据ID查询MCP配置\n新增MCP配置更新MCP配置\n更新MCP配置\n删除MCP配置\n\nAiAdminRagOrderController对AiRagOrder的CRUD\nAiRagOrder: 知识库的订单, 这里的订单不是真的什么下单的那个订单, 这里只是一种抽象的业务模型, 下单-处理业务-返回处理结果\npublic class AiRagOrder extends Page &#123;     /**     * 主键ID     */    private Long id;    /**     * 知识库名称     */    private String ragName;    /**     * 知识标签     */    private String knowledgeTag;    /**     * 状态(0:禁用,1:启用)     */    private Integer status;&#125;\n\nCRUD的方法\n\n分页查询RAG订单列表\n查询所有RAG订单列表\n根据ID查询RAG订单\n新增RAG订单\n更新RAG订单\n删除RAG订单\n\n总结\ntaskSchedule: 定时任务调度, task绑定agentId, 通过corn表达式设置任务定时策略, 通过taskParam配置, 这里的业务流程可能是通过业务系统创建定时任务, 根据配置信息, 调用某个agent执行配置信息中的任务\nAdvisor: 存在多种类型的顾问, 调用知识库的, 带prompt的, 还有一个未知的simplelogger, 同时advisor绑定client, advisor可以看作是提供了提问的配置信息, 你可以根据不同的配置来进行不同类型的提问\nmodel: 模型的配置信息, 一个配置信息也就代表了一个模型实体, model和client绑定\nTool: AI可以使用的工具(MCP等)的配置信息, tool和client绑定\nRag: 存储在PG数据库里面, MySQL里面只记录了id, name, tag等信息\\\nclient: 绑定advisor, model, tool, 一个AI服务的实体, 定义了这个服务使用的tool, advisor配置信息, model模型配置信息\nagent: 绑定多个client, 是一个综合AI服务的实体, 一个agent能通过绑定多个client, 并定义执行顺序, 完成对多个client的串联, 实现复杂的AI服务\n\n","categories":["项目实战","AI-Agent","架构分析"],"tags":["DDD","AI-Agent","Spring AI","架构分析","Controller","业务建模"]},{"title":"AI-Agent项目解析02 - preheat预热机制深度解析","url":"/2025/07/08/Project/ai-agent/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/ai-agent-1/","content":"ai-agent-1-preheat解析接着上篇对于Controller的解析, 我们现在需要深入到service-controller中的domain层的具体实现, 来看详细看业务的实现\n按照实际业务流程-preheat -&gt; ragupload -&gt; chat -&gt; task的顺序解析\n这篇主要解析preheat方法(也是实现最复杂的一个)\npreheat解析\nAiAgentPreheatService中的preheat\n\npublic void preheat(Long aiClientId) throws Exception &#123;    StrategyHandler&lt;AiAgentEngineStarterEntity, DefaultArmoryStrategyFactory.DynamicContext, String&gt; handler = defaultArmoryStrategyFactory.strategyHandler();    handler.apply(AiAgentEngineStarterEntity.builder()                  .clientIdList(Collections.singletonList(aiClientId))                  .build(), new DefaultArmoryStrategyFactory.DynamicContext());&#125;\n\n可以看到这里这个方法主要就是从规则树工厂defaultArmoryStrategyFactory中获取到根节点, 然后执行整颗树(这部分的具体实现是在扳手工程中, 可以看我在扳手工程下写的作业)\n\n这里简单说明下这个规则树框架怎么使用, 类继承AbstractMultiThreadStrategyRouter&lt;T, D, R&gt;, 每个树节点通过重写get方法的返回来控制下一个要访问的节点, 重写doapply()方法来处理这个节点要处理的业务流程, 重写multiThread()来异步加载数据\n\n我们可以大致知道preheat有一个预热的流程, 按着树逐步完成预热, 顺着树读流程就能知道preheat整个流程\n规则树的工厂public class DefaultArmoryStrategyFactory &#123;    @Resource    private ApplicationContext applicationContext;    private final RootNode rootNode;    public StrategyHandler&lt;AiAgentEngineStarterEntity, DefaultArmoryStrategyFactory.DynamicContext, String&gt; strategyHandler() &#123;        return rootNode;    &#125;    public ChatClient chatClient(Long clientId) &#123;        return (ChatClient) applicationContext.getBean(&quot;ChatClient_&quot; + clientId);    &#125;    public ChatModel chatModel(Long modelId) &#123;        return (ChatModel) applicationContext.getBean(&quot;AiClientModel_&quot; + modelId);    &#125;    @Data    @Builder    @AllArgsConstructor    @NoArgsConstructor    public static class DynamicContext &#123;        private int level;        private Map&lt;String, Object&gt; dataObjects = new HashMap&lt;&gt;();        public &lt;T&gt; void setValue(String key, T value) &#123;            dataObjects.put(key, value);        &#125;        public &lt;T&gt; T getValue(String key) &#123;            return (T) dataObjects.get(key);        &#125;    &#125;&#125;\n\n上面的strategyHandler()方法向外暴露了规则树的根节点chatClient()与chatModel()方法从applicationContext中获取Bean说明在别的业务代码中我们会运行时创建bean\nDynamicContext中level记录了现在在树中的深度, dataObjects就是运行时上下文的记录\nAbstractArmorySupportRootNode继承自AbstractArmorySupport我们还得先从这个类开始看\npublic abstract class AbstractArmorySupport extends AbstractMultiThreadStrategyRouter&lt;AiAgentEngineStarterEntity, DefaultArmoryStrategyFactory.DynamicContext, String&gt; &#123;    private final Logger log = LoggerFactory.getLogger(AbstractArmorySupport.class);    @Resource    protected ApplicationContext applicationContext;    @Resource    protected ThreadPoolExecutor threadPoolExecutor;    @Resource    protected IAgentRepository repository;    /**     * 通用的Bean注册方法     *     * @param beanName  Bean名称     * @param beanClass Bean类型     * @param &lt;T&gt;       Bean类型     */    protected synchronized &lt;T&gt; void registerBean(String beanName, Class&lt;T&gt; beanClass, T beanInstance) &#123;        DefaultListableBeanFactory beanFactory = (DefaultListableBeanFactory) applicationContext.getAutowireCapableBeanFactory();        // 注册Bean        BeanDefinitionBuilder beanDefinitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(beanClass, () -&gt; beanInstance);        BeanDefinition beanDefinition = beanDefinitionBuilder.getRawBeanDefinition();        beanDefinition.setScope(BeanDefinition.SCOPE_SINGLETON);        // 如果Bean已存在，先移除        if (beanFactory.containsBeanDefinition(beanName)) &#123;            beanFactory.removeBeanDefinition(beanName);        &#125;        // 注册新的Bean        beanFactory.registerBeanDefinition(beanName, beanDefinition);        log.info(&quot;成功注册Bean: &#123;&#125;&quot;, beanName);    &#125;    protected &lt;T&gt; T getBean(String beanName) &#123;        return (T) applicationContext.getBean(beanName);    &#125;&#125;\n\n去掉这个类中占位的方法, 剩下就是registerBean这个核心方法和getBean这个获取已经注册好的bean的方法(这里能自动转换类型)\nregisterBean方法通用的注册一个bean的方法, 传入beanName, 说明bean类型的beanClass, bean实例的beanInstance\n\n先获取Spring的核心Bean工厂实现类(用于管理Bean的生命周期, 提供注册bean和移除的API), 强转是因为applicationContext返回的是接口, 转换成DefaultListableBeanFactory来使用高级功能\n构建Bean的定义, 需要传入beanClass和instance. 其中的() -&gt; beanInstance: Lambda表达式作为Bean实例供应器, 设置Bean的作用域, 这里设置为单例模式\n如果存在, 删除, 通过bean工厂实现类来注册新的bean\n\n\n这个类主要就是为了额外提供一个动态注册bean的方法\n\nRootNodepublic class RootNode extends AbstractArmorySupport &#123;    @Resource    private AiClientToolMcpNode aiClientToolMcpNode;    @Override    protected void multiThread(AiAgentEngineStarterEntity requestParameter, DefaultArmoryStrategyFactory.DynamicContext dynamicContext) throws ExecutionException, InterruptedException, TimeoutException &#123;        CompletableFuture&lt;List&lt;AiClientModelVO&gt;&gt; aiClientModelListFuture = CompletableFuture.supplyAsync(() -&gt; &#123;            log.info(&quot;查询配置数据(ai_client_model) &#123;&#125;&quot;, requestParameter.getClientIdList());            return repository.queryAiClientModelVOListByClientIds(requestParameter.getClientIdList());        &#125;, threadPoolExecutor);        CompletableFuture&lt;List&lt;AiClientToolMcpVO&gt;&gt; aiClientToolMcpListFuture = CompletableFuture.supplyAsync(() -&gt; &#123;            log.info(&quot;查询配置数据(ai_client_tool_mcp) &#123;&#125;&quot;, requestParameter.getClientIdList());            return repository.queryAiClientToolMcpVOListByClientIds(requestParameter.getClientIdList());        &#125;, threadPoolExecutor);        CompletableFuture&lt;List&lt;AiClientAdvisorVO&gt;&gt; aiClientAdvisorListFuture = CompletableFuture.supplyAsync(() -&gt; &#123;            log.info(&quot;查询配置数据(ai_client_advisor) &#123;&#125;&quot;, requestParameter.getClientIdList());            return repository.queryAdvisorConfigByClientIds(requestParameter.getClientIdList());        &#125;, threadPoolExecutor);        CompletableFuture&lt;Map&lt;Long, AiClientSystemPromptVO&gt;&gt; aiSystemPromptConfigFuture = CompletableFuture.supplyAsync(() -&gt; &#123;            log.info(&quot;查询配置数据(ai_client_system_prompt) &#123;&#125;&quot;, requestParameter.getClientIdList());            return repository.querySystemPromptConfigByClientIds(requestParameter.getClientIdList());        &#125;, threadPoolExecutor);        CompletableFuture&lt;List&lt;AiClientVO&gt;&gt; aiClientListFuture = CompletableFuture.supplyAsync(() -&gt; &#123;            log.info(&quot;查询配置数据(ai_client) &#123;&#125;&quot;, requestParameter.getClientIdList());            return repository.queryAiClientByClientIds(requestParameter.getClientIdList());        &#125;, threadPoolExecutor);        CompletableFuture.allOf(aiClientModelListFuture)                .thenRun(() -&gt; &#123;                    dynamicContext.setValue(&quot;aiClientModelList&quot;, aiClientModelListFuture.join());                    dynamicContext.setValue(&quot;aiClientToolMcpList&quot;, aiClientToolMcpListFuture.join());                    dynamicContext.setValue(&quot;aiClientAdvisorList&quot;, aiClientAdvisorListFuture.join());                    dynamicContext.setValue(&quot;aiSystemPromptConfig&quot;, aiSystemPromptConfigFuture.join());                    dynamicContext.setValue(&quot;aiClientList&quot;, aiClientListFuture.join());                &#125;).join();    &#125;    @Override    protected String doApply(...) throws Exception &#123;\t\t// 空    &#125;    @Override    public StrategyHandler&lt;...&gt; get(...) &#123;        return aiClientToolMcpNode; // 下一个要访问的节点    &#125;&#125;\n\ndoApply实际上就是空内容, 这个节点没有需要处理业务的内容\nget说明RootNode的下一个Node是aiClientToolMcpNode\nmultiThread方法从大的框架上了来说就是创建了一批要查询的任务, 然后异步多线程同时执行查询, 并在执行完查询以后, 将值存入dynamicContext中, 其中每个respository中的查询方法, 其实可以简单看作就是填充好VO对象的一个过程, 调用多个dao层接口, 组装数据库中的数据成实际的业务中会使用的VO对象\n这些repository属于没什么复杂逻辑但是又是很重要的代码, 可以看看最后组装出来的各个VO对象具体是怎么样的, 以及是怎么组装出来, 这样的也能反向理解库表应该怎么配置, 建议通读一遍\n\n为什么需要转化成VO对象? 某些地方能直接使用po对象但是还是多此一举的创建了一个几乎一模一样的VO对象?\nVO和Entity对象是业务中实际上使用的对象, 也是实际上在各个方法之间传递, 是”业务实体”, 而持久化对象是面向库表的, 是我们从库表中读取出来的结构, 往往不会是和我们要的业务实体是一样的形式, 因为库表之间往往会进行解耦比如通过范式约束设计, 最后呈现出来的形式并不是和业务直接对应的\n创建一个一样的VO对象是因为我们这里的业务实体刚好和PO对象相差无几, 一方面是为了保持编码风格的统一, 另一方面是为了保证以后的拓展性, 如果这里的业务发生了什么变化, 我们修改VO对象就行, 确保PO对象不被随意修改\nVO（及其所在的聚合根Entity）是承载核心业务规则和逻辑的地方。直接使用PO会导致业务规则无法内聚在合适的对象中，散落在服务层或更糟的地方，违反高内聚原则。\n同时使用VO对象还能封装简单的领域行为\n\nAiClientToolMcpNodedoApply()\nprotected String doApply(...) throws Exception &#123;    log.info(&quot;Ai Agent 构建，tool mcp 节点 &#123;&#125;&quot;, JSON.toJSONString(requestParameter));    List&lt;AiClientToolMcpVO&gt; aiClientToolMcpList = dynamicContext.getValue(&quot;aiClientToolMcpList&quot;);    if (aiClientToolMcpList == null || aiClientToolMcpList.isEmpty()) &#123;        //&quot;没有可用的AI客户端工具配置 MCP&quot;        return router(requestParameter, dynamicContext);    &#125;    for (AiClientToolMcpVO mcpVO : aiClientToolMcpList) &#123;        // 创建McpSyncClient对象        McpSyncClient mcpSyncClient = createMcpSyncClient(mcpVO);        // 使用父类的通用注册方法        registerBean(beanName(mcpVO.getId()), McpSyncClient.class, mcpSyncClient);    &#125;    return router(requestParameter, dynamicContext);&#125;\n\n整个程序的执行流程是从上下文中获取到aiClientToolMcpList也就是List&lt;AiClientToolMcpVO&gt;, 如果获取到的不为空, 则将他们都注册成bean对象\ncreateMcpSyncClient这个方法的名称很明显地说明了这个方法地作用, 将我们的AiClientToolMcpVO注册成一个McpSyncClient\nMcpSyncClient是一个同步的MCP客户端接口, 用于与MCP服务器进行通信. MCP是一个标准协议, 允许AI模型访问外部工具和数据源\n// 与MCP服务器建立连接var initResult = mcpSyncClient.initialize();// 获取可用工具列表var tools = mcpSyncClient.getTools();// 调用特定工具var result = mcpSyncClient.callTool(toolName, arguments);// 获取资源列表var resources = mcpSyncClient.getResources();// 读取特定资源var content = mcpSyncClient.readResource(resourceUri);\n\n\n\n如果MCP工具是SSE传输模式\n\n配置解析\n解析URL: 如果URL里面有”sse”, 将URL中的”sse”分割出去, 并且这种配置说明baseUri和sseEndpoint是在一起配置的, 否则使用分离配置 &quot;baseUri&quot;:&quot;http://127.0.0.1:9999/sse?apikey=xxx&quot; &#96;&#96;”baseUri”:”https://mcp.amap.com“, “sseEndpoint”:”&#x2F;sse?key&#x3D;xxx”&#96;\n创建SSE客户端\n\nHttpClientSseClientTransport sseClientTransport = HttpClientSseClientTransport    .builder(baseUri)    .sseEndpoint(sseEndpoint)    .build();McpSyncClient mcpSyncClient = McpClient.sync(sseClientTransport)    .requestTimeout(Duration.ofMinutes(aiClientToolMcpVO.getRequestTimeout()))    .build();\n\n\n客户端初始化\n\nvar init_sse = mcpSyncClient.initialize();log.info(&quot;Tool SSE MCP Initialized &#123;&#125;&quot;, init_sse);\n\n如果MCP工具是STDIO传输模式\n\n配置获取\n服务器参数构建(Command和args)\n创建客户端\n\nAiClientAdvisorNode和上一个Node是一样的逻辑, 从Context中获取, 如果成功获取, 则将其注册为Advisor类型的Bean\ncreateAdvisor如果是ChatMemory聊天上下文类型\n\n从VO对象中获取聊天最长上下文长度\n构建并返回提示词记忆顾问\n\n如果是RagAnswer知识库类型\n\n从VO对象中获取RagAnswer对象(topk, filter)\n传入向量数据库和用RagAnswer构建的SearchRequest来构建出来知识库顾问\n\nPromptChatMemoryAdvisorSpring AI实现的提示词记忆顾问\n\n自动维护历史对话记录\n在每次请求的时候将相关的历史消息自动注入到提示词中\n\n// 项目中的实际使用ChatClient chatClient = ChatClient.builder(chatModel)    .defaultAdvisors(        // 添加记忆顾问        new PromptChatMemoryAdvisor(MessageWindowChatMemory.builder()            .maxMessages(10)  // 最多记住10条消息            .build())    )    .build();// 调用时指定会话IDString response = chatClient    .prompt(&quot;你好，我是张三&quot;)    .advisors(a -&gt; a.param(CHAT_MEMORY_CONVERSATION_ID_KEY, &quot;user_123&quot;))    .call()    .content();\n\nMessageWindowChatMemory是消息窗口记忆的实现, 通过滑动窗口的形式保存maxMessages条消息\nRagAnswerAdvisor自定义的RAG顾问实现\n这个方法是核心的从向量数据库中获取到和提问相关的documents, 然后由此注入上下文参数, 构建一个新的增强请求\nHashMap&lt;String, Object&gt; context = new HashMap(request.adviseContext());\n// 1. 构建增强提示词\nString advisedUserText = request.userText() + System.lineSeparator() + this.userTextAdvise;\n\n// 2. 渲染查询模板\nString query = new PromptTemplate(request.userText(), request.userParams()).render();\n\n// 3. 执行向量检索\nSearchRequest searchRequestToUse = SearchRequest.from(this.searchRequest)\n.query(query)\n.filterExpression(this.doGetFilterExpression(context))\n.build();\nList&lt;Document&gt; documents = this.vectorStore.similaritySearch(searchRequestToUse);\n\n// 4. 构建文档上下文\ncontext.put(&quot;qa_retrieved_documents&quot;, documents);\nString documentContext = (String)documents.stream()\n.map(Document::getText)\n.collect(Collectors.joining(System.lineSeparator()));\nMap&lt;String, Object&gt; advisedUserParams = new HashMap(request.userParams());\n\n// 5. 注入上下文参数\nadvisedUserParams.put(&quot;question_answer_context&quot;, documentContext);\n\nAdvisedRequest advisedRequest = AdvisedRequest\n.from(request)\n.userText(advisedUserText)\n.userParams(advisedUserParams)\n.adviseContext(context).build();\nreturn advisedRequest;\n&#125;\n\nAdvisedRequest 和 AdvisedResponse 是 Spring AI 的增强请求和响应对象这两个类的作用是在于提供一个增强的上下文，使得在处理请求和响应时可以携带额外的信息，比如用户的查询、上下文信息等。通过增强请求和响应，可以在处理过程中注入更多的上下文信息在before中处理请求时，可以根据用户的查询和上下文信息来构建一个更丰富的请求对象。这里的上下文是通过知识库向量存储（VectorStore）进行检索得到的，增强请求可以包含检索到的相关文档信息。这里的nextAroundCall和nextAroundStream方法是调用链的一部分，用于在增强请求处理完成后继续执行下一个环节的逻辑。在aroundCall和aroundStream方法中，增强请求会被传递到下一个环节进行处理。在处理响应时，增强响应对象可以携带更多的信息，比如检索到的文档信息、处理结果等。也就是我能从增强相应对象中获取到rag知识库检索到的相关文档信息。\nAiClientModelNode同上的流程, 不过创建的bean变成了OpenAiChatModel, 并且将所有这个模型可以使用的MCP Tool添加到模型中\nAiClientNode在doApply方法中将chatModel, MCP, Advisor这三类Bean组装成一个对话客户端ChatClient, 然后将其注册为bean\n总结自此我们就完成了对于整个服务的预热, 将model, mcp, advisor注册成bean并相互绑定在一起, 这里使用规则树单纯是为了制定一个预热的流程\n我们先根据aiClientIds從RootNode节点出發, 異步從庫表中查詢組裝出來業務中流轉的VO對象,  并將它們添加到Map中\n然後進入到AiClientToolMcpNode, 根據Map中的MCPVOList組轉起來所有McpSyncClient然後將其註冊為Bean\n進入到AiClientAdvisorNode, 根據Advisor的類型,  組裝rag或者chatmemory類型的bean\n再到AiClientModelNode,  組裝OpenAiChatModel並這個model綁定的MCP Tool添加進去\n最後就是AiClientNode將chatModel, MCP, Advisor這三類Bean組裝成一個對話客戶端ChatClient, 然後將其註冊為bean\n","categories":["项目实战","AI-Agent","核心功能"],"tags":["AI-Agent","Spring AI","preheat","预热机制","策略模式","规则树","Bean装配"]},{"title":"AI-Agent项目解析03 - 对话功能和定时任务实现","url":"/2025/07/08/Project/ai-agent/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/ai-agent-2-%E5%89%A9%E4%BD%99%E5%8A%9F%E8%83%BD/","content":"ai-agent-2-剩余功能在完成预热以后, 我们就正式进入到用户直接面向的核心功能: 对话和定时任务\naiAgentChat对话分成流式对话和普通对话两种\n普通对话-aiAgentChat方法获取到完整的AI的回答以后再给出返回\n\n获取所有的client的ID\n\nList&lt;Long&gt; aiClientIds = repository.queryAiClientIdsByAiAgentId(aiAgentId);String content = &quot;&quot;;\n\n\n根据clientId取出来对应的client Bean对象, 链式调用这个agent对应的client们, 渐进式提问\n这里传入的advisor的参数, CHAT_MEMORY_CONVERSATION_ID_KEY是用于标识这次对话的ID, 这个ID是用来区分上下文的, 不同的对话有着不同的ID不同的上下文\nparam(CHAT_MEMORY_RETRIEVE_SIZE_KEY, 100)) 这个参数的作用是将对话历史记录的数量限制在100条\n\n\n\nfor (Long aiClientId : aiClientIds) &#123;    ChatClient chatClient = defaultArmoryStrategyFactory.chatClient(aiClientId);    content = chatClient.prompt(message + &quot;，&quot; + content)        .system(s -&gt; s.param(&quot;current_date&quot;, LocalDate.now().toString()))        .advisors(a -&gt; a                  .param(CHAT_MEMORY_CONVERSATION_ID_KEY, &quot;chatId-101&quot;)                  .param(CHAT_MEMORY_RETRIEVE_SIZE_KEY, 100))        .call().content();&#125;\n\n\n这里为什么会是链式调用, 一个问题调用一个Client进行回答不就行了吗?\n注意我们的方法名不是clientChat而是agentChat, 一个agent能够串联多个client, 在这个方法中多client协作的工作共同构建最后的回答, 实现功能互补或者质量提升, 亦或是问题分解, 举例:\n场景一：专业分工协作\n假设有3个智能体：&#x2F;&#x2F; aiClientId &#x3D; 1: 文本分析专家&#x2F;&#x2F; aiClientId &#x3D; 2: 逻辑推理专家&#x2F;&#x2F; aiClientId &#x3D; 3: 总结归纳专家\n&#x2F;&#x2F; 第一轮：分析专家处理原始问题content &#x3D; “”; &#x2F;&#x2F; 初始为空content &#x3D; 分析专家.process(“用户问题” + “，” + “”); &#x2F;&#x2F; 得到分析结果\n&#x2F;&#x2F; 第二轮：推理专家基于分析结果进行推理content &#x3D; 推理专家.process(“用户问题” + “，” + “分析结果”); &#x2F;&#x2F; 得到推理结论\n&#x2F;&#x2F; 第三轮：总结专家整合前面的结果content &#x3D; 总结专家.process(“用户问题” + “，” + “分析结果+推理结论”); &#x2F;&#x2F; 最终答案\n场景二：渐进式优化\n&#x2F;&#x2F; 智能体链逐步完善答案质量&#x2F;&#x2F; 第一个智能体：给出初步答案&#x2F;&#x2F; 第二个智能体：基于初步答案进行补充和优化&#x2F;&#x2F; 第三个智能体：进行最终校验和润色\n\n流式对话-aiAgentChatStream方法获取到一部分返回以后立马呈现给用户\n\n获取配置\n\n// 查询模型IDLong modelId = repository.queryAiClientModelIdByAgentId(aiAgentId);// 获取对话模型ChatModel chatModel = defaultArmoryStrategyFactory.chatModel(modelId);\n\n\n构建messages\n\n如果对话不携带rag, 则messages就只有传入的message\nelse &#123;            messages.add(new UserMessage(message));        &#125;\n\n如果携带rag\n\n根据ragId获取到tag\n\n从pg中查询到相近的documents\nSearchRequest searchRequest = SearchRequest.builder()    .query(message)    .topK(5)    .filterExpression(&quot;knowledge == &#x27;&quot; + tag + &quot;&#x27;&quot;)    .build();List&lt;Document&gt; documents = vectorStore.similaritySearch(searchRequest);\n\n构建结构化的rag prompt\nString documentCollectors = documents.stream()    .map(Document::getFormattedContent)    .collect(Collectors.joining());Message ragMessage = new SystemPromptTemplate(&quot;&quot;&quot;....DOCUMENTS:&#123;documents&#125; &quot;&quot;&quot;).createMessage(Map.of(&quot;documents&quot;, documentCollectors));                                              messages.add(new UserMessage(message));\n\n\n\n\n使用messages与第一步获取到的model对话\n\n\nreturn chatModel.stream(Prompt.builder()                        .messages(messages)                        .build());\n\n\n为什么这里又不使用链式调用多个client了?\n链式调用多个client的本质是将当前client的输出 + 原问题作为下一个client的输入, 如果这样我们必须阻塞式等待clien完整回答完毕, 而当前方法实现的是流式回答, 是输出了一部分就给用户呈现一部分, 所以不能链式调用\n\nAiAgentRagService里面就上传RagFile一个方法, 用于将知识库文件上传\nstoreRagFile\n遍历所有的文件\n\n读取文件 TikaDocumentReader documentReader = new TikaDocumentReader(file.getResource());\n\n将文件切分成一个个documentdocumentList.forEach(doc -&gt; doc.getMetadata().put(&quot;knowledge&quot;, tag));\n\n为文件添加知识库标签documentList.forEach(doc -&gt; doc.getMetadata().put(&quot;knowledge&quot;, tag));\n\n存储到pg数据库中 vectorStore.accept(documentList);\n\n将这个我们新建的知识库的tag和名字存储进数据库中, 用于chat的时候查询到我们可用的知识库有哪些\nAiRagOrderVO aiRagOrderVO = new AiRagOrderVO();aiRagOrderVO.setRagName(name);aiRagOrderVO.setKnowledgeTag(tag);repository.createTagOrder(aiRagOrderVO);\n\nAgentTaskJob这里略过了TaskService的两个查询的方法, 一个是查询所有有效的任务, 一个是查询所有无效的任务的ID\ninit方法-在Bean初始化以后执行这个方法上有个@PostConstruct注解, 这个注解的功能是在Spring容器初始化完成后执行该方法\n这个方法的主要功能就是初始化了一个任务调度器\npublic void init() &#123;    // 初始化任务调度器    ThreadPoolTaskScheduler scheduler = new ThreadPoolTaskScheduler(); // 这个类是 Spring 提供的一个线程池任务调度器    scheduler.setPoolSize(10);    scheduler.setThreadNamePrefix(&quot;agent-task-scheduler-&quot;);    scheduler.setWaitForTasksToCompleteOnShutdown(true); // 设置在关闭时等待任务完成    scheduler.setAwaitTerminationSeconds(60); // 设置等待任务完成的时间    scheduler.initialize();    this.taskScheduler = scheduler;&#125;\n\nexecuteTask方法-执行任务\n获取任务的参数(json格式) String taskParam = task.getTaskParam();\n执行任务aiAgentChatService.aiAgentChat(task.getAgentId(), taskParam);\n\n\n这里的执行任务为什么就是aiAgentChat?\n在前面的xfg的mcp章节, 其实就能看到我们让AI执行一个任务就是与AI对话, 让它调用对应的MCP执行特定的任务\n这里也是一样的, 同时agent的链式调用client还能使得我们这个任务由多个client协同执行\n\nscheduleTask方法-调度器执行任务\n创建任务调度器\n\n调度器要执行的方法就是executeTask(task)\n时间设置通过task的cron表达式\n\nScheduledFuture&lt;?&gt; future = taskScheduler.schedule(    () -&gt; executeTask(task),    new CronTrigger(task.getCronExpression()));\n\n将这个任务放到类全局map中, 记录这个任务已经被我们调度执行成功了scheduledTasks.put(task.getId(), future);\n\n\nrefreshTasks方法-移除invalid任务, 执行valid任务​    @Scheduled(fixedRate &#x3D; 60000) &#x2F;&#x2F; 每分钟执行一次\n\n从taskService中查询到所有有效的任务配置\nList&lt;AiAgentTaskScheduleVO&gt; taskSchedules = aiAgentTaskService.queryAllValidTaskSchedule();\n\n处理每个任务\n\n将这个任务的id放入到Map中, 用于后面删除调度器中已经invalid任务\n如果任务不存在调用scheduleTask(task)创建并调度新任务\n\nfor (AiAgentTaskScheduleVO task : taskSchedules) &#123;    Long taskId = task.getId();    currentTaskIds.put(taskId, true);    // 如果任务已经存在，则跳过    if (scheduledTasks.containsKey(taskId)) &#123;        continue;    &#125;    // 创建并调度新任务    scheduleTask(task);&#125;\n\n移除不存在的任务\n\n获取现在所有在调度器中的任务的keySet, 也就是所有在调度器中的任务的taskId集合A\n上面处理每个任务的时候记录的现在仍然有效的taskId集合B, 如果A不在B中, 说明这个任务已经不存在了\n从调度器task集合中获取任务并将任务移除\n\nscheduledTasks.keySet().removeIf(taskId -&gt; &#123;    if (!currentTaskIds.containsKey(taskId)) &#123;        ScheduledFuture&lt;?&gt; future = scheduledTasks.remove(taskId);        if (future != null) &#123;            future.cancel(true);            log.info(&quot;已移除任务，ID: &#123;&#125;&quot;, taskId);        &#125;        return true;    &#125;    return false;&#125;);\n\ncleanInvalidTasks方法-清理已经被标记为无效的任务​    @Scheduled(cron &#x3D; “0 0&#x2F;10 * * * ?”) &#x2F;&#x2F; 每10分钟执行一次\n\n获取所有已经失效的任务的IDList&lt;Long&gt; invalidTaskIds = aiAgentTaskService.queryAllInvalidTaskScheduleIds();\n\n从调度器中移除这些任务\nfor (Long taskId : invalidTaskIds) &#123;    ScheduledFuture&lt;?&gt; future = scheduledTasks.remove(taskId);    if (future != null) &#123;        future.cancel(true);        log.info(&quot;已移除无效任务，ID: &#123;&#125;&quot;, taskId);    &#125;&#125;\n\n总结chat和task模块可以说是看似简单的实现, 但是具有很强的拓展性, 比如我想设置一个监控数据监控面板然后发现异常微信推送消息的组件\n\n实现能从数据监控面板获取数据的MCP工具\n实现发送微信消息的MCP工具\n注册一个分析数据监控面板client, 注册一个发送总结分析发送微信消息的client\n将两个client串联成一个agent, 设置这个agent的定时任务\n这样就实现了监控数据面板在AI分析即将出现问题的时候通知开发者的功能\n\n","categories":["项目实战","AI-Agent","核心功能"],"tags":["AI-Agent","对话系统","流式对话","定时任务","ChatClient","上下文管理"]},{"url":"/2025/07/08/Java/DataBase/JDBC/JDBC/","content":"JDBC基础篇2. JDBC的概述java只实现了连接数据库的接口的规范, 而没有定义详细的实现, 详细的实现交给实际的数据库场上实现, 所以想通过Java连接特定的数据库, 实际上需要下载对应厂商的jar包\n3. Quick-start// 1. 指明使用的数据库, 为其创建驱动Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);// 2. 建立与数据库的连接String url = &quot;jdbc:mysql://localhost:3306/atguigu&quot;;String username = &quot;root&quot;;String password = &quot;root&quot;;Connection connection = DriverManager.getConnection(url, username, password);// 3. 创建承载语句的对象Statement statement = connection.createStatement();// 4. 编写SQL语句, 并执行, 同时接收返回String sql = &quot;SELECT * FROM t_emp&quot;;ResultSet resultSet = statement.executeQuery(sql);// 5. 处理查询结果while (resulteSet.next()) &#123;    // 获取查询的结果    int empId = resultSet.getInt(&quot;emp_id&quot;);    String empName = resultSet.getString(&quot;emp_name&quot;);    double empSalary = resultSet.getDouble(&quot;emp_salary&quot;);    int empAge = resultSet.getInt(&quot;emp_age&quot;);    System.out.println(empId + &quot;\\t&quot; + empName + &quot;\\t&quot; + empSalary + &quot;\\t&quot; + empAge);&#125;// 6. 释放资源resulteSet.close();statement.close();connection.close();\n\n4. 对于API的讲解4.1 Driver -&gt; 注册驱动Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);, 可以替换为Class.forName(new Driver());, 原本的写法填入的参数是资源路径, 我们可以直接传入驱动对象\n\n也可以直接省略不写, 因为从JDK6开始后, 都会自动注册驱动\n\n\n驱动程序用于和数据库进行通讯\n\n4.2 Connection -&gt; 代表和数据库的一次连接\n用于事务级的管理, 能执行rollback和commit\n建立连接需要指明url, username, password\nurl &#x3D; “jdbc:mysql:&#x2F;&#x2F;ip:port&#x2F;database?字段1&#x3D;…&amp;字段2&#x3D;…”\n\n\n使用后记得关闭, 避免资源泄露\n\n4.3 StatementStatement可以通过Connection对象创建\n但是会有sql注入的问题\n\n这个问题发生于想动态查询的时候\n\n// 4. 编写SQl语句, 并执行, 以及接收返回\nScanner scanner = new Scanner(System.in);\nString name = scanner.nextLine();\nString sql = &quot;SELECT * FROM t_emp WHERE emp_name = &#39;&quot; + name+ &quot;&#39;&quot;;\nResultSet resultSet = statement.executeQuery(sql);\n- 这个时候输入的name如果是abc&#x27; or &#x27;1&#x27; = &#x27;1, 会在WHERE条件处构建一个永真句, 从而查询到所有内容#### 4.4 PreparedStatementStatement的子类, 独有的特性- 预编译SQL语句 =&gt; 重复执行的时候, 不用每次都重新编译运行, 提高运行效率- 能够防止SQL注入使用上的特点- 不支持无参构造- 通过?占位符说明哪个位置需要传参- 再在后续set, 将参数传给指定位置的占位符```javaString sql = &quot;SELECT * FROM t_emp WHERE emp_name = ?&quot;;PreparedStatement preparedStatement = connection.prepareStatement(sql);preparedStatement.setString(1,name);ResultSet resultSet = preparedStatement.executeQuery();\n\n\n\n\n如果这个时候传入 “abc’ or  ‘1’ &#x3D; ‘1 “, 原语句会被修改, 其中的特殊字符会被做转义, 从而只作为字符串的内容传入, 比如这句会变为 “abc\\‘ or \\‘1\\‘ &#x3D; \\‘1”同时传入的时候set的是String, 会自动加上 ‘’ 包裹\n\n4.5 ResultSet用于接收查询语句返回的多行结果, 可以通过getInt(getDouble…)等方法从结果集中获取数据\n关键方法 : ResultSet.next() 返回的是boolean类型, 在还没有执行这个语句的最初, ResultSet指向的是第-1行, 该方法会先判定是否有下一行, 如果有, 移动到下一行, 用于给使用者获取下一行的数据,\n用于获取一行的数据\n5. 用PreparedStatement执行CRUD5.1 查询单行单列5.2 查询单行多列5.3 查询多行多列5.4 插入删除修改数据将执行查询的executeQuery()修改为executeUpdate()\n这个时候接收的返回int result的内容是收到影响的行数, 如果是0, 说明失败\n进阶篇7. JDBC拓展7.1 实体类和ORM7.2 主键回显  由于执行插入语句即preparedStatement.executeUpdate(), 返回的只是受影响的行数, 但是我们现在有个使用的情景是, 我们插入数据的时候, 并不会指定主键的值, 那么这个时候, 实体类其中Id即主键号该怎么获取 &#x3D;&gt; 主键回显, 具体代码\n// 声明预编译对象的时候, 添加参数, 表明需要返回主键值PreparedStatement preparedStatement =     DriverManager.preparedStatement(sql,Statement.RETURN_GENERATED_KEYS);// 在成功执行插入语句后if (result &gt; 0) &#123;    sout (&quot;成功&quot;);    resultSet = preparedStatement.getGaneratedKeys();    if (resultSet.next()) &#123;        int empId = resultSet.getInt(1);        employee.setId(empId);    &#125;&#125; else &#123;    sout(&quot;失败&quot;);&#125;\n\n7.3 批量操作\n原因 : 如果我现在需要插入一万条数据, 按照之前的写法, 我们需要重复执行executeUpdate一万次, 从而插入一万条数据, 这个时候会与数据库连接一万次, 网络上的往返也有一万次, 效率极低\n\n解决策略 : 缓存, 建立buffer, 每次添加数据后, 并不是将直接executeUpdate()而是AddBatch(), 将数据添加到批处理的缓存区, 最后执行一次executeBatch()将语句发送往数据库\\\n\n操作 :\n// step 1 : 将在与数据库建立连接的url最后的添加参数的位置加入?rewriteBatchedStatements=trueDriverManager.getConnection(&quot;jdbc:mysql:///atguigu?rewriteBatchedStatements=true&quot;                            , &quot;root&quot;, &quot;root&quot;);// step 2 : 将原来的executeUpdate的位置换为addBatch()preparedStatement.addBatch();// step 3 : 最后在所有语句的最后写入executeBatch()preparedStatement.executeBatch();\n\n\n需要执行批量操作的SQL语句最后不能有 “;”\n\n8. 连接池8.1 问题简述问题的出现 \n\n每次建立连接都需要创建新的对象, 频繁的创建和销毁连接对象, 造成资源的浪费\n连接的数量是不可控的, 对服务器的压力很大\n\n解决方式\n\n创建数据库连接的缓冲区, 如果连接池中有资源, 就直接从连接池中获取连接对象, 如果连接池中没有资源且连接数量未打到上限, 创建新的连接对象, 如果连接池已满, 则等待建立连接, 同时还有超时等设置 \n就像客服一样, 并不是为每一个用户都设立一个客服\n\n8.3 Druid连接池使用Druid连接池硬编码使用\n使用流程\n创建DruidDataSource对象\n配置DruidDataSource对象\n配置必须项 : driver, url, username, password\n配置非必须项 : 最大连接数量 maxActive, 初始化的连接数量 initialSize\n\n\n通过DruidDataSource创建连接对象\n通过connection对象CRUD\n最后关闭connection &#x3D;&gt; 这个时候是将资源回收给\n\n\n\n// 1. 创建德鲁伊资源对象对象DruidDataSource dataSource = new DruidDataSource();// 2. 配置参数// 必须项dataSource.setDriverClassName(&quot;com.mysql.cj.jdbc.Driver&quot;);dataSource.setUrl(&quot;jdbc:mysql:///atguigu&quot;);dataSource.setUsername(&quot;root&quot;);dataSource.setPassword(&quot;root&quot;);// 非必须项dataSource.setInitialSize(10);dataSource.setMaxActive(20);// 3. 创建连接对象DruidPooledConnection connection = dataSource.getConnection();// 4. 正常进行CRUD//        connection.prepareStatement()// 5. 回收资源connection.close();\n\nDruid连接池软编码使用 (推荐)\n实现步骤\n\n\n项目文件夹下创建resources文件夹, 用于存放配置文件, 然后Mark as “Resources root”\n\n创建db.properties文件, 在new里选resource bundle, 在里面以key&#x3D;value的形式写入配置信息\n\n新建Properties集合对象\n\n通过InputStream对象获取输入流 ClassName.class.getClassLoader().getResourceAsStream(“file name”)\n\nproperties.load(inputStream)\n\n通过Druid的工厂方法创建connection\n\n接下来就正常使用\n\n\n\n第四步中的ClassName表示的是写入代码的那个类 &#x3D;&gt; 含义是加载这个类的时候就会去读取信息\n\n// 创建properties集合对象Properties properties = new Properties();// 将文件内容加载到集合中InputStream inputStream = DruidTest.class.getClassLoader().getResourceAsStream(&quot;db.properties&quot;);properties.load(inputStream);// 将配置信息加载到DruidDataSourceDataSource dataSource = DruidDataSourceFactory.createDataSource(properties);// 创建Connection后正常使用Connection connection = dataSource.getConnection();connection.close();\n\n8.4 Hikari(&#x2F;hiːˈkɑːri&#x2F;)连接池的使用硬编码的使用方式\n使用流程\n创建的对象从DruidDataSource改为HikariDataSource\nsetUrl改为SetJdbcUrl\n其他和Druid相同\n\n\n\n软编码的使用方式\n使用流程\n读取配置信息相同\n设置最大和最小的函数名变为setMaximumPoolSize, setMinimumIdle\n需要用properities创建HikariConfig对象\n再用HikariConfig创建DataSource对象 &#x3D;&gt; new HikariDataSource(hikariConfig)\n\n\n\n高级篇9. 对连接池的操作的封装9.1 工具类的简单封装封装的内容\n\n连接池的对象的创建\n获取连接池的中的连接\n连接的释放\n\npublic class JDBCUtil &#123;    private static DataSource dataSource;    static &#123;        try &#123;            Properties properties = new Properties();            InputStream inputStream = JDBCUtil.class.getClassLoader().getResourceAsStream(&quot;db.properties&quot;);            properties.load(inputStream);            dataSource = DruidDataSourceFactory.createDataSource(properties);        &#125; catch (Exception e) &#123;            throw new RuntimeException(e);        &#125;    &#125;    public static Connection getConnection() &#123;        try &#123;            return dataSource.getConnection();        &#125; catch (SQLException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;    public static void release(Connection connection) &#123;        try &#123;            connection.close();        &#125; catch (SQLException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\n9.2 ThreadLocal\n新的问题\n如果一个用户完成一系列操作, 每一步都需要操作数据库, 那么按照原来的代码, 他会从连接池中频繁的获取连接, 占用过多的资源\n\n\n解决方案\n让用户从头至尾获取的都是同一个connection\n\n\n实现\n通过ThreadLocal将Connection对象和线程绑定, 这个线程对象又是JDBCUtil类的中的成员, 从而将Connction和这个类绑定\ngetConnection需要先get, 如果从线程中get的是null, 则重新set并返回\nrelease不再需要传参, 先closeCnnection, 再remove()fromThread\n\n\n\n10. DAO工具的封装10.1 封装的层次\n与pojo的区别 : 不同于pojo存放类的实体, DAO存放的是操作, 基础的操作集 : Data Access Operation, 数据访问操作\n\n封装的层次化结构\n|--pojo =&gt; 存放类的实体|--dao \t=&gt; 存放操作集的接口, 里面存放的全是接口文件|---|--DaoImpl =&gt; 存放接口的实际实现\n\n10.4 对于executeUpdate()通用方法的封装\n实现的思路\n操作 :\n\n\n\n","tags":["Java","MySQL","JDBC"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/Ajax/","content":"Ajax1. Ajax概述\nAJAX &#x3D; Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。\n\nAJAX 不是新的编程语言，而是一种使用现有标准的新方法。\n\nAJAX 最大的优点是在不重新加载整个页面的情况下，可以与服务器交换数据并更新部分网页内容。\n\nAJAX 不需要任何浏览器插件，但需要用户允许 JavaScript 在浏览器上执行。\n\nXMLHttpRequest 只是实现 Ajax 的一种方式。\n\n\najax工作原理：\n![[images&#x2F;image_bjXPJoLb6a-1690508517199.png]]\n\n简单来说,我们之前发的请求通过类似  form表单标签,a标签 这种方式,现在通过 运行js代码动态决定什么时候发送什么样的请求\n通过运行JS代码发送的请求浏览器可以不用跳转页面 ,我们可以在JS代码中决定是否要跳转页面\n通过运行JS代码发送的请求,接收到返回结果后,我们可以将结果通过dom编程渲染到页面的某些元素上,实现局部更新\n\n2 如何实现ajax请求\n原生javascript方式进行ajax(了解):\n\n&lt;script&gt;  function loadXMLDoc()&#123;    var xmlhttp=new XMLHttpRequest();      // 设置回调函数处理响应结果    xmlhttp.onreadystatechange=function()&#123;      if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200)      &#123;        document.getElementById(&quot;myDiv&quot;).innerHTML=xmlhttp.responseText;      &#125;    &#125;      // 设置请求方式和请求的资源路径    xmlhttp.open(&quot;GET&quot;,&quot;/try/ajax/ajax_info.txt&quot;,true);      // 发送请求    xmlhttp.send();  &#125;&lt;/script&gt; \n\n","tags":["Java","frontend","JavaWeb","Ajax","async"]},{"title":"MyBatis框架详解 - ORM映射与SQL操作","url":"/2025/07/08/Java/DataBase/MyBatis/Mybatis/","content":"MyBatis1. HelloWord - 第一个程序\n创建mybatis-config.xml 配置文件, 用于加载mybatis配置\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;settings&gt;        &lt;setting name=&quot;logImpl&quot; value=&quot;STDOUT_LOGGING&quot; /&gt;    &lt;/settings&gt;    &lt;environments default=&quot;development&quot;&gt;        &lt;environment id=&quot;development&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;        &lt;!--sql映射文件创建好之后，需要将该文件路径配置到这里--&gt;        &lt;mapper resource=&quot;CarMapper.xml&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\n\n\n创建数据库和表\n\n… 省略\n\n创建查询resource.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;!--namespace先随意写一个--&gt;&lt;mapper namespace=&quot;car&quot;&gt;    &lt;!--insert sql：保存一个汽车信息--&gt;    &lt;insert id=&quot;insertCar&quot;&gt;        insert into t_car            (id,car_num,brand,guide_price,produce_time,car_type)        values            (null,&#x27;102&#x27;,&#x27;丰田mirai&#x27;,40.30,&#x27;2014-10-05&#x27;,&#x27;氢能源&#x27;)    &lt;/insert&gt;&lt;/mapper&gt;\n\n\n创建第一个程序\n\n执行步骤\n\n创建SqlSessionFactoryBuilder(), 用于创建SqlSessionFactory\n通过SqlSessionFactory创建Session\nSession执行对应id的SQL\n接受返回并提交\n执行错误则回滚\n在finally中关闭连接\n\npublic class HelloWord &#123;    public static void main(String[] args) &#123;        SqlSession sqlSession = null;        try &#123;            SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();            SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;));            sqlSession = sqlSessionFactory.openSession();            int count = sqlSession.insert(&quot;insertCar&quot;);            System.out.println(&quot;插入了&quot; + count + &quot;条数据&quot;);            sqlSession.commit();        &#125; catch (Exception e) &#123;            if (sqlSession != null) &#123;                sqlSession.rollback();            &#125;            e.printStackTrace();        &#125; finally &#123;            if (sqlSession != null) &#123;                sqlSession.close();            &#125;        &#125;    &#125;&#125;\n\n\n集成日志框架\n\n\n添加logback依赖\n添加相关配置文件到类的根路径下, 文件命名可以为logback.xml或者&#96;logback-config.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration debug=&quot;false&quot;&gt;    &lt;!-- 控制台输出 --&gt;    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;            &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;    &lt;!-- 按照每天生成日志文件 --&gt;    &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;!--日志文件输出的文件名--&gt;            &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt;            &lt;!--日志文件保留天数--&gt;            &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;        &lt;/rollingPolicy&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;            &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;        &lt;/encoder&gt;        &lt;!--日志文件最大的大小--&gt;        &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt;            &lt;MaxFileSize&gt;100MB&lt;/MaxFileSize&gt;        &lt;/triggeringPolicy&gt;    &lt;/appender&gt;    &lt;!--mybatis log configure--&gt;    &lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt;    &lt;logger name=&quot;java.sql.Connection&quot; level=&quot;DEBUG&quot;/&gt;    &lt;logger name=&quot;java.sql.Statement&quot; level=&quot;DEBUG&quot;/&gt;    &lt;logger name=&quot;java.sql.PreparedStatement&quot; level=&quot;DEBUG&quot;/&gt;    &lt;!-- 日志输出级别,logback日志级别包括五个：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR --&gt;    &lt;root level=&quot;DEBUG&quot;&gt;        &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;        &lt;appender-ref ref=&quot;FILE&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;\n\n\n将繁琐的创建session的过程包装为一个工具类\n\npublic class SqlSessionUtil &#123;    private static SqlSessionFactory sqlSessionFactory;    // 类加载的时初始化SqlSessionFactor对象    static &#123;        try &#123;            SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();            sqlSessionFactory =  sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;));        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    public static SqlSession openSession()&#123;        return sqlSessionFactory.openSession(true);    &#125;&#125;\n\n2. 使用MyBatis完成CRUD2.1 Create\n使用SqlSession.insert(&quot;id&quot;, map/object)接口\n\n\n有两种实现方式, MyBatis支持使用Map和对象两种方式传入数据\n\n\nMap\n\npublic void testMapInsert()&#123;    HashMap map = new HashMap&lt;&gt;();    map.put(&quot;carNum&quot;, &quot;111&quot;);    map.put(&quot;brand&quot;, &quot;奔驰E300L&quot;);    map.put(&quot;guidePrice&quot;, 70.3);    map.put(&quot;produceTime&quot;, &quot;2020-10-12&quot;);    map.put(&quot;carType&quot;, &quot;燃油车&quot;);    SqlSession sqlSession = null;    try &#123;        SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();        SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;));        sqlSession = sqlSessionFactory.openSession();        int count = sqlSession.insert(&quot;insertCar&quot;, map);        System.out.println(&quot;count = &quot; + count);        sqlSession.commit();    &#125; catch (Exception e) &#123;        e.printStackTrace();        if (sqlSession != null) &#123;            sqlSession.rollback();        &#125;    &#125; finally &#123;        if (sqlSession != null) &#123;            sqlSession.close();        &#125;    &#125;&#125;\n\n\nObject\n\n\n使用对象的话, 如果是需要将对象中数据传入, 则对象需要有get方法如果需要通过Mybatis创建对象, 则其中需要有set方法\n\n    Car car = new Car();    car.setBrand(&quot;奔驰E&quot;);    car.setCarNum(&quot;124&quot;);    car.setCarType(&quot;燃油车&quot;);    car.setGuidePrice(123.2);    car.setProduceTime(&quot;2023-12-05&quot;);    SqlSession sqlSession = SqlSessionUtil.openSession();    int count = sqlSession.insert(&quot;insertCar&quot;, car);    System.out.println(&quot;count = &quot; + count);&#125;\n\n\nxml\n\n&lt;insert id=&quot;insertCar&quot;&gt;    insert into t_car        (car_num,brand,guide_price,produce_time,car_type)    values        (#&#123;carNum&#125;,#&#123;brand&#125;, #&#123;guidePrice&#125;, #&#123;produceTime&#125;, #&#123;carType&#125;)&lt;/insert&gt;\n\n2.2 Update\n后续都只演示两种方式中, 使用Object传入数据的方式\n\n\n使用SqlSession.update(&quot;id&quot;, map/object)接口\n\n\njava\n\n    @Testpublic void testUpdate()&#123;    Car car = new Car();    car.setId(7);    car.setBrand(&quot;奔驰&quot;);    car.setCarType(&quot;电车&quot;);    car.setProduceTime(&quot;2022-01-23&quot;);    car.setGuidePrice(12.3);    car.setCarNum(&quot;126&quot;);    SqlSession sqlSession = SqlSessionUtil.openSession();    int count = sqlSession.update(&quot;updateById&quot;, car);    System.out.println(&quot;count = &quot; + count);&#125;\n\n\nxml\n\n&lt;update id=&quot;updateById&quot;&gt;    UPDATE t_car SET        car_num = #&#123;carNum&#125;, brand = #&#123;brand&#125;, guide_price = #&#123;guidePrice&#125;,        produce_time = #&#123;produceTime&#125;, car_type = #&#123;carType&#125;    where id = #&#123;id&#125;&lt;/update&gt;\n\n2.3 Delete\n使用SqlSession.delete(&quot;id&quot;, map/object)接口\n\n\njava\n\npublic void testDelete()&#123;    SqlSession sqlSession = SqlSessionUtil.openSession();    int count = sqlSession.delete(&quot;deleteByCarNum&quot;, &quot;124&quot;);    System.out.println(&quot;count = &quot; + count);&#125;\n\n\nxml\n\n&lt;delete id=&quot;deleteByCarNum&quot;&gt;    DELETE FROM t_car WHERE car_num = #&#123;carNum&#125;&lt;/delete&gt;\n\n2.4 Read\n需要特别注意的时候, 因为返回的数量不同, 所以对于selete, 有两个接口分别用于返回单个结果的查询语句和返回List的查询语句\n\n\n同时对于xml而言, 也需要额外指定resultType这个属性, 用于获取类的字节码\n\n\n同时注意数据库中字段命名的方式和Java程序中往往不一样, 所以对查询出来的内容做重命名\n\n@Testpublic void testSelectList()&#123;    SqlSession sqlSession = SqlSessionUtil.openSession();    List&lt;Object&gt; cars = sqlSession.selectList(&quot;selectCarAll&quot;);    cars.forEach(car -&gt; System.out.println(car));&#125;@Testpublic void testQueryOne()&#123;    SqlSession sqlSession = SqlSessionUtil.openSession();    Object car = sqlSession.selectOne(&quot;selectCarById&quot;, 1);    System.out.println(&quot;car = &quot; + car);&#125;\n\n\nxml\n\n&lt;select id=&quot;selectCarById&quot; resultType=&quot;com.func.mybatis.crud.Car&quot;&gt;    SELECT id, brand, car_num carNum, guide_price guidePrice, produce_time produceTime, car_type carType    FROM t_car    WHERE id = #&#123;id&#125;&lt;/select&gt;&lt;select id=&quot;selectCarAll&quot; resultType=&quot;com.func.mybatis.crud.Car&quot;&gt;    SELECT id, brand, car_num carNum, guide_price guidePrice, produce_time produceTime, car_type carType    FROM t_car&lt;/select&gt;\n\n2.5 名称空间\n如果多个resource文件中的sql语句id一样, 这个时候通过添加namespace来进行区分\n\n3. Mybatis核心配置文件详解&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;environments default=&quot;development&quot;&gt;        &lt;environment id=&quot;development&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/powernode&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;        &lt;mapper resource=&quot;CarMapper.xml&quot;/&gt;        &lt;mapper resource=&quot;CarMapper2.xml&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\n\n\nconfiguration：根标签，表示配置信息。\nenvironments：环境（多个），以“s”结尾表示复数，也就是说mybatis的环境可以配置多个数据源。\ndefault属性：表示默认使用的是哪个环境，default后面填写的是environment的id。default的值只需要和environment的id值一致即可。\n\n\nenvironment：具体的环境配置（主要包括：事务管理器的配置 + 数据源的配置）\nid：给当前环境一个唯一标识，该标识用在environments的default后面，用来指定默认环境的选择。\n\n\ntransactionManager：配置事务管理器\ntype属性：指定事务管理器具体使用什么方式，可选值包括两个\nJDBC：使用JDBC原生的事务管理机制。底层原理：事务开启conn.setAutoCommit(false); …处理业务…事务提交conn.commit();\nMANAGED：交给其它容器来管理事务，比如WebLogic、JBOSS等。如果没有管理事务的容器，则没有事务。没有事务的含义：只要执行一条DML语句，则提交一次。\n\n\n\n\ndataSource：指定数据源\ntype属性：用来指定具体使用的数据库连接池的策略，可选值包括三个\nUNPOOLED：采用传统的获取连接的方式，虽然也实现Javax.sql.DataSource接口，但是并没有使用池的思想。\nproperty可以是：\ndriver 这是 JDBC 驱动的 Java 类全限定名。\nurl 这是数据库的 JDBC URL 地址。\nusername 登录数据库的用户名。\npassword 登录数据库的密码。\ndefaultTransactionIsolationLevel 默认的连接事务隔离级别。\ndefaultNetworkTimeout 等待数据库操作完成的默认网络超时时间（单位：毫秒）\n\n\n\n\nPOOLED：采用传统的javax.sql.DataSource规范中的连接池，mybatis中有针对规范的实现。\nproperty可以是（除了包含UNPOOLED中之外）：\npoolMaximumActiveConnections 在任意时间可存在的活动（正在使用）连接数量，默认值：10\npoolMaximumIdleConnections 任意时间可能存在的空闲连接数。\n其它….\n\n\n\n\nJNDI：采用服务器提供的JNDI技术实现，来获取DataSource对象，不同的服务器所能拿到DataSource是不一样。如果不是web或者maven的war工程，JNDI是不能使用的。\nproperty可以是（最多只包含以下两个属性）：\ninitial_context 这个属性用来在 InitialContext 中寻找上下文（即，initialContext.lookup(initial_context)）这是个可选属性，如果忽略，那么将会直接从 InitialContext 中寻找 data_source 属性。\ndata_source 这是引用数据源实例位置的上下文路径。提供了 initial_context 配置时会在其返回的上下文中进行查找，没有提供时則直接在 InitialContext 中查找。\n\n\n\n\n\n\n\n\nmappers：在mappers标签中可以配置多个sql映射文件的路径。\nmapper：配置某个sql映射文件的路径\nresource属性：使用相对于类路径的资源引用方式\nurl属性：使用完全限定资源定位符（URL）方式\n\n\n\n4.1 environmentmybatis-003-configuration\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;!--默认使用开发环境--&gt;    &lt;!--&lt;environments default=&quot;dev&quot;&gt;--&gt;    &lt;!--默认使用生产环境--&gt;    &lt;environments default=&quot;production&quot;&gt;        &lt;!--开发环境--&gt;        &lt;environment id=&quot;dev&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/powernode&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;        &lt;!--生产环境--&gt;        &lt;environment id=&quot;production&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot; /&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;        &lt;mapper resource=&quot;CarMapper.xml&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;car&quot;&gt;    &lt;insert id=&quot;insertCar&quot;&gt;        insert into t_car(id,car_num,brand,guide_price,produce_time,car_type) values(null,#&#123;carNum&#125;,#&#123;brand&#125;,#&#123;guidePrice&#125;,#&#123;produceTime&#125;,#&#123;carType&#125;)    &lt;/insert&gt;&lt;/mapper&gt;\npackage com.powernode.mybatis;import com.powernode.mybatis.pojo.Car;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.junit.Test;public class ConfigurationTest &#123;    @Test    public void testEnvironment() throws Exception&#123;        // 准备数据        Car car = new Car();        car.setCarNum(&quot;133&quot;);        car.setBrand(&quot;丰田霸道&quot;);        car.setGuidePrice(50.3);        car.setProduceTime(&quot;2020-01-10&quot;);        car.setCarType(&quot;燃油车&quot;);        // 一个数据库对应一个SqlSessionFactory对象        // 两个数据库对应两个SqlSessionFactory对象，以此类推        SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();        // 使用默认数据库        SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;));        SqlSession sqlSession = sqlSessionFactory.openSession(true);        int count = sqlSession.insert(&quot;insertCar&quot;, car);        System.out.println(&quot;插入了几条记录：&quot; + count);        // 使用指定数据库        SqlSessionFactory sqlSessionFactory1 = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;), &quot;dev&quot;);        SqlSession sqlSession1 = sqlSessionFactory1.openSession(true);        int count1 = sqlSession1.insert(&quot;insertCar&quot;, car);        System.out.println(&quot;插入了几条记录：&quot; + count1);    &#125;&#125;\n执行结果：\n4.2 transactionManager&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;environments default=&quot;dev&quot;&gt;        &lt;environment id=&quot;dev&quot;&gt;            &lt;transactionManager type=&quot;MANAGED&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/powernode&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;        &lt;mapper resource=&quot;CarMapper.xml&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\n@Testpublic void testTransactionManager() throws Exception&#123;    // 准备数据    Car car = new Car();    car.setCarNum(&quot;133&quot;);    car.setBrand(&quot;丰田霸道&quot;);    car.setGuidePrice(50.3);    car.setProduceTime(&quot;2020-01-10&quot;);    car.setCarType(&quot;燃油车&quot;);    // 获取SqlSessionFactory对象    SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();    SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config2.xml&quot;));    // 获取SqlSession对象    SqlSession sqlSession = sqlSessionFactory.openSession();    // 执行SQL    int count = sqlSession.insert(&quot;insertCar&quot;, car);    System.out.println(&quot;插入了几条记录：&quot; + count);&#125;\n当事务管理器是：JDBC\n\n采用JDBC的原生事务机制：\n开启事务：conn.setAutoCommit(false);\n处理业务……\n提交事务：conn.commit();\n\n\n\n当事务管理器是：MANAGED\n\n交给容器去管理事务，但目前使用的是本地程序，没有容器的支持，当mybatis找不到容器的支持时：没有事务。也就是说只要执行一条DML语句，则提交一次。\n\n4.3 dataSource&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;environments default=&quot;dev&quot;&gt;        &lt;environment id=&quot;dev&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;UNPOOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/powernode&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;        &lt;mapper resource=&quot;CarMapper.xml&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\n@Testpublic void testDataSource() throws Exception&#123;    // 准备数据    Car car = new Car();    car.setCarNum(&quot;133&quot;);    car.setBrand(&quot;丰田霸道&quot;);    car.setGuidePrice(50.3);    car.setProduceTime(&quot;2020-01-10&quot;);    car.setCarType(&quot;燃油车&quot;);    // 获取SqlSessionFactory对象    SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();    SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config3.xml&quot;));    // 获取SqlSession对象    SqlSession sqlSession = sqlSessionFactory.openSession(true);    // 执行SQL    int count = sqlSession.insert(&quot;insertCar&quot;, car);    System.out.println(&quot;插入了几条记录：&quot; + count);    // 关闭会话    sqlSession.close();&#125;\n当type是UNPOOLED，控制台输出：修改配置文件mybatis-config3.xml中的配置：\n&lt;dataSource type=&quot;POOLED&quot;&gt;\nJava测试程序不需要修改，直接执行，看控制台输出：通过测试得出：UNPOOLED不会使用连接池，每一次都会新建JDBC连接对象。POOLED会使用数据库连接池。【这个连接池是mybatis自己实现的。】\n&lt;dataSource type=&quot;JNDI&quot;&gt;\nJNDI的方式：表示对接JNDI服务器中的连接池。这种方式给了我们可以使用第三方连接池的接口。如果想使用dbcp、c3p0、druid（德鲁伊）等，需要使用这种方式。这种再重点说一下type&#x3D;”POOLED”的时候，它的属性有哪些？\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;environments default=&quot;dev&quot;&gt;        &lt;environment id=&quot;dev&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/powernode&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;                &lt;!--最大连接数--&gt;                &lt;property name=&quot;poolMaximumActiveConnections&quot; value=&quot;3&quot;/&gt;                &lt;!--这是一个底层设置，如果获取连接花费了相当长的时间，连接池会打印状态日志并重新尝试获取一个连接（避免在误配置的情况下一直失败且不打印日志），默认值：20000 毫秒（即 20 秒）。--&gt;                &lt;property name=&quot;poolTimeToWait&quot; value=&quot;20000&quot;/&gt;                &lt;!--强行回归池的时间--&gt;                &lt;property name=&quot;poolMaximumCheckoutTime&quot; value=&quot;20000&quot;/&gt;                &lt;!--最多空闲数量--&gt;                &lt;property name=&quot;poolMaximumIdleConnections&quot; value=&quot;1&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;        &lt;mapper resource=&quot;CarMapper.xml&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\npoolMaximumActiveConnections：最大的活动的连接数量。默认值10poolMaximumIdleConnections：最大的空闲连接数量。默认值5poolMaximumCheckoutTime：强行回归池的时间。默认值20秒。poolTimeToWait：当无法获取到空闲连接时，每隔20秒打印一次日志，避免因代码配置有误，导致傻等。（时长是可以配置的）当然，还有其他属性。对于连接池来说，以上几个属性比较重要。最大的活动的连接数量就是连接池连接数量的上限。默认值10，如果有10个请求正在使用这10个连接，第11个请求只能等待空闲连接。最大的空闲连接数量。默认值5，如何已经有了5个空闲连接，当第6个连接要空闲下来的时候，连接池会选择关闭该连接对象。来减少数据库的开销。需要根据系统的并发情况，来合理调整连接池最大连接数以及最多空闲数量。充分发挥数据库连接池的性能。【可以根据实际情况进行测试，然后调整一个合理的数量。】下图是默认配置：在以上配置的基础之上，可以编写java程序测试：\n@Testpublic void testPool() throws Exception&#123;    SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();    SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config3.xml&quot;));    for (int i = 0; i &lt; 4; i++) &#123;        SqlSession sqlSession = sqlSessionFactory.openSession();        Object selectCarByCarNum = sqlSession.selectOne(&quot;selectCarByCarNum&quot;);    &#125;&#125;\n&lt;select id=&quot;selectCarByCarNum&quot; resultType=&quot;com.powernode.mybatis.pojo.Car&quot;&gt;  select id,car_num carNum,brand,guide_price guidePrice,produce_time produceTime,car_type carType from t_car where car_num = &#x27;100&#x27;&lt;/select&gt;\n\n4.4 propertiesmybatis提供了更加灵活的配置，连接数据库的信息可以单独写到一个属性资源文件中，假设在类的根路径下创建jdbc.properties文件，配置如下：\njdbc.driver=com.mysql.cj.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/powernode\n在mybatis核心配置文件中引入并使用：\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;!--引入外部属性资源文件--&gt;    &lt;properties resource=&quot;jdbc.properties&quot;&gt;        &lt;property name=&quot;jdbc.username&quot; value=&quot;root&quot;/&gt;        &lt;property name=&quot;jdbc.password&quot; value=&quot;root&quot;/&gt;    &lt;/properties&gt;    &lt;environments default=&quot;dev&quot;&gt;        &lt;environment id=&quot;dev&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;!--$&#123;key&#125;使用--&gt;                &lt;property name=&quot;driver&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;        &lt;mapper resource=&quot;CarMapper.xml&quot;/&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\n编写Java程序进行测试：\n@Testpublic void testProperties() throws Exception&#123;    SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();    SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config4.xml&quot;));    SqlSession sqlSession = sqlSessionFactory.openSession();    Object car = sqlSession.selectOne(&quot;selectCarByCarNum&quot;);    System.out.println(car);&#125;\nproperties两个属性：resource：这个属性从类的根路径下开始加载。【常用的。】url：从指定的url加载，假设文件放在d:&#x2F;jdbc.properties，这个url可以写成：file:&#x2F;&#x2F;&#x2F;d:&#x2F;jdbc.properties。注意是三个斜杠哦。注意：如果不知道mybatis-config.xml文件中标签的编写顺序的话，可以有两种方式知道它的顺序：\n\n第一种方式：查看dtd约束文件。\n第二种方式：通过idea的报错提示信息。【一般采用这种方式】\n\n4.5 mappermapper标签用来指定SQL映射文件的路径，包含多种指定方式，这里先主要看其中两种：第一种：resource，从类的根路径下开始加载【比url常用】\n&lt;mappers&gt;  &lt;mapper resource=&quot;CarMapper.xml&quot;/&gt;&lt;/mappers&gt;\n如果是这样写的话，必须保证类的根下有CarMapper.xml文件。如果类的根路径下有一个包叫做test，CarMapper.xml如果放在test包下的话，这个配置应该是这样写：\n&lt;mappers&gt;  &lt;mapper resource=&quot;test/CarMapper.xml&quot;/&gt;&lt;/mappers&gt;\n第二种：url，从指定的url位置加载假设CarMapper.xml文件放在d盘的根下，这个配置就需要这样写：\n&lt;mappers&gt;  &lt;mapper url=&quot;file:///d:/CarMapper.xml&quot;/&gt;&lt;/mappers&gt;\nmapper还有其他的指定方式，后面再看！！！\n5. 在WEB中应用Mybatis5.1 实现在代码或者官方文档中查看, 这里不再赘述\n5.2 Mybatis对象作用域以及事务问题5.2.1 对象作用域SqlSessionFactoryBuilder这个对象一旦创建了SqlSessionFactory以后就不再被需要, 故最好的作用域就是局部作用域, 创建后就销毁, 以释放XML资源\nSqlSessionFactory一旦被创建后就应该在应用运行期间一直存在, 重复创建SqlSessionFactory被视作一种坏习惯. 最佳作用域就是应用作用域, 最简单的实现方式就是使用单例模式或者静态单例模式\nSqlSession每个线程都应该有他自己的SqlSession实例, 该实例是不线程安全的, 所以是不能被共享的, 最佳作用域是请求或方法作用域, 每次收到一个HTTP请求, 就可以打开一个SqlSession, 返回一个响应以后, 就关闭他, 关闭操作必须执行, 并且很重要\n事务问题如果需要实现事务的提交, 以保证Sql语句都成功或失败执行, 该怎么做 ? \n\n修改SqlSessionUtil, 创建线程本地SqlSession变量, 以此保证能在Dao中执行sql语句, 能在Service中commit\nThreadLocal&lt;?&gt; : 线程本地变量, 会为每个线程独立创建一个对应变量的副本, 以供整个线程使用\n\npublic class SqlSessionUtil &#123;    private static SqlSessionFactory sqlSessionFactory;    private static ThreadLocal&lt;SqlSession&gt; local = new ThreadLocal&lt;&gt;();    static &#123;        try &#123;            SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();            sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;));        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    public static SqlSession openSession()&#123;        SqlSession sqlSession = local.get();        if (sqlSession == null) &#123;            sqlSession = sqlSessionFactory.openSession();            local.set(sqlSession);        &#125;        return sqlSession;    &#125;    public static void close(SqlSession sqlSession)&#123;        if (sqlSession != null) &#123;            sqlSession.close();        &#125;        local.remove();    &#125;&#125;\n\n6. javassist生成类\n用于解决Dao层重复的sql代码, 可以为类动态添加方法\n\n6.1 第一个程序\n创建类池 ClassPool = ClassPool.getDeault()\n从类池中创建类 pool.makeClass(&quot;package name&quot;)\n为类创建方法, 需要指定返回类型, 方法名, 形参列表, 所属类 CtMethod = new\n为方法添加权限修饰符 ctMethod.setModifiters()\n为方法添加方法体 ctClass.addMethod(ctMethod)\n将方法添加到类上ctClass.addMethod(ctMethod)\n获取类的实例 newInstance()\n执行方法\n\n    public void testJavassist() throws CannotCompileException, InstantiationException, IllegalAccessException, NoSuchMethodException, InvocationTargetException &#123;        // 获取类池        ClassPool pool = ClassPool.getDefault();        // 创建类        CtClass ctClass = pool.makeClass(&quot;com.func.bank.test.Test&quot;);        // 为类创建方法        // 返回类型, 方法名, 形式参数列表, 所属类        CtMethod ctMethod = new CtMethod(CtClass.voidType, &quot;execute&quot;, new CtClass[]&#123;&#125;, ctClass);        // 为方法添加权限修饰符        ctMethod.setModifiers(Modifier.PUBLIC);        // 为方法添加方法体        ctMethod.setBody(&quot;&#123;System.out.println(\\&quot;Hello world\\&quot;);&#125;&quot;);        // 为类添加方法        ctClass.addMethod(ctMethod);        //调用方法j        Class&lt;?&gt; aClass = ctClass.toClass();        Object o = aClass.newInstance();        Method method = o.getClass().getDeclaredMethod(&quot;execute&quot;);        method.invoke(o);    &#125;&#125;\n\n6.2 使用Javassist动态生成DaoImplpackage com.func.javassist;import com.func.bank.pojo.Account;import javassist.CannotCompileException;import javassist.ClassPool;import javassist.CtClass;import javassist.CtMethod;import org.apache.ibatis.mapping.SqlCommandType;import org.apache.ibatis.session.SqlSession;import java.lang.reflect.*;import java.util.Arrays;public class GenerateDaoByJavassist &#123;    /**     * 创建dao层的接口的代理对象, 实现其中的增删改查     * @param sqlSession 会话实例     * @param daoInterface 需要被代理的接口     * @return 接口的代理类     */    public static Object getMapper(SqlSession sqlSession, Class daoInterface)&#123;        // 生成代理类        ClassPool classPool = ClassPool.getDefault();            // 拼接代理类的完整包名        CtClass ctClass = classPool.makeClass(daoInterface.getPackageName() + &quot;.impl.&quot; + daoInterface.getSimpleName() + &quot;Impl&quot;);            // 将接口类放入类池        CtClass ctInterface = classPool.makeClass(daoInterface.getName());            // 代理类代理接口类        ctClass.addInterface(ctInterface);        // 获取接口中的所有方法并实现        Method[] methods = daoInterface.getDeclaredMethods();        Arrays.stream(methods).forEach(method -&gt; &#123;            // 拼接方法的签名            StringBuilder methodStr = new StringBuilder();            // 返回类型, 直接获取的是Class&lt;?&gt;, 不是类型名            String returnType = method.getReturnType().getName();            methodStr.append(returnType);            methodStr.append(&quot; &quot;);            // 拼接方法名            String methodName = method.getName();            methodStr.append(methodName);            methodStr.append(&quot; &quot;);            // 拼接参数列表            methodStr.append(&quot;(&quot;);            Class&lt;?&gt;[] parameterTypes = method.getParameterTypes();            for (int i = 0; i &lt; parameterTypes.length; i++) &#123;                Class&lt;?&gt; parameterType = parameterTypes[i];                String typeName = parameterType.getName();                methodStr.append(typeName);                methodStr.append(&quot; arg&quot;);                methodStr.append(i);                if (i != parameterTypes.length - 1) &#123;                    methodStr.append(&quot;, &quot;);                &#125;            &#125;            methodStr.append(&quot;) &#123;&quot;);            // 拼接方法体                // 获取对应需要执行的Sql语句的type            // 这行代码导致以后namespace必须是接口的全限定接口名, sqlId必须是方法名            String sqlId = daoInterface.getName() + &quot;.&quot; + methodName;            // 获取SQLCommandType            String sqlCommandType = sqlSession.getConfiguration().getMappedStatement(sqlId).getSqlCommandType().name();            if (&quot;SELECT&quot;.equals(sqlCommandType)) &#123;                // 获取session对象                methodStr.append(&quot;org.apache.ibatis.session.SqlSession sqlSession = com.func.bank.utils.SqlSessionUtil.openSession();&quot;);                // 执行SQL语句                methodStr.append(&quot;Object obj = sqlSession.selectOne(\\&quot;&quot;+ sqlId + &quot;\\&quot;,&quot; + &quot;arg0);&quot;);                methodStr.append(&quot;return (&quot; + returnType + &quot;) obj;&quot;);            &#125; else if (&quot;UPDATE&quot;.equals(sqlCommandType)) &#123;                // 获取session对象                methodStr.append(&quot;org.apache.ibatis.session.SqlSession sqlSession = com.func.bank.utils.SqlSessionUtil.openSession();&quot;);                // 执行SQL语句                methodStr.append(&quot;int count = sqlSession.update(\\&quot;&quot;+ sqlId + &quot;\\&quot;,&quot; + &quot;arg0);&quot;);                methodStr.append(&quot;return count;&quot;);            &#125;            methodStr.append(&quot;&#125;&quot;);            System.out.println(methodStr);            try &#123;                // 将方法添加到类中                CtMethod ctMethod = CtMethod.make(methodStr.toString(), ctClass);                ctMethod.setModifiers(Modifier.PUBLIC);                ctClass.addMethod(ctMethod);            &#125; catch (CannotCompileException e) &#123;                throw new RuntimeException(e);            &#125;        &#125;);        try &#123;            // 创建实体类            Class&lt;?&gt; aClass = ctClass.toClass();            Constructor&lt;?&gt; declaredConstructor = aClass.getDeclaredConstructor();            Object o = declaredConstructor.newInstance();            return o;        &#125; catch (CannotCompileException e) &#123;            throw new RuntimeException(e);        &#125; catch (NoSuchMethodException e) &#123;            throw new RuntimeException(e);        &#125; catch (InstantiationException e) &#123;            throw new RuntimeException(e);        &#125; catch (IllegalAccessException e) &#123;            throw new RuntimeException(e);        &#125; catch (InvocationTargetException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\n7. MyBatis中的接口代理机制\n很不幸的消息 : 第六章中的对于Dao层重复代码的抽象, 在Mybatis中已经实现了\n\n\n但是这个时候一般不写Dao作为标注, 而是Mapper, 也是为了能说明这是MyBatis实现的Dao层接口\n\nAccountDao accountDao = (AccountDao)sqlSession.getMapper(AccountDao.class)\n\n8. 一些MyBatis使用技巧\n主要是一些便捷的设置和SQL拼接上的说明\n\n8.1 IDEA设置模板文件\nsetting -&gt; Editor -&gt; File and Code Templates\n\nmybatis-config.xml\n\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration        PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;    &lt;properties resource=&quot;jdbc.properties&quot;/&gt;    &lt;environments default=&quot;dev&quot;&gt;        &lt;environment id=&quot;dev&quot;&gt;            &lt;transactionManager type=&quot;JDBC&quot;/&gt;            &lt;dataSource type=&quot;POOLED&quot;&gt;                &lt;property name=&quot;driver&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;/&gt;                &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt;                &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot;/&gt;                &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;mappers&gt;        &lt;!--一定要注意这里的路径哦！！！--&gt;    &lt;/mappers&gt;&lt;/configuration&gt;\n\n\nsqlMapper.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper        PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;        &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace = &gt;&lt;/mapper&gt;\n\n8.2 #{}和${}\n前者就是我们经常使用的那个, 它和后者的区别在于底层的实现, 前者是PreparedStatement, 后者是Statement, 也就是说, 这两者不能混用, 带有前者的是预编译后再传值, 能预防sql注入, 后者先传值后编译, 存在sql注入\n\n\n${}的用法, 其实就是sql拼接的应用\n\n8.2.1 两者的区别\n在#{value}中填入的值, 最后在SQL语句中是以’value’的形式存在的\n执行后生成的sql语句中带有 ? 占位符, 用于接收传入的值\n\n\n在${value}中填入的值, 最后在SQL中是直接以value的形式存在的\n执行后生成的sql语句是没有占位符的完全的sql语句\n\n\n\n8.2.2 ${}的特殊用法拼接表名\n实际开发中, 存在分库分表, 这个时候往往会有需要通过拼接表名\n通过查询的sql语句, 很容易知道, 这个时候不能通过#{}去填入表名, 这样表名会带’’, 所以只能通过${}拼接表名\n\n批量删除\n通过sql语句中的in(list)实现删除, 这个时候也是不能传入#{}, 会带有’’\n\n模糊查询\n与上同理, 但这个时候, 由模糊查询的多种形式, 其实两种方式都可以\n\n${}\n\n\n&lt;select id=&quot;selectLikeByBrand&quot; resultType=&quot;Car&quot;&gt;    select *    from t_car    where     brand like &#x27;%$&#123;brand&#125;%&#x27;&lt;/select&gt;\n\n\n#{}\n\n&lt;select id=&quot;selectLikeByBrand&quot; resultType=&quot;Car&quot;&gt;    select *    from t_car    where     brand like concat(&#x27;%&#x27;, #&#123;brand&#125;, &#x27;%&#x27;)&lt;/select&gt;\n\n8.3 别名\n一般就用于给resultType做简化, 不然每次都需要从项目根路径开始填起\n\n\n在mybatis-config中&lt;configuration&gt;下\n别名不区分大小写\n\n指定单个&lt;typeAliases&gt;    &lt;typeAlias type=&quot;com.func.mybatis.crud.Car&quot; alias=&quot;Car&quot;/&gt;&lt;/typeAliases&gt;\n\n\n也可以不填alias, 这个时候默认是类的SimpleName()\n\n指定整个包&lt;!-- 在properties下面 --&gt;&lt;typeAliases&gt;  &lt;package name=&quot;com.powernode.mybatis.pojo&quot;/&gt;&lt;/typeAliases&gt;\n\n\n这个时候会自动为这个包下的类取别名, 名字就是简类名\n\n8.4 mappers\nresource：从类路径中加载\n\n从类路径开始加载\n\n\nurl：从指定的全限定资源路径中加载\n\n绝对路径\n\n\nclass：使用映射器接口实现类的完全限定类名\n\nSQL映射文件(Mapper.xml文件)和mapper接口放在同一个目录下\nSQL映射文件的名字也必须和mapper接口名字的完全相同\n\n\npackage：将包内的映射器接口实现全部注册为映射器\n\n\n8.5 插入数据的时候自动获取主键\n主键往往是自增的, 这个时候我们往往给主键设置的值都是null, 这个时候我们就在向数据库插入数据以后, 需要反向从数据库中获取id赋值给实体对象\n\n\n在映射文件中, 在其中的insert标签中添加useGeneratedKeys属性, 值为”true”即可, 并指定主键的列名 keyProperty&#x3D;”id”\n\n&lt;insert id=&quot;insertUseGeneratedKeys&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt;  insert into t_car(id,car_num,brand,guide_price,produce_time,car_type) values(null,#&#123;carNum&#125;,#&#123;brand&#125;,#&#123;guidePrice&#125;,#&#123;produceTime&#125;,#&#123;carType&#125;)&lt;/insert&gt;\n\n9. 使用Mapper执行语句以后的特殊处理9.1 多参数\n现在我们想通过name和sex共同查询, 多参数的传入就是个问题了如果還是和之前一样直接传值, 会出错\n\n错误例子\n\n\n/** * 根据name和sex查询 * @param name * @param sex * @return */List&lt;Student&gt; selectByNameAndSex(String name, Character sex);\n\n@Testpublic void testSelectByNameAndSex()&#123;    List&lt;Student&gt; students = mapper.selectByNameAndSex(&quot;张三&quot;, &#x27;女&#x27;);    students.forEach(student -&gt; System.out.println(student));&#125;\n\n&lt;select id=&quot;selectByNameAndSex&quot; resultType=&quot;student&quot;&gt;  select * from t_student where name = #&#123;name&#125; and sex = #&#123;sex&#125;&lt;/select&gt;\n\n\n分析报错, 我们可以知道, 问题是name参数没有找到, 能找到的可用参数只用[arg1, arg0, param1, param2]\n\n之前我们碰到了这个问题吗, 没有的话, 为什么 ?\n以前是通过将传入的参数, 存储到Map中, 再将map传入, 但是现在Dao层是MyBaties自动实现的, 所以这个方法行不通了\n\n\n\n\n解决方法 1\n\n\n根据报错信息, 直接将select语句中的参数改为arg0, arg1 (param1, param2) 即可\n\n&lt;select id=&quot;selectByNameAndSex&quot; resultType=&quot;student&quot;&gt;  &lt;!--select * from t_student where name = #&#123;name&#125; and sex = #&#123;sex&#125;--&gt;  &lt;!--select * from t_student where name = #&#123;arg0&#125; and sex = #&#123;arg1&#125;--&gt;  &lt;!--select * from t_student where name = #&#123;param1&#125; and sex = #&#123;param2&#125;--&gt;  select * from t_student where name = #&#123;arg0&#125; and sex = #&#123;param2&#125;&lt;/select&gt;\n\n\n原理, MyBatis底层会创建一个map集合, 以arg0,&#x2F;param1为key, 以上方法上的参数为value\n\nMap&lt;String,Object&gt; map = new HashMap&lt;&gt;();map.put(&quot;arg0&quot;, name);map.put(&quot;arg1&quot;, sex);map.put(&quot;param1&quot;, name);map.put(&quot;param2&quot;, sex);// 所以可以这样取值：#&#123;arg0&#125; #&#123;arg1&#125; #&#123;param1&#125; #&#123;param2&#125;// 其本质就是#&#123;map集合的key&#125;\n\n9.2 @Param 注解\n这就是第二种解决方案\n\n第一种解决方案, 实际上使用了MyBatis自己创建的map, 我们也可以自己创建map\n\n在Mapper的参数上, 指定这个变量的在Map中的key\n\n/** * 根据name和age查询 * @param name * @param age * @return */List&lt;Student&gt; selectByNameAndAge(@Param(value=&quot;name&quot;) String name, @Param(&quot;age&quot;) int age);\n\n\n映射文件以{Key}中 key 去map中查找值\n\n&lt;select id=&quot;selectByNameAndAge&quot; resultType=&quot;student&quot;&gt;  select * from t_student where name = #&#123;name&#125; and age = #&#123;age&#125;&lt;/select&gt;\n\n10. MyBatis查询语句专题10.1 一些常见报错的解释\nTooManyResultException\n解释 : 只是用了Object接收List, 非集合对象, 无法接收多个返回结果\n\n\n\n10.2 使用Map集合接收返回结果\n使用Map&lt;String, Object&gt; 作为返回值\n这个时候就会将返回结果以键值对的形式存储到返回的Map中\n这个时候的select的返回类型, 需要设定为 “map”, 这个是MyBatis内置的别名\n\n10.3 使用List&lt;Map&gt; 作为返回结果\n这个就对应着前面的返回多个Object的时候需要使用List&lt;&gt;接收是一样的情况\nresultType同样设置为map\n\n10.4 使用Map&lt;String, Map&gt;\n使用这个存储结构, 一般是将id作为外层Map的key, 这样方便查找\n\n实现\n\n\n\n创建Mapper, 这里需要指定map的key是查找到的对象的什么字段, 一般就是指定id作为key\n\npublic interface CarMapper &#123;    /**     * 设定map的key是id, value是Car     * @return     */    @MapKey(&quot;id&quot;)    Map&lt;Long, Map&lt;String, Object&gt;&gt; selectAll();&#125;\n\nCarMapper mapper = SqlSessionUtil.openSession().getMapper(CarMapper.class);    @Test    public void testMapSelect()&#123;        Map&lt;Long, Map&lt;String, Object&gt;&gt; map = mapper.selectAll();        System.out.println(map);    &#125;\n\n    &lt;select id=&quot;selectAll&quot; resultType=&quot;map&quot;&gt;    SELECT id,car_num carNum,brand,guide_price guidePrice,produce_time produceTime,car_type carType    from t_car&lt;/select&gt;\n\n10.5 resultMap结果映射\n主要是为了解决查询结果的列名和对象的字段名不同的问题\n\n这个问题一般是用数据库中的列名命名风格往往是_, 下划线式, 但是java中的属性的命名一般是驼峰命名\n\n三种解决方式\n\n在查询语句中使用as给列起别名\n使用resultMap进行结果映射, 在&lt;mapper&gt;标签中\n开启驼峰命名自动映射, 在&lt;settings&gt;标签中\n\n\n使用resultMap映射\n\n\n&lt;mapper namespace = &quot;com.func.mybatis.select.CarMapper&quot;&gt;        &lt;resultMap id=&quot;carResult&quot; type=&quot;car&quot;&gt;        &lt;id property=&quot;id&quot; column=&quot;id&quot;/&gt;        &lt;result property=&quot;carNum&quot; column=&quot;car_num&quot;/&gt;        &lt;result property=&quot;guidePrice&quot; column=&quot;guide_price&quot;/&gt;        &lt;result property=&quot;produceTime&quot; column=&quot;produce_time&quot;/&gt;        &lt;result property=&quot;carType&quot; column=&quot;car_type&quot;/&gt;    &lt;/resultMap&gt;    &lt;select id=&quot;selectAllByResultMap&quot; resultMap=&quot;carResult&quot; resultType=&quot;car&quot;&gt;        SELECT * from t_car    &lt;/select&gt;&lt;/mapper&gt;\n\npublic interface CarMapper &#123;    List&lt;Car&gt; selectAllByResultMap();    /**     * 设定map的key是id, value是Car     * @return     */    @MapKey(&quot;id&quot;)    Map&lt;Long, Map&lt;String, Object&gt;&gt; selectAll();&#125;\n\n\n自动映射\n\n&lt;!--在properties后面--&gt;&lt;settings&gt;    &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt;&lt;/settings&gt;\n\n11. 动态SQL\n其实之前也介绍过动态SQL的实现, 通过${}拼接, 但是这种实现, 过于繁琐, 如果我们想在查询过程中动态加上某个where条件, 通过${}拼接实现, 是很繁琐且奇怪的实现方式\nMyBatis为我们提供了实现便捷实现动态SQL的功能\n\n11.1 if标签\n该标签的主要功能是测试test中的语句, 如果满足条件, 才会为sql添加value中的内容\n\n&lt;select id=&quot;selectDynamic&quot; resultType=&quot;car&quot;&gt;    SELECT * from t_car WHERE    &lt;if test=&quot;brand != null and brand != &#x27;&#x27;&quot;&gt;        brand LIKE #&#123;brand&#125;&quot;%&quot;     &lt;/if&gt;    &lt;if test=&quot;carType != null and carType != &#x27;&#x27;&quot;&gt;        and car_type = #&#123;carType&#125;     &lt;/if&gt;    &lt;if test=&quot;carNum != null and carNum != &#x27;&#x27;&quot;&gt;        and car_num = #&#123;carNum&#125;    &lt;/if&gt;&lt;/select&gt;\n\nList&lt;Car&gt; selectDynamic(@Param(&quot;carNum&quot;) String carNum, @Param(&quot;carType&quot;) String carType, @Param(&quot;brand&quot;) String brand);    List&lt;Car&gt; cars = mapper.selectDynamic(&quot;102&quot;, &quot;氢能源&quot;, &quot;丰&quot;);    System.out.println(cars);\n\n\n但是使用这个查询有个问题, 如果第一句或最后一句为空, 则会有多余的and出现\n\n\n我们可以在 where的后面添加上 0 &#x3D; 0 这样的恒等式来解决前面的多余的and , MyBatis也考虑到了这一点, 给了更便捷的消去前面的多余的and的方法, where标签\n\n11.2 where标签\n功能 : 让where子句更加智能, 如果条件都为空的时候, 能保证不会生成where子句, 自动去除 前面 的多余的and和or\n\n&lt;select id=&quot;selectDynamic&quot; resultType=&quot;car&quot;&gt;    SELECT * from t_car    &lt;where&gt;        &lt;if test=&quot;brand != null and brand != &#x27;&#x27;&quot;&gt;            brand LIKE #&#123;brand&#125;&quot;%&quot;        &lt;/if&gt;        &lt;if test=&quot;carType != null and carType != &#x27;&#x27;&quot;&gt;            and car_type = #&#123;carType&#125;        &lt;/if&gt;        &lt;if test=&quot;carNum != null and carNum != &#x27;&#x27;&quot;&gt;            and car_num = #&#123;carNum&#125;        &lt;/if&gt;    &lt;/where&gt;&lt;/select&gt;\n\n\n但是问题是, 它并不能去除句末的多余的and或or\n\n11.3 trim标签\n更加智能的, 能指定在句前添加内容和去除多余前缀或多余后缀的标签\nprefix : trim标签中的语句前添加内容\nsuffix : 在trim标签中的语句后添加内容\nprefixOverrides : 前缀去掉的内容\nsuffixOverrides : 后缀去掉的内容\n\n\n\n&lt;select id=&quot;selectDynamic&quot; resultType=&quot;car&quot;&gt;    SELECT * from t_car    &lt;trim prefix=&quot;where&quot; prefixOverrides=&quot;and|or&quot; suffixOverrides=&quot;and|or&quot;&gt;        &lt;if test=&quot;brand != null and brand != &#x27;&#x27;&quot;&gt;            brand LIKE #&#123;brand&#125;&quot;%&quot;        &lt;/if&gt;        &lt;if test=&quot;carType != null and carType != &#x27;&#x27;&quot;&gt;            and car_type = #&#123;carType&#125;        &lt;/if&gt;        &lt;if test=&quot;carNum != null and carNum != &#x27;&#x27;&quot;&gt;            and car_num = #&#123;carNum&#125;        &lt;/if&gt;    &lt;/trim&gt;&lt;/select&gt;\n\n11.4 set标签\n主要用在update操作上, 以实现只更新我们填入了的字段\n\n&lt;update id=&quot;updateWithSet&quot;&gt;  update t_car  &lt;set&gt;    &lt;if test=&quot;carNum != null and carNum != &#x27;&#x27;&quot;&gt;car_num = #&#123;carNum&#125;,&lt;/if&gt;    &lt;if test=&quot;brand != null and brand != &#x27;&#x27;&quot;&gt;brand = #&#123;brand&#125;,&lt;/if&gt;    &lt;if test=&quot;guidePrice != null and guidePrice != &#x27;&#x27;&quot;&gt;guide_price = #&#123;guidePrice&#125;,&lt;/if&gt;    &lt;if test=&quot;produceTime != null and produceTime != &#x27;&#x27;&quot;&gt;produce_time = #&#123;produceTime&#125;,&lt;/if&gt;    &lt;if test=&quot;carType != null and carType != &#x27;&#x27;&quot;&gt;car_type = #&#123;carType&#125;,&lt;/if&gt;  &lt;/set&gt;  where id = #&#123;id&#125;&lt;/update&gt;\n\n11.5 choose when otherwise\n三个标签是一起使用的\n能实现递进式的查询, 如果有brand属性, 就按照brand属性查, 如果没有就按照price查, 如果还没有就按照type查\n\n&lt;choose&gt;  &lt;when&gt;&lt;/when&gt;  &lt;when&gt;&lt;/when&gt;  &lt;when&gt;&lt;/when&gt;  &lt;otherwise&gt;&lt;/otherwise&gt;&lt;/choose&gt;\n\n\n相当于 if else default\n\n&lt;select id=&quot;selectWithChoose&quot; resultType=&quot;car&quot;&gt;    SELECT * from t_car    &lt;where&gt;        &lt;choose&gt;            &lt;when test=&quot;brand != null and brand != &#x27;&#x27;&quot;&gt;                brand = #&#123;brand&#125;            &lt;/when&gt;            &lt;when test=&quot;guidePrice != null and guidePrice != &#x27;&#x27;&quot;&gt;                and guide_price = #&#123;guidePrice&#125;            &lt;/when&gt;            &lt;otherwise&gt;                and car_type = #&#123;carType&#125;            &lt;/otherwise&gt;        &lt;/choose&gt;    &lt;/where&gt;&lt;/select&gt;\n\n\nList&lt;Car&gt; selectWithChoose(@Param(&quot;guidePrice&quot;) String guidePrice, @Param(&quot;carType&quot;) String carType, @Param(&quot;brand&quot;) String brand);\n\n11.6 foreach标签\n用于动态生成批量操作, 比如\n\ndelete from t_car where id in(1,2,3);delete from t_car where id = 1 or id = 2 or id = 3;// 或者insert into t_car values  (null,&#x27;1001&#x27;,&#x27;凯美瑞&#x27;,35.0,&#x27;2010-10-11&#x27;,&#x27;燃油车&#x27;),  (null,&#x27;1002&#x27;,&#x27;比亚迪唐&#x27;,31.0,&#x27;2020-11-11&#x27;,&#x27;新能源&#x27;),  (null,&#x27;1003&#x27;,&#x27;比亚迪宋&#x27;,32.0,&#x27;2020-10-11&#x27;,&#x27;新能源&#x27;)\n\n这样的重复格式的语句\n批量删除\n使用in来删除\n\n&lt;delete id=&quot;deleteWithForeach&quot;&gt;    delete from t_car WHERE id in    &lt;foreach collection=&quot;ids&quot; item=&quot;id&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;, &quot;&gt;        #&#123;id&#125;    &lt;/foreach&gt;&lt;/delete&gt;\n\n\n属性解释\ncollection：集合或数组\nitem：集合或数组中的元素\nseparator：分隔符\nopen：foreach标签中所有内容的开始\nclose：foreach标签中所有内容的结束\n\n\n\nint deleteWithForeach(@Param(&quot;ids&quot;) Integer[] ids);\n\n\n通过 or 删除\n\n&lt;delete id=&quot;deleteWithForeach&quot;&gt;    delete from t_car WHERE    &lt;foreach collection=&quot;ids&quot; item=&quot;id&quot; separator=&quot;or&quot;&gt;        id = #&#123;id&#125;    &lt;/foreach&gt;&lt;/delete&gt;\n\n批量增加&lt;insert id=&quot;insertBatchForeach&quot;&gt;    INSERT INTO t_car VALUES     &lt;foreach collection=&quot;cars&quot; item=&quot;car&quot; separator=&quot;,&quot;&gt;        (null, #&#123;car.carNum&#125;, #&#123;car.brand&#125;, #&#123;car.guidePrice&#125;, #&#123;car.produceTime&#125;, #&#123;car.carType&#125;)    &lt;/foreach&gt;&lt;/insert&gt;\n\nCar car1 = new Car(&quot;1022&quot;, &quot;兰博基尼&quot;, 100.0,&quot;1998-10-11&quot;, &quot;燃油车&quot; ,  null);Car car2 = new Car(&quot;1022&quot;, &quot;兰博基尼&quot;, 100.0,&quot;1998-10-11&quot;, &quot;燃油车&quot; ,  null);Car car3 = new Car(&quot;1022&quot;, &quot;兰博基尼&quot;, 100.0,&quot;1998-10-11&quot;, &quot;燃油车&quot; ,  null);List&lt;Car&gt; cars = Arrays.asList(car1, car2, car3);System.out.println(mapper.insertBatchForeach(cars));SqlSessionUtil.openSession().commit();\n\nint insertBatchForeach(@Param(&quot;cars&quot;) List&lt;Car&gt; cars);\n\n11.7 sql标签和include标签\nsql用于声明sql片段\ninclude用于添加sql到sql语句中\n主要是用于代码复用\n\n&lt;sql id=&quot;carCols&quot;&gt;id,car_num carNum,brand,guide_price guidePrice,produce_time produceTime,car_type carType&lt;/sql&gt;&lt;select id=&quot;selectAllRetMap&quot; resultType=&quot;map&quot;&gt;  select &lt;include refid=&quot;carCols&quot;/&gt; from t_car&lt;/select&gt;&lt;select id=&quot;selectAllRetListMap&quot; resultType=&quot;map&quot;&gt;  select &lt;include refid=&quot;carCols&quot;/&gt; carType from t_car&lt;/select&gt;&lt;select id=&quot;selectByIdRetMap&quot; resultType=&quot;map&quot;&gt;  select &lt;include refid=&quot;carCols&quot;/&gt; from t_car where id = #&#123;id&#125;&lt;/select&gt;\n\n12. 高级映射和延迟加载\n本章节的主要是讲解级联查询, 及多表联查, 还有mybatis的延迟加载\n\n\npojo类\n\n\nStudent\n\n@Datapublic class Student &#123;    private Integer sid;    private String sname;    private Clazz clazz;&#125;\n\n\nClazz\n\n@Datapublic class Clazz &#123;    private Integer cid;    private String cname;&#125;\n\n12.1  多对一\n需求 : t_student表中有cid这一个属性, 我们希望查出来对应的clazz, 并将其赋值给Student类中的Clazz属性\n\n测试类\n\n\nStudentMapper mapper = SqlSessionUtil.openSession().getMapper(StudentMapper.class);@Testpublic void testMapping() &#123;    Student student = mapper.selectBySid(2);    System.out.println(student);&#125;\n\n级联属性映射\n这种查询方式, 其实就是直接用sql语句实现多表联查的直接搬运, 通过join语句, 查出来两个表的属性, 然后再在resultmap中将查出来的对应的结果赋值给clazz类返回\n\n\nSQL\n\n&lt;!--SQL--&gt;&lt;select id=&quot;selectBySid&quot; resultType=&quot;Student&quot; resultMap=&quot;studentResultMap&quot;&gt;    SELECT s.*, c.*    from t_student s JOIN t_clazz c        ON c.cid = s.cid    WHERE sid = #&#123;sid&#125;&lt;/select&gt;\n\n\nResultMap\n\n&lt;resultMap id=&quot;studentResultMap&quot; type=&quot;Student&quot;&gt;    &lt;id column=&quot;sid&quot; property=&quot;sid&quot;/&gt;    &lt;result property=&quot;sname&quot; column=&quot;sname&quot;/&gt;    &lt;result property=&quot;clazz.cid&quot; column=&quot;cid&quot;/&gt;    &lt;result property=&quot;clazz.cname&quot; column=&quot;cname&quot;/&gt;&lt;/resultMap&gt;\n\n\nStudentMapper\n\npublic interface StudentMapper &#123;    Student selectBySid(@Param(&quot;sid&quot;) Integer sid);&#125;\n通过配置association\n这种方式是对上面的多表联查的语法糖, 有更清晰的结构, 再resultMap中有体现返回的是Clazz类, 并且为其中的属性赋值的过程\n\n\nSQL &#x3D;&#x3D;&gt; 不变\n\nResultMap\n\n\n&lt;resultMap id=&quot;studentResultMap&quot; type=&quot;Student&quot;&gt;    &lt;id column=&quot;sid&quot; property=&quot;sid&quot;/&gt;    &lt;result property=&quot;sname&quot; column=&quot;sname&quot;/&gt;    &lt;association property=&quot;clazz&quot; javaType=&quot;Clazz&quot;&gt;        &lt;id property=&quot;cid&quot; column=&quot;cid&quot;/&gt;        &lt;result property=&quot;cname&quot; column=&quot;cname&quot;/&gt;    &lt;/association&gt;&lt;/resultMap&gt;\n\n分步查询\n将原先的查询语句分割成了两个子模块, 主查询语句, 子查询语句, 相比于第二种做法这里更加模块化, 能提高代码的复用性\n\n\n实现步骤 :\n\n在association的基础上, 添加column, property, javaType, select四个属性\njavaType : 返回的类型\nselect : 用于查询返回需要类型的sql语句的sqlId, 必须是全限定的id\ncolumn : 主select语句中的列, 用于关联子表, 也是select语句查询传入的参数\nproperty : 类中对应的属性名\n\n\n\n\n\n\nClazzMapper\n\n\n&lt;mapper namespace = &quot;com.func.mybatis.mapper.ClazzMapper&quot;&gt;    &lt;select id=&quot;selectByCid&quot; resultType=&quot;Clazz&quot;&gt;        SELECT *        from t_clazz        where cid = #&#123;cid&#125;    &lt;/select&gt;&lt;/mapper&gt;\n\n\nStudentSQL\n\n&lt;select id=&quot;selectBySid&quot; resultMap=&quot;studentResultMap&quot; resultType=&quot;Student&quot;&gt;    SELECT *    from t_student    where sid = #&#123;sid&#125;&lt;/select&gt;\n\n\nResultMap\n\n&lt;resultMap id=&quot;studentResultMap&quot; type=&quot;Student&quot;&gt;    &lt;id column=&quot;sid&quot; property=&quot;sid&quot;/&gt;    &lt;result property=&quot;sname&quot; column=&quot;sname&quot;/&gt;    &lt;association property=&quot;clazz&quot; javaType=&quot;Clazz&quot;                select=&quot;com.func.mybatis.mapper.ClazzMapper.selectByCid&quot;                column=&quot;cid&quot;&gt;    &lt;/association&gt;&lt;/resultMap&gt;\n\n\n新增的接口方法\n\nStudent selectByCid(@Param(&quot;cid&quot;) Integer cid);\n\n新增的查询语句\n\n&lt;select id=&quot;selectByCid&quot; resultType=&quot;Student&quot;&gt;    SELECT *    FROM t_student    WHERE cid = #&#123;cid&#125;&lt;/select&gt;\n\n13. Mybatis的缓存\n缓存 : cache , 通过减少IO的次数, 来提高程序执行的效率\n\n\nmybatis的缓存 : 将select查询的结果, 放到缓存 (内存中去) , 下次再次执行这条SQL语句的时候, 直接从缓存中读取而不再查数据库, 减少了IO和执行繁琐的查找算法的时间\n缓存分为\n一级缓存 : 将查到的数据存储到SqlSession中\n二级缓存 : 将查到的数据存储到SqlSessionFactory中\n集成第三方的缓存 : 如EhCache\n\n\n无论哪级缓存, 在数据库发生变化以后, 缓存都会作废\n\n13.1 一级缓存\n一级缓存是默认开启的, 不需要任何配置, 只要用同一个SqlSession查询同一条DQL语句就会走缓存\n因为缓存是存在SqlSession中的, 所以更换了Session以后, 也会重新查询\n\n@Testpublic void testFirstCache() throws Exception&#123;    SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();    SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;));    SqlSession sqlSession = sqlSessionFactory.openSession();    ClazzMapper mapper = sqlSession.getMapper(ClazzMapper.class);    System.out.println(mapper.selectStusByCid(1001));    // 完全一样的语句    System.out.println(mapper.selectStusByCid(1001)); // 只这次执行并没有执行SQL语句    // 改变查询内容    System.out.println(mapper.selectStusByCid(1002));    //  更换SqlSession    ClazzMapper mapper1 = sqlSessionFactory.openSession().getMapper(ClazzMapper.class);    System.out.println(mapper1.selectStusByCid(1001));    // 对数据库进行增删改查    System.out.println(mapper.insertClazz(&quot;高三六班&quot;, 1003));    sqlSession.commit();    // 再次进行查询    System.out.println(mapper.selectStusByCid(1001));&#125;\n\n13.2 二级缓存\n二级缓存的范围是SqlSessionFactory\n\n使用二级缓存需要满足以下的条件\n\n&lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;&gt;全局性开启或关闭所有映射器配置文件中已配置的任何缓存, 默认为true\n在使用二级缓存的SqlMapper.xml文件中添加配置 &lt;cache /&gt;\n使用二级缓存的实体类对象必须是可序列化的, 也就是必须实现Serializable接口\nSqlSession对象关闭或提交以后, 一级缓存中的数据才会被写入二级缓存, 此时二级缓存才是可用的\n\n\nClazzMapper.xml\n\n\n&lt;mapper namespace = &quot;com.func.mybatis.cache.mapper.ClazzMapper&quot;&gt;    &lt;!--开启二级缓存--&gt;    &lt;cache/&gt;    &lt;resultMap id=&quot;resultMapper&quot; type=&quot;Clazz&quot;&gt;        &lt;id property=&quot;cid&quot; column=&quot;cid&quot;/&gt;        &lt;result property=&quot;cname&quot; column=&quot;cname&quot;/&gt;        &lt;collection property=&quot;stus&quot; ofType=&quot;Student&quot;                    select=&quot;com.func.mybatis.cache.mapper.StudentMapper.selectByCid&quot;                    column=&quot;cid&quot;/&gt;    &lt;/resultMap&gt;    &lt;select id=&quot;selectStusByCid&quot; resultMap=&quot;resultMapper&quot; resultType=&quot;Clazz&quot;&gt;        SELECT *        FROM t_clazz        WHERE cid = #&#123;cid&#125;    &lt;/select&gt;    &lt;insert id=&quot;insertClazz&quot;&gt;        INSERT INTO t_clazz            VALUES (#&#123;cid&#125;, #&#123;cname&#125;)    &lt;/insert&gt;    &lt;select id=&quot;selectAll&quot; resultType=&quot;Clazz&quot;&gt;        select * from t_clazz    &lt;/select&gt;&lt;/mapper&gt;\n\n\nClazz.java\n\n@Datapublic class Clazz implements Serializable&#123;    private Integer cid;    private String cname;    private List&lt;Student&gt; stus;&#125;\n\n\nTest\n\npublic void testSecondCache() throws Exception&#123;    SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder();    SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;));    SqlSession sqlSession = sqlSessionFactory.openSession();    ClazzMapper mapper = sqlSession.getMapper(ClazzMapper.class);    List&lt;Clazz&gt; clazzes = mapper.selectAll();    System.out.println(clazzes);    sqlSession.close();    ClazzMapper mapper1 = sqlSessionFactory.openSession().getMapper(ClazzMapper.class);    List&lt;Clazz&gt; clazzes1 = mapper1.selectAll(); // 直接返回了在缓存中的结果    System.out.println(clazzes1); &#125;\n\n\ncache的属性\neviction：指定从缓存中移除某个对象的淘汰算法。默认采用LRU策略。\n\nLRU：Least Recently Used。最近最少使用。优先淘汰在间隔时间内使用频率最低的对象。(其实还有一种淘汰算法LFU，最不常用。)\nFIFO：First In First Out。一种先进先出的数据缓存器。先进入二级缓存的对象最先被淘汰。\nSOFT：软引用。淘汰软引用指向的对象。具体算法和JVM的垃圾回收算法有关。\nWEAK：弱引用。淘汰弱引用指向的对象。具体算法和JVM的垃圾回收算法有关。\n\n\nflushInterval：\n\n二级缓存的刷新时间间隔。单位毫秒。如果没有设置。就代表不刷新缓存，只要内存足够大，一直会向二级缓存中缓存数据。除非执行了增删改。\n\n\nreadOnly：\n\ntrue：多条相同的sql语句执行之后返回的对象是共享的同一个。性能好。但是多线程并发可能会存在安全问题。\nfalse：多条相同的sql语句执行之后返回的对象是副本，调用了clone方法。性能一般。但安全。\n\n\nsize：\n\n设置二级缓存中最多可存储的java对象数量。默认值1024。\n\n\n\n\n\n13.3 Mybatis集成EhCaChe\n用于替代mybatis自带的二级缓存, 一级缓存是不能替代的, 算是第三方的缓存组件\n\n\n导入依赖\n\n&lt;!--mybatis集成ehcache的组件--&gt;&lt;dependency&gt;  &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt;  &lt;artifactId&gt;mybatis-ehcache&lt;/artifactId&gt;  &lt;version&gt;1.2.2&lt;/version&gt;&lt;/dependency&gt;\n\n\n在mybatis-config.xml中配置插件 : 位置在typeAliases后面\n\n&lt;plugins&gt;    &lt;plugin interceptor=&quot;com.github.pagehelper.PageInterceptor&quot;&gt;&lt;/plugin&gt;&lt;/plugins&gt;\n\n使用\n使用PageHelper开启分页, 开启以后, 这个时候查出来的cars结果集已经是分页后的结果了\n同时如果想在开启分页以后获取特定页的数据, 再在之后获取pageinfo就行\n\n        PageHelper.startPage(2, 2);        List&lt;Car&gt; cars = mapper.selectAll();//        System.out.println(cars);        PageInfo&lt;Car&gt; pageInfo = new PageInfo&lt;&gt;(cars, 5);        System.out.println(pageInfo);","categories":["Java","DataBase","MyBatis"],"tags":["八股文","面试","ORM","MyBatis","JDBC","SQL映射","数据库操作","持久层框架","动态SQL"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/CSS/","content":"CSScss的三种引入方式\n行内式\n直接将style放在对应的标签内部\n\n\n\n&lt;input type=&quot;button&quot; value=&quot;按钮&quot;        style=&quot;              display: block;              width: auto;              height: auto;              font-family: 隶书;              background-color: bisque;              border-radius: 5px;              border: 3px solid goldenrod;              color: brown;              font-size: 22px;              line-height: 30px;              &quot;       /&gt;\n\n\n内嵌式\n将行内式的style提取出来, 放在head里, 用于规范所有的对应标签\n\n\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        input &#123;            display: block;            width: auto;            height: auto;            font-family: 隶书;            background-color: bisque;            border-radius: 5px;            border: 3px solid goldenrod;            color: brown;            font-size: 22px;            line-height: 30px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;input type=&quot;button&quot; value=&quot;按钮&quot; /&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n外部引用式\n将css样式提取出来, 放在别的文件中, 然后在head中引用\n\n```## 引用样式之元素选择法- id法  - 创造以id命名的样式, 然后标签的id设置为对应样式的id, 就能获取到对应的样式```html&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        #btn1 &#123;            display: block;            width: auto;            height: auto;            font-family: 隶书;            background-color: bisque;            border-radius: 5px;            border: 3px solid goldenrod;            color: brown;            font-size: 22px;            line-height: 30px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;!-- id法 --&gt;    &lt;input type=&quot;button&quot; id=&quot;btn1&quot; value=&quot;按钮&quot;/&gt;    &lt;input type=&quot;button&quot; id=&quot;btn2&quot; value=&quot;按钮&quot;/&gt;    &lt;input type=&quot;button&quot; id=&quot;btn3&quot; value=&quot;按钮&quot;/&gt;    &lt;input type=&quot;button&quot; id=&quot;btn4&quot; value=&quot;按钮&quot;/&gt;&lt;/body&gt;&lt;/html&gt;\n\n\nclass法\n通过 .ClassName{}的形式设置样式, 每个标签再去选择使用哪些样式\n\n\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .shapeClass &#123;            display: block;            width: auto;            height: auto;            border-radius: 5px;        &#125;        .colorClass &#123;            background-color: bisque;            border: 3px solid goldenrod;        &#125;        .fontClass&#123;            font-family: 隶书;            color: brown;            font-size: 22px;            line-height: 30px;        &#125;        #btn1 &#123;            display: block;            width: auto;            height: auto;            font-family: 隶书;            background-color: bisque;            border-radius: 5px;            border: 3px solid goldenrod;            color: brown;            font-size: 22px;            line-height: 30px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;!-- id法 --&gt;    &lt;input type=&quot;button&quot; id=&quot;btn1&quot; value=&quot;按钮&quot;/&gt;    &lt;input type=&quot;button&quot; id=&quot;btn2&quot; value=&quot;按钮&quot;/&gt;    &lt;input type=&quot;button&quot; id=&quot;btn3&quot; value=&quot;按钮&quot;/&gt;    &lt;input type=&quot;button&quot; id=&quot;btn4&quot; value=&quot;按钮&quot;/&gt;    &lt;!-- class法 --&gt;    &lt;input class=&quot;fontClass colorClass shapeClass&quot; type=&quot;button&quot; value=&quot;按钮&quot;/&gt;    &lt;input class=&quot;fontClass colorClass&quot; type=&quot;button&quot; value=&quot;按钮&quot;/&gt;    &lt;input class=&quot;shapeClass&quot; type=&quot;button&quot; value=&quot;按钮&quot;/&gt;    &lt;input type=&quot;button&quot; value=&quot;按钮&quot;/&gt;&lt;/body&gt;&lt;/html&gt;\n\n块的浮动\n最开始的设计初衷是为了解决图片环绕文字的问题 : float属性\n发生浮动以后, 块就脱离了文档流, 相当于图层变得更上层了, 会直接覆盖原来的文档流内容, 如果发生了重叠现象的话\n浮动有向左和向右, 如果有多个元素, 则会叠起来\n\n\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .innerDiv &#123;            width: 60px;            height: 60px;            background-color: aqua;                        color: black;            border: 1px black solid;            float: left;        &#125;        .outerDiv &#123;            width: 60px;            height: 60px;            background-color: red;            color: black;            border: 1px rgb(48, 144, 19) solid;            float: right;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=&quot;innerDiv&quot;&gt;框1&lt;/div&gt;    &lt;div class=&quot;outerDiv&quot;&gt;框2&lt;/div&gt;    &lt;div class=&quot;innerDiv&quot;&gt;框3&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n定位\n\n\nposition\n功能\n\n\n\nabsolute\n绝对定位, 相对static定位以外的第一个父元素进行定位\n\n\nfixed\n生成绝对定位, 相对于浏览器窗口进行定位\n\n\nrelative\n生成相对定位, 相对于其原本的位置进行定位\n\n\nstatic\n默认的情况, 没有定位, 定位元素不会生效\n\n\n\nstatic &#x3D;&gt; 默认情况, 块元素垂直排列, 行内元素水平排列\nabsolute\n很像float, 移动后会让出自己原来的位置\n\n\n\n&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;style&gt;        .innerDiv&#123;                width: 100px;                height: 100px;        &#125;        .d1&#123;            background-color: rgb(166, 247, 46);            position: absolute;            left: 120px;            top: 50px;        &#125;        .d2&#123;            background-color: rgb(79, 230, 124);            position: absolute;            left: 220px;            top: 50px;        &#125;        .d3&#123;            background-color: rgb(26, 165, 208);            position: absolute;            left: 320px;            top: 50px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;        &lt;div class=&quot;innerDiv d1&quot;&gt;框1&lt;/div&gt;        &lt;div class=&quot;innerDiv d2&quot;&gt;框2&lt;/div&gt;        &lt;div class=&quot;innerDiv d3&quot;&gt;框3&lt;/div&gt;&lt;/body&gt;\n\n\nrelative, 不用赘述了, 相对于其原来的位置有left, right, top, bottom四个属性\n会保留原来的位置, 其他元素并不会移动到位置\n\n\nfixed : 相对于浏览器窗口定位\n定位后会让出原来的位置, 其他元素可以占用\n\n\n\nCSS盒子模型\n\n\n说明\nMargin : 清除边框外的区域, 外边距是透明的\nBorder : 围绕在内边距和内容上的边框\nPadding : 内容和边框之间的距离\nContent : 内容\n\n\n\n&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;style&gt;        .outerDiv&#123;            width: 800px;            height: 400px;            border: 1px solid green;            background-color: aliceblue;            margin: 0px auto;            padding: 20px;            position: relative;        &#125;        .innerDiv&#123;                width: 100px;                height: 100px;        &#125;        .d1&#123;            background-color: rgb(166, 247, 46);            position: absolute;            right: 30px;            top: 30px;        &#125;        .d2&#123;            background-color: rgb(79, 230, 124);        &#125;        .d3&#123;            background-color: rgb(26, 165, 208);        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=&quot;outerDiv&quot;&gt;        &lt;div class=&quot;innerDiv d1&quot;&gt;框1&lt;/div&gt;        &lt;div class=&quot;innerDiv d2&quot;&gt;框2&lt;/div&gt;        &lt;div class=&quot;innerDiv d3&quot;&gt;框3&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;\n\n","tags":["Java","frontend","JavaWeb","CSS"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/ES6/","content":"ES61. ES6的介绍\nECMAScript 6，简称ES6，是JavaScript语言的一次重大更新。它于2015年发布，是原来的ECMAScript标准的第六个版本。ES6带来了大量的新特性，包括箭头函数、模板字符串、let和const关键字、解构、默认参数值、模块系统等等，大大提升了JavaScript的开发体验。由于VUE3中大量使用了ES6的语法,所以ES6成为了学习VUE3的门槛之一 ES6对JavaScript的改进在以下几个方面：\n\n\n更加简洁：ES6引入了一些新的语法，如箭头函数、类和模板字符串等，使代码更加简洁易懂。\n\n更强大的功能：ES6引入了一些新的API、解构语法和迭代器等功能，从而使得JavaScript更加强大。\n\n更好的适用性：ES6引入的模块化功能为JavaScript代码的组织和管理提供了更好的方式，不仅提高了程序的可维护性，还让JavaScript更方便地应用于大型的应用程序。\n\n\n\n总的来说，ES6在提高JavaScript的核心语言特性和功能方面取得了很大的进展。由于ES6已经成为了JavaScript的标准，它的大多数新特性都已被现在浏览器所支持，因此现在可以放心地使用ES6来开发前端应用程序。\n\n2. ES6的变量和模板字符\nES6新增了let和const, 用于声明变量\n\n\nlet和var的区别\nlet有作用域, 在不是函数的花括号内\n不能重复声明\n不存在变量提升, 不能先使用后定义\n不会变成window属性\n循环中更推荐使用\n\n\n\n&lt;script&gt;&#123;    let a = 1    let b = 2    console.log(a)    console.log(b)&#125;// 有作用域// console.log(a)// console.log(b)// 不能重复赋值// let name = 1// let name = 2 // 变量提升console.log(test)var test = &#x27;test&#x27;// console.log(test1)// let test1 = &#x27;test1&#x27;// 不会成为window属性var a  = 100console.log(window.a) // 100let b = 122console.log(window.b) // undefine// 循环中推荐使用for (let i=0;i &lt; 10; i++)&#123;    console.log(i)&#125;console.log(i)&lt;/script&gt;\n\n\nconst和var的差异\n和let类似, 是不能修改的let\n对于对象和数组, const只能保证地址不变, 不保证对象内部的值不变\n\n\n\n&lt;script&gt;    const PI = 3.1415926    const TEAM = [1,2,3,4,5]    TEAM.push(6)    // TEAM = []    console.log(TEAM)&lt;/script&gt;\n\n\n模板字符串\n\n\n使用``括起\n允许多行字符串\n支持行内拼接\n\n&lt;script&gt;        let ulstr =             &#x27;&lt;ul&gt;&#x27;+            &#x27;&lt;li&gt;JAVA&lt;/li&gt;&#x27;+            &#x27;&lt;li&gt;html&lt;/li&gt;&#x27;+            &#x27;&lt;li&gt;VUE&lt;/li&gt;&#x27;+            &#x27;&lt;/ul&gt;&#x27;        console.log(ulstr)        let ulstr2 = `        &lt;ul&gt;            &lt;li&gt;JAVA&lt;/li&gt;            &lt;li&gt;html&lt;/li&gt;            &lt;li&gt;VUE&lt;/li&gt;        &lt;/ul&gt;`        console.log(ulstr2)        // 普通字符串拼接        let name = &quot;小明&quot;        let infoStr = name+&#x27;sb&#x27;        console.log(name+infoStr)        // 模板字符串拼接        let infoStr2 = `$&#123;name&#125;被品味sb`        console.log(infoStr2)    &lt;/script&gt;\n\n3. ES6的解构表达式&lt;script&gt;// 数组解构    let [a,b,c] = [1,2,&quot;33&quot;]    console.log(a)    console.log(b)    console.log(c)    // 默认值    let [a1,b1,c1, d = 4] = [1,2,3,5]    console.log(d)// 对象解构    let &#123;o1, o2&#125; = &#123;o1:1, o2:2&#125;    //新增变量名必须和属性名相同, 本质是初始化变量的值为对象中同名属性的值    // 等价于 let o1 = Object.o1, let o2 = Object.o2    console.log(o1) // 1    console.log(o2) // 2    // 该语句将对象 &#123;a: 1, b: 2&#125; 中的 a 属性值赋值给 a 变量，b 属性值赋值给 b 变量。 可以为标识符分配不同的变量名称，使用 : 操作符指定新的变量名    let &#123;a2:x, b2:y&#125; = &#123;a2:2, b2:12421&#125;    console.log(x) // 2    console.log(y) // 12421// 函数参数解构function sum([x,y]) &#123;    return x + y&#125;sum([1,2]); // 3&lt;/script&gt;\n\n4. ES6的箭头函数4.1 声明和特点\n语法类似于Java中的Lambda表达式\n\n&lt;script&gt;    let fn1 = function()&#123;&#125;    let fn2 = x =&gt; &#123;&#125;    let fn3 = () =&gt; &#123;&#125;    let fn4 = x =&gt; console.log(x) // 只有一行函数体可以省略&#123;&#125;    let fn5 = x =&gt; x + 1    //2. 使用特点 箭头函数this关键字    // 在 JavaScript 中，this 关键字通常用来引用函数所在的对象，    // 或者在函数本身作为构造函数时，来引用新对象的实例。    // 但是在箭头函数中，this 的含义与常规函数定义中的含义不同，    // 并且是由箭头函数定义时的上下文来决定的，而不是由函数调用时的上下文来决定的。    // 箭头函数没有自己的this，this指向的是外层上下文环境的this    let person =&#123;        name:&quot;张三&quot;,        showName: function()&#123;            console.log(this) // 指向的person对象            console.log(this.name)        &#125;,        viewName: () =&gt;&#123;            console.log(this) // 指向window            console.log(this.name)        &#125;    &#125;    person.showName()    person.viewName()    // 对于这样依赖于上下文的this的应用    function Counter() &#123;        this.count = 0;        setInterval(()=&gt;&#123;            // 这里的this是上一层作用域中的this, 即Counter实例化对象            this.count++;            console.log(this.count)        &#125;, 1000)    &#125;    let counter = new Counter();&lt;/script&gt;\n\n\n可以利用这个this的特性返回上一层作用域\n\n4.2 实践和应用场景&lt;div id=&quot;xdd&quot;&gt;&lt;/div&gt;&lt;script&gt;    let xdd = document.getElementById(&quot;xdd&quot;)    xdd.onclick = function()&#123;        console.log(this)        let _this = this; // xdd        // 开启定时器        setTimeout(function()&#123;            console.log(this)            // 变成粉色            _this.style.backgroundColor = &#x27;black&#x27;        &#125;, 2000)    &#125;    xdd.onclick = function()&#123;        console.log(this)        setTimeout(()=&gt;&#123;            console.log(this)            this.style.backgroundColor = &#x27;black&#x27;        &#125;, 2000)    &#125;&lt;/script&gt;\n\n\n可以充当一个..&#x2F;, 向上一层索引的功能\n\n4.3 rest和spread\nrest参数, 在形参上使用和Java中的可变参数一样\n\n&lt;script&gt;    // res参数    let fun1 = function(...args)&#123;         console.log(args)    &#125;    let fun2 = (...args) =&gt; console.log(args)    fun1(1,2,3,4)    fun2(1,2,3,4,5,6,6)        // 只能是最后一个参数, 并且只能有一个    // let fun3 = (...args, ...args2) =&gt; &#123;&#125; // 报错&lt;/script&gt;\n\n\nspread参数, 在实参上使用rest参数\n\n&lt;script&gt;    // spread 语法可以将[1,2,3] =&gt; 1,2,3 , 像是一种拆包    let arr = [1,2,3]    // let arrSpread = ...arr // 错误, 不能直接拆包, 只能在函数调用的时候作为参数传递    let fn1 = (a,b,c) =&gt; console.log(a,b,c)    fn1(...arr) // 1 2 3    fn1(arr) // [1,2,3] undefine undefine    // 应用场景1 合并数组    let arr2 = [2,3,4]    console.log(...arr, ...arr2)    // 应用场景2 合并对象属性    let p1 = &#123;name:&quot;张三&quot;&#125;    let p2 = &#123;age:10&#125;    let p3 = &#123;gender:&quot;boy&quot;&#125;    let person = &#123;...p1, ...p2, ...p3&#125;    console.log(person)&lt;/script&gt;\n\n5. es6的对象创建和拷贝5.1 对象创建上的语法糖&lt;script&gt;    class Person&#123;        // 属性名        #n; // 私有成员        age;                // getter and setter        get name() &#123;            console.log(&quot;getter&quot;)            return this.#n        &#125;        set name(n) &#123;            console.log(&quot;setter&quot;)            this.#n = n;        &#125;        // 实例方法        eat(food) &#123;            console.log(`$&#123;this.age&#125;的$&#123;this.#n&#125;正在吃$&#123;food&#125;`)        &#125;        // 构造方法        constructor(name, age)&#123;            this.#n = name            this.age = age        &#125;    &#125;    let p = new Person();    p.name = &quot;zhangsan&quot;;    p.age = 123;    // let p = new Person(&quot; zhangsan &quot;, 123)    p.eat(&quot;答辩&quot;)    // p.#n; 私有属性不能直接访问    // 继承    class Student extends Person&#123;        score;        constructor(name, age, score) &#123;            super(name,age)            this.score = score        &#125;        study()&#123;            console.log(`$&#123;this.age&#125;岁的$&#123;this.name&#125;考了$&#123;this.score&#125;正在装死`)        &#125;        // 静态方法         static sum(a,b)&#123;            return a+b        &#125;    &#125;    let s = new Student(&quot;fun&quot;,1213,234)    s.study()    console.log(Student.sum(1,23))&lt;/script&gt;\n\n5.2 对象的深拷贝和浅拷贝    &lt;script&gt;        // 浅拷贝        let arr = [1,2,3,4]        let person = &#123;            name:&quot;zhangsn&quot;,            number : arr        &#125;        let person2 = person        person2.name = &quot;sss231&quot;        console.log(person)        console.log(person2)        // 深拷贝        // 实质上是通过JSON和字符串的转化生成一个新的对象        let person3 = JSON.parse(JSON.stringify(person))        person3.name = &quot;ssdevice-width&quot;        console.log(person)        console.log(person3)    &lt;/script&gt;script&gt;/script&gt;\n\n6. ES6的模块化处理6.1 模块化的介绍\n模块化是一种组织和管理前端代码的方式，将代码拆分成小的模块单元，使得代码更易于维护、扩展和复用。它包括了定义、导出、导入以及管理模块的方法和规范。前端模块化的主要优势如下：\n\n\n提高代码可维护性：通过将代码拆分为小的模块单元，使得代码结构更为清晰，可读性更高，便于开发者阅读和维护。\n\n提高代码可复用性：通过将重复使用的代码变成可复用的模块，减少代码重复率，降低开发成本。\n\n提高代码可扩展性：通过模块化来实现代码的松耦合，便于更改和替换模块，从而方便地扩展功能。\n\n\n\n目前，前端模块化有多种规范和实现，包括 CommonJS、AMD 和 ES6 模块化。ES6 模块化是 JavaScript 语言的模块标准，使用 import 和 export 关键字来实现模块的导入和导出。现在，大部分浏览器都已经原生支持 ES6 模块化，因此它成为了最为广泛使用的前端模块化标准. &#96;\n\n\n\n简单来说就是可以复用其它文件中的代码\n\n\nES6模块化的几种暴露和导入方式\n分别导出\n统一导出\n默认导出\n\n\nES6中无论以何种方式导出,导出的都是一个对象,导出的内容都可以理解为是向这个对象中添加属性或者方法\n\n6.2 分别导出\napp.js\n\n// 导入module.js中的所有成员import * as m1 from &#x27;./module.js&#x27;console.log(m1.PI)let result = m1.sum(1,2)console.log(result)let person = new m1.Person(&quot;张三&quot;, 123123)person.toString();\n\n\nmodule.js\n\n// 1. 分别暴露// 将需要暴露的模块添加export关键字export const PI = 3.1415926export function sum(a,b)&#123;    return a+b&#125;export class Person&#123;    name    age    constructor(name, age)&#123;        this.name = name        this.age = age    &#125;    toString()&#123;        console.log(`$&#123;this.age&#125;岁的$&#123;this.name&#125;`)    &#125;&#125;\n\n\nindex.html (后面的演示代码中index.html都是这个样子的, 所以后面不再写了)\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;script src=&quot;./app.js&quot; type=&quot;module&quot;&gt;&lt;/script&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;/body&gt;&lt;/html&gt;\n\n6.3 统一导出\napp.js\n\n// import &#123;PI, sum, Person&#125; from &#x27;./module.js&#x27;// import &#123;PI as pi, sum as add, Person as People&#125; from &#x27;./module.js&#x27;import &#123;PI, Person, sum, PI as pi, sum as add, Person as People&#125; from &#x27;./module.js&#x27;console.log(PI)console.log(pi)let result1 = sum(1,223)let result2 = add(12,3213)console.log(result1)console.log(result2)let person = new Person(&quot;萨汗&quot;, 1312)let person2 = new People(&quot;sad&quot;, 1321)person.sayHello()person2.sayHello()\n\n\nmodule.js\n\n// 统一暴露// 整个模块对外导出const PI = 3.14// 定义一个函数function sum(a, b) &#123;    return a + b;&#125;// 定义一个类class Person &#123;constructor(name, age) &#123;    this.name = name;    this.age = age;&#125;sayHello() &#123;    console.log(`Hello, my name is $&#123;this.name&#125;, I&#x27;m $&#123;this.age&#125; years old.`);&#125;&#125;export &#123;    PI,    sum,    Person,&#125;\n\n6.4 默认导出\napp.js\n\nimport * as m1 from &#x27;./module.js&#x27;console.log(m1.default(12,1234))// import &#123;default as add&#125; from &#x27;./module.js&#x27;import add from &#x27;./module.js&#x27;console.log(add(1,24))\n\n\nmodule.js\n\nconst PI = 3.1415926let sum = function(a,b)&#123;    return a+b&#125;// 只能有一个export default sum// export default PI","tags":["Java","frontend","JavaWeb","JS","ES6"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/HTML/","content":"HTML整体框架&lt;!DOCTYPE html&gt; \t\t\t\t-&gt; HTML5的文档声明&lt;html lang=&quot;en&quot;&gt;\t\t\t\t-&gt; 根标签, 并说明语言是英语&lt;head&gt;\t\t\t\t\t\t\t-&gt; \t头部标签    &lt;meta charset=&quot;UTF-8&quot;&gt;\t\t-&gt; 用于指明字符编码    &lt;title&gt;Document&lt;/title&gt;\t\t-&gt; 网页的标题&lt;/head&gt;\t\t\t\t\t\t\t-&gt; 头部标签的结尾&lt;body&gt;\t\t\t\t\t\t\t-&gt; 文档的内容    &lt;/body&gt;&lt;/html&gt;\n\n\n\nHTML的常用标签标题标签 &amp; 段落标签 &amp;换行标签hr &#x3D;&gt; horizontal rule 水平线, br &#x3D;&gt; line break &#x3D;&gt; 换行\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1&gt;一级标题&lt;/h1&gt;    &lt;h2&gt;二级标题&lt;/h2&gt;    &lt;h3&gt;三级标题&lt;/h3&gt;    &lt;h4&gt;四级标题&lt;/h4&gt;    &lt;h5&gt;五级标题&lt;/h5&gt;    &lt;h6&gt;六级标题&lt;/h6&gt;    &lt;p&gt;第一个段落&lt;/p&gt;    &lt;p&gt;段落之间是有换行的一&lt;/p&gt;    如果没有p包裹,    是没有换行的    &lt;br&gt;    强行换行符号    &lt;hr&gt;     分割线&lt;/body&gt;&lt;/html&gt;\n\n列表标签&lt;ol&gt; =&gt; 有序列表    &lt;li&gt;&lt;/li&gt; =&gt; 列表项&lt;/ol&gt;&lt;ul&gt; =&gt; 无序列表    &lt;li&gt;&lt;/li&gt;&lt;/ul&gt;\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;ol&gt;        &lt;li&gt;JJAVASE&lt;/li&gt;        &lt;li&gt;JAVAWeb&lt;/li&gt;        &lt;li&gt;MYSql&lt;/li&gt;    &lt;/ol&gt;    &lt;ul&gt;        &lt;li&gt;好困&lt;/li&gt;        &lt;li&gt;怎么会这么困&lt;/li&gt;        &lt;li&gt;是什么原因            &lt;ol&gt;                &lt;li&gt;运动后肉体上疲惫&lt;/li&gt;                &lt;li&gt;集中精力累的&lt;/li&gt;                &lt;li&gt;差的配合掉的san值&lt;/li&gt;            &lt;/ol&gt;        &lt;/li&gt;    &lt;/ul&gt;&lt;/body&gt;&lt;/html&gt;\n\n链接标签 &amp; 多媒体标签&lt;a href=&quot;资源路径&quot; target=&quot;_blank/_self&quot;&gt;文字&lt;/a&gt;  =&gt; 默认的时候target的值是_self, 如果是外部链接需要使用_blank\n\n&lt;a href=&quot;Demo1.html&quot;, target=&quot;_blank&quot;&gt;相对路径本地资源链接&lt;/a&gt; &lt;br&gt;&lt;a href=&quot;Demo2.html&quot;, target=&quot;_self&quot;&gt;绝对路径本地资源链接&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.bing.com&quot;, target=&quot;_blank&quot;&gt;外部资源链接&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;IMG.png&quot; title=&quot;鼠标悬停在图像上显示的文字&quot; alt=&quot;显示失败的时候显示的内容&quot; /&gt;&lt;audio src=&quot;path&quot; autoplay=&quot;autoplay&quot; controls=&quot;controls&quot; loop=&quot;loop&quot; &gt;&lt;/audio&gt;&lt;video src=&quot;path&quot; autoplay=&quot;autoplay&quot; controls=&quot;controls&quot; loop=&quot;loop&quot; &gt;&lt;/video&gt;\n\n表格标签&lt;table&gt; =&gt; 声明表格    &lt;tr&gt; =&gt; 一行数据        &lt;th&gt;&lt;/th&gt; =&gt; 文字在表格中居中加粗        &lt;td&gt;&lt;/td&gt; =&gt; 正常的表格中的一格    &lt;/tr&gt;    &lt;tr&gt;    \t&lt;td colspan=&quot;a&quot; rowspan=&quot;b&quot;&gt;&lt;/td&gt; =&gt; a:跨的列数, b:跨的行数    &lt;/tr&gt;&lt;/table&gt;\n\n\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;table border=&quot;1px&quot; style=&quot;width: 400px; margin: 0px auto;&quot;&gt;        &lt;tr&gt;            &lt;th&gt;排名&lt;/th&gt;            &lt;th&gt;name&lt;/th&gt;            &lt;th&gt;score&lt;/th&gt;            &lt;th&gt;备注&lt;/th&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;1&lt;/td&gt;            &lt;td&gt;zxm&lt;/td&gt;            &lt;td&gt;100&lt;/td&gt;            &lt;td rowspan=&quot;6&quot;&gt;前三名升职加薪&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;2&lt;/td&gt;            &lt;td&gt;lxh&lt;/td&gt;            &lt;td&gt;99&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;3&lt;/td&gt;            &lt;td&gt;wxh&lt;/td&gt;            &lt;td&gt;98&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;总人数&lt;/td&gt;            &lt;td colspan=&quot;2&quot;&gt;2000&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;平均分&lt;/td&gt;            &lt;td colspan=&quot;2&quot;&gt;90&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;及格率&lt;/td&gt;            &lt;td colspan=&quot;2&quot;&gt;80%&lt;/td&gt;        &lt;/tr&gt;    &lt;/table&gt;&lt;/body&gt;&lt;/html&gt;\t\n\n\n表单标签\n用于向特定服务器提交内容\n两种method的区别 : \nget : 数据会到action中填写的url后面url?name1&#x3D;value&amp;name2&#x3D;value…\npost : 数据会通过请求体发送, 不会后缀在url后\n\n\n\n&lt;from action=&quot;目标服务器的地址&quot; method=&quot;提交的方法&quot;&gt; =&gt; 父级标签\t&lt;input type=&quot;&quot; name=&quot;&quot; value=&quot;&quot;/&gt; &lt;br&gt; =&gt; 表单项标签&lt;/from&gt;\n\n&lt;form action=&quot;http://atguigu.com&quot; method=&quot;get&quot;&gt;    用户名 &lt;input type=&quot;text&quot; name = &quot;username&quot;/&gt; &lt;br&gt;    密&amp;nbsp;&amp;nbsp;&amp;nbsp;码 &lt;input type=&quot;password&quot; name=&quot;password&quot; /&gt; &lt;br&gt;    &lt;input type=&quot;submit&quot; value=&quot;登录&quot; /&gt;    &lt;input type=&quot;reset&quot; value=&quot;重置&quot; /&gt;&lt;/form&gt;\n\n表单项标签\n单选框\n\n&lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;man&quot;/&gt;男&lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;woman&quot;/&gt;女\n\n\nname &#x3D;&gt; 用于将单选框分组, 组内被选是互斥的, value &#x3D;&gt; 提交上去的表单中sex的值\n\n\n复选框\n\n&lt;input type=&quot;checkbox&quot; name=&quot;team&quot; value=&quot;China&quot;/&gt;中国&lt;input type=&quot;checkbox&quot; name=&quot;team&quot; value=&quot;France&quot; checked/&gt;法国&lt;input type=&quot;checkbox&quot; name=&quot;team&quot; value=&quot;Italian&quot;/&gt;意大利\n\n\n下拉框\n\n&lt;select name=&quot;interesting&quot;&gt;    &lt;option value=&quot;swimming&quot;&gt;游泳&lt;/option&gt;    &lt;option value=&quot;running&quot; selected&gt;跑步&lt;/option&gt;    &lt;option value=&quot;shooting&quot;&gt;射击&lt;/option&gt;&lt;/select&gt;\n\n\n按钮\n\n&lt;p&gt;按钮&lt;/p&gt;&lt;input type=&quot;button&quot; value=&quot;普通按钮&quot;&gt;&lt;input type=&quot;submit&quot; value=&quot;提交按钮&quot;&gt;&lt;input type=&quot;reset&quot; value=&quot;重置按钮&quot;&gt;&lt;p&gt;通过button实现的按钮&lt;/p&gt;&lt;button type=&quot;button&quot;&gt;普通按钮&lt;/button&gt;&lt;button type=&quot;submit&quot;&gt;提交按钮&lt;/button&gt;&lt;button type=&quot;reset&quot;&gt;重置按钮&lt;/button&gt;\n\n\n隐藏域\n\n  用于设置固定会提交的内容, 不需要也不希望用户看到的表单内容, 比如用户的uuid等\n &lt;input type=&quot;hidden&quot; value=&quot;123456789&quot; name=&quot;userId&quot;/&gt;\n\n\n多行文本框\n\n\n没有value选项, 可以通过在双标签中间填入内容来设定默认内容\n\n自我介绍:&lt;textarea name=&quot;desc&quot;&gt;默认信息&lt;/textarea&gt;\n\n\n文件\n\n&lt;input type=&quot;file&quot; name=&quot;file&quot;/&gt;\n\n布局相关的标签\ndiv &#x3D;&gt; 用于做块的划分\nspan &#x3D;&gt; 用作对层的划分\n\n&lt;div style=&quot;width: 500px; height:400px; background-color: brown;&quot;&gt;    &lt;div style=&quot;width: 300px; height: 200px; background-color: beige;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;width: 100px; height: 100px; background-color: rebeccapurple;&quot;&gt;&lt;/div&gt;&lt;span style=&quot;width: auto; height: 12px; background-color: aqua;&quot;&gt;span显示的内容&lt;/span&gt;\n\n常常通过CSS设置大小背景颜色等参数\n","tags":["Java","frontend","JavaWeb","HTML"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/HTTP/","content":"hijinint main ()  {|\nadadadadasdadasdasdasdas} HTTP协议hijinint main ()  {|\nadadadadasdadasdasdasdas}\n1 HTTP简介![[images&#x2F;1681522638617.png]]\n![[images&#x2F;1681522600239.png]]\n\nHTTP 超文本传输协议 (HTTP-Hyper Text transfer protocol)，是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过十几年的使用与发展，得到不断地完善和扩展。它是一种详细规定了浏览器和万维网服务器之间互相通信的规则，通过因特网传送万维网文档的数据传送协议。客户端与服务端通信时传输的内容我们称之为报文。HTTP协议就是规定报文的格式。HTTP就是一个通信规则，这个规则规定了客户端发送给服务器的报文格式，也规定了服务器发送给客户端的报文格式。实际我们要学习的就是这两种报文。客户端发送给服务器的称为”请求报文“，服务器发送给客户端的称为”响应报文”。\n\n^HTTP\n3.1.1 发展历程\nHTTP&#x2F;0.9 \n\n\n蒂姆伯纳斯李是一位英国计算机科学家，也是万维网的发明者。他在 1989 年创建了单行 HTTP 协议。它只是返回一个网页。这个协议在 1991 年被命名为 HTTP&#x2F;0.9。\n\n\n HTTP&#x2F;1.0\n\n\n1996 年，HTTP&#x2F;1.0 发布。该规范是显著扩大，并且支持三种请求方法：GET，Head，和POST。 \nHTTP&#x2F;1.0 相对于 HTTP&#x2F;0.9 的改进如下：\n每个请求都附加了 HTTP 版本。\n在响应开始时发送状态代码。\n请求和响应都包含 HTTP 报文头。\n内容类型能够传输 HTML 文件以外的文档。\n\n\n但是，HTTP&#x2F;1.0 不是官方标准。\n\n\nHTTP&#x2F;1.1\n\n\nHTTP 的第一个标准化版本 HTTP&#x2F;1.1 ( RFC 2068 ) 于 1997 年初发布，支持七种请求方法：OPTIONS，GET，HEAD，POST，PUT，DELETE，和TRACE \n\nHTTP&#x2F;1.1 是 HTTP 1.0 的增强：\n\n虚拟主机允许从单个 IP 地址提供多个域。\n\n持久连接和流水线连接允许 Web 浏览器通过单个持久连接发送多个请求。\n\n缓存支持节省了带宽并使响应速度更快。\n\n\n\nHTTP&#x2F;1.1 在接下来的 15 年左右将非常稳定。 \n\n在此期间，出现了 HTTPS（安全超文本传输协议）。它是使用 SSL&#x2F;TLS 进行安全加密通信的 HTTP 的安全版本。\n\n\n\nHTTP&#x2F;2\n\n\n由IETF在2015年发布。HTTP&#x2F;2旨在提高Web性能，减少延迟，增加安全性，使Web应用更加快速、高效和可靠。\n\n\n多路复用：HTTP&#x2F;2 允许同时发送多个请求和响应，而不是像 HTTP&#x2F;1.1 一样只能一个一个地处理。这样可以减少延迟，提高效率，提高网络吞吐量。\n二进制传输：HTTP&#x2F;2 使用二进制协议，与 HTTP&#x2F;1.1 使用的文本协议不同。二进制协议可以更快地解析，更有效地传输数据，减少了传输过程中的开销和延迟。\n头部压缩：HTTP&#x2F;2 使用 HPACK 算法对 HTTP 头部进行压缩，减少了头部传输的数据量，从而减少了网络延迟。\n服务器推送：HTTP&#x2F;2 支持服务器推送，允许服务器在客户端请求之前推送资源，以提高性能。\n改进的安全性：HTTP&#x2F;2 默认使用 TLS（Transport Layer Security）加密传输数据，提高了安全性。\n兼容 HTTP&#x2F;1.1：HTTP&#x2F;2 可以与 HTTP&#x2F;1.1 共存，服务器可以同时支持 HTTP&#x2F;1.1 和 HTTP&#x2F;2。如果客户端不支持 HTTP&#x2F;2，服务器可以回退到 HTTP&#x2F;1.1。\n\n\nHTTP&#x2F;3\n\n\n于 2021 年 5 月 27 日发布 , HTTP&#x2F;3 是一种新的、快速、可靠且安全的协议，适用于所有形式的设备。 HTTP&#x2F;3 没有使用 TCP，而是使用谷歌在 2012 年开发的新协议 QUIC \n\nHTTP&#x2F;3 是继 HTTP&#x2F;1.1 和 HTTP&#x2F;2之后的第三次重大修订。 \n\nHTTP&#x2F;3 带来了革命性的变化，以提高 Web 性能和安全性。设置 HTTP&#x2F;3 网站需要服务器和浏览器支持。\n\n目前，谷歌云、Cloudflare和Fastly支持 HTTP&#x2F;3。Chrome、Firefox、Edge、Opera 和一些移动浏览器支持 HTTP&#x2F;3。\n\n\n3.1.2 HTTP协议的会话方式\n浏览器与服务器之间的通信过程要经历四个步骤\n\n\n\n浏览器与WEB服务器的连接过程是短暂的，每次连接只处理一个请求和响应。对每一个页面的访问，浏览器与WEB服务器都要建立一次单独的连接。\n浏览器到WEB服务器之间的所有通讯都是完全独立分开的请求和响应对。\n\n3.1.3 HTTP1.0和HTTP1.1的区别\n在HTTP1.0版本中，浏览器请求一个带有图片的网页，会由于下载图片而与服务器之间开启一个新的连接；但在HTTP1.1版本中，允许浏览器在拿到当前请求对应的全部资源后再断开连接，提高了效率。\n\n\n3.1.4 在浏览器中通过F12工具抓取请求响应报文包\n几乎所有的PC端浏览器都支持了F12开发者工具,只不过不同的浏览器工具显示的窗口有差异\n\n![[images&#x2F;1681522138051.png]]\n3.2 请求和响应报文3.2.1 报文的格式\n主体上分为报文首部和报文主体,中间空行隔开\n\n![[images&#x2F;1681522962846.png]]\n\n报文部首可以继续细分为  “行” 和 “头”\n\n![[images&#x2F;1681522998417.png]]\n3.2.2 请求报文\n客户端发给服务端的报文\n\n\n请求报文格式\n请求首行（请求行）；    GET&#x2F;POST   资源路径?参数   HTTP&#x2F;1.1\n请求头信息（请求头）；\n空行；\n请求体；POST请求才有请求体\n\n\n\n\n浏览器 f12 网络下查看请求数据包\n\n![[images&#x2F;1681524200024.png]]\n\nform表单发送GET请求特点\n\n1、由于请求参数在请求首行中已经携带了，所以没有请求体，也没有请求空行2、请求参数拼接在url地址中，地址栏可见[url?name1&#x3D;value1&amp;name2&#x3D;value2]，不安全3、由于参数在地址栏中携带，所以由大小限制[地址栏数据大小一般限制为4k]，只能携带纯文本4、get请求参数只能上传文本数据5、没有请求体。所以封装和解析都快，效率高， 浏览器默认提交的请求都是get请求比如：地址栏输入回车,超链接,表单默认的提交方式\n\n查看GET请求行,请求头,请求体\n\n\n请求行组成部分\n请求方式  GET\n访问服务器的资源路径?参数1&#x3D;值1&amp;参数2&#x3D;值2 … …\n协议及版本 HTTP&#x2F;1.1\n\n\n\nGET /05_web_tomcat/login_success.html?username=admin&amp;password=123213 HTTP/1.1\n\n\n请求头\n\n-主机虚拟地址Host: localhost:8080   -长连接Connection: keep-alive -请求协议的自动升级[http的请求，服务器却是https的，浏览器自动会将请求协议升级为https的]Upgrade-Insecure-Requests: 1  - 用户系统信息User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36- 浏览器支持的文件类型Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8- 当前页面的上一个页面的路径[当前页面通过哪个页面跳转过来的]：   可以通过此路径跳转回上一个页面， 广告计费，防止盗链Referer: http://localhost:8080/05_web_tomcat/login.html- 浏览器支持的压缩格式Accept-Encoding: gzip, deflate, br- 浏览器支持的语言Accept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7\n\n\n请求空行\n\n请求体\n\nGET请求数据不放在请求体\n\n\n\n\nform表单发送post请求特点\n\n1、POST请求有请求体，而GET请求没有请求体。2、post请求数据在请求体中携带，请求体数据大小没有限制，可以用来上传所有内容[文件、文本]3、只能使用post请求上传文件4、post请求报文多了和请求体相关的配置[请求头]5、地址栏参数不可见，相对安全6、post效率比get低\n\nPOST请求要求将form标签的method的属性设置为post\n\n![[images&#x2F;1681525012046.png]]\n\n查看post的请求行 请求头 请求体\n\n\n请求行组成部分\n请求方式 POST\n访问服务器的资源路径?参数1&#x3D;值1&amp;参数2&#x3D;值2 … …\n协议及版本 HTTP&#x2F;1.1\n\n\n\nPOST /05_web_tomcat/login_success.html HTTP/1.1\n\n\n请求头\n\nHost: localhost:8080Connection: keep-aliveContent-Length: 31     -请求体内容的长度Cache-Control: max-age=0  -无缓存Origin: http://localhost:8080Upgrade-Insecure-Requests: 1  -协议的自动升级Content-Type: application/x-www-form-urlencoded   -请求体内容类型[服务器根据类型解析请求体参数]User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8Referer: http://localhost:8080/05_web_tomcat/login.htmlAccept-Encoding: gzip, deflate, brAccept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7Cookie:JSESSIONID-\n\n\n请求空行\n\n请求体:浏览器提交给服务器的数据\n\n\nusername=admin&amp;password=1232131\n\n3.2.3 响应报文\n响应报文格式\n\n\n响应首行（响应行）； 协议&#x2F;版本  状态码    状态码描述\n响应头信息（响应头）；\n空行；\n响应体；\n\n![[images&#x2F;1681525347456.png]]\n![[images&#x2F;1681525384347.png]]\n\n响应行组成部分\n协议及版本 HTTP&#x2F;1.1\n响应状态码 200\n状态描述   OK  (缺省)\n\n\n\nHTTP/1.1 200 OK说明：响应协议为HTTP1.1，响应状态码为200，表示请求成功； \n\n\n响应头\n\nServer: Apache-Coyote/1.1   服务器的版本信息Accept-Ranges: bytesETag: W/&quot;157-1534126125811&quot;Last-Modified: Mon, 13 Aug 2018 02:08:45 GMTContent-Type: text/html    响应体数据的类型[浏览器根据类型解析响应体数据]Content-Length: 157   响应体内容的字节数Date: Mon, 13 Aug 2018 02:47:57 GMT  响应的时间，这可能会有8小时的时区差\n\n\n响应体\n\n&lt;!--需要浏览器解析使用的内容[如果响应的是html页面，最终响应体内容会被浏览器显示到页面中]--&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;  &lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Insert title here&lt;/title&gt;  &lt;/head&gt;  &lt;body&gt;    恭喜你，登录成功了...  &lt;/body&gt;&lt;/html&gt;\n\n\n响应状态码:响应码对浏览器来说很重要，它告诉浏览器响应的结果。比较有代表性的响应码如下：\n\n\n200： 请求成功，浏览器会把响应体内容（通常是html）显示在浏览器中；\n302： 重定向，当响应码为302时，表示服务器要求浏览器重新再发一个请求，服务器会发送一个响应头Location指定新请求的URL地址；\n304： 使用了本地缓存\n404： 请求的资源没有找到，说明客户端错误的请求了不存在的资源；\n405： 请求的方式不允许\n500： 请求资源找到了，但服务器内部出现了错误；\n\n\n更多的响应状态码\n\n\n\n\n状态码\n状态码英文描述\n中文含义\n\n\n\n1**\n\n\n\n\n100\nContinue\n继续。客户端应继续其请求\n\n\n101\nSwitching Protocols\n切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议\n\n\n2**\n\n\n\n\n200\nOK\n请求成功。一般用于GET与POST请求\n\n\n201\nCreated\n已创建。成功请求并创建了新的资源\n\n\n202\nAccepted\n已接受。已经接受请求，但未处理完成\n\n\n203\nNon-Authoritative Information\n非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本\n\n\n204\nNo Content\n无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档\n\n\n205\nReset Content\n重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域\n\n\n206\nPartial Content\n部分内容。服务器成功处理了部分GET请求\n\n\n3**\n\n\n\n\n300\nMultiple Choices\n多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择\n\n\n301\nMoved Permanently\n永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替\n\n\n302\nFound\n临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI\n\n\n303\nSee Other\n查看其它地址。与301类似。使用GET和POST请求查看\n\n\n304\nNot Modified\n未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源\n\n\n305\nUse Proxy\n使用代理。所请求的资源必须通过代理访问\n\n\n306\nUnused\n已经被废弃的HTTP状态码\n\n\n307\nTemporary Redirect\n临时重定向。与302类似。使用GET请求重定向\n\n\n4**\n\n\n\n\n400\nBad Request\n客户端请求的语法错误，服务器无法理解\n\n\n401\nUnauthorized\n请求要求用户的身份认证\n\n\n402\nPayment Required\n保留，将来使用\n\n\n403\nForbidden\n服务器理解请求客户端的请求，但是拒绝执行此请求\n\n\n404\nNot Found\n服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面\n\n\n405\nMethod Not Allowed\n客户端请求中的方法被禁止\n\n\n406\nNot Acceptable\n服务器无法根据客户端请求的内容特性完成请求\n\n\n407\nProxy Authentication Required\n请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权\n\n\n408\nRequest Time-out\n服务器等待客户端发送的请求时间过长，超时\n\n\n409\nConflict\n服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突\n\n\n410\nGone\n客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置\n\n\n411\nLength Required\n服务器无法处理客户端发送的不带Content-Length的请求信息\n\n\n412\nPrecondition Failed\n客户端请求信息的先决条件错误\n\n\n413\nRequest Entity Too Large\n由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息\n\n\n414\nRequest-URI Too Large\n请求的URI过长（URI通常为网址），服务器无法处理\n\n\n415\nUnsupported Media Type\n服务器无法处理请求附带的媒体格式\n\n\n416\nRequested range not satisfiable\n客户端请求的范围无效\n\n\n417\nExpectation Failed\n服务器无法满足Expect的请求头信息\n\n\n5**\n\n\n\n\n500\nInternal Server Error\n服务器内部错误，无法完成请求\n\n\n501\nNot Implemented\n服务器不支持请求的功能，无法完成请求\n\n\n502\nBad Gateway\n作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应\n\n\n503\nService Unavailable\n由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中\n\n\n504\nGateway Time-out\n充当网关或代理的服务器，未及时从远端服务器获取请求\n\n\n505\nHTTP Version not supported\n服务器不支持请求的HTTP协议的版本，无法完成处理\n\n\n","tags":["Java","frontend","JavaWeb","HTTP","protocol"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/Servlet/","content":"Servlet1. Servlet简介\n一个运行在tomcat这样的服务器软件容器中的程序, 能够接受响应请求, 协同调度功能, 响应数据的一个Web应用控制器\n是运行在服务端(Tomcat)的Java小程序, 从代码层面来讲就是一系列的接口, 是sun公司定义访问动态资源的规范\n\n2. Servlet开发流程\n步骤1 : 先完成前端发送请求的form\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form method=&quot;get&quot; action=&quot;userServlet&quot;&gt;    用户名:&lt;input type=&quot;text&quot; name=&quot;username&quot; /&gt; &lt;br&gt;    &lt;input  type=&quot;submit&quot; value=&quot;校验&quot;/&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n步骤 2 : 完成Java业务逻辑, 处理接收与返回\n\n\n在Java代码中完成业务, Step :\n实现Servlet接口, 可以通过继承HttpServlet实现\n重写service方法, 其中的参数是(HttpServletRequest req, resp)\n获取请求中的参数\n业务逻辑处理\n设置响应内容\n\n\n\npackage com.f.servlet;import jakarta.servlet.ServletException;import jakarta.servlet.http.HttpServlet;import jakarta.servlet.http.HttpServletRequest;import jakarta.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;public class UserServlet extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;//        super.service(req, resp);        String username = req.getParameter(&quot;username&quot;);        if (&quot;funtianyu&quot;.equals(username))&#123;            resp.getWriter().write(&quot;NO&quot;);        &#125; else &#123;            resp.getWriter().write(&quot;YES&quot;);        &#125;    &#125;&#125;\n\n\n步骤 3 : 在Web.xml中完成路径的映射和补全html中的action中的url路径\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot;         version=&quot;4.0&quot;&gt;    &lt;!--给UserServlet起别名, 用于做映射--&gt;    &lt;servlet&gt;        &lt;servlet-name&gt;userServlet&lt;/servlet-name&gt;        &lt;servlet-class&gt;com.f.servlet.UserServlet&lt;/servlet-class&gt;    &lt;/servlet&gt;    &lt;!--做路径映射--&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;userServlet&lt;/servlet-name&gt;        &lt;url-pattern&gt;/userServlet&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;&lt;/web-app&gt;\n\n\n通过设置servlet标签, 将一个serv-name和Java业务逻辑代码绑定再通过servlet-mapping标签, 将一个serv-name和访问路径绑定设置完访问路径后再将这个路径填入html中的action\n\n3. Servlet注解方法配置\n主要是用于简化繁琐的web.xml的配置, 可以在Servlet对象上通过添加注解的方式, 便捷配置Servlet\n\n@WebServlet(    name=&quot;xxx&quot;,  // servlet-name    urlPartterns == value == &quot;url&quot;, // url-parttern    loadOnStartup = int)\n\n4. Servlet生命周期4.1 简介与测试\n一个Servlet对象有四个阶段\n构造 &#x3D;&gt; 在访问到对应的URL的时候执行 : 1次\n初始化 &#x3D;&gt; 构造完毕以后就执行初始化 : 1次\n执行服务 &#x3D;&gt; 在每次请求的时候 : 无数次\n销毁 &#x3D;&gt; 在关闭tomcat的时候最后调用 : 1次\n\n\n\n\n测试代码\n\npackage com.f.servlet;import jakarta.servlet.ServletException;import jakarta.servlet.http.HttpServlet;import jakarta.servlet.http.HttpServletRequest;import jakarta.servlet.http.HttpServletResponse;import java.io.IOException;public class LifeCycle extends HttpServlet &#123;    public LifeCycle()&#123;        System.out.println(&quot;构造方法&quot;);    &#125;    @Override    public void init() throws ServletException &#123;        System.out.println(&quot;初始化方法&quot;);    &#125;    @Override    public void destroy() &#123;        System.out.println(&quot;销毁方法()&quot;);    &#125;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;service()&quot;);    &#125;&#125;\n\n\n&lt;load-on-startup&gt;参数 : 如果值是正整数, 那么这个Servlet对象会在Tomcat启动的时候就执行构造和初始化, 如果有多个对象设定了这个值, 则会根据按大小, 从小到大以此执行\n\n&lt;servlet&gt;    &lt;servlet-name&gt;lifeCycle&lt;/servlet-name&gt;    &lt;servlet-class&gt;com.f.servlet.LifeCycle&lt;/servlet-class&gt;    &lt;load-on-startup&gt;100&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;    &lt;servlet-name&gt;lifeCycle&lt;/servlet-name&gt;    &lt;url-pattern&gt;/lifeCycle&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;\n\n4.2 总结\nServlet对象在容器中是单例的\n容器可以处理并发的用户请求, 每个请求在容器中都会开启一个线程\n所以多个线程可能同时使用相同的Servlet对象, 故我们不要轻易在定义一些容易经常发生修改的成员变量, 会有线程冲突\n\n5. Servlet继承结构5.1 继承结构和如何查阅源码\n继承结构 : HttpServlet &#x3D;&gt; GenericServlet &#x3D;&gt; Servlet(interface)\n\n\n如何查阅源码\n\n\n从结构开始, 去查阅它的实现类中对于各个方法的实现, 并理解在这一层实现的功能\n\n5.2 Servlet.class\nServlet源码\n\npublic interface Servlet &#123;    void init(ServletConfig var1) throws ServletException;    ServletConfig getServletConfig();    void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException;    String getServletInfo();    void destroy();&#125;\n\n5.3 GenericServlet.class\ninit(ServletConfig var1)的重写\n\n// 有参的实现public void init(ServletConfig config) throws ServletException &#123;        this.config = config;         this.init();    &#125;// 无参的实现public void init() throws ServletException &#123;    &#125;\n\n实现的内容\n设置config, 并执行无参的init\n无参的init()用于重写, 这样我们就不用重新写加载config这个操作了\n\n\n\n\n\n ServletConfig getServletConfig();\n\npublic ServletConfig getServletConfig() &#123;        return this.config;    &#125;\n\n简单的返回config参数\n\n\n\n void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException;\n\npublic abstract void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException;\n\n没有实现\n\n\n\nString getServletInfo();\n\npublic String getServletInfo() &#123;        return &quot;&quot;;    &#125;\n\n返回空\n\n\n\nvoid destroy();\n\npublic void destroy() &#123;    &#125;\n\n消极实现\n\n\n\n总结\n\n\n实现了基础的配置和初始化, service留作下一层实现\n\n5.4 HttpServlet.class\n public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException\n\npublic void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123;        HttpServletRequest request;        HttpServletResponse response;        try &#123;            request = (HttpServletRequest)req;            response = (HttpServletResponse)res;        &#125; catch (ClassCastException var6) &#123;            throw new ServletException(lStrings.getString(&quot;http.non_http&quot;));        &#125;        this.service(request, response);    &#125;\n\n完成了对传入参数从父类 &#x3D;&gt; 子类的类型转变\n并将调用用于接收子类类型的service方法\n\n\n\nprotected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException\n\nprotected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        String method = req.getMethod();        long lastModified;        if (method.equals(&quot;GET&quot;)) &#123;            lastModified = this.getLastModified(req);            if (lastModified == -1L) &#123;                this.doGet(req, resp);            &#125; else &#123;                long ifModifiedSince;                try &#123;                    ifModifiedSince = req.getDateHeader(&quot;If-Modified-Since&quot;);                &#125; catch (IllegalArgumentException var9) &#123;                    ifModifiedSince = -1L;                &#125;                if (ifModifiedSince &lt; lastModified / 1000L * 1000L) &#123;                    this.maybeSetLastModified(resp, lastModified);                    this.doGet(req, resp);                &#125; else &#123;                    resp.setStatus(304);                &#125;            &#125;        &#125; else if (method.equals(&quot;HEAD&quot;)) &#123;            lastModified = this.getLastModified(req);            this.maybeSetLastModified(resp, lastModified);            this.doHead(req, resp);        &#125; else if (method.equals(&quot;POST&quot;)) &#123;            this.doPost(req, resp);        &#125; else if (method.equals(&quot;PUT&quot;)) &#123;            this.doPut(req, resp);        &#125; else if (method.equals(&quot;DELETE&quot;)) &#123;            this.doDelete(req, resp);        &#125; else if (method.equals(&quot;OPTIONS&quot;)) &#123;            this.doOptions(req, resp);        &#125; else if (method.equals(&quot;TRACE&quot;)) &#123;            this.doTrace(req, resp);        &#125; else &#123;            String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;);            Object[] errArgs = new Object[]&#123;method&#125;;            errMsg = MessageFormat.format(errMsg, errArgs);            resp.sendError(501, errMsg);        &#125;    &#125;\n\n主要功能, 验证方法, 并执行对应的doxxx方法\n\n\n\ndoXXX()方法\n\n// dorGetprotected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        String msg = lStrings.getString(&quot;http.method_get_not_supported&quot;);        this.sendMethodNotAllowed(req, resp, msg);    &#125;// doPostprotected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        String msg = lStrings.getString(&quot;http.method_post_not_supported&quot;);        this.sendMethodNotAllowed(req, resp, msg);    &#125;\n\n无论传入的内容返回405界面\n\n\n\n总结\n\n\n默认的service方法会无论方法都去执行返回405界面\n所以我们需要重写service方法, 这样才能正常显示\n但是如果我们重写service方法,  我们会失去service的一些功能, 还有种做法是重写doGet等do方法\n\n6. ServletConfig6.1 ServletConfig的使用\nServlet是什么?\n\n\n为Servlet提供初始参数配置的对象, 每个Servlet对象都有一个自己ServletConfig对象\n会在Servlet的init方法中将config传入\n\n\n\n基本的使用\n\n\n使用步骤 : \n在web.xml或者@WebServlet注解中传入参数\n在Servlet中获取\n\n\n四个方法\n\n\n\n\n方法名\n作用\n\n\n\ngetServletName()\n获取&lt;servlet-name&gt;HelloServlet&lt;&#x2F;servlet-name&gt;定义的Servlet名称\n\n\ngetServletContext()\n获取ServletContext对象\n\n\ngetInitParameter()\n获取配置Servlet时设置的『初始化参数』，根据名字获取值\n\n\ngetInitParameterNames()\n获取所有初始化参数名组成的Enumeration对象\n\n\n\n示例\n\n@WebServlet(        name=&quot;ServletA&quot;,        urlPatterns = &quot;/servletA&quot;,        initParams = &#123;@WebInitParam(name=&quot;paramA&quot;, value = &quot;valueA&quot;), @WebInitParam(name=&quot;paramB&quot;, value = &quot;valueB&quot;)&#125;)public class ServletA extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        String name = getServletName();        String value = getInitParameter(&quot;paramA&quot;);        System.out.println(&quot;servletName = &quot; + name);        System.out.println(&quot;paramsA :&quot; + value);        Enumeration&lt;String&gt; parameterNames = getInitParameterNames();        while (parameterNames.hasMoreElements()) &#123;            String pname = parameterNames.nextElement();            String pvalue = getInitParameter(pname);            System.out.println(pname + &quot; : &quot; + pvalue);        &#125;    &#125;&#125;\n\n\n使用web.xml配置的时候\n\n&lt;servlet&gt;     &lt;servlet-name&gt;ServletA&lt;/servlet-name&gt;     &lt;servlet-class&gt;com.atguigu.servlet.ServletA&lt;/servlet-class&gt;     &lt;!--配置ServletA的初始参数--&gt;     &lt;init-param&gt;         &lt;param-name&gt;param1&lt;/param-name&gt;         &lt;param-value&gt;value1&lt;/param-value&gt;     &lt;/init-param&gt;     &lt;init-param&gt;         &lt;param-name&gt;param2&lt;/param-name&gt;         &lt;param-value&gt;value2&lt;/param-value&gt;     &lt;/init-param&gt; &lt;/servlet&gt;  &lt;servlet-mapping&gt;      &lt;servlet-name&gt;ServletA&lt;/servlet-name&gt;      &lt;url-pattern&gt;/servletA&lt;/url-pattern&gt;  &lt;/servlet-mapping&gt;\n6.2 ServletConfig\n用来干什么的?\n\n\n是所有的在同一个容器中的Servlet对象所可以共同使用的ServletConfig, 像是全局的config\n示例\n\n\n\n@WebServlet(        name = &quot;servletB&quot;,        urlPatterns = &quot;/servletB&quot;)public class ServletB extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        // 获取ServletContext对象        ServletContext servletContext = this.getServletContext();        String valueA = servletContext.getInitParameter(&quot;name1&quot;);        System.out.println(&quot;name1 : &quot; + valueA);        Enumeration&lt;String&gt; names = servletContext.getInitParameterNames();        while (names.hasMoreElements()) &#123;            String name = names.nextElement();            String value = servletContext.getInitParameter(name);            System.out.println(name + &quot; = &quot; + value);        &#125;    &#125;&#125;\n6.3 ServletContext其他重要的API\n获取一个指向项目部署位置下的某个文件&#x2F;目录的磁盘真实路径的API\n\n servletContext.getRealPath(filename/dircname)\n\n实现了动态获取项目运行的实际路径的功能\n\n\n获取项目的上下文路径\n\nString contextPath = servletContext.getContextPath();\n\n可以解决后端的实现中的路径问题\n\n\n域对象相关的API\n\n\n域对象 : 用于存储和传递数据的对象,不同的域对象代表不同的共享数据的范围\nServletContext代表应用是最大的域, 可以在本应用实现数据的共享和传递\nwebapp的三大域对象是应用域, 会话域, 请求域\n\n\n\n\nAPI\n功能解释\n\n\n\nvoid setAttribute(String key,Object value);\n向域中存储&#x2F;修改数据\n\n\nObject getAttribute(String key);\n获得域中的数据\n\n\nvoid removeAttribute(String key);\n移除域中的数据\n\n\n7. HttpServletRequest7.1 HttpServletRequest简介\nHttpServletRequest是什么\n\n\nHttpServletRequest是一个接口,其父接口是ServletRequest\n\nHttpServletRequest是Tomcat将请求报文转换封装而来的对象,在Tomcat调用service方法时传入\n\nHttpServletRequest代表客户端发来的请求,所有请求中的信息都可以通过该对象获得\n\n\n7.2 HttpServletRequest常见API\nHttpServletRequest怎么用\n\n\n获取请求行信息相关(方式,请求的url,协议及版本)\n\n\n\n\nAPI\n功能解释\n\n\n\nStringBuffer getRequestURL();\n获取客户端请求的url\n\n\nString getRequestURI();\n获取客户端请求项目中的具体资源\n\n\nint getServerPort();\n获取客户端发送请求时的端口\n\n\nint getLocalPort();\n获取本应用在所在容器的端口\n\n\nint getRemotePort();\n获取客户端程序的端口\n\n\nString getScheme();\n获取请求协议\n\n\nString getProtocol();\n获取请求协议及版本号\n\n\nString getMethod();\n获取请求方式\n\n\n\n获得请求头信息相关\n\n\n\n\nAPI\n功能解释\n\n\n\nString getHeader(String headerName);\n根据头名称获取请求头\n\n\nEnumeration getHeaderNames();\n获取所有的请求头名字\n\n\nString getContentType();\n获取content-type请求头\n\n\n\n获得请求参数相关\n\n\n\n\nAPI\n功能解释\n\n\n\nString getParameter(String parameterName);\n根据请求参数名获取请求单个参数值\n\n\nString[] getParameterValues(String parameterName);\n根据请求参数名获取请求多个参数值数组\n\n\nEnumeration getParameterNames();\n获取所有请求参数名\n\n\nMap&lt;String, String[]&gt; getParameterMap();\n获取所有请求参数的键值对集合\n\n\nBufferedReader getReader() throws IOException;\n获取读取请求体的字符输入流\n\n\nServletInputStream getInputStream() throws IOException;\n获取读取请求体的字节输入流\n\n\nint getContentLength();\n获得请求体长度的字节数\n\n\n\n其他API\n\n\n\n\nAPI\n功能解释\n\n\n\nString getServletPath();\n获取请求的Servlet的映射路径\n\n\nServletContext getServletContext();\n获取ServletContext对象\n\n\nCookie[] getCookies();\n获取请求中的所有cookie\n\n\nHttpSession getSession();\n获取Session对象\n\n\nvoid setCharacterEncoding(String encoding) ;\n设置请求体字符集\n\n\n8. HttpServletResponse8.1 HttpServletResponse简介\nHttpServletResponse是什么\n\n\nHttpServletResponse是一个接口,其父接口是ServletResponse\n\nHttpServletResponse是Tomcat预先创建的,在Tomcat调用service方法时传入\n\nHttpServletResponse代表对客户端的响应,该对象会被转换成响应的报文发送给客户端,通过该对象我们可以设置响应信息\n\n\n8.2 HttpServletResponse的常见API\nHttpServletRequest怎么用\n\n\n设置响应行相关\n\n\n\n\nAPI\n功能解释\n\n\n\nvoid setStatus(int code);\n设置响应状态码\n\n\n\n设置响应头相关\n\n\n\n\nAPI\n功能解释\n\n\n\nvoid setHeader(String headerName, String headerValue);\n设置&#x2F;修改响应头键值对\n\n\nvoid setContentType(String contentType);\n设置content-type响应头及响应字符集(设置MIME类型)\n\n\n\n设置响应体相关\n\n\n\n\nAPI\n功能解释\n\n\n\nPrintWriter getWriter() throws IOException;\n获得向响应体放入信息的字符输出流\n\n\nServletOutputStream getOutputStream() throws IOException;\n获得向响应体放入信息的字节输出流\n\n\nvoid setContentLength(int length);\n设置响应体的字节长度,其实就是在设置content-length响应头\n\n\n\n其他API\n\n\n\n\nAPI\n功能解释\n\n\n\nvoid sendError(int code, String message) throws IOException;\n向客户端响应错误信息的方法,需要指定响应码和响应信息\n\n\nvoid addCookie(Cookie cookie);\n向响应体中增加cookie\n\n\nvoid setCharacterEncoding(String encoding);\n设置响应体字符集\n\n\n\nMIME类型\n\n\nMIME类型,可以理解为文档类型,用户表示传递的数据是属于什么类型的文档\n\n浏览器可以根据MIME类型决定该用什么样的方式解析接收到的响应体数据\n\n可以这样理解: 前后端交互数据时,告诉对方发给对方的是 html&#x2F;css&#x2F;js&#x2F;图片&#x2F;声音&#x2F;视频&#x2F;… …\n\ntomcat&#x2F;conf&#x2F;web.xml中配置了常见文件的拓展名和MIMIE类型的对应关系\n\n常见的MIME类型举例如下\n\n\n\n\n\n文件拓展名\nMIME类型\n\n\n\n.html\ntext&#x2F;html\n\n\n.css\ntext&#x2F;css\n\n\n.js\napplication&#x2F;javascript\n\n\n.png &#x2F;.jpeg&#x2F;.jpg&#x2F;… …\nimage&#x2F;jpeg\n\n\n.mp3&#x2F;.mpe&#x2F;.mpeg&#x2F; … …\naudio&#x2F;mpeg\n\n\n.mp4\nvideo&#x2F;mp4\n\n\n.m1v&#x2F;.m1v&#x2F;.m2v&#x2F;.mpe&#x2F;… …\nvideo&#x2F;mpeg\n\n\n9. 请求转发和响应重定向9.1 概述\n什么是请求转发和响应重定向\n\n\n请求转发和响应重定向是web应用中间接访问项目资源的两种手段,也是Servlet控制页面跳转的两种手段\n\n请求转发通过HttpServletRequest实现,响应重定向通过HttpServletResponse实现\n\n请求转发生活举例: 张三找李四借钱,李四没有,李四找王五,让王五借给张三\n\n响应重定向生活举例:张三找李四借钱,李四没有,李四让张三去找王五,张三自己再去找王五借钱\n\n\n9.2 请求转发(含八股)\n请求转发特点(背诵)\n\n\n请求转发通过HttpServletRequest对象获取请求转发器实现\n\n请求转发是服务器内部的行为,对客户端是屏蔽的\n\n客户端只发送了一次请求,客户端地址栏不变\n\n服务端只产生了一对请求和响应对象,这一对请求和响应对象会继续传递给下一个资源\n\n因为全程只有一个HttpServletRequset对象,所以请求参数可以传递,请求域中的数据也可以传递\n\n请求转发可以转发给其他Servlet动态资源,也可以转发给一些静态资源以实现页面跳转\n\n请求转发可以转发给WEB-INF下受保护的资源\n\n请求转发不能转发到本项目以外的外部资源\n\n\n\n请求转发测试代码\n\n![[images&#x2F;1682323740343.png]]\n\nServletA\n\n  @WebServlet(&quot;/servletA&quot;)   public class ServletA extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           //  获取请求转发器           //  转发给servlet  ok           RequestDispatcher  requestDispatcher = req.getRequestDispatcher(&quot;servletB&quot;);           //  转发给一个视图资源 ok           //RequestDispatcher requestDispatcher = req.getRequestDispatcher(&quot;welcome.html&quot;);           //  转发给WEB-INF下的资源  ok           //RequestDispatcher requestDispatcher = req.getRequestDispatcher(&quot;WEB-INF/views/view1.html&quot;);           //  转发给外部资源   no           //RequestDispatcher requestDispatcher = req.getRequestDispatcher(&quot;http://www.atguigu.com&quot;);           //  获取请求参数           String username = req.getParameter(&quot;username&quot;);           System.out.println(username);           //  向请求域中添加数据           req.setAttribute(&quot;reqKey&quot;,&quot;requestMessage&quot;);           //  做出转发动作           requestDispatcher.forward(req,resp);       &#125;   &#125;\n\nServletB\n\n  @WebServlet(&quot;/servletB&quot;)   public class ServletB extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           // 获取请求参数           String username = req.getParameter(&quot;username&quot;);           System.out.println(username);           // 获取请求域中的数据           String reqMessage = (String)req.getAttribute(&quot;reqKey&quot;);           System.out.println(reqMessage);           // 做出响应           resp.getWriter().write(&quot;servletB response&quot;);               &#125;   &#125;\n\n打开浏览器,输入以下url测试\n\n http://localhost:8080/web03_war_exploded/servletA?username=atguigu\n9.3 响应重定向(含八股)\n响应重定向特点(背诵)\n\n\n响应重定向通过HttpServletResponse对象的sendRedirect方法实现\n\n响应重定向是服务端通过302响应码和路径,告诉客户端自己去找其他资源,是在服务端提示下的,客户端的行为\n\n客户端至少发送了两次请求,客户端地址栏是要变化的\n\n服务端产生了多对请求和响应对象,且请求和响应对象不会传递给下一个资源\n\n因为全程产生了多个HttpServletRequset对象,所以请求参数不可以传递,请求域中的数据也不可以传递\n\n重定向可以是其他Servlet动态资源,也可以是一些静态资源以实现页面跳转\n\n重定向不可以到给WEB-INF下受保护的资源\n\n重定向可以到本项目以外的外部资源\n\n\n\n响应重定向测试代码\n\n![[images&#x2F;1682323740343.png]]\n\nServletA\n\n ​ @WebServlet(&quot;/servletA&quot;)   public class ServletA extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           //  获取请求参数           String username = req.getParameter(&quot;username&quot;);           System.out.println(username);           //  向请求域中添加数据           req.setAttribute(&quot;reqKey&quot;,&quot;requestMessage&quot;);           //  响应重定向           // 重定向到servlet动态资源 OK           resp.sendRedirect(&quot;servletB&quot;);           // 重定向到视图静态资源 OK           //resp.sendRedirect(&quot;welcome.html&quot;);           // 重定向到WEB-INF下的资源 NO           //resp.sendRedirect(&quot;WEB-INF/views/view1&quot;);           // 重定向到外部资源           //resp.sendRedirect(&quot;http://www.atguigu.com&quot;);       &#125;   &#125;\n\nServletB\n\n @WebServlet(&quot;/servletB&quot;)   public class ServletB extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           // 获取请求参数           String username = req.getParameter(&quot;username&quot;);           System.out.println(username);           // 获取请求域中的数据           String reqMessage = (String)req.getAttribute(&quot;reqKey&quot;);           System.out.println(reqMessage);           // 做出响应           resp.getWriter().write(&quot;servletB response&quot;);   ​       &#125;   &#125;\n10. 乱码问题\n归根结底就是字符集的匹配问题\n\n10.1 乱码问题\n乱码问题产生的根本原因是什么\n\n\n数据的编码和解码使用的不是同一个字符集\n使用了不支持某个语言文字的字符集\n\n\n各个字符集的兼容性\n\n![[images&#x2F;1682326867396.png]]\n\n由上图得知,上述字符集都兼容了ASCII\nASCII中有什么? 英文字母和一些通常使用的符号,所以这些东西无论使用什么字符集都不会乱码\n\n10.1.1 HTML乱码问题\n设置项目文件的字符集要使用一个支持中文的字符集\n\n\n查看当前文件的字符集\n\n![[images&#x2F;1682325817829.png]]\n\n查看项目字符集 配置,将Global Encoding 全局字符集,Project Encoding 项目字符集, Properties Files 属性配置文件字符集设置为UTF-8\n\n![[images&#x2F;1682326229063.png]]\n\n当前视图文件的字符集通过 来告知浏览器通过什么字符集来解析当前文件\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    中文&lt;/body&gt;&lt;/html&gt;\n\n10.1.2 Tomcat控制台乱码\n在tomcat10.1.7这个版本中,修改 tomcat&#x2F;conf&#x2F;logging.properties中,所有的UTF-8为GBK即可\n\n\n修改前\n\n![[images&#x2F;1681443202115.png]]\n\n修改后\n\n![[images&#x2F;1681443273573.png]]\n\n重启测试\n\n![[images&#x2F;1681443314432.png]]\n![[images&#x2F;1682325615922.png]]\n\nsout乱码问题,设置JVM加载.class文件时使用UTF-8字符集\n\n\n设置虚拟机加载.class文件的字符集和编译时使用的字符集一致\n\n![[images&#x2F;1695189588009.png]]\n10.1.3 请求乱码问题10.1.3.1 GET请求乱码\nGET请求方式乱码分析\n\n\nGET方式提交参数的方式是将参数放到URL后面,如果使用的不是UTF-8,那么会对参数进行URL编码处理\nHTML中的  影响了GET方式提交参数的URL编码\ntomcat10.1.7的URI编码默认为 UTF-8\n当GET方式提交的参数URL编码和tomcat10.1.7默认的URI编码不一致时,就会出现乱码\n\n\nGET请求方式乱码演示\n\n\n浏览器解析的文档的\n\n![[images&#x2F;1682385870660.png]]\n\nGET方式提交时,会对数据进行URL编码处理 ,是将GBK 转码为 “百分号码”\n\n![[images&#x2F;1682385997927.png]]\n\ntomcat10.1.7 默认使用UTF-8对URI进行解析,造成前后端使用的字符集不一致,出现乱码\n\n![[images&#x2F;1682386110151.png]]\n\nGET请求方式乱码解决\n\n\n方式1  :设置GET方式提交的编码和Tomcat10.1.7的URI默认解析编码一致即可 (推荐)\n\n![[images&#x2F;1682386298048.png]]\n![[images&#x2F;1682386374464.png]]\n\n方式2 : 设置Tomcat10.1.7的URI解析字符集和GET请求发送时所使用URL转码时的字符集一致即可,修改conf&#x2F;server.xml中 Connecter 添加 URIEncoding&#x3D;”GBK”  (不推荐)\n\n![[images&#x2F;1682386551684.png]]\n![[images&#x2F;1682386611945.png]]\n10.1.3.2 POST方式请求乱码\nPOST请求方式乱码分析\n\n\nPOST请求将参数放在请求体中进行发送\n请求体使用的字符集受到了 的影响\nTomcat10.1.7 默认使用UTF-8字符集对请求体进行解析\n如果请求体的URL转码和Tomcat的请求体解析编码不一致,就容易出现乱码\n\n\nPOST方式乱码演示\n\n\nPOST请求请求体受到了 的影响\n\n![[images&#x2F;1682387258428.png]]\n\n请求体中,将GBK数据进行 URL编码\n\n![[images&#x2F;1682387349916.png]]\n\n后端默认使用UTF-8解析请求体,出现字符集不一致,导致乱码\n\n![[images&#x2F;1682387412704.png]]\n\nPOST请求方式乱码解决\n\n\n方式1 : 请求时,使用UTF-8字符集提交请求体 (推荐)\n\n![[images&#x2F;1682387836615.png]]\n![[images&#x2F;1682387857587.png]]\n\n方式2 : 后端在获取参数前,设置解析请求体使用的字符集和请求发送时使用的字符集一致 (不推荐)\n\n![[images&#x2F;1682388026978.png]]\n10.1.3 响应乱码问题\n响应乱码分析\n\n\n在Tomcat10.1.7中,向响应体中放入的数据默认使用了工程编码 UTF-8\n浏览器在接收响应信息时,使用了不同的字符集或者是不支持中文的字符集就会出现乱码\n\n\n响应乱码演示\n\n\n服务端通过response对象向响应体添加数据\n\n![[images&#x2F;1682388204239.png]]\n\n浏览器接收数据解析乱码\n\n![[images&#x2F;1682388599014.png]]\n\n响应乱码解决\n\n\n方式1 : 手动设定浏览器对本次响应体解析时使用的字符集(不推荐)\n\nedge和 chrome浏览器没有提供直接的比较方便的入口,不方便\n\n\n方式2: 后端通过设置响应体的字符集和浏览器解析响应体的默认字符集一致(不推荐)\n\n\n![[images&#x2F;1682389063225.png]]\n方式3: 通过设置content-type响应头,告诉浏览器以指定的字符集解析响应体(推荐)\n![[images&#x2F;1682389263627.png]]\n![[images&#x2F;1682389317234.png]]\n11. 工程开发实践\n说明 :  这部分内容, 并不做实际的实现, 只针对其中用到的部分新的jar包和API和整体的结构以及规范说明, 因为有需要做的项目, 实现他的简陋的项目, 浪费时间\n\n11.1 项目结构11.1.1 Module层\n实现的内容\n\n\n对于数据库中的数据的增删改查\ndao层 &#x3D;&gt; 实现对数据的增删改查操作类\nimpl层 : 对于接口的实现\n接口的定义\nBaseDao : 基础类\n\n\n\n\n实体类\npojo层 &#x3D;&gt; 对于实体类的实现\n\n\n服务\nservice &#x3D;&gt; 对于服务的实现\n相关接口的定义\nimpl\n对于服务的实现\n\n\n\n\n\n\n\n\n11.1.2 Controller层\n实现的内容\n\n\n接收前端请求和给出响应\nBaseController &#x3D;&gt; 基础操作的实现\nController类\n\n\n\n\n11.1.3 View层\n实现的内容\n\n\n页面的显示传递以及接收后端的数据\nstatic等\n\n\n\n11.2 代码说明11.2.1 pojo层与Lombok\n需要实现序列化接口\n避免繁琐的getter setter等的设置, 使用Lombok可以集成实现\n\n@AllArgsConstructor // 全参构造@NoArgsConstructor // 无参构造@Data // getter setter equals hashcode toStringpublic class Sysuser implements Serializable\n\n11.2.2 加密工具类的使用import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;public final class MD5Util &#123;    public static String encrypt(String strSrc) &#123;        try &#123;            char hexChars[] = &#123; &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;,                    &#x27;9&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27; &#125;;            byte[] bytes = strSrc.getBytes();            MessageDigest md = MessageDigest.getInstance(&quot;MD5&quot;);            md.update(bytes);            bytes = md.digest();            int j = bytes.length;            char[] chars = new char[j * 2];            int k = 0;            for (int i = 0; i &lt; bytes.length; i++) &#123;                byte b = bytes[i];                chars[k++] = hexChars[b &gt;&gt;&gt; 4 &amp; 0xf];                chars[k++] = hexChars[b &amp; 0xf];            &#125;            return new String(chars);        &#125; catch (NoSuchAlgorithmException e) &#123;            e.printStackTrace();            throw new RuntimeException(&quot;MD5加密出错!!!&quot;)        &#125;    &#125;&#125;\n","tags":["Java","JavaWeb","backend","Servlet","含有八股内容"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/JavaScript/","content":"JavaScript1. JS的特性\nJS是一门解释性的语言\nJS是弱类型的语言\n句尾;可加可不加\nJS并不算是面对对象的语言\n\n2. 数据类型和运算符数据类型\n数字类型 Number\n字符串类型 String\n布尔类型 boolean\n引用类型 Object\n函数类型 function\n未命名的类型 var\n可以通过 typeof判断数据类型\n\n运算符\n&#x3D;&#x3D; 与 &#x3D;&#x3D;&#x3D;\n前者在进行判断的时候, 如果两边的变量类型不一致, 会进行对齐转换处理, 后在进行判断\n而&#x3D;&#x3D;&#x3D;, 如果类型不一致, 直接回返回false\n\n\n特性\n变量具有的特性\n\n\nvar类型的变量可以再次声明\n所有类型的变量可以被多次赋予不同类型的值\n因为是弱类型, 所以如果变量声明但是未赋值是undefine类型\n如果给变量赋值null, 数据类型是Object\n声明变量的时候, 不能指定类型\n\n总结\n声明变量的时候, 不能指定类型\n\n3. JS的流程控制和函数3.1 分支结构和Java一样\n3.2 循环结构\nfor循环\n\n\n和Java一致\n\n\nforeach循环\n\n\n返回的是数组的索引\n使用in而不是:\n\nvar arr = [1,2,3,4,5];document.write(&quot;&lt;ul&gt;&quot;);for (var index in arr) &#123;document.write(&quot;&lt;li&gt;&quot;+arr[index]+&quot;&lt;/li&gt;&quot;);&#125;document.write(&quot;&lt;/ul&gt;&quot;)\n\n3.3 函数声明\n函数声明的时候需要function关键字\n参数列表不需要表明参数类型\n直接return就行, 没有返回限制\n调用函数的时候实参数量和形参数量可以不一致, 但是多出来的部分不生效\n\n// 第一种声明方式function sum (a, b) &#123;return a + b;&#125;var s = sum(1,2);console.log(s);// 第二种声明方式var add = function (a, b) &#123;return a + b;&#125;console.log(add(1,23));\n\n4. JS的对象和JSON4.1 对象\n声明对象的两种方式\n\n// 第一种方式var person = new Object();person.name = &quot;...&quot;;person.age = 20;person.arr = [1,2,3,4];person.func = function()&#123;console.log(this.age + &quot; years, &quot; + this.name);for (var index in this.arr) &#123;console.log(this.arr[index]);&#125;&#125;person.func();// 第二种方式var person = &#123;&quot;name&quot; : &quot;funfs&quot;,&quot;foods&quot; : [1,2,3,4],&#125;console.log(person.foods);\n\n\n第二种方式更像是JSON风格的\n\n4.2 JSON格式\n全程 JavaScript Object Notation, JS对象简谱, 因为容易转换为对象, 所以常被用于数据传输\n\n\nJSON.parse : 将JSON格式字符串转化为Object对象\nJSON.stringify : 将Object对象转化为JSON格式字符串\n\nvar personStr = &#x27;&#123;&quot;name&quot;:&quot;...&quot;, &quot;age&quot;:123, &quot;girlFriend&quot;:&#123;&quot;name&quot;:&quot;ghg&quot;, &quot;age&quot;:12&#125;, &quot;foods&quot;:[1,2,3,4]&#125;&#x27;;console.log(personStr);console.log(typeof personStr);var person = JSON.parse(personStr);console.log(typeof person);console.log(person.name);console.log(person);var person = &#123;&quot;name&quot;:&quot;ssb&quot;,&quot;foods&quot;:[1,2,3,4],&#125;var personStr = JSON.stringify(person);console.log(personStr); // &#123;&quot;name&quot;:&quot;ssb&quot;,&quot;foods&quot;:[1,2,3,4]&#125;\n\n4.3 JS常见对象4.3.1 数组\n创建数组的四种方式\n\n\nnew Array()                                                   创建空数组\nnew Array(5)                                                 创建数组时给定长度\nnew Array(ele1,ele2,ele3,… … ,elen);          创建数组时指定元素值\n[ele1,ele2,ele3,… … ,elen];                           相当于第三种语法的简写\n\n\n数组的常见API\n\n\n在JS中,数组属于Object类型,其长度是可以变化的,更像JAVA中的集合\n\n\n\n\n方法\n描述\n\n\n\nconcat()\n连接两个或更多的数组，并返回结果。\n\n\ncopyWithin()\n从数组的指定位置拷贝元素到数组的另一个指定位置中。\n\n\nentries()\n返回数组的可迭代对象。\n\n\nevery()\n检测数值元素的每个元素是否都符合条件。\n\n\nfill()\n使用一个固定值来填充数组。\n\n\nfilter()\n检测数值元素，并返回符合条件所有元素的数组。\n\n\nfind()\n返回符合传入测试（函数）条件的数组元素。\n\n\nfindIndex()\n返回符合传入测试（函数）条件的数组元素索引。\n\n\nforEach()\n数组每个元素都执行一次回调函数。\n\n\nfrom()\n通过给定的对象中创建一个数组。\n\n\nincludes()\n判断一个数组是否包含一个指定的值。\n\n\nindexOf()\n搜索数组中的元素，并返回它所在的位置。\n\n\nisArray()\n判断对象是否为数组。\n\n\njoin()\n把数组的所有元素放入一个字符串。\n\n\nkeys()\n返回数组的可迭代对象，包含原始数组的键(key)。\n\n\nlastIndexOf()\n搜索数组中的元素，并返回它最后出现的位置。\n\n\nmap()\n通过指定函数处理数组的每个元素，并返回处理后的数组。\n\n\npop()\n删除数组的最后一个元素并返回删除的元素。\n\n\npush()\n向数组的末尾添加一个或更多元素，并返回新的长度。\n\n\nreduce()\n将数组元素计算为一个值（从左到右）。\n\n\nreduceRight()\n将数组元素计算为一个值（从右到左）。\n\n\nreverse()\n反转数组的元素顺序。\n\n\nshift()\n删除并返回数组的第一个元素。\n\n\nslice()\n选取数组的一部分，并返回一个新数组。\n\n\nsome()\n检测数组元素中是否有元素符合指定条件。\n\n\nsort()\n对数组的元素进行排序。\n\n\nsplice()\n从数组中添加或删除元素。\n\n\ntoString()\n把数组转换为字符串，并返回结果。\n\n\nunshift()\n向数组的开头添加一个或更多元素，并返回新的长度。\n\n\nvalueOf()\n返回数组对象的原始值。\n\n\nArray.of()\n将一组值转换为数组。\n\n\nArray.at()\n用于接收一个整数值并返回该索引对应的元素，允许正数和负数。负整数从数组中的最后一个元素开始倒数。\n\n\nArray.flat()\n创建一个新数组，这个新数组由原数组中的每个元素都调用一次提供的函数后的返回值组成。\n\n\nArray.flatMap()\n使用映射函数映射每个元素，然后将结果压缩成一个新数组。\n\n\n4.3.2 Boolean对象\nboolean对象的方法比较简单\n\n\n\n\n方法\n描述\n\n\n\ntoString()\n把布尔值转换为字符串，并返回结果。\n\n\nvalueOf()\n返回 Boolean 对象的原始值。\n\n\n4.3.3 Date对象\n和JAVA中的Date类比较类似\n\n\n\n\n方法\n描述\n\n\n\ngetDate()\n从 Date 对象返回一个月中的某一天 (1 ~ 31)。\n\n\ngetDay()\n从 Date 对象返回一周中的某一天 (0 ~ 6)。\n\n\ngetFullYear()\n从 Date 对象以四位数字返回年份。\n\n\ngetHours()\n返回 Date 对象的小时 (0 ~ 23)。\n\n\ngetMilliseconds()\n返回 Date 对象的毫秒(0 ~ 999)。\n\n\ngetMinutes()\n返回 Date 对象的分钟 (0 ~ 59)。\n\n\ngetMonth()\n从 Date 对象返回月份 (0 ~ 11)。\n\n\ngetSeconds()\n返回 Date 对象的秒数 (0 ~ 59)。\n\n\ngetTime()\n返回 1970 年 1 月 1 日至今的毫秒数。\n\n\ngetTimezoneOffset()\n返回本地时间与格林威治标准时间 (GMT) 的分钟差。\n\n\ngetUTCDate()\n根据世界时从 Date 对象返回月中的一天 (1 ~ 31)。\n\n\ngetUTCDay()\n根据世界时从 Date 对象返回周中的一天 (0 ~ 6)。\n\n\ngetUTCFullYear()\n根据世界时从 Date 对象返回四位数的年份。\n\n\ngetUTCHours()\n根据世界时返回 Date 对象的小时 (0 ~ 23)。\n\n\ngetUTCMilliseconds()\n根据世界时返回 Date 对象的毫秒(0 ~ 999)。\n\n\ngetUTCMinutes()\n根据世界时返回 Date 对象的分钟 (0 ~ 59)。\n\n\ngetUTCMonth()\n根据世界时从 Date 对象返回月份 (0 ~ 11)。\n\n\ngetUTCSeconds()\n根据世界时返回 Date 对象的秒钟 (0 ~ 59)。\n\n\ngetYear()\n已废弃。 请使用 getFullYear() 方法代替。\n\n\nparse()\n返回1970年1月1日午夜到指定日期（字符串）的毫秒数。\n\n\nsetDate()\n设置 Date 对象中月的某一天 (1 ~ 31)。\n\n\nsetFullYear()\n设置 Date 对象中的年份（四位数字）。\n\n\nsetHours()\n设置 Date 对象中的小时 (0 ~ 23)。\n\n\nsetMilliseconds()\n设置 Date 对象中的毫秒 (0 ~ 999)。\n\n\nsetMinutes()\n设置 Date 对象中的分钟 (0 ~ 59)。\n\n\nsetMonth()\n设置 Date 对象中月份 (0 ~ 11)。\n\n\nsetSeconds()\n设置 Date 对象中的秒钟 (0 ~ 59)。\n\n\nsetTime()\nsetTime() 方法以毫秒设置 Date 对象。\n\n\nsetUTCDate()\n根据世界时设置 Date 对象中月份的一天 (1 ~ 31)。\n\n\nsetUTCFullYear()\n根据世界时设置 Date 对象中的年份（四位数字）。\n\n\nsetUTCHours()\n根据世界时设置 Date 对象中的小时 (0 ~ 23)。\n\n\nsetUTCMilliseconds()\n根据世界时设置 Date 对象中的毫秒 (0 ~ 999)。\n\n\nsetUTCMinutes()\n根据世界时设置 Date 对象中的分钟 (0 ~ 59)。\n\n\nsetUTCMonth()\n根据世界时设置 Date 对象中的月份 (0 ~ 11)。\n\n\nsetUTCSeconds()\nsetUTCSeconds() 方法用于根据世界时 (UTC) 设置指定时间的秒字段。\n\n\nsetYear()\n已废弃。请使用 setFullYear() 方法代替。\n\n\ntoDateString()\n把 Date 对象的日期部分转换为字符串。\n\n\ntoGMTString()\n已废弃。请使用 toUTCString() 方法代替。\n\n\ntoISOString()\n使用 ISO 标准返回字符串的日期格式。\n\n\ntoJSON()\n以 JSON 数据格式返回日期字符串。\n\n\ntoLocaleDateString()\n根据本地时间格式，把 Date 对象的日期部分转换为字符串。\n\n\ntoLocaleTimeString()\n根据本地时间格式，把 Date 对象的时间部分转换为字符串。\n\n\ntoLocaleString()\n根据本地时间格式，把 Date 对象转换为字符串。\n\n\ntoString()\n把 Date 对象转换为字符串。\n\n\ntoTimeString()\n把 Date 对象的时间部分转换为字符串。\n\n\ntoUTCString()\n根据世界时，把 Date 对象转换为字符串。实例：var today = new Date(); var UTCstring = today.toUTCString();\n\n\nUTC()\n根据世界时返回 1970 年 1 月 1 日 到指定日期的毫秒数。\n\n\nvalueOf()\n返回 Date 对象的原始值。\n\n\n4.3.4 Math\n 和JAVA中的Math类比较类似\n\n\n\n\n方法\n描述\n\n\n\nabs(x)\n返回 x 的绝对值。\n\n\nacos(x)\n返回 x 的反余弦值。\n\n\nasin(x)\n返回 x 的反正弦值。\n\n\natan(x)\n以介于 -PI&#x2F;2 与 PI&#x2F;2 弧度之间的数值来返回 x 的反正切值。\n\n\natan2(y,x)\n返回从 x 轴到点 (x,y) 的角度（介于 -PI&#x2F;2 与 PI&#x2F;2 弧度之间）。\n\n\nceil(x)\n对数进行上舍入。\n\n\ncos(x)\n返回数的余弦。\n\n\nexp(x)\n返回 Ex 的指数。\n\n\nfloor(x)\n对 x 进行下舍入。\n\n\nlog(x)\n返回数的自然对数（底为e）。\n\n\nmax(x,y,z,…,n)\n返回 x,y,z,…,n 中的最高值。\n\n\nmin(x,y,z,…,n)\n返回 x,y,z,…,n中的最低值。\n\n\npow(x,y)\n返回 x 的 y 次幂。\n\n\nrandom()\n返回 0 ~ 1 之间的随机数。\n\n\nround(x)\n四舍五入。\n\n\nsin(x)\n返回数的正弦。\n\n\nsqrt(x)\n返回数的平方根。\n\n\ntan(x)\n返回角的正切。\n\n\ntanh(x)\n返回一个数的双曲正切函数值。\n\n\ntrunc(x)\n将数字的小数部分去掉，只保留整数部分。\n\n\n4.3.5 Number\nNumber中准备了一些基础的数据处理函数\n\n\n\n\n方法\n描述\n\n\n\nisFinite\n检测指定参数是否为无穷大。\n\n\nisInteger\n检测指定参数是否为整数。\n\n\nisNaN\n检测指定参数是否为 NaN。\n\n\nisSafeInteger\n检测指定参数是否为安全整数。\n\n\ntoExponential(x)\n把对象的值转换为指数计数法。\n\n\ntoFixed(x)\n把数字转换为字符串，结果的小数点后有指定位数的数字。\n\n\ntoLocaleString(locales, options)\n返回数字在特定语言环境下的表示字符串。\n\n\ntoPrecision(x)\n把数字格式化为指定的长度。\n\n\ntoString()\n把数字转换为字符串，使用指定的基数。\n\n\nvalueOf()\n返回一个 Number 对象的基本数字值。\n\n\n4.3.6 String\n和JAVA中的String类似\n\n\n\n\n方法\n描述\n\n\n\ncharAt()\n返回在指定位置的字符。\n\n\ncharCodeAt()\n返回在指定的位置的字符的 Unicode 编码。\n\n\nconcat()\n连接两个或更多字符串，并返回新的字符串。\n\n\nendsWith()\n判断当前字符串是否是以指定的子字符串结尾的（区分大小写）。\n\n\nfromCharCode()\n将 Unicode 编码转为字符。\n\n\nindexOf()\n返回某个指定的字符串值在字符串中首次出现的位置。\n\n\nincludes()\n查找字符串中是否包含指定的子字符串。\n\n\nlastIndexOf()\n从后向前搜索字符串，并从起始位置（0）开始计算返回字符串最后出现的位置。\n\n\nmatch()\n查找找到一个或多个正则表达式的匹配。\n\n\nrepeat()\n复制字符串指定次数，并将它们连接在一起返回。\n\n\nreplace()\n在字符串中查找匹配的子串，并替换与正则表达式匹配的子串。\n\n\nreplaceAll()\n在字符串中查找匹配的子串，并替换与正则表达式匹配的所有子串。\n\n\nsearch()\n查找与正则表达式相匹配的值。\n\n\nslice()\n提取字符串的片断，并在新的字符串中返回被提取的部分。\n\n\nsplit()\n把字符串分割为字符串数组。\n\n\nstartsWith()\n查看字符串是否以指定的子字符串开头。\n\n\nsubstr()\n从起始索引号提取字符串中指定数目的字符。\n\n\nsubstring()\n提取字符串中两个指定的索引号之间的字符。\n\n\ntoLowerCase()\n把字符串转换为小写。\n\n\ntoUpperCase()\n把字符串转换为大写。\n\n\ntrim()\n去除字符串两边的空白。\n\n\ntoLocaleLowerCase()\n根据本地主机的语言环境把字符串转换为小写。\n\n\ntoLocaleUpperCase()\n根据本地主机的语言环境把字符串转换为大写。\n\n\nvalueOf()\n返回某个字符串对象的原始值。\n\n\ntoString()\n返回一个字符串。\n\n\n5. 事件的绑定5.1 绑定事件的作用\n用于捕捉用户的操作, 并对之做出响应, 可通过定义函数, 并绑定操作实现\n\n5.2 常见事件\n鼠标事件\n\n\n\n\n属性\n描述\n\n\n\nonclick\n当用户点击某个对象时调用的事件句柄。\n\n\noncontextmenu\n在用户点击鼠标右键打开上下文菜单时触发\n\n\nondblclick\n当用户双击某个对象时调用的事件句柄。\n\n\nonmousedown\n鼠标按钮被按下。\n\n\nonmouseenter\n当鼠标指针移动到元素上时触发。\n\n\nonmouseleave\n当鼠标指针移出元素时触发\n\n\nonmousemove\n鼠标被移动。\n\n\nonmouseover\n鼠标移到某元素之上。\n\n\nonmouseout\n鼠标从某元素移开。\n\n\nonmouseup\n鼠标按键被松开。\n\n\n\n键盘事件\n\n\n\n\n属性\n描述\n\n\n\nonkeydown\n某个键盘按键被按下。\n\n\nonkeypress\n某个键盘按键被按下并松开。\n\n\nonkeyup\n某个键盘按键被松开。\n\n\n\n\n\n\n\n表单事件\n\n\n\n\n属性\n描述\n\n\n\nonblur\n元素失去焦点时触发\n\n\nonchange\n该事件在表单元素的内容改变时触发( &lt;input&gt;, &lt;keygen&gt;, &lt;select&gt;, 和 &lt;textarea&gt;)\n\n\nonfocus\n元素获取焦点时触发\n\n\nonfocusin\n元素即将获取焦点时触发\n\n\nonfocusout\n元素即将失去焦点时触发\n\n\noninput\n元素获取用户输入时触发\n\n\nonreset\n表单重置时触发\n\n\nonsearch\n用户向搜索域输入文本时触发 ( &lt;input&#x3D;”search”&gt;)\n\n\nonselect\n用户选取文本时触发 ( &lt;input&gt; 和 &lt;textarea&gt;)\n\n\nonsubmit\n表单提交时触发\n\n\n5.3 事件的绑定\n常规的绑定与触发\n\nfunction testDown1() &#123;console.log(&quot;键盘按键被按下了&quot;);&#125;function testDown2() &#123;console.log(&quot;键盘按键被按下了2&quot;);&#125;function downAndPress() &#123;console.log(&quot;某个按键被按下了并松开&quot;);&#125;function up() &#123;console.log(&quot;按键被松开&quot;);&#125;function loseFocus() &#123;console.log(&quot;即将失去焦点&quot;);&#125;function lostFocus() &#123;console.log(&quot;失去焦点&quot;);&#125;function change(input) &#123;console.log(&quot;表单内容被改变&quot;);console.log(input.value);&#125;\n\n&lt;input type=&quot;text&quot;            onblur=&quot;lostFocus()&quot;           onfocusout=&quot;loseFocus()&quot;           onkeydown=&quot;testDown1(), testDown2()&quot;           onkeypress=&quot;downAndPress()&quot;           onkeyup=&quot;up()&quot;           onchange=&quot;change(this)&quot;           &gt;\n\n\n特点\n\n\n一个事件能绑定多个函数\n\n一个函数能被多个事件同时绑定\n\n可以传递this对象, 代表当前元素\n\n即将失去焦点和失去焦点的两个事件的区别是前者会有事件冒泡 : 事件从最内层的目标元素向上传播到最外层的父元素\n\n通过DOM编程绑定\n\n\n通过指定ID找到元素, 再对应事件绑定触发事件\n\n\nwindow.onload=function()&#123;var in1 = document.getElementById(&quot;in1&quot;);// DOM编程绑定事件in1.onchange=change;&#125;function change() &#123;console.log(event.target.value);console.log(&quot;表单内容被改变&quot;);&#125;\n\n&lt;input type=&quot;text&quot; id=&quot;in1&quot;/&gt;\n5.4 事件的触发\n行为触发 : 就是最开始演示的如何绑定事件的方式, 发生行为时触发\n\n\nDOM编程触发\n\n\n通过代码触发, 执行某些行为的时候相当于触发了某些事件\n\n// 页面加载完毕事件, 加载完毕后加载事件window.onload=function()&#123;var in1 = document.getElementById(&quot;in1&quot;);// DOM编程绑定事件in1.onchange=change;var btn1 = document.getElementById(&quot;btn1&quot;);btn1.onclick=function() &#123;console.log(&quot;pressed&quot;);in1.onchange();&#125;&#125;function change() &#123;console.log(event.target.value);console.log(&quot;表单内容被改变&quot;);&#125;\n\n6. BOM编程6.1 什么是BOM\nBOM是Browser Object Model的简写, 是浏览器对象模型\n将浏览器抽象为一个对象, 从而可以得到这个对象的行为和属性\nBOM是一系列对象的集合, 是访问, 控制, 修改浏览器的属性和方法\n简单来说, BOM提供了可以控制和查看浏览器的一系列API\nBOM编程的对象结构\nwindow 顶层对象, 代表整个浏览器窗口\nlocation对象 window对象的属性之一,代表浏览器的地址栏\n\nhistory对象 window对象的属性之一,代表浏览器的访问历史\n\nscreen对象 window对象的属性之一,代表屏幕\n\nnavigator对象 window对象的属性之一,代表浏览器软件本身\n\ndocument对象 window对象的属性之一,代表浏览器窗口目前解析的html文档\n\nconsole对象 window对象的属性之一,代表浏览器开发者工具的控制台\n\nlocalStorage对象 window对象的属性之一,代表浏览器的本地数据持久化存储\n\nsessionStorage对象 window对象的属性之一,代表浏览器的本地数据会话级存储\n\n\n\n\n\n\n6.2 window对象的常见属性\n\n\n属性\n描述\n\n\n\nclosed\n返回窗口是否已被关闭。\n\n\ndefaultStatus\n设置或返回窗口状态栏中的默认文本。\n\n\ndocument\n对 Document 对象的只读引用。(请参阅对象)\n\n\nframes\n返回窗口中所有命名的框架。该集合是 Window 对象的数组，每个 Window 对象在窗口中含有一个框架。\n\n\nhistory\n对 History 对象的只读引用。请参数 History 对象。\n\n\ninnerHeight\n返回窗口的文档显示区的高度。\n\n\ninnerWidth\n返回窗口的文档显示区的宽度。\n\n\nlocalStorage\n在浏览器中存储 key&#x2F;value 对。没有过期时间。\n\n\nlength\n设置或返回窗口中的框架数量。\n\n\nlocation\n用于窗口或框架的 Location 对象。请参阅 Location 对象。\n\n\nname\n设置或返回窗口的名称。\n\n\nnavigator\n对 Navigator 对象的只读引用。请参数 Navigator 对象。\n\n\nopener\n返回对创建此窗口的窗口的引用。\n\n\nouterHeight\n返回窗口的外部高度，包含工具条与滚动条。\n\n\nouterWidth\n返回窗口的外部宽度，包含工具条与滚动条。\n\n\npageXOffset\n设置或返回当前页面相对于窗口显示区左上角的 X 位置。\n\n\npageYOffset\n设置或返回当前页面相对于窗口显示区左上角的 Y 位置。\n\n\nparent\n返回父窗口。\n\n\nscreen\n对 Screen 对象的只读引用。请参数 Screen 对象。\n\n\nscreenLeft\n返回相对于屏幕窗口的x坐标\n\n\nscreenTop\n返回相对于屏幕窗口的y坐标\n\n\nscreenX\n返回相对于屏幕窗口的x坐标\n\n\nsessionStorage\n在浏览器中存储 key&#x2F;value 对。 在关闭窗口或标签页之后将会删除这些数据。\n\n\nscreenY\n返回相对于屏幕窗口的y坐标\n\n\nself\n返回对当前窗口的引用。等价于 Window 属性。\n\n\nstatus\n设置窗口状态栏的文本。\n\n\ntop\n返回最顶层的父窗口。\n\n\n6.3 window对象的常见方法(了解)\n\n\n方法\n描述\n\n\n\nalert()\n显示带有一段消息和一个确认按钮的警告框。\n\n\natob()\n解码一个 base-64 编码的字符串。\n\n\nbtoa()\n创建一个 base-64 编码的字符串。\n\n\nblur()\n把键盘焦点从顶层窗口移开。\n\n\nclearInterval()\n取消由 setInterval() 设置的 timeout。\n\n\nclearTimeout()\n取消由 setTimeout() 方法设置的 timeout。\n\n\nclose()\n关闭浏览器窗口。\n\n\nconfirm()\n显示带有一段消息以及确认按钮和取消按钮的对话框。\n\n\ncreatePopup()\n创建一个 pop-up 窗口。\n\n\nfocus()\n把键盘焦点给予一个窗口。\n\n\ngetSelection()\n返回一个 Selection 对象，表示用户选择的文本范围或光标的当前位置。\n\n\ngetComputedStyle()\n获取指定元素的 CSS 样式。\n\n\nmatchMedia()\n该方法用来检查 media query 语句，它返回一个 MediaQueryList对象。\n\n\nmoveBy()\n可相对窗口的当前坐标把它移动指定的像素。\n\n\nmoveTo()\n把窗口的左上角移动到一个指定的坐标。\n\n\nopen()\n打开一个新的浏览器窗口或查找一个已命名的窗口。\n\n\nprint()\n打印当前窗口的内容。\n\n\nprompt()\n显示可提示用户输入的对话框。\n\n\nresizeBy()\n按照指定的像素调整窗口的大小。\n\n\nresizeTo()\n把窗口的大小调整到指定的宽度和高度。\n\n\nscroll()\n已废弃。 该方法已经使用了 scrollTo() 方法来替代。\n\n\nscrollBy()\n按照指定的像素值来滚动内容。\n\n\nscrollTo()\n把内容滚动到指定的坐标。\n\n\nsetInterval()\n按照指定的周期（以毫秒计）来调用函数或计算表达式。\n\n\nsetTimeout()\n在指定的毫秒数后调用函数或计算表达式。\n\n\nstop()\n停止页面载入。\n\n\npostMessage()\n安全地实现跨源通信。\n\n\n6.4 通过BOM编程控制浏览器行为演示\n三种弹窗方式\n\nfunction testAlert() &#123;window.alert(&quot;提示信息&quot;)&#125;function testConfirm() &#123;// 确认框var con = confirm(&quot;确认要删除吗&quot;);if (con) &#123;alert(&quot;删除成功&quot;);&#125; else &#123;alert(&quot;取消成功&quot;);&#125;&#125;function testPrompt() &#123;// 信息输入对话框var res = prompt(&quot;请输入信息&quot;);alert(&quot;你输入的是:&quot; + res);&#125;\n\n页面跳转\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;script&gt;function goAtguigu()&#123;var flag = confirm(&quot;即将跳转到尚硅谷官网, 你会丢失当前页面的信息, 确定吗&quot;);if (flag) &#123;// 通过BOM编程地址栏URL切换window.location.href=&quot;http://www.atguigu.com&quot;;&#125;&#125;&lt;/script&gt;&lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;input type=&quot;button&quot; id=&quot;btn1&quot; value=&quot;跳转到尚硅谷官网&quot; onclick=&quot;goAtguigu()&quot;/&gt;&lt;/body&gt;\n\n6.5 通过BOM编程实现会话级和持久级数据存储\n会话级数据 : 内存型数据, 是浏览器在内存上临时存储的数据, 浏览器关闭后, 就会失去\n持久级数据 : 磁盘型数据, 会一直保存, 浏览器关闭后, 仍然存在\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;script&gt;function saveItem()&#123;window.sessionStorage.setItem(&quot;sessionMsg&quot;, &quot;sessionValue&quot;);window.localStorage.setItem(&quot;localMsg&quot;, &quot;localItem&quot;);console.log(&quot;saved&quot;);&#125;function removeItem()&#123;window.sessionStorage.removeItem(&quot;sessionMsg&quot;);window.localStorage.removeItem(&quot;localMsg&quot;);console.log(&quot;Deleted&quot;);&#125;function readItem()&#123;console.log(&quot;read&quot;);console.log(&quot;session : &quot; + sessionStorage.getItem(&quot;sessionMsg&quot;));console.log(&quot;local : &quot; + localStorage.getItem(&quot;localMsg&quot;));&#125;&lt;/script&gt;&lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;button onclick=&quot;saveItem()&quot;&gt;存储&lt;/button&gt; &lt;br&gt;&lt;button onclick=&quot;removeItem()&quot;&gt;删除&lt;/button&gt; &lt;br&gt;&lt;button onclick=&quot;readItem()&quot;&gt;读取&lt;/button&gt; &lt;br&gt;&lt;/body&gt;&lt;/html&gt;\n\n7. DOM编程7.1 DOM编程简介\nDOM指的就是BOM中的document对象, 通过这个对象, 我们能获取到传进来的html文本中的各个结点\nJS可以根据HTML的结构树, 生成document的节点树, 从而实现对页面中的各个节点的精准操控\n\n7.2 获取页面元素的几种方式7.2.1 在整个文档范围内查找元素结点\n\n\n功能\nAPI\n返回值\n\n\n\n根据id值查询\ndocument.getElementById(“id值”)\n一个具体的元素节\n\n\n根据标签名查询\ndocument.getElementsByTagName(“标签名”)\n元素节点数组\n\n\n根据name属性值查询\ndocument.getElementsByName(“name值”)\n元素节点数组\n\n\n根据类名查询\ndocument.getElementsByClassName(“类名”)\n元素节点数组\n\n\n7.2.2 在具体元素节点范围内查找子节点\n\n\n功能\nAPI\n返回值\n\n\n\n查找子标签\nelement.children\n返回子标签数组\n\n\n查找第一个子标签\nelement.firstElementChild\n标签对象\n\n\n查找最后一个子标签\nelement.lastElementChild\n节点对象\n\n\n7.2.3 查找指定子元素节点的父节点\n\n\n功能\nAPI\n返回值\n\n\n\n查找指定元素节点的父标签\nelement.parentElement\n标签对象\n\n\n7.2.4  查找指定元素节点的兄弟节点\n\n\n功能\nAPI\n返回值\n\n\n\n查找前一个兄弟标签\nnode.previousElementSibling\n标签对象\n\n\n查找后一个兄弟标签\nnode.nextElementSibling\n标签对象\n\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;&lt;script&gt;// 获取元素-直接获取function fun1() &#123;var ele1 = document.getElementById(&quot;username&quot;);console.log(ele1);&#125;function fun2()&#123;var ele1 = document.getElementsByTagName(&quot;input&quot;)for (var i in ele1) &#123;console.log(ele1[i])&#125;&#125;function fun3()&#123;var ele1 = document.getElementsByName(&quot;aaa&quot;)for (var i in ele1) &#123;console.log(ele1[i])&#125;&#125;function fun4()&#123;var ele1 = document.getElementsByClassName(&quot;b&quot;)for (var i in ele1) &#123;console.log(ele1[i])&#125;&#125;function fun5()&#123;// 获取父元素的所有子元素var div01 = document.getElementById(&quot;div01&quot;)var child = div01.childrenfor (var i in child) &#123;console.log(child[i])&#125;// 获取第一个子元素console.log(div01.firstElementChild)// 获取最后一个子元素console.log(div01.lastElementChild)&#125;function fun6()&#123;// 通过子元素获取父元素var child = document.getElementById(&quot;username&quot;)var f = child.parentElementconsole.log(f)&#125;function fun7()&#123;// 获取子元素的兄弟元素var child = document.getElementById(&quot;username&quot;)console.log(child.previousElementSibling)console.log(child.nextElementSibling)&#125;&lt;/script&gt;&lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=&quot;div01&quot;&gt;&lt;input type=&quot;text&quot; class=&quot;a&quot; id=&quot;username&quot; name=&quot;aaa&quot;/&gt;&lt;input type=&quot;text&quot; class=&quot;b&quot; id=&quot;password&quot; name=&quot;aaa&quot;/&gt;&lt;input type=&quot;text&quot; class=&quot;a&quot; id=&quot;email&quot;/&gt;&lt;input type=&quot;text&quot; class=&quot;b&quot; id=&quot;address&quot;/&gt;&lt;/div&gt;&lt;input type=&quot;text&quot; class=&quot;a&quot;/&gt;&lt;br&gt;&lt;hr&gt;&lt;input type=&quot;button&quot; value=&quot;通过父元素获取子元素&quot; onclick=&quot;fun5()&quot; id=&quot;btn05&quot;/&gt;&lt;input type=&quot;button&quot; value=&quot;通过子元素获取父元素&quot; onclick=&quot;fun6()&quot; id=&quot;btn06&quot;/&gt;&lt;input type=&quot;button&quot; value=&quot;通过当前元素获取兄弟元素&quot; onclick=&quot;fun7()&quot; id=&quot;btn07&quot;/&gt;&lt;hr&gt;&lt;input type=&quot;button&quot; value=&quot;根据id获取指定元素&quot; onclick=&quot;fun1()&quot; id=&quot;btn01&quot;/&gt;&lt;input type=&quot;button&quot; value=&quot;根据标签名获取多个元素&quot; onclick=&quot;fun2()&quot; id=&quot;btn02&quot;/&gt;&lt;input type=&quot;button&quot; value=&quot;根据name属性值获取多个元素&quot; onclick=&quot;fun3()&quot; id=&quot;btn03&quot;/&gt;&lt;input type=&quot;button&quot; value=&quot;根据class属性值获得多个元素&quot; onclick=&quot;fun4()&quot; id=&quot;btn04&quot;/&gt;&lt;/body&gt;&lt;/html&gt;\n\n7.3 操作元素属性值7.3.1 属性操作\n读取属性值 &#x3D;&gt; 元素对象.属性名\n修改属性值 &#x3D;&gt; 元素对象.属性名 &#x3D; 新的属性值\n\n7.3.2 内部文本操作\n获取或者设置标签体的文本内容 &#x3D;&gt; element.innerText\n获取或者设置标签体的内容 &#x3D;&gt; element.innerHTML\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;&lt;script&gt;function changeAttribute()&#123;// 操作属性var in1 = document.getElementById(&quot;in1&quot;)console.log(in1.type)console.log(in1.value)in1.type = &quot;button&quot;in1.value = &quot;hi&quot;&#125;function changeStyle()&#123;// 操作元素的样式var in1 = document.getElementById(&quot;in1&quot;)in1.style.color = &quot;green&quot;in1.style.fontSize = &quot;45px&quot;&#125;function changeText()&#123;// 修改文本var div1 = document.getElementById(&quot;div01&quot;)console.log(div1.innerText)console.log(div1.innerHTML)div1.innerHTML = &quot;&lt;h1&gt;hi&lt;/h1&gt;&quot;&#125;&lt;/script&gt;&lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;input id=&quot;in1&quot; type=&quot;text&quot; value=&quot;hello&quot;&gt;&lt;div id=&quot;div01&quot;&gt;hello&lt;/div&gt;&lt;hr&gt;&lt;button onclick=&quot;changeAttribute()&quot;&gt;操作属性&lt;/button&gt;&lt;button onclick=&quot;changeStyle()&quot;&gt;操作样式&lt;/button&gt;&lt;button onclick=&quot;changeText()&quot;&gt;操作文本&lt;/button&gt;&lt;/body&gt;&lt;/html&gt;\n7.4 增删元素7.4.1 对页面的元素进行增删操作\n\n\nAPI\n功能\n\n\n\ndocument.createElement(“标签名”)\n创建元素节点并返回，但不会自动添加到文档中\n\n\ndocument.createTextNode(“文本值”)\n创建文本节点并返回，但不会自动添加到文档中\n\n\nelement.appendChild(ele)\n将ele添加到element所有子节点后面\n\n\nparentEle.insertBefore(newEle,targetEle)\n将newEle插入到targetEle前面\n\n\nparentEle.replaceChild(newEle, oldEle)\n用新节点替换原有的旧子节点\n\n\nelement.remove()\n删除某个标签\n\n\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;&lt;script&gt;function addCs()&#123;// 添加元素var csli = document.createElement(&quot;li&quot;)csli.id = &quot;cs&quot;csli.innerText = &quot;长沙&quot;// 将元素添加到父元素末尾var cityul = document.getElementById(&quot;city&quot;)        cityul.appendChild(csli)    &#125;    function addCsBeforeSz()&#123;        // 在某个元素前面追加子元素        // 添加元素        var csli = document.createElement(&quot;li&quot;)        csli.id = &quot;cs&quot;        csli.innerText = &quot;长沙&quot;        // 在指定元素前面添加元素        var cityul = document.getElementById(&quot;city&quot;)        var szli = document.getElementById(&quot;sz&quot;)        cityul.insertBefore(csli,szli)    &#125;    function replaceSz()&#123;        // 在某个元素前面追加子元素        var csli = document.createElement(&quot;li&quot;)        csli.id = &quot;cs&quot;        csli.innerText = &quot;长沙&quot;        // 替换子元素        var cityul = document.getElementById(&quot;city&quot;)        var szli = document.getElementById(&quot;sz&quot;)        cityul.replaceChild(csli,szli)    &#125;    function removeSz()&#123;        // 删除子元素        var cityul = document.getElementById(&quot;city&quot;)        var szli = document.getElementById(&quot;sz&quot;)        cityul.removeChild(szli)    &#125;    function clearCity()&#123;        // 清空所有        var cityul = document.getElementById(&quot;city&quot;)        cityul.innerHTML = &quot;&quot;    &#125;    &lt;/script&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;ul id=&quot;city&quot;&gt;        &lt;li id=&quot;bj&quot;&gt;北京&lt;/li&gt;        &lt;li id=&quot;sh&quot;&gt;上海&lt;/li&gt;        &lt;li id=&quot;sz&quot;&gt;深圳&lt;/li&gt;        &lt;li id=&quot;gz&quot;&gt;广州&lt;/li&gt;    &lt;/ul&gt;    &lt;hr&gt;    &lt;!-- 目标1 在城市列表的最后添加一个子标签  &lt;li id=&quot;cs&quot;&gt;长沙&lt;/li&gt;  --&gt;    &lt;button onclick=&quot;addCs()&quot;&gt;增加长沙&lt;/button&gt;    &lt;!-- 目标2 在城市列表的深圳前添加一个子标签  &lt;li id=&quot;cs&quot;&gt;长沙&lt;/li&gt;  --&gt;    &lt;button onclick=&quot;addCsBeforeSz()&quot;&gt;在深圳前插入长沙&lt;/button&gt;    &lt;!-- 目标3  将城市列表的深圳替换为  &lt;li id=&quot;cs&quot;&gt;长沙&lt;/li&gt;  --&gt;    &lt;button onclick=&quot;replaceSz()&quot;&gt;替换深圳&lt;/button&gt;    &lt;!-- 目标4  将城市列表删除深圳  --&gt;    &lt;button onclick=&quot;removeSz()&quot;&gt;删除深圳&lt;/button&gt;    &lt;!-- 目标5  清空城市列表  --&gt;    &lt;button onclick=&quot;clearCity()&quot;&gt;清空&lt;/button&gt;&lt;/body&gt;&lt;/html&gt;\n\n8. 正则表达式8.1 正则表达式简介\n用于匹配字符串以执行检索, 验证, 替换等操作, 执行逻辑是匹配定义格式的字符串\n\n\n语法\n\nvar patt=new RegExp(pattern,modifiers);或者更简单的方式:var patt=/pattern/modifiers; // pattern :定义的匹配格式, modifiers :定义的修饰符\n\n\n修饰符\n\n\n\n\n修饰符\n描述\n\n\n\ni\n执行对大小写不敏感的匹配。\n\n\ng\n执行全局匹配（查找所有匹配而非在找到第一个匹配后停止）。\n\n\nm\n执行多行匹配。\n\n\n\n方括号\n\n\n\n\n表达式\n描述\n\n\n\n[abc]\n查找方括号之间的任何字符。\n\n\n[^abc]\n查找任何不在方括号之间的字符。\n\n\n[0-9]\n查找任何从 0 至 9 的数字。\n\n\n[a-z]\n查找任何从小写 a 到小写 z 的字符。\n\n\n[A-Z]\n查找任何从大写 A 到大写 Z 的字符。\n\n\n[A-z]\n查找任何从大写 A 到小写 z 的字符。\n\n\n[adgk]\n查找给定集合内的任何字符。\n\n\n[^adgk]\n查找给定集合外的任何字符。\n\n\n(red|blue|green)\n查找任何指定的选项。\n\n\n\n元字符\n\n\n\n\n元字符\n描述\n\n\n\n.\n查找单个字符，除了换行和行结束符。\n\n\n\\w\n查找数字、字母及下划线。\n\n\n\\W\n查找非单词字符。\n\n\n\\d\n查找数字。\n\n\n\\D\n查找非数字字符。\n\n\n\\s\n查找空白字符。\n\n\n\\S\n查找非空白字符。\n\n\n\\b\n匹配单词边界。\n\n\n\\B\n匹配非单词边界。\n\n\n\\0\n查找 NULL 字符。\n\n\n\\n\n查找换行符。\n\n\n\\f\n查找换页符。\n\n\n\\r\n查找回车符。\n\n\n\\t\n查找制表符。\n\n\n\\v\n查找垂直制表符。\n\n\n\\xxx\n查找以八进制数 xxx 规定的字符。\n\n\n\\xdd\n查找以十六进制数 dd 规定的字符。\n\n\n\\uxxxx\n查找以十六进制数 xxxx 规定的 Unicode 字符。\n\n\n\n量词\n\n\n\n\n量词\n描述\n\n\n\nn+\n匹配任何包含至少一个 n 的字符串。例如，&#x2F;a+&#x2F; 匹配 “candy” 中的 “a”，”caaaaaaandy” 中所有的 “a”。\n\n\nn*\n匹配任何包含零个或多个 n 的字符串。例如，&#x2F;bo*&#x2F; 匹配 “A ghost booooed” 中的 “boooo”，”A bird warbled” 中的 “b”，但是不匹配 “A goat grunted”。\n\n\nn?\n匹配任何包含零个或一个 n 的字符串。例如，&#x2F;e?le?&#x2F; 匹配 “angel” 中的 “el”，”angle” 中的 “le”。\n\n\nn{X}\n匹配包含 X 个 n 的序列的字符串。例如，&#x2F;a{2}&#x2F; 不匹配 “candy,” 中的 “a”，但是匹配 “caandy,” 中的两个 “a”，且匹配 “caaandy.” 中的前两个 “a”。\n\n\nn{X,}\nX 是一个正整数。前面的模式 n 连续出现至少 X 次时匹配。例如，&#x2F;a{2,}&#x2F; 不匹配 “candy” 中的 “a”，但是匹配 “caandy” 和 “caaaaaaandy.” 中所有的 “a”。\n\n\nn{X,Y}\nX 和 Y 为正整数。前面的模式 n 连续出现至少 X 次，至多 Y 次时匹配。例如，&#x2F;a{1,3}&#x2F; 不匹配 “cndy”，匹配 “candy,” 中的 “a”，”caandy,” 中的两个 “a”，匹配 “caaaaaaandy” 中的前面三个 “a”。注意，当匹配 “caaaaaaandy” 时，即使原始字符串拥有更多的 “a”，匹配项也是 “aaa”。\n\n\nn$\n匹配任何结尾为 n 的字符串。\n\n\n^n\n匹配任何开头为 n 的字符串。\n\n\n?&#x3D;n\n匹配任何其后紧接指定字符串 n 的字符串。\n\n\n?!n\n匹配任何其后没有紧接指定字符串 n 的字符串。\n\n\n\nRegExp对象方法\n\n\n\n\n方法\n描述\n\n\n\ncompile\n在 1.5 版本中已废弃。 编译正则表达式。\n\n\nexec\n检索字符串中指定的值。返回找到的值，并确定其位置。\n\n\ntest\n检索字符串中指定的值。返回 true 或 false。\n\n\ntoString\n返回正则表达式的字符串。\n\n\n\n支持正则的String的方法\n\n\n\n\n方法\n描述\n\n\n\nsearch\n检索与正则表达式相匹配的值。\n\n\nmatch\n找到一个或多个正则表达式的匹配。\n\n\nreplace\n替换与正则表达式匹配的子串。\n\n\nsplit\n把字符串分割为字符串数组。\n\n\n8.2 正则表带式体验8.2.1 验证注意：这里是使用正则表达式对象来调用方法。\n// 创建一个最简单的正则表达式对象var reg = /o/;// 创建一个字符串对象作为目标字符串var str = &#x27;Hello World!&#x27;;// 调用正则表达式对象的test()方法验证目标字符串是否满足我们指定的这个模式，返回结果trueconsole.log(&quot;/o/.test(&#x27;Hello World!&#x27;)=&quot;+reg.test(str));\n\n8.2.2 匹配// 创建一个最简单的正则表达式对象var reg = /o/;// 创建一个字符串对象作为目标字符串var str = &#x27;Hello World!&#x27;;// 在目标字符串中查找匹配的字符，返回匹配结果组成的数组var resultArr = str.match(reg);// 数组长度为1console.log(&quot;resultArr.length=&quot;+resultArr.length);// 数组内容是oconsole.log(&quot;resultArr[0]=&quot;+resultArr[0]);\n\n8.2.3 替换注意：这里是使用字符串对象来调用方法。\n// 创建一个最简单的正则表达式对象var reg = /o/;// 创建一个字符串对象作为目标字符串var str = &#x27;Hello World!&#x27;;var newStr = str.replace(reg,&#x27;@&#x27;);// 只有第一个o被替换了，说明我们这个正则表达式只能匹配第一个满足的字符串console.log(&quot;str.replace(reg)=&quot;+newStr);//Hell@ World!// 原字符串并没有变化，只是返回了一个新字符串console.log(&quot;str=&quot;+str);//str=Hello World!\n\n8.2.4  全文查找如果不使用g对正则表达式对象进行修饰，则使用正则表达式进行查找时，仅返回第一个匹配；使用g后，返回所有匹配。\n// 目标字符串var targetStr = &#x27;Hello World!&#x27;;// 没有使用全局匹配的正则表达式var reg = /[A-Z]/;// 获取全部匹配var resultArr = targetStr.match(reg);// 数组长度为1console.log(&quot;resultArr.length=&quot;+resultArr.length);// 遍历数组，发现只能得到&#x27;H&#x27;for(var i = 0; i &lt; resultArr.length; i++)&#123;  console.log(&quot;resultArr[&quot;+i+&quot;]=&quot;+resultArr[i]);&#125;\n\n对比\n// 目标字符串var targetStr = &#x27;Hello World!&#x27;;// 使用了全局匹配的正则表达式var reg = /[A-Z]/g;// 获取全部匹配var resultArr = targetStr.match(reg);// 数组长度为2console.log(&quot;resultArr.length=&quot;+resultArr.length);// 遍历数组，发现可以获取到“H”和“W”for(var i = 0; i &lt; resultArr.length; i++)&#123;  console.log(&quot;resultArr[&quot;+i+&quot;]=&quot;+resultArr[i]);&#125;\n\n8.2.5 忽略大小写//目标字符串var targetStr = &#x27;Hello WORLD!&#x27;;//没有使用忽略大小写的正则表达式var reg = /o/g;//获取全部匹配var resultArr = targetStr.match(reg);//数组长度为1console.log(&quot;resultArr.length=&quot;+resultArr.length);//遍历数组，仅得到&#x27;o&#x27;for(var i = 0; i &lt; resultArr.length; i++)&#123;  console.log(&quot;resultArr[&quot;+i+&quot;]=&quot;+resultArr[i]);&#125;\n\n对比\n//目标字符串var targetStr = &#x27;Hello WORLD!&#x27;;//使用了忽略大小写的正则表达式var reg = /o/gi;//获取全部匹配var resultArr = targetStr.match(reg);//数组长度为2console.log(&quot;resultArr.length=&quot;+resultArr.length);//遍历数组，得到&#x27;o&#x27;和&#x27;O&#x27;for(var i = 0; i &lt; resultArr.length; i++)&#123;  console.log(&quot;resultArr[&quot;+i+&quot;]=&quot;+resultArr[i]);&#125;\n\n8.2.6 元字符使用var str01 = &#x27;I love Java&#x27;;var str02 = &#x27;Java love me&#x27;;// 匹配以Java开头var reg = /^Java/g;console.log(&#x27;reg.test(str01)=&#x27;+reg.test(str01)); // falseconsole.log(&quot;&lt;br /&gt;&quot;);console.log(&#x27;reg.test(str02)=&#x27;+reg.test(str02)); // true\n\nvar str01 = &#x27;I love Java&#x27;;var str02 = &#x27;Java love me&#x27;;// 匹配以Java结尾var reg = /Java$/g;console.log(&#x27;reg.test(str01)=&#x27;+reg.test(str01)); // trueconsole.log(&quot;&lt;br /&gt;&quot;);console.log(&#x27;reg.test(str02)=&#x27;+reg.test(str02)); // false\n\n8.2.7 字符集合的使用//n位数字的正则var targetStr=&quot;123456789&quot;;var reg=/^[0-9]&#123;0,&#125;$/;//或者 ： var reg=/^\\d*$/;var b = reg.test(targetStr);//true\n\n//数字+字母+下划线，6-16位var targetStr=&quot;HelloWorld&quot;;var reg=/^[a-z0-9A-Z_]&#123;6,16&#125;$/;var b = reg.test(targetStr);//true\n\n8.3  常用正则表达式\n\n\n需求\n正则表达式\n\n\n\n用户名\n&#x2F;^[a-zA-Z ][a-zA-Z-0-9]{5,9}$&#x2F;\n\n\n密码\n&#x2F;^[a-zA-Z0-9 _-@#&amp; *]{6,12}$&#x2F;\n\n\n前后空格\n&#x2F;^\\s+|\\s+$&#x2F;g\n\n\n电子邮箱\n&#x2F;^[a-zA-Z0-9 _.-]+@([a-zA-Z0-9-]+[.]{1})+[a-zA-Z]+$&#x2F;\n\n\n\n解释说明\n用户名: 首个字符需要是字母, 后面的字符有5-9个, 可以有字母和数字\n密码: 字符有字母数字, _ - @ # &amp; * , 6-12位的密码\n前后空格: 匹配任意数量的空白字符开头或者任意数量的空白字符结尾\n电子邮箱, 同上, 不做额外过多解释\n\n\n\n","tags":["Java","frontend","JavaWeb","JS"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/Tomcat/","content":"^Tomcat\nTomcat1. Tomcat的作用\n一个服务器软件, 用于部署一个完整的Web应用\n\n2. Tomcat服务器2.1 简介\nTomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun 和其他一些公司及个人共同开发而成。最新的Servlet 和JSP 规范总是能在Tomcat 中得到体现，因为Tomcat 技术先进、性能稳定，而且免费，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。\n\n2.2 安装\n版本\n\n\n版本：企业用的比较广泛的是8.0和9.0,目前比较新正式发布版本是Tomcat10.0, Tomcat11仍然处于测试阶段。\n10和之前的版本使用的API接口不同, 所以8和9之间是可以移植的, 但是10和之前的无法相互移植, 虽然移植Tomcat是一件很蠢的事情\nJAVAEE 版本和Servlet版本号对应关系 Jakarta EE Releases\n\n\n\n\nSERVLET VERSION\nEE VERSION\n\n\n\n6.1\nJakarta EE ?\n\n\n6.0\nJakarta EE 10\n\n\n5.0\nJakarta EE 9&#x2F;9.1\n\n\n4.0\nJAVA EE 8\n\n\n3.1\nJAVA EE 7\n\n\n3.1\nJAVA EE 7\n\n\n3.0\nJAVAEE 6\n\n\n\nTomcat 版本和Servlet版本之间的对应关系\n\n\n\n\nSERVLET VERSION\nTOMCAT VERSION\nJDK VERSION\n\n\n\n6.1\n11.0.x\n17 and later\n\n\n6.0\n10.1.x\n11 and later\n\n\n5.0\n10.0.x (superseded)\n8 and later\n\n\n4.0\n9.0.x\n8 and later\n\n\n3.1\n8.5.x\n7 and later\n\n\n3.1\n8.0.x (superseded)\n7 and later\n\n\n3.0\n7.0.x (archived)\n6 and later (7 and later for WebSocket)\n\n\n\n下载\n\n\nTomcat官方网站：http://tomcat.apache.org/\n安装\n\n\n\n\n正确安装JDK并配置JAVA_HOME(以JDK17为例 https://injdk.cn中可以下载各种版本的JDK)\n解压tomcat到非中文无空格目录\n点击bin&#x2F;startup.bat启动\n处理dos窗口日志中文乱码问题: 修改conf&#x2F;logging.properties,将所有的UTF-8修改为GBK\n\n3. Tomcat目录及测试\nbin：该目录下存放的是二进制可执行文件，如果是安装版，那么这个目录下会有两个exe文件：tomcat10.exe、tomcat10w.exe，前者是在控制台下启动Tomcat，后者是弹出GUI窗口启动Tomcat；如果是解压版，那么会有startup.bat和shutdown.bat文件，startup.bat用来启动Tomcat，但需要先配置JAVA_HOME环境变量才能启动，shutdawn.bat用来停止Tomcat；\n\nconf：这是一个非常非常重要的目录，这个目录下有四个最为重要的文件：\n\nserver.xml：配置整个服务器信息。例如修改端口号。默认HTTP请求的端口号是：8080\n\ntomcat-users.xml：存储tomcat用户的文件，这里保存的是tomcat的用户名及密码，以及用户的角色信息。可以按着该文件中的注释信息添加tomcat用户，然后就可以在Tomcat主页中进入Tomcat Manager页面了；\n  &lt;tomcat-users xmlns=&quot;http://tomcat.apache.org/xml&quot;   xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;   xsi:schemaLocation=&quot;http://tomcat.apache.org/xml tomcat-users.xsd&quot;   version=&quot;1.0&quot;&gt;\t     \t&lt;role rolename=&quot;admin-gui&quot;/&gt;     \t&lt;role rolename=&quot;admin-script&quot;/&gt;     \t&lt;role rolename=&quot;manager-gui&quot;/&gt;     \t&lt;role rolename=&quot;manager-script&quot;/&gt;     \t&lt;role rolename=&quot;manager-jmx&quot;/&gt;     \t&lt;role rolename=&quot;manager-status&quot;/&gt;     \t&lt;user \tusername=&quot;admin&quot;      \t\t\tpassword=&quot;admin&quot;      \t\t\troles=&quot;admin-gui,admin-script,manager-gui,manager-script,manager-jmx,manager-status&quot;     \t/&gt; &lt;/tomcat-users&gt;\n  web.xml：部署描述符文件，这个文件中注册了很多MIME类型，即文档类型。这些MIME类型是客户端与服务器之间说明文档类型的，如用户请求一个html网页，那么服务器还会告诉客户端浏览器响应的文档是text&#x2F;html类型的，这就是一个MIME类型。客户端浏览器通过这个MIME类型就知道如何处理它了。当然是在浏览器中显示这个html文件了。但如果服务器响应的是一个exe文件，那么浏览器就不可能显示它，而是应该弹出下载窗口才对。MIME就是用来说明文档的内容是什么类型的！\n\ncontext.xml：对所有应用的统一配置，通常我们不会去配置它。\n\n\n\nlib：Tomcat的类库，里面是一大堆jar文件。如果需要添加Tomcat依赖的jar文件，可以把它放到这个目录中，当然也可以把应用依赖的jar文件放到这个目录中，这个目录中的jar所有项目都可以共享之，但这样你的应用放到其他Tomcat下时就不能再共享这个目录下的jar包了，所以建议只把Tomcat需要的jar包放到这个目录下；\n\nlogs：这个目录中都是日志文件，记录了Tomcat启动和关闭的信息，如果启动Tomcat时有错误，那么异常也会记录在日志文件中。\n\ntemp：存放Tomcat的临时文件，这个目录下的东西可以在停止Tomcat后删除！\n\nwebapps：存放web项目的目录，其中每个文件夹都是一个项目；如果这个目录下已经存在了目录，那么都是tomcat自带的项目。其中ROOT是一个特殊的项目，在地址栏中访问：http://127.0.0.1:8080，没有给出项目目录时，对应的就是ROOT项目.http://localhost:8080/examples，进入示例项目。其中examples”就是项目名，即文件夹的名字。\n\nwork：运行时生成的文件，最终运行的文件都在这里。通过webapps中的项目生成的！可以把这个目录下的内容删除，再次运行时会生再次生成work目录。当客户端用户访问一个JSP文件时，Tomcat会通过JSP生成Java文件，然后再编译Java文件生成class文件，生成的java和class文件都会存放到这个目录下。\n\nLICENSE：许可证。\n\nNOTICE：说明文件。\n\n\n4. WEB项目的标准结构\n一个标准的可以用于发布的WEB项目标准结构如下\n\n![[1.png]]\n\napp  本应用根目录\nstatic 非必要目录,约定俗成的名字,一般在此处放静态资源 ( css  js  img)\nWEB-INF  必要目录,必须叫WEB-INF,受保护的资源目录,浏览器通过url不可以直接访问的目录\nclasses     必要目录,src下源代码,配置文件,编译后会在该目录下,web项目中如果没有源码,则该目录不会出现\nlib             必要目录,项目依赖的jar编译后会出现在该目录下,web项目要是没有依赖任何jar,则该目录不会出现\nweb.xml   必要文件,web项目的基本配置文件. 较新的版本中可以没有该文件,但是学习过程中还是需要该文件\n\n\n\n\nindex.html  非必要文件,index.html&#x2F;index.htm&#x2F;index.jsp为默认的欢迎页^  Tomcat部署\n\n\n\n5. IDEA部署-运行项目2.6.1 IDEA关联本地Tomcat\n可以在创建项目前设置本地tomcat,也可以在打开某个项目的状态下找到settings\n\n![[images&#x2F;1681457611053.png]]\n\n找到 Build,Execution,Eeployment下的Application Servers ,找到+号\n\n![[images&#x2F;1681457711914.png]]\n\n选择Tomcat Server\n\n![[images&#x2F;1681457800708.png]]\n\n选择tomcat的安装目录\n\n![[images&#x2F;1681457879937.png]]\n\n点击ok\n\n![[images&#x2F;1681457921094.png]]\n\n关联完毕\n\n![[images&#x2F;1681458031957.png]]\n2.6.2 IDEA创建web工程\n推荐先创建一个空项目,这样可以在一个空项目下同时存在多个modules,不用后续来回切换之前的项目,当然也可以忽略此步直接创建web项目\n\n![[images&#x2F;1681458194939.png]]![[images&#x2F;1681458273381.png]]\n\n检查项目的SDK,语法版本,以及项目编译后的输出目录\n\n![[images&#x2F;1681458343921.png]]\n![[images&#x2F;1681458393871.png]]\n\n先创建一个普通的JAVA项目\n\n![[images&#x2F;1681458485837.png]]\n\n检查各项信息是否填写有误\n\n![[images&#x2F;1681458599545.png]]\n\n创建完毕后,为项目添加Tomcat依赖\n\n![[images&#x2F;1681458857830.png]]\n![[images&#x2F;1681458897017.png]]\n![[images&#x2F;1681458939400.png]]\n\n选择modules,添加  framework support\n\n![[images&#x2F;1681458672258.png]]\n\n选择Web Application 注意Version,勾选  Create web.xml\n\n![[images&#x2F;1681459007273.png]]\n\n删除index.jsp ,替换为 index.html\n\n![[images&#x2F;1681459080873.png]]\n![[images&#x2F;1681459147133.png]]\n\n处理配置文件\n\n\n在工程下创建resources目录,专门用于存放配置文件(都放在src下也行,单独存放可以尽量避免文件集中存放造成的混乱)\n标记目录为资源目录,不标记的话则该目录不参与编译\n\n![[images&#x2F;1681461443278.png]]\n\n标记完成后,显示效果如下\n\n![[images&#x2F;1681461513406.png]]\n\n处理依赖jar包问题\n\n\n在WEB-INF下创建lib目录\n必须在WEB-INF下,且目录名必须叫lib!!!\n复制jar文件进入lib目录\n\n![[images&#x2F;1681461788411.png]]\n\n将lib目录添加为当前项目的依赖,后续可以用maven统一解决\n\n![[images&#x2F;1681461846178.png]]\n![[images&#x2F;1681461881121.png]]\n\n环境级别推荐选择module 级别,降低对其他项目的影响,name可以空着不写\n\n![[images&#x2F;1681461923761.png]]\n\n查看当前项目有那些环境依赖\n\n![[images&#x2F;1681463867295.png]]\n![[images&#x2F;1681462179671.png]]\n\n在此位置,可以通过-号解除依赖\n\n![[images&#x2F;1681462247973.png]]\n2.6.3 IDEA部署-运行web项目\n检查idea是否识别modules为web项目并存在将项目构建成发布结构的配置\n\n\n就是检查工程目录下,web目录有没有特殊的识别标记\n\n![[images&#x2F;1681462523901.png]]\n\n以及artifacts下,有没有对应 _war_exploded,如果没有,就点击+号添加\n\n![[images&#x2F;1681462584524.png]]\n\n点击向下箭头,出现 Edit Configurations选项\n\n![[images&#x2F;1681462645070.png]]\n\n出现运行配置界面\n\n![[images&#x2F;1681462710108.png]]\n\n点击+号,添加本地tomcat服务器\n\n![[images&#x2F;1681462754191.png]]\n\n因为IDEA 只关联了一个Tomcat,红色部分就只有一个Tomcat可选\n\n![[images&#x2F;1681462798933.png]]\n\n选择Deployment,通过+添加要部署到Tomcat中的artifact\n\n![[images&#x2F;1681463011546.png]]\n\napplicationContext中是默认的项目上下文路径,也就是url中需要输入的路径,这里可以自己定义,可以和工程名称不一样,也可以不写,但是要保留&#x2F;,我们这里暂时就用默认的\n\n![[images&#x2F;1681463049807.png]]\n\n点击apply 应用后,回到Server部分. After Launch是配置启动成功后,是否默认自动打开浏览器并输入URL中的地址,HTTP port是Http连接器目前占用的端口号\n\n![[images&#x2F;1681463212587.png]]\n\n点击OK后,启动项目,访问测试\n\n\n绿色箭头是正常运行模式\n“小虫子”是debug运行模式\n\n![[images&#x2F;1681463386274.png]]\n\n点击后,查看日志状态是否有异常\n\n![[images&#x2F;1681463361795.png]]\n\n浏览器自动打开并自动访问了index.html欢迎页\n\n![[images&#x2F;1681520068936.png]]\n\n工程结构和可以发布的项目结构之间的目录对应关系\n\n![[images&#x2F;1681464081226.png]]\n\nIDEA部署并运行项目的原理\n\n\nidea并没有直接进将编译好的项目放入tomcat的webapps中\nidea根据关联的tomcat,创建了一个tomcat副本,将项目部署到了这个副本中\nidea的tomcat副本在C:\\用户\\当前用户\\AppData\\Local\\JetBrains\\IntelliJIdea2022.2\\tomcat\\中\nidea的tomcat副本并不是一个完整的tomcat,副本里只是准备了和当前项目相关的配置文件而已\nidea启动tomcat时,是让本地tomcat程序按照tomcat副本里的配置文件运行\nidea的tomcat副本部署项目的模式是通过conf&#x2F;Catalina&#x2F;localhost&#x2F;*.xml配置文件的形式实现项目部署的\n\n![[images&#x2F;1681521240438.png]]\n","tags":["Java","frontend","JavaWeb","Tomcat","Deployment"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/XML/","content":"XML\nXML是EXtensible Markup Language的缩写, 翻译过来就是课拓展标记语言, 基本语法也是标签\n\n\nHTML实际上是XML加上HTML的约束后形成的语言, 算是XML的子集\nXML可以通过添加约束的方式, 规定配置文件中可以写什么和怎么写\n\n1. 常见配置文件类型\nproperties文件, 例如druid的连接池使用的就是properties文件作为配置文件\nXML文件, 如Tomcat\nYAML文件, 如SprintBoot\njson文件,  常用来做文件传输\n\n1.1 properties配置文件\n示例\n\natguigu.jdbc.url=jdbc:mysql://localhost:3306/atguiguatguigu.jdbc.driver=com.mysql.cj.jdbc.Driveratguigu.jdbc.username=rootatguigu.jdbc.password=root\n\n语法规范\n\n\n由键值对组成\n连接符是&#x3D;号\n每一行必须顶格写\n\n1.2 XML文件\n示例\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;students&gt;    &lt;student&gt;        &lt;name id = &quot;1&quot;&gt;张&lt;/name&gt;        &lt;aeg&gt;18&lt;/aeg&gt;    &lt;/student&gt;    &lt;student&gt;        &lt;name id = &quot;2&quot;&gt;Lee&lt;/name&gt;        &lt;age&gt;111&lt;/age&gt;    &lt;/student&gt;&lt;/students&gt;  \n\nXML基本语法\n\n\n第一行是默认的文档声明, 基本不需要改动, 但是必须是第一行顶格写\n根标签\n只能有一个\n\n\n属性\n属性必须有值\n属性值必须加引号, 单双都行\nXML约束\n\n\n\n\n编写XML文件的时候, 需要根据XML约束中的规定来编写XML配置文件, 同时这些规定也能提示如何编写\n主要有DTD, Schema两种\nSchema约束, 要求一个XML文档中, 所有标签, 所有属性, 都必须在约束中有明确的定义\n\n1.3 DOM4J进行XML解析1.3.1 DOM4J使用步骤\n创建SAXReader对象\n将XML文件读取为inputSteam流[[javaAdvance#41. IO流]]\n将输入流传入SAXReader的read方法, 传回来的是Element节点对象\n获取Element的子节点, 获取节点名, 获取属性值, 获取指定的节点, 获取所有节点\n\n1.3.2 API介绍\n创建SAXReader对象\n\nSAXReader saxReader = new SAXReader();\n\n\n解析XML获取Document对象: 需要传入要解析的XML文件的字节输入流\n\nDocument document = reader.read(inputStream);\n\n\n获取文档的根标签\n\nElement rootElement = documen.getRootElement()\n\n\n获取标签的子标签\n\n//获取所有子标签List&lt;Element&gt; sonElementList = rootElement.elements();//获取指定标签名的子标签List&lt;Element&gt; sonElementList = rootElement.elements(&quot;标签名&quot;);\n\n\n获取标签体内的文本\n\nString text = element.getText();\n\n\n获取标签的某个属性的值\n\nString value = element.attributeValue(&quot;属性名&quot;);\n\n1.3.3 codepackage tomcat.com;import org.dom4j.Document;import org.dom4j.Element;import org.dom4j.io.SAXReader;import java.io.*;import java.util.List;public class XML &#123;    public static void main(String[] args) throws Exception &#123;        SAXReader saxReader= new SAXReader();        InputStream inputStream = new FileInputStream(&quot;src/tomcat/com/demo01.xml&quot;);        Document xml = saxReader.read(inputStream);        Element rootElement = xml.getRootElement();        List&lt;Element&gt; sonElementList = rootElement.elements();        // 指定标签名的子标签        List&lt;Element&gt; sonElement = rootElement.elements(&quot;name&quot;);        for (Element e : sonElement) &#123;            String text = e.getText();            System.out.println(text);        &#125;        for (Element e : sonElementList) &#123;            Element s = e.element(&quot;name&quot;);            String text = s.getText();            String attribute = s.attributeValue(&quot;id&quot;);            System.out.println(text);            System.out.println(&quot;id = &quot; + attribute);        &#125;    &#125;&#125;\n\n\n","tags":["Java","frontend","JavaWeb","XML"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86/","content":"会话管理1. 会话管理的意义\n用于解决HTTP是无状态协议在某些时候引发的麻烦\n例如, 多次登录同一网站, 每次都需要填写相同的账号\n我希望这个HTTP是有状态的, 能记录我上一次访问的状态\n\n\n这个时候我们就可以通过 “补丁” 会话管理来完成这个事情\n\n2. Cookie\n服务端创建cookie, 将cookie放入响应对象中, Tomcat容器将cookie转化为set-cookie响应头, 响应给客户端\n客户端在带有set-cookie的响应头后, 在下次发送信息给服务端的时候, 会将其中的内容以cookie请求头的形式传递给服务端\n\n2.1 Cookie的设置与获取\n设置步骤1. 创建Cookie对象, 并赋值键值对2. 为resp对象设置cookie\n\n\n获取步骤    1. 创建Cookies数组    2. 从req对象中获取并传递给Cookies数组    3. 判断是否非空或者长度为0    4. 从Cookie对象中获取键值对\n\n\n示例代码\n\n@WebServlet(&quot;/servletA&quot;)public class ServletA extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        Cookie cookie1 = new Cookie(&quot;C1&quot;, &quot;c1-value&quot;);        cookie1.setMaxAge(60);        Cookie cookie2 = new Cookie(&quot;C2&quot;, &quot;c2-value&quot;);        resp.addCookie(cookie1);        resp.addCookie(cookie2);    &#125;&#125;@WebServlet(&quot;/servletV&quot;)public class ServletB extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        Cookie[] cookies = req.getCookies();         if (cookies == null || cookies.length == 0) &#123;            System.out.println(&quot;null&quot;);        &#125; else &#123;            for (Cookie c : cookies) &#123;                System.out.println(c.getName() + &quot;:&quot; + c.getValue());            &#125;        &#125;    &#125;&#125;\n2.2 Cookie的时效性\n时效性说明\n\n\nCookie分为持久级Cookie和会话级Cookie\n会话级 : \n浏览器的打开 &#x3D;&gt; 会话的开始\n浏览器的关闭 &#x3D;&gt; 会话的关闭\n\n\n持久级 :\n在客户端, Cookie数据被持久化保存在硬盘\n保存时间根据服务器端设定的时间来管控, 不受浏览器的限制\n\n\n\n\n\n\n示例代码\n\nCookie cookie1 = new Cookie(&quot;C1&quot;, &quot;c1-value&quot;);cookie1.setMaxAge(60);resp.addCookie(cookie1);\n\n\n2.3 Cookie的提交路径\n访问网页的时候, 我们往往不希望将所有的cookie都携带上, 只需要携带上需要的部分, 不同的网页携带不同的cookie, 我们可以通过设置cookie的路径\\\n\n\ncode\n\nCookie cookie1 = new Cookie(&quot;C1&quot;, &quot;c1-value&quot;);cookie1.setPath(&quot;/demo02_war_exploded/servletB&quot;);Cookie cookie2 = new Cookie(&quot;C2&quot;, &quot;c2-value&quot;);\n\n路径从项目的根路径开始填写\n默认不填写的时候, 实际的path是项目的根路径, 即demo02_war_exploded\n\n3. Session\nHttpSession是一种能在服务端保留更多数据的一种方式, 服务器会为每一个客户端开辟一个内容空间, 即Session对象, 通过id访问和修改\n\n\n服务端会在为客户端创建了session对象后, 将ID以JSESSION键值对设置入set-cookie中传回客户端\n\n客户端下次访问时携带JSESSIONID, 后端收到后, 就会根据ID找到对应的对象\n\n从而实现针对某一个客户端提供服务的功能\n\n作用\n\n\n记录用户的登录状态 &#x3D;&gt; 你交的校园网\n\n记录用户的访问痕迹, 比如上次查看的是哪个页面等\n\n\n3.1 Session的设置和获取\nSession 的设置\n\n步骤 : \n\n新建HttpSession对象用于接收req.getSession()\nHttpSession.isNew()用于查看当前session是否是新建的\nHttpSession.getId()获取当前session的id\nHttpSession.setAttribute(s,s)设置这个session对应的数据\n.getAttribute(s)获取对应名字的数据\n\n\ncode\n\n@WebServlet(&quot;/sessionA&quot;)public class SessionA extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        String name = req.getParameter(&quot;username&quot;);        // 获取Session对线        HttpSession httpSession = req.getSession();        // 获取SessionId        String JSESSIONID = httpSession.getId();        System.out.println(&quot;JSESSIONID = &quot; + JSESSIONID);        // 判断是不是新创建的session        boolean isNew = httpSession.isNew();        System.out.println(&quot;isNew = &quot; + isNew);        // 在服务端向sessionID中存入数据        httpSession.setAttribute(&quot;username&quot;, name);    &#125;&#125;\n\n\nSession的获取\n\n步骤与上面类似, 只不过从添加数据变为查询数据\n@WebServlet(&quot;/sessionB&quot;)public class SessionB extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        // 获取session        HttpSession session = req.getSession();        String JSESSIONID = session.getId();        System.out.println(&quot;JSESSIONID = &quot; + JSESSIONID);        // 是不是新的ID        boolean isNew = session.isNew();        System.out.println(isNew);        // 获取其中的数据        String name = (String) session.getAttribute(&quot;username&quot;);        System.out.println(&quot;name = &quot; + name);    &#125;&#125;\n3.2 getSession方法的处理逻辑![[images&#x2F;1682477914654.png]]\nSession的时效性\n用户量大了以后, Session对象相应的也要创建很多, 如果一味创建不释放, 很快内存空间就会被占满\n\n\n客户端关闭行为, 服务端无法检测, 客户端长时间不操作的情况也经常出现, 类似这些情况, 就需要对Session的时限进行设置\n\n\n四种配置方法\n\n\n默认最长闲置时间是30min, 在tomcat&#x2F;conf&#x2F;web.xml中配置![[images&#x2F;1682478412527.png]]\n在自己的Web.xml中设置![[images&#x2F;1682478633650.png]]\n通过HttpSession的API设置\n\n// 设置最大闲置时间session.setMaxInactiveInterval(60);\n\n直接让Session失效\n\n// 直接让session失效session.invalidate();\n\n4. 三大域对象4.1 域对象概述\n三种域对象 : 请求域, 会话域, 应用域\n\n\n请求域对象是HttpServletRequest ,  传递数据的范围是一次请求\n会话域对象是HttpSession, 传递数据的范围是一次会话, 可以有多次请求\n应用域对象是HttpContext, 传递数据的范围是整个应用, 可以跨对话\n\n![[images&#x2F;1682488186891.png]]\n4.2 域对象的使用\n域对象API, 三个域相关的API都是这些\n\n\n\n\nAPI\n功能\n\n\n\nvoid setAttribute(String name,String value)\n向域对象中添加&#x2F;修改数据\n\n\nObject getAttribute(String name);\n从域对象中获取数据\n\n\nremoveAttribute(String name);\n移除域对象中的数据\n\n\n\n三个域的常规使用\n\n\n请求域一般存放和这次请求业务相关的数据, 比如这次请求查询到的部门信息\n会话域一般存放客户端有关的数据, 比如登录的用户\n同一个APP内, 不同的客户端, 应用域一般存放本程序应用有关的数据, 比如Spring框架的IOC容器\n\n","tags":["Java","JavaWeb","backend","session"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/%E7%9B%91%E5%90%AC%E5%99%A8/","content":"监听器1. 监听器概述\n监听器可以看作是JavaWeb中后端的事件驱动触发器, 是对域对象身上发生的事件或状态的改变进行监听和进行处理的对象\n\n\n是典型的GOF设计模式中, 观察者模式的典型案例\n观察者模式 : 当被监听对象发生改变的时候, 观察者自动采取相应措施的模式\n监听器只监听域对象\n\n\n监听器的分类\n\n\n监听器的分类\n\n\nweb中定义八个监听器接口作为监听器的规范,这八个接口按照不同的标准可以形成不同的分类\n\n按监听的对象划分\n\napplication域监听器 ServletContextListener ServletContextAttributeListener\n\nsession域监听器 HttpSessionListener HttpSessionAttributeListener HttpSessionBindingListener HttpSessionActivationListener\n\nrequest域监听器 ServletRequestListener ServletRequestAttributeListener\n\n\n\n按监听的事件分\n\n域对象的创建和销毁监听器 ServletContextListener HttpSessionListener ServletRequestListener\n\n域对象数据增删改事件监听器 ServletContextAttributeListener HttpSessionAttributeListener ServletRequestAttributeListener\n\n其他监听器 HttpSessionBindingListener HttpSessionActivationListener\n\n\n\n\n2 监听器的六个主要接口2.1 application域监听器\nServletContextListener 监听ServletContext对象的创建与销毁\n\n\n\n\n方法名\n作用\n\n\n\ncontextInitialized(ServletContextEvent sce)\nServletContext创建时调用\n\n\ncontextDestroyed(ServletContextEvent sce)\nServletContext销毁时调用\n\n\n\nServletContextEvent对象代表从ServletContext对象身上捕获到的事件，通过这个事件对象我们可以获取到ServletContext对象。\n\n\nServletContextAttributeListener 监听ServletContext中属性的添加、移除和修改\n\n\n\n\n方法名\n作用\n\n\n\nattributeAdded(ServletContextAttributeEvent scab)\n向ServletContext中添加属性时调用\n\n\nattributeRemoved(ServletContextAttributeEvent scab)\n从ServletContext中移除属性时调用\n\n\nattributeReplaced(ServletContextAttributeEvent scab)\n当ServletContext中的属性被修改时调用\n\n\n\nServletContextAttributeEvent对象代表属性变化事件，它包含的方法如下：\n\n\n\n\n方法名\n作用\n\n\n\n\ngetName()\n获取修改或添加的属性名\n\n\n\ngetValue()\n获取被修改或添加的属性值\n\n\n\ngetServletContext()\n获取ServletContext对象\n\n\n\n\n测试代码\n\n\n监听器代码\n\n/** * @brief   实现应用域的监听 */@WebListenerpublic class ApplicationListener implements ServletContextListener, ServletContextAttributeListener &#123;    /**     * 监听ServletContext对象的创建和销毁     */    @Override    public void contextInitialized(ServletContextEvent sce) &#123;        ServletContext application = sce.getServletContext();        System.out.println(&quot;application&quot;+application.hashCode()+&quot; initialized&quot;);    &#125;    @Override    public void contextDestroyed(ServletContextEvent sce) &#123;        ServletContext application = sce.getServletContext();        System.out.println(&quot;application&quot;+application.hashCode()+&quot; destroyed&quot;);    &#125;    /**     * 监听ServletContext中的属性的添加移除和修改     */    @Override    public void attributeAdded(ServletContextAttributeEvent scae) &#123;        ServletContext application = scae.getServletContext();        System.out.println(&quot;application = &quot; + application.hashCode() + &quot; added&quot;);    &#125;    @Override    public void attributeReplaced(ServletContextAttributeEvent scae) &#123;        ServletContext application = scae.getServletContext();        System.out.println(&quot;application = &quot; + application.hashCode() + &quot; replaced&quot;);    &#125;    @Override    public void attributeRemoved(ServletContextAttributeEvent scae) &#123;        ServletContext application = scae.getServletContext();        System.out.println(&quot;application = &quot; + application.hashCode() + &quot; removed&quot;);    &#125;&#125;\n\n\nServlet代码\n\n@WebServlet(&quot;/servletB&quot;)public class ServletB extends HttpServlet &#123;    /**     * 对App数据域的数据的修改和删除     * @param req     * @param resp     * @throws ServletException     * @throws IOException     */    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        ServletContext  application = this.getServletContext();        application.setAttribute(&quot;App-key&quot;, &quot;value1&quot;);        application.removeAttribute(&quot;App-key&quot;);    &#125;&#125;@WebServlet(&quot;/servletA&quot;)public class ServletA extends HttpServlet &#123;    /**     * 向Context中添加数据     * @param req     * @param resp     * @throws ServletException     * @throws IOException     */    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        ServletContext context = this.getServletContext();        context.setAttribute(&quot;App-key&quot;, &quot;App-Msg&quot;);    &#125;&#125;\n\n2.2 session域监听器\nHttpSessionListener 监听HttpSession对象的创建与销毁\n\n\n\n\n方法名\n作用\n\n\n\nsessionCreated(HttpSessionEvent hse)\nHttpSession对象创建时调用\n\n\nsessionDestroyed(HttpSessionEvent hse)\nHttpSession对象销毁时调用\n\n\n\nHttpSessionEvent对象代表从HttpSession对象身上捕获到的事件，通过这个事件对象我们可以获取到触发事件的HttpSession对象。\n\n\nHttpSessionAttributeListener 监听HttpSession中属性的添加、移除和修改\n\n\n\n\n方法名\n作用\n\n\n\nattributeAdded(HttpSessionBindingEvent se)\n向HttpSession中添加属性时调用\n\n\nattributeRemoved(HttpSessionBindingEvent se)\n从HttpSession中移除属性时调用\n\n\nattributeReplaced(HttpSessionBindingEvent se)\n当HttpSession中的属性被修改时调用\n\n\n\nHttpSessionBindingEvent对象代表属性变化事件，它包含的方法如下：\n\n\n\n\n方法名\n作用\n\n\n\ngetName()\n获取修改或添加的属性名\n\n\ngetValue()\n获取被修改或添加的属性值\n\n\ngetSession()\n获取触发事件的HttpSession对象\n\n\n\n示例代码\n\n\n监听器\n\npackage com.f.servlet;import jakarta.servlet.annotation.WebListener;import jakarta.servlet.http.*;@WebListenerpublic class SessionListener implements HttpSessionListener, HttpSessionAttributeListener&#123;    @Override    public void sessionCreated(HttpSessionEvent se) &#123;        HttpSession session = se.getSession();        System.out.println(&quot;session.Id = &quot; + session.getId() + &quot;initialized&quot;);    &#125;    @Override    public void sessionDestroyed(HttpSessionEvent se) &#123;        HttpSession session = se.getSession();        System.out.println(&quot;session.Id = &quot; + session.getId() + &quot;destroyed&quot;);    &#125;    @Override    public void attributeAdded(HttpSessionBindingEvent se) &#123;        HttpSession session = se.getSession();        String id = session.getId();        System.out.println(&quot;session.id &quot; + id + &quot;added&quot;);    &#125;    @Override    public void attributeReplaced(HttpSessionBindingEvent se) &#123;        HttpSession session = se.getSession();        String id = session.getId();        System.out.println(&quot;session.id &quot; + id + &quot;replaced&quot;);    &#125;    @Override    public void attributeRemoved(HttpSessionBindingEvent se) &#123;        HttpSession session = se.getSession();        String id = session.getId();        System.out.println(&quot;session.id &quot; + id + &quot;removed&quot;);    &#125;&#125;\n\n\n触发监听器代码\n\n@WebServlet(&quot;/servletC&quot;)public class ServletC extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        HttpSession session = req.getSession();//        String ID = session.getId();//        System.out.println(&quot;ID = &quot; + ID);        session.setAttribute(&quot;s-K&quot;, &quot;s-M&quot;);    &#125;&#125;@WebServlet(&quot;/servletD&quot;)public class ServletD extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        HttpSession session = req.getSession();//        String bId = session.getId();//        System.out.println(&quot;bId = &quot; + bId);        session.setAttribute(&quot;s-K&quot;, &quot;s-V&quot;);        session.removeAttribute(&quot;s-K&quot;);        session.invalidate();    &#125;&#125;\n\n2.3 request域监听器\nServletRequestListener 监听ServletRequest对象的创建与销毁\n\n\n\n\n方法名\n作用\n\n\n\nrequestInitialized(ServletRequestEvent sre)\nServletRequest对象创建时调用\n\n\nrequestDestroyed(ServletRequestEvent sre)\nServletRequest对象销毁时调用\n\n\n\nServletRequestEvent对象代表从HttpServletRequest对象身上捕获到的事件，通过这个事件对象我们可以获取到触发事件的HttpServletRequest对象。另外还有一个方法可以获取到当前Web应用的ServletContext对象。\n\n\nServletRequestAttributeListener 监听ServletRequest中属性的添加、移除和修改\n\n\n\n\n方法名\n作用\n\n\n\nattributeAdded(ServletRequestAttributeEvent srae)\n向ServletRequest中添加属性时调用\n\n\nattributeRemoved(ServletRequestAttributeEvent srae)\n从ServletRequest中移除属性时调用\n\n\nattributeReplaced(ServletRequestAttributeEvent srae)\n当ServletRequest中的属性被修改时调用\n\n\n\nServletRequestAttributeEvent对象代表属性变化事件，它包含的方法如下：\n\n\n\n\n方法名\n作用\n\n\n\ngetName()\n获取修改或添加的属性名\n\n\ngetValue()\n获取被修改或添加的属性值\n\n\ngetServletRequest ()\n获取触发事件的ServletRequest对象\n\n\n\n定义监听器\n\n package com.atguigu.listeners;   ​   import jakarta.servlet.*;   import jakarta.servlet.annotation.WebListener;   ​   ​   @WebListener   public class RequestListener implements ServletRequestListener , ServletRequestAttributeListener &#123;       // 监听初始化       @Override       public void requestInitialized(ServletRequestEvent sre) &#123;           ServletRequest request = sre.getServletRequest();           System.out.println(&quot;request&quot;+request.hashCode()+&quot; initialized&quot;);       &#125;   ​       // 监听销毁       @Override       public void requestDestroyed(ServletRequestEvent sre) &#123;           ServletRequest request = sre.getServletRequest();           System.out.println(&quot;request&quot;+request.hashCode()+&quot; destoryed&quot;);       &#125;   ​   ​       // 监听数据增加       @Override       public void attributeAdded(ServletRequestAttributeEvent srae) &#123;           String name = srae.getName();           Object value = srae.getValue();           ServletRequest request = srae.getServletRequest();           System.out.println(&quot;request&quot;+request.hashCode()+&quot; add:&quot;+name+&quot;=&quot;+value);       &#125;   ​       //  监听数据移除       @Override       public void attributeRemoved(ServletRequestAttributeEvent srae) &#123;           String name = srae.getName();           Object value = srae.getValue();           ServletRequest request = srae.getServletRequest();           System.out.println(&quot;request&quot;+request.hashCode()+&quot; remove:&quot;+name+&quot;=&quot;+value);       &#125;       // 监听数据修改       @Override       public void attributeReplaced(ServletRequestAttributeEvent srae) &#123;           String name = srae.getName();           Object value = srae.getValue();           ServletRequest request = srae.getServletRequest();           Object newValue = request.getAttribute(name);           System.out.println(&quot;request&quot;+request.hashCode()+&quot; change:&quot;+name+&quot;=&quot;+value+&quot; to &quot;+newValue);       &#125;   &#125;\n\n定义触发监听器的代码\n\n //  servletA向请求域中放数据   @WebServlet(urlPatterns = &quot;/servletA&quot;,name = &quot;servletAName&quot;)   public class ServletA extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           // 向request中增加数据           req.setAttribute(&quot;k1&quot;,&quot;v1&quot;);           req.setAttribute(&quot;k2&quot;,&quot;v2&quot;);           // 请求转发           req.getRequestDispatcher(&quot;servletB&quot;).forward(req,resp);       &#125;   &#125;   ​   // servletB修改删除域中的数据   @WebServlet(urlPatterns = &quot;/servletB&quot;, name = &quot;servletBName&quot;)   public class ServletB extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           //  修改request域中的数据           req.setAttribute(&quot;k1&quot;,&quot;value1&quot;);           //  删除session域中的数据           req.removeAttribute(&quot;k2&quot;);   ​       &#125;   &#125;\n\n3. session域中的两个特殊监听器3.1 session绑定监听器\n这类的监听器被用作给session绑定, 绑定的时候触发事件, 作用未知\n\n\n示例代码\n\n\n监听器代码\n\n@WebListenerpublic class SessionBindListener implements HttpSessionBindingListener &#123;    @Override    public void valueBound(HttpSessionBindingEvent event) &#123;        HttpSession session = event.getSession();        String name = event.getName();        System.out.println(&quot;MySessionBindingListener &quot;+this.hashCode()+&quot; binding into session &quot;+session.getId()+&quot; with name &quot;+name);    &#125;    @Override    public void valueUnbound(HttpSessionBindingEvent event) &#123;        HttpSession session = event.getSession();        String name = event.getName();        System.out.println(&quot;MySessionBindingListener &quot;+this.hashCode()+&quot; unbinding into session &quot;+session.getId()+&quot; with name &quot;+name);    &#125;&#125;\n\n\n触发监听器的代码\n\n@WebServlet(&quot;/servletE&quot;)public class ServletE extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        HttpSession session = req.getSession();        //绑定监听器        session.setAttribute(&quot;bindingListener&quot;, new SessionBindListener());        // 解除绑定监听器        session.removeAttribute(&quot;bindingListener&quot;);    &#125;&#125;\n\n3.3.4 钝化活化监听器\nHttpSessionActivationListener 监听某个对象在Session中的序列化与反序列化。\n\n\n\n\n方法名\n作用\n\n\n\nsessionWillPassivate(HttpSessionEvent se)\n该类实例和Session一起钝化到硬盘时调用\n\n\nsessionDidActivate(HttpSessionEvent se)\n该类实例和Session一起活化到内存时调用\n\n\n\nHttpSessionEvent对象代表事件对象，通过getSession()方法获取事件涉及的HttpSession对象。\n\n\n什么是钝化活化\n\n\nsession对象在服务端是以对象的形式存储于内存的,session过多,服务器的内存也是吃不消的\n\n而且一旦服务器发生重启,所有的session对象都将被清除,也就意味着session中存储的不同客户端的登录状态丢失\n\n为了分摊内存 压力并且为了保证session重启不丢失,我们可以设置将session进行钝化处理\n\n在关闭服务器前或者到达了设定时间时,对session进行序列化到磁盘,这种情况叫做session的钝化\n\n在服务器启动后或者再次获取某个session时,将磁盘上的session进行反序列化到内存,这种情况叫做session的活化\n\n\n\n如何配置钝化活化\n\n\n在web目录下,添加 META-INF下创建Context.xml\n\n文件中配置钝化\n\n\n &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;   &lt;Context&gt;       &lt;Manager className=&quot;org.apache.catalina.session.PersistentManager&quot; maxIdleSwap=&quot;1&quot;&gt;           &lt;Store className=&quot;org.apache.catalina.session.FileStore&quot; directory=&quot;d:\\mysession&quot;&gt;&lt;/Store&gt;       &lt;/Manager&gt;   &lt;/Context&gt;\n\n请求servletA,获得session,并存入数据,然后重启服务器\n\n @WebServlet(urlPatterns = &quot;/servletA&quot;,name = &quot;servletAName&quot;)   public class ServletA extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           HttpSession session = req.getSession();           // 添加数据           session.setAttribute(&quot;k1&quot;,&quot;v1&quot;);       &#125;   &#125;\n\n请求servletB获取session,获取重启前存入的数据\n\n @WebServlet(urlPatterns = &quot;/servletB&quot;, name = &quot;servletBName&quot;)   public class ServletB extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           HttpSession session = req.getSession();           Object v1 = session.getAttribute(&quot;k1&quot;);           System.out.println(v1);   ​       &#125;   &#125;\n\n如何监听钝化活化\n\n\n定义监听器\n\n package com.atguigu.listeners;   ​   import jakarta.servlet.http.HttpSession;   import jakarta.servlet.http.HttpSessionActivationListener;   import jakarta.servlet.http.HttpSessionEvent;   ​   import java.io.Serializable;   ​   public class ActivationListener  implements HttpSessionActivationListener, Serializable &#123;       //  监听钝化       @Override       public void sessionWillPassivate(HttpSessionEvent se) &#123;           HttpSession session = se.getSession();           System.out.println(&quot;session with JSESSIONID &quot;+ session.getId()+&quot; will passivate&quot;);       &#125;   ​       //  监听活化       @Override       public void sessionDidActivate(HttpSessionEvent se) &#123;           HttpSession session = se.getSession();           System.out.println(&quot;session with JSESSIONID &quot;+ session.getId()+&quot; did activate&quot;);       &#125;   &#125;   ​\n\n定义触发监听器的代码\n\n @WebServlet(urlPatterns = &quot;/servletA&quot;,name = &quot;servletAName&quot;)   public class ServletA extends HttpServlet &#123;       @Override       protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;           HttpSession session = req.getSession();           // 添加数据           session.setAttribute(&quot;k1&quot;,&quot;v1&quot;);           // 添加钝化活化监听器           session.setAttribute(&quot;activationListener&quot;,new ActivationListener());       &#125;   &#125;\n","tags":["Java","JavaWeb","backend","Listener"]},{"url":"/2025/07/08/Java/JavaWeb/%E7%AC%94%E8%AE%B0/%E8%BF%87%E6%BB%A4%E5%99%A8/","content":"过滤器1. 过滤器概述\n所有的过滤器需要实现Filter接口\nFilter的doFilter方法会控制请求是否继续\n工作时机是在HttpServletRequest和response创建之前\n\n\n图解\n\n![[images&#x2F;1682494494396.png]]\n\nFilter接口\n\n\n源码\n\npackage jakarta.servlet;import java.io.IOException;public interface Filter &#123;    default public void init(FilterConfig filterConfig) throws ServletException &#123;    &#125;    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)            throws IOException, ServletException;    default public void destroy() &#123;    &#125;&#125;\n\nAPI\n\n\n\n\nAPI\n目标\n\n\n\ndefault public void init(FilterConfig filterConfig)\n初始化方法,由容器调用并传入初始配置信息filterConfig对象\n\n\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n过滤方法,核心方法,过滤请求,决定是否放行,响应之前的其他处理等都在该方法中\n\n\ndefault public void destroy()\n销毁方法,容器在回收过滤器对象之前调用的方法\n\n\n2. 过滤器的使用\n一个简单的日志记录过滤器 ( 这里并不是过滤了日志, 而是通过这个过滤器生成了日志)\n\n\n过滤器代码\n\npublic class LoggingFilter implements Filter &#123;    private SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);    @Override    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;        // 父转子        HttpServletRequest req = (HttpServletRequest) servletRequest;        HttpServletResponse resp = (HttpServletResponse) servletResponse;        // 拼接日志文本        String requestURI = req.getRequestURI();        String time = dateFormat.format(new Date());        String beforeLogging = requestURI + &quot; at &quot; + time;        System.out.println(&quot;beforeLogging = &quot; + beforeLogging);        long t1 = System.currentTimeMillis();        filterChain.doFilter(req, resp);        long t2 = System.currentTimeMillis();        String afterLogging = requestURI + &quot; 耗时 &quot; + (t2-t1);        System.out.println(&quot;afterLogging = &quot; + afterLogging);    &#125;&#125;\n\n\nServlet代码\n\n@WebServlet(urlPatterns = &quot;/servletF&quot;,            name = &quot;servletF&quot;)public class ServletF extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;servletF请求耗时10ms&quot;);        try &#123;            Thread.sleep(50);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\n\n配置过滤器以及过滤器的过滤范围\n\n&lt;filter&gt;    &lt;filter-name&gt;LoggingFilter&lt;/filter-name&gt;    &lt;filter-class&gt;com.f.filter.LoggingFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;!-- 过滤范围 --&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;LoggingFilter&lt;/filter-name&gt;    &lt;servlet-name&gt;servletF&lt;/servlet-name&gt;    &lt;url-pattern&gt;/servletV&lt;/url-pattern&gt;&lt;/filter-mapping&gt;\n\n3. 过滤器的作用说明\n理解的关键因素在于filterChain.doFilter和执行的时机上\n在doFilter也就是放行的时候, \n过滤器其实相当于一个在特定业务执行前会执行的内容\n业务会在doFilter的位置执行, 执行完毕以后, Filter执行doFilter下面的内容\n\n\n在没有放行的时候, 才更相当于一个过滤器, 阻止了业务接下来的进行\n\n\n在有了过滤器以后, 请求会先进入过滤器, 再由过滤器判断是否要执行接下来的业务\n更详细的用途, 等后面使用的时候会由更多的体悟\n\n4. 过滤器的生命周期\n过滤器作为web项目的组件之一,和Servlet的生命周期类似,略有不同,没有servlet的load-on-startup的配置,默认就是系统启动立刻构造\n\n\n\n\n阶段\n对应方法\n执行时机\n执行次数\n\n\n\n创建对象\n构造器\nweb应用启动时\n1\n\n\n初始化方法\nvoid init(FilterConfig filterConfig)\n构造完毕\n1\n\n\n过滤请求\nvoid doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)\n每次请求\n多次\n\n\n销毁\ndefault void destroy()\nweb应用关闭时\n1次\n\n\n5. 过滤器链的使用\n实际的使用中, 很容易碰到多个过滤器过滤同一个servlet的时候. 工作时间有先后, 整体形成一个工作链, 称作过滤器链\n\n![[images&#x2F;1682556566084.png]]\n\n过滤器\n\npublic class Filter1 implements Filter &#123;    @Override    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;        System.out.println(&quot;Filter1 before chain.doFilter code invoked&quot;);        filterChain.doFilter(servletRequest, servletResponse);        System.out.println(&quot;Filter1 before chain.doFilter code invoked&quot;);    &#125;&#125;public class Filter2 implements Filter &#123;    @Override    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;        System.out.println(&quot;Filter2 before chain.doFilter code invoked&quot;);        filterChain.doFilter(servletRequest, servletResponse);        System.out.println(&quot;Filter2 before chain.doFilter code invoked&quot;);    &#125;&#125;public class Filter3 implements Filter &#123;    @Override    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;        System.out.println(&quot;Filter3 before chain.doFilter code invoked&quot;);        filterChain.doFilter(servletRequest, servletResponse);        System.out.println(&quot;Filter3 before chain.doFilter code invoked&quot;);    &#125;&#125;\n\n\nServlet\n\n@WebServlet(        name=&quot;ServletG&quot;,        urlPatterns = &quot;/servletG&quot;)public class ServletG extends HttpServlet &#123;    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(&quot;ServletG service method invoked&quot;);    &#125;&#125;\n\n\n结果\n\nFilter2 before chain.doFilter code invokedFilter3 before chain.doFilter code invokedFilter1 before chain.doFilter code invokedServletG service method invokedFilter1 before chain.doFilter code invokedFilter3 before chain.doFilter code invokedFilter2 before chain.doFilter code invoked\n\n\n从输出可以看出, 过滤器链是以递归的形式向下一层过滤器深入的\n\n![[images&#x2F;1682497251883.png]]\n\n顺序问题\n\n\n如果某个Filter是使用ServletName进行匹配规则的配置，那么这个Filter执行的优先级要更低\n过滤器的执行顺序就是在web.xml中的声明顺序\n\n&lt;filter&gt;    &lt;filter-name&gt;filter1&lt;/filter-name&gt;    &lt;filter-class&gt;com.f.filter.Filter1&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter&gt;    &lt;filter-name&gt;filter2&lt;/filter-name&gt;    &lt;filter-class&gt;com.f.filter.Filter2&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter&gt;    &lt;filter-name&gt;filter3&lt;/filter-name&gt;    &lt;filter-class&gt;com.f.filter.Filter3&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;filter1&lt;/filter-name&gt;    &lt;servlet-name&gt;ServletG&lt;/servlet-name&gt;&lt;/filter-mapping&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;filter2&lt;/filter-name&gt;    &lt;url-pattern&gt;/servletG&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;filter3&lt;/filter-name&gt;    &lt;url-pattern&gt;/servletG&lt;/url-pattern&gt;&lt;/filter-mapping&gt;\n\n6. 注解方式配置过滤器\nweb.xml形式\n\n&lt;!--配置filter,并为filter起别名--&gt;&lt;filter&gt;    &lt;filter-name&gt;loggingFilter&lt;/filter-name&gt;    &lt;filter-class&gt;com.atguigu.filters.LoggingFilter&lt;/filter-class&gt;    &lt;!--配置filter的初始参数--&gt;    &lt;init-param&gt;        &lt;param-name&gt;dateTimePattern&lt;/param-name&gt;        &lt;param-value&gt;yyyy-MM-dd HH:mm:ss&lt;/param-value&gt;    &lt;/init-param&gt;&lt;/filter&gt;&lt;!--为别名对应的filter配置要过滤的目标资源--&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;loggingFilter&lt;/filter-name&gt;    &lt;!--通过映射路径确定过滤资源--&gt;    &lt;url-pattern&gt;/servletA&lt;/url-pattern&gt;    &lt;!--通过后缀名确定过滤资源--&gt;    &lt;url-pattern&gt;*.html&lt;/url-pattern&gt;    &lt;!--通过servlet别名确定过滤资源--&gt;    &lt;servlet-name&gt;servletBName&lt;/servlet-name&gt;&lt;/filter-mapping&gt;\n\n\n转化为注解形式\n\n  @WebFilter(        filterName = &quot;loggingFilter&quot;,        initParams = &#123;@WebInitParam(name = &quot;dateTimePattern&quot;, value = &quot;yyyy-MM-dd HH:mm:ss&quot;)&#125;,        urlPatterns = &#123;                &quot;/servletG&quot;,                &quot;*.html&quot;        &#125;,        servletNames = &#123;&quot;servletG&quot;&#125;)\n\n\n\n如果同时存在xml中的配置和注解形式的配置, 那么执行顺序是怎么样的\n\n\n先执行xml中的, 再执行注释中的, 具体的执行顺序为\nxml.url -&gt; 注释.url -&gt; xml.name -&gt; 注释.name\n\n","tags":["Java","JavaWeb","backend","Filter"]},{"title":"Java内存模型(JMM)详解 - 并发编程核心理论","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/1_JMM/","content":"Java内存模型什么是JMMJMM指的是Java Memory Model, 是Java虚拟机规范中定义的一组规则, 用于规范多线程环境下的内存访问操作\n\n从通信的角度来看, JMM决定了一个线程对共享变量的写入什么时候对另一个线程可见\n从抽象的角度来看, JMM定义了线程和主内存之间的抽象关系 :\n线程之间共享变量存储在主内存\n每个线程都有一个私有的本地内存\n本地内存中存储了该线程以读&#x2F;写共享变量的副本\n\n\n关于本地内存\n本地内存是JMM的一个抽象概念, 并不是真实存在的. \n它涵盖了缓存, 写寄存器以及其他的硬件和编译器优化导致的线程中实际读写共享变量的时候, 并不是直接读写主存中的共享变量\n\n\nJMM的目的\nJMM通过控制主内存与每个线程的本地内存之间的交互, 来为Java程序员提供内存可见性, 操作原子性, 有序性的保证\n为程序员提供跨平台的内存可见性保证\n为程序员屏蔽各种硬件架构和操作系统之间的差异\n\n\nJMM解决的核心问题\n可见性: 保证一个线程修改的数据对其他线程可见\n通过内存屏障保证修改后的值能立即被其他线程看到\n\n\n原子性: 保证操作不会被线程调度机制打断\n主要通过synvhronized和各种锁机制实现\nJMM本身只保证基本的读取和赋值操作的原子性\n\n\n有序性: 保证程序执行的顺序符合预期\n通过happens-before规则定义操作之间的偏序关系\n通过内存屏障禁止特定类型的指令重排序\n\n\n\n\n\n可见性happens-beforeJMM向程序员提供了happens-before规则, 阐述了操作之间的内存可见性, 如果一个操作执行的结果需要对另一个操作可见, 两个操作之间必须存在happens-bofore规则, 这两个规则可以是同一个线程下的, 也可以是多个线程下的, 和程序员相关的规则如下:\n\n程序顺序规则: 一个线程中的每个操作, happens-before于该线程中的任意后续操作\n监视器锁规则: 对于一个监视器锁的解锁, happens-before于随后对于这个监视器锁的加锁\nvolatile变量规则: 对于一个volatile字段的写, happens-before于任意后续对这个volatile字段的读\n传递性: 如果A happens-before B, B happens-before C, 那么A happens-before C\n\n两个操作之间如果存在happens-before关系, 并不意味着前一个操作一定先于后一个操作执行, happens-before只保证前一个操作的结果对后一个操作可见\n通过happens-before规则, 能让Java程序员不需要关注硬件架构和操作系统, 就能知道怎么样保证可见性\n重排序什么时候会发生指令重排序? 指令重排序在多线程情境下会带来什么问题? 回答这个问题是理解JMM为什么需要提供happens-before规则, 以及怎么提供的关键\n数据依赖性如果两个操作访问同一个变量, 其中有一个操作是写操作, 此时两个操作之间存在数据依赖性\n分为三种\n\n写后读 : a&#x3D;1; b&#x3D;a;\n写后写 : a&#x3D;1; a&#x3D;2;\n读后写 : b&#x3D;a; a&#x3D;1\n\n上面三种操作, 只要重排序两个操作之间的顺序, 程序的执行结果就会造成改变\n编译器和处理器可能会对操作重排序, 但是它们两个在重排序的时候都会遵守数据依赖性, 不会改变存在数据依赖性的两个操作的执行顺序\n这里的数据依赖性只针对单个处理器中的指令序列和单个线程中执行的操作, 不同处理器之间和不同线程之间的数据依赖心不被处理器和编译器考虑\nas-if-serial语义as-if-serial语义的意思是 : 不管怎么重排序, 单线程程序的执行结果不能被改变\n遵守as-if-serial语义的编译器和runtime和处理器, 共同为程序员提供了一种幻觉 : 程序是严格按照顺序执行的, 这个语义使得单线程程序中不需要担心指令重排带来的干扰和内存可见性问题\n重排序对多线程的影响class ReorderExample &#123;    int a = 0;    boolean flag = false;    public void writer() &#123; // Thread A        a = 1;                   //1        flag = true;             //2    &#125;    public void reader() &#123; // Thread B        if (flag) &#123;                //3            int i =  a * a;        //4            ……        &#125;    &#125;&#125;\n\n线程A执行writer函数, 线程B执行reader()函数, 我们期望的执行顺序是\n\na &#x3D; 1\nflag &#x3D; true\nif (flag)\ni &#x3D; a * a\n\n我们想通过flag标记变量保证如果执行了操作4一定是已经执行了操作1\n但是线程B在执行操作4的时候能看到线程A操作1对于共享变量的写入吗?\n不一定能看到\n操作1和操作2之间没有数据依赖性, 可能做重排序, 程序执行的时候, 会出现线程A首先标记flag &#x3D; true, 然后线程B读这个变量, 然后执行i &#x3D; a * a, 最后线程A执行A &#x3D; 1, 多线程的语义就被破坏掉了\n\n操作3和操作4, 通过猜测执行机制, 实质上也可以对操作做重排序\n\n操作3和操作4之间存在控制依赖关系, 当代码中存在控制依赖性的时候, 会影响程序的并行度. 这个时候编译器和处理器会采用猜测执行来克服相关性对并行度的影响\n\n\n这个时候多线程程序的语义就被重排序破坏掉了\n顺序一致性数据竞争和顺序一致性保证当程序没有正确同步的时候, 就会存在数据竞争, JMM对数据竞争的定义\n\n在一个线程中写一个变量\n在另一个线程中读同一个变量\n而且写和读没有通过同步来排序\n\nJMM对正确同步的多线程程序的内存一致性做了如下保证\n\n如果程序是正确同步的, 程序的执行将具有顺序一致性, 即程序的执行结果和该程序在顺序一致性模型中的执行结果是一样的\n\n顺序一致性模型顺序一致性模型为程序员提供了极强的内存可见性保证, 是一个理论参考模型\n\n一个线程中的所有操作必须按照程序的顺序执行\n(不管程序是否同步) 所有线程都只能看到单一的操作执行顺序\n每个操作都是原子执行且立刻对所有线程可见\n\n假设有两个线程 A 和 B 并发执行。其中 A 线程有三个操作，它们在程序中的顺序是：A1-&gt;A2-&gt;A3。B 线程也有三个操作，它们在程序中的顺序是：B1-&gt;B2-&gt;B3。\n假设这两个线程使用监视器来正确同步：A 线程的三个操作执行后释放监视器，随后 B 线程获取同一个监视器。那么程序在顺序一致性模型中的执行效果将如下图所示：\n\n现在我们再假设这两个线程没有做同步，下面是这个未同步程序在顺序一致性模型中的执行示意图：\n\n未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。以上图为例，线程 A 和 B 看到的执行顺序都是：B1-&gt;A1-&gt;A2-&gt;B2-&gt;A3-&gt;B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。\n但是JMM对未同步程序没有做这个保证, 未同步程序在JMM中不但整体的执行顺序使无序的, 而且所有线程看到的操作执行顺序也可能是不一致的. 比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本还没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见\n同步程序的顺序一致性效果在顺序一致性模型中, 所有操作完全按照程序的顺序串行执行, 但是在JMM中, 临界区内的代码可以重排序\n虽然线程A在临界区内做了重排序, 但是由于锁的互斥执行的特性, 线程B根本无法观察到A中的重排序, 所以没有改变程序执行的结果\nJMM在具体实现上的基本方针 : 在不改变(正确同步)程序执行结果的前提下, 尽可能未编译器和处理器的优化提供便利\n未同步程序的执行特性未同步程序在JMM中的执行, 整体上是无序的, 其执行结果也无法预知\n\n顺序一致性模型保证单线程内的操作会按程序的顺序执行，而 JMM 不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前面已经讲过了，这里就不再赘述。\n\n顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而 JMM 不保证所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。\n\nJMM 不保证对 64 位的 long 型和 double 型变量的读 &#x2F; 写操作具有原子性，而顺序一致性模型保证对所有的内存读 &#x2F; 写操作都具有原子性。\n\n\n在一些 32 位的处理器上，如果要求对 64 位数据的读 &#x2F; 写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java 语言规范鼓励但不强求 JVM 对 64 位的 long 型变量和 double 型变量的读 &#x2F; 写具有原子性。当 JVM 在这种处理器上运行时，会把一个 64 位 long&#x2F; double 型变量的读 &#x2F; 写操作拆分为两个 32 位的读 &#x2F; 写操作来执行。这两个 32 位的读 &#x2F; 写操作可能会被分配到不同的总线事务中执行，此时对这个 64 位变量的读 &#x2F; 写将不具有原子性。\n总结处理器的内存模型顺序一致性内存模型是一个理论参考模型，JMM 和处理器内存模型在设计时通常会把顺序一致性内存模型作为参照。JMM 和处理器内存模型在设计时会对顺序一致性模型做一些放松，因为如果完全按照顺序一致性模型来实现处理器和 JMM，那么很多的处理器和编译器优化都要被禁止，这对执行性能将会有很大的影响。\n根据对不同类型读 &#x2F; 写操作组合的执行顺序的放松，可以把常见处理器的内存模型划分为下面几种类型：\n\n放松程序中写 - 读操作的顺序，由此产生了 total store ordering 内存模型（简称为 TSO）。\n在前面 1 的基础上，继续放松程序中写 - 写操作的顺序，由此产生了 partial store order 内存模型（简称为 PSO）。\n在前面 1 和 2 的基础上，继续放松程序中读 - 写和读 - 读操作的顺序，由此产生了 relaxed memory order 内存模型（简称为 RMO）和 PowerPC 内存模型。\n\n注意，这里处理器对读 &#x2F; 写操作的放松，是以两个操作之间不存在数据依赖性为前提的（因为处理器要遵守 as-if-serial 语义，处理器不会对存在数据依赖性的两个内存操作做重排序）。\n下面的表格展示了常见处理器内存模型的细节特征：\n\n\n\n内存模型名称\n对应的处理器\nStore-Load 重排序\nStore-Store 重排序\nLoad-Load 和 Load-Store 重排序\n可以更早读取到其它处理器的写\n可以更早读取到当前处理器的写\n\n\n\nTSO\nsparc-TSO X64\nY\n\n\n\nY\n\n\nPSO\nsparc-PSO\nY\nY\n\n\nY\n\n\nRMO\nia64\nY\nY\nY\n\nY\n\n\nPowerPC\nPowerPC\nY\nY\nY\nY\nY\n\n\n在这个表格中，我们可以看到所有处理器内存模型都允许写 - 读重排序，原因在第一章以说明过：它们都使用了写缓存区，写缓存区可能导致写 - 读操作重排序。同时，我们可以看到这些处理器内存模型都允许更早读到当前处理器的写，原因同样是因为写缓存区：由于写缓存区仅对当前处理器可见，这个特性导致当前处理器可以比其他处理器先看到临时保存在自己的写缓存区中的写。\n上面表格中的各种处理器内存模型，从上到下，模型由强变弱。越是追求性能的处理器，内存模型设计的会越弱。因为这些处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。\n由于常见的处理器内存模型比 JMM 要弱，java 编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。同时，由于各种处理器内存模型的强弱并不相同，为了在不同的处理器平台向程序员展示一个一致的内存模型，JMM 在不同的处理器中需要插入的内存屏障的数量和种类也不相同。下图展示了 JMM 在不同处理器内存模型中需要插入的内存屏障的示意图\n\nJMM屏蔽了不同处理器内存模型之间的差异, 它在不同的处理器平台上为java程序员呈现了一个一致的内存模型\nJMM，处理器内存模型与顺序一致性内存模型之间的关系JMM 是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。下面是语言内存模型，处理器内存模型和顺序一致性内存模型的强弱对比示意图：\n\n从上图我们可以看出：常见的 4 种处理器内存模型比常用的 3 中语言内存模型要弱，处理器内存模型和语言内存模型都比顺序一致性内存模型要弱。同处理器内存模型一样，越是追求执行性能的语言，内存模型设计的会越弱。\nJMM 的设计从 JMM 设计者的角度来说，在设计 JMM 时，需要考虑两个关键因素：\n\n程序员对内存模型的使用。程序员希望内存模型易于理解，易于编程。程序员希望基于一个强内存模型来编写代码。\n编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。\n\n由于这两个因素互相矛盾，所以 JSR-133 专家组在设计 JMM 时的核心目标就是找到一个好的平衡点：一方面要为程序员提供足够强的内存可见性保证；另一方面，对编译器和处理器的限制要尽可能的放松。下面让我们看看 JSR-133 是如何实现这一目标的。\n为了具体说明，请看前面提到过的计算圆面积的示例代码：\ndouble pi  = 3.14;    //Adouble r   = 1.0;     //Bdouble area = pi * r * r; //C\n\n上面计算圆的面积的示例代码存在三个 happens- before 关系：\n\nA happens- before B；\nB happens- before C；\nA happens- before C；\n\n由于 A happens- before B，happens- before 的定义会要求：A 操作执行的结果要对 B 可见，且 A 操作的执行顺序排在 B 操作之前。 但是从程序语义的角度来说，对 A 和 B 做重排序即不会改变程序的执行结果，也还能提高程序的执行性能（允许这种重排序减少了对编译器和处理器优化的束缚）。也就是说，上面这 3 个 happens- before 关系中，虽然 2 和 3 是必需要的，但 1 是不必要的。因此，JMM 把 happens- before 要求禁止的重排序分为了下面两类：\n\n会改变程序执行结果的重排序。\n不会改变程序执行结果的重排序。\n\nJMM 对这两种不同性质的重排序，采取了不同的策略：\n\n对于会改变程序执行结果的重排序，JMM 要求编译器和处理器必须禁止这种重排序。\n对于不会改变程序执行结果的重排序，JMM 对编译器和处理器不作要求（JMM 允许这种重排序）。\n\n下面是 JMM 的设计示意图：\n\n从上图可以看出两点：\n\nJMM 向程序员提供的 happens- before 规则能满足程序员的需求。JMM 的 happens- before 规则不但简单易懂，而且也向程序员提供了足够强的内存可见性保证（有些内存可见性保证其实并不一定真实存在，比如上面的 A happens- before B）。\nJMM 对编译器和处理器的束缚已经尽可能的少。从上面的分析我们可以看出，JMM 其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。比如，如果编译器经过细致的分析后，认定一个锁只会被单个线程访问，那么这个锁可以被消除。再比如，如果编译器经过细致的分析后，认定一个 volatile 变量仅仅只会被单个线程访问，那么编译器可以把这个 volatile 变量当作一个普通变量来对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。\n\nJMM 的内存可见性保证Java 程序的内存可见性保证按程序类型可以分为下列三类：\n\n单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime 和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。\n正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是 JMM 关注的重点，JMM 通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。\n未同步 &#x2F; 未正确同步的多线程程序。JMM 为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）\n\n","categories":["Java","Java进阶","JUC并发编程"],"tags":["八股文","面试","JMM","Java内存模型","可见性","原子性","有序性","并发编程","volatile","synchronized"]},{"title":"volatile关键字深度解析 - 可见性与有序性保证","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/2_volatile/","content":"volatile关键字大厂的问题volatile关键字的作用是什么?\nvolatile能保证原子性吗?\n之前32位机器上共享的long和double变量的为什么要用volatile? 现在64位机器上是否也要设置呢?\ni++为什么不能保证原子性?\nvolatile是如何实现可见性的? 内存屏障。\nvolatile是如何实现有序性的? happens-before等\n说下volatile的应用场景?\nvolatile关键字的作用防止指令重排序&#x2F;实现有序性最典型的例子就是双重检查锁定模式中, 需要对对象的实例加上volatile关键字的问题\npublic class Singleton &#123;    public static volatile Singleton singleton;    /**     * 构造函数私有，禁止外部实例化     */    private Singleton() &#123;&#125;;    public static Singleton getInstance() &#123;        if (singleton == null) &#123;            synchronized (singleton.class) &#123;                if (singleton == null) &#123;                    singleton = new Singleton();                &#125;            &#125;        &#125;        return singleton;    &#125;&#125;\n\n首先为什么会出现问题, 原因就是singleton = new Singleton();不是一个原子指令, 实际上是三个步骤\n\n分配内存空间\n初始化对象\n将内存空间的地址赋值给引用\n\n而处理器或者编译器是可以对2和3步骤进行指令重排的, 重拍以后就变成了\n\n分配内存空间\n将内存空间的地址赋值给引用\n初始化对象\n\n这个时候如果线程A执行到了第2步, 线程B也尝试去获取这个单例对象, 这个时候因为引用已经不是null了, B线程就会获取到一个没有初始化完毕的对象\n而加上volatile关键字以后, 就能不会出现这样的指令重排, 原因有二\n\n从happens-before中的volatile规则来看, 保证了对于instance的写操作一定happens-before于instance的读操作\n从volatile实现的原理来看, 通过在这个写操作前后加上内存屏障, 保证了有序性\n\n实现可见性通过给一个变量加上volatile关键字, 能保证这个变量在多线程语义下, 被一个线程写了以后, 这个修改对于其他线程是可见的, 如果没有加上这个关键字, 就会因为每个线程有自己独有的工作线程而导致的对于共享变量的修改的不可见\n保证单次读&#x2F;写操作的原子性\n 问题2 : volatile能保证原子性吗?\n\nvolatile能保证单次读&#x2F;写操作的原子性, 但是无法保证这种情况之外的原子性\n\n问题3 : i++为什么不能保证原子性\n\ni++实际上并不是单次读&#x2F;写, 而是三步操作\n\n读取i的值\n对i加一\n将i的值写回内存\n\nvolatile是无法保证这三个操作是具有原子性的\n\n问题4 : 共享的long和double变量的为什么要用volatile?\n\n在32位的系统上, 硬件是不保证读写long和double这种64位的变量是原子的, 可能被分解成两个32位的操作, 这个时候就需要使用volatile让JVM来保证它们的读写操作的原子的\n\nJVM主要通过加锁机制保证, 会在访问的时候自动添加内部锁\n特殊的硬件指令实现\n\nvolatile的实现原理可见性对于读操作: 基于内存屏障实现了从主存中读取最新值\n对于写操作: 基于内存屏障实现了会将写操作之后的值立即写回到主存中, 从而对所有线程可见(在写操作以后, volatile变量在的Cache Line会被标记为I, 不利用CPU缓存的写缓冲)\n基于内存屏障来实现\n通过插入特定类型的内存屏障来禁止特定类型的指令重排序. 插入一条内存屏障会告诉CPU和编译器, 不管什么指令都不能和这条内存屏障重排序\n在volatile修饰的共享变量进行写操作的时候, 会多出lock前缀的指令, 这条指令会导致\n\n将当前处理器缓存行的数据写回到系统内存\n写回内存的操作会使其他CPU中缓存了该内存地址的数据无效(MESI协议)\n\n这样就会保证主存中存有最新的修改后的共享变量数据\n其他线程如果还要读共享变量, 会先尝试从CPU缓存中读取, 但是会因为数据无效, 重新从主存中读取, 从而读取到最新的修改后的数据\n有序性同样是基于内存屏障实现的\n在happens-before规则里面有这么一条volatile规则: 对于volatile字段的写操作, happens-before于后续任意对于volatile字段的读操作\n为了实现volatile的内存语义, 编译器在生成字节码的时候, 会在指令序列中插入内存屏障来禁止特定类型的处理器重排序\n\n在每个volatile写操作的前面插入一个StoreStore屏障\n确保屏障前的写操作在后续的写操作之前完成并刷入内存\n防止普通写和volatile写重排序\n\n\n在每个volatile写操作的后面插入一个StoreLoad屏障(全能型屏障)\n确保屏障前的写操作在后续的读操作之前完成并全局可见\n保证写操作立即可见, 后续读操作不会乱序\n\n\n在每个volatile读操作的后面插入一个LoadLoad屏障(先插入)\n确保屏障前的读操作在后续的读操作之前完成\n保证volatile读操作之后的读操作不会乱序到普通读操作之前\n\n\n在每个volatile读操作的后面插入一个LoadStore屏障\n确保屏障前的读操作在后续的写操作之前完成\n确保volatile读操作之前的普通写操作不会乱序到读操作之后\n\n\n\n通过插入这四条内存屏障, 实现了在执行volatile写操作不会\nvolatile应用场景使用volatile必须具备的条件\n\n对变量的写不依赖于该变量的值, 也就是不能有i++这种先读才能写的操作, 不能需要看到之前变量写了什么才能写入新的值\n变量的值不应该和其他变量的值有联系, 因为其他变量的值可能会是不保证可见性的\n状态真正独立于程序内其他内容, 这个变量的变化不应该影响程序的其他逻辑或状态, 因为volatile无法保证复杂操作的原子性\n\n1. 双重检查经典案例\npublic class Singleton &#123;    public static volatile Singleton singleton;    /**     * 构造函数私有，禁止外部实例化     */    private Singleton() &#123;&#125;;    public static Singleton getInstance() &#123;        if (singleton == null) &#123;            synchronized (singleton.class) &#123;                if (singleton == null) &#123;                    singleton = new Singleton();                &#125;            &#125;        &#125;        return singleton;    &#125;&#125;\n\n\n\n这里通过volatile保证了singleton  &#x3D; memory前后插入内存屏障, 保证了这个操作不会和前面的对象初始化之间指令重排\n2. 状态标志volatile boolean shutdownRequested;......public void shutdown() &#123; shutdownRequested = true; &#125;public void doWork() &#123;     while (!shutdownRequested) &#123;         // do stuff    &#125;&#125;\n\n3. 开销较低的读-写锁策略通过volatile保证变量的可见性, 通过synchronized保证写操作的原子性\n@ThreadSafepublic class CheesyCounter &#123;    // Employs the cheap read-write lock trick    // All mutative operations MUST be done with the &#x27;this&#x27; lock held    @GuardedBy(&quot;this&quot;) private volatile int value;     public int getValue() &#123; return value; &#125;     public synchronized int increment() &#123;        return value++;    &#125;&#125;\n","categories":["Java","Java进阶","JUC并发编程"],"tags":["八股文","面试","JMM","可见性","有序性","并发编程","volatile","内存屏障","happens-before"]},{"title":"Synchronized关键字详解 - Java同步机制核心","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/3_synchronized/","content":"Synchronized关键字大厂问题Synchronized可以作用在哪里? 分别通过对象锁和类锁进行举例。\nSynchronized本质上是通过什么保证线程安全的? 分三个方面回答：加锁和释放锁的原理，可重入原理，保证可见性原理。\nSynchronized由什么样的缺陷? Java Lock是怎么弥补这些缺陷的。\nSynchronized和Lock的对比，和选择?\nSynchronized在使用时有何注意事项?\nSynchronized修饰的方法在抛出异常时,会释放锁吗?\n多个线程等待同一个Synchronized锁的时候，JVM如何选择下一个获取锁的线程?\nSynchronized使得同时只有一个线程可以执行，性能比较差，有什么提升的方法?\n我想更加灵活的控制锁的释放和获取(现在释放锁和获取锁的时机都被规定死了)，怎么办?\n什么是锁的升级和降级? 什么是JVM里的偏斜锁、轻量级锁、重量级锁?\n不同的JDK中对Synchronized有何优化?\nSynchronized的使用\n一把锁同时只能被一个线程获取, 没有获得锁得线程只能等待\n每个实例都对应自己的一把锁(this), 不同实例之间互不影响; 锁对象是*.class以及synchronized修饰的是static的时候, 所有对象公用一把锁\nsynchronized修饰的方法, 无论方法正常执行完毕还是抛出异常, 都会释放锁\n\n对象锁包括方法锁(默认锁对象是this, 当前实例对象)和同步代码块(自己指定锁对象)\n代码块形式: 手动指定锁定对象, 可以是this, 也可以是自定义的锁\n锁是this, 在创建线程的时候传入锁对象实例\n\npublic class SynchronizedObjectLock implements Runnable &#123;    static SynchronizedObjectLock instance = new SynchronizedObjectLock();    @Override    public void run() &#123;        // 同步代码块形式——锁为this,两个线程使用的锁是一样的,线程1必须要等到线程0释放了该锁后，才能执行        synchronized (this) &#123;            System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName());            try &#123;                Thread.sleep(3000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(Thread.currentThread().getName() + &quot;结束&quot;);        &#125;    &#125;    public static void main(String[] args) &#123;        Thread t1 = new Thread(instance);        Thread t2 = new Thread(instance);        t1.start();        t2.start();    &#125;&#125;/*我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束*/\n\n\n锁是自定义的锁, 这个时候不用传入锁对象, 一般通过这个实现同步, 是在类中创建锁\n\npublic class SynchronizedObjectLock implements Runnable &#123;    static SynchronizedObjectLock instance = new SynchronizedObjectLock();    // 创建2把锁    Object block1 = new Object();    Object block2 = new Object();    @Override    public void run() &#123;        // 这个代码块使用的是第一把锁，当他释放后，后面的代码块由于使用的是第二把锁，因此可以马上执行        synchronized (block1) &#123;            System.out.println(&quot;block1锁,我是线程&quot; + Thread.currentThread().getName());            try &#123;                Thread.sleep(3000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(&quot;block1锁,&quot;+Thread.currentThread().getName() + &quot;结束&quot;);        &#125;        synchronized (block2) &#123;            System.out.println(&quot;block2锁,我是线程&quot; + Thread.currentThread().getName());            try &#123;                Thread.sleep(3000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(&quot;block2锁,&quot;+Thread.currentThread().getName() + &quot;结束&quot;);        &#125;    &#125;    public static void main(String[] args) &#123;        Thread t1 = new Thread(instance);        Thread t2 = new Thread(instance);        t1.start();        t2.start();    &#125;&#125;/*block1锁,我是线程Thread-0block1锁,Thread-0结束block2锁,我是线程Thread-0　　// 可以看到当第一个线程在执行完第一段同步代码块之后，第二个同步代码块可以马上得到执行，因为他们使用的锁不是同一把block1锁,我是线程Thread-1block2锁,Thread-0结束block1锁,Thread-1结束block2锁,我是线程Thread-1block2锁,Thread-1结束*/\n\n方法锁形式: synchronized修饰普通方法, 锁对象默认为thispublic class SynchronizedObjectLock implements Runnable &#123;    static SynchronizedObjectLock instance = new SynchronizedObjectLock();    @Override    public void run() &#123;        method();    &#125;    public synchronized void method() &#123;        System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName());        try &#123;            Thread.sleep(3000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(Thread.currentThread().getName() + &quot;结束&quot;);    &#125;    public static void main(String[] args) &#123;        Thread t1 = new Thread(instance);        Thread t2 = new Thread(instance);        t1.start();        t2.start();    &#125;&#125;/*我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束*/\n\n类锁指synchronized修饰静态的方法或指定锁对象为Class对象, 这两种情况都是所有线程共用一把类锁\nsynchronized修饰静态的方法\n修饰普通方法\n\npublic class SynchronizedObjectLock implements Runnable &#123;    static SynchronizedObjectLock instance1 = new SynchronizedObjectLock();    static SynchronizedObjectLock instance2 = new SynchronizedObjectLock();    @Override    public void run() &#123;        method();    &#125;    // synchronized用在普通方法上，默认的锁就是this，当前实例    public synchronized void method() &#123;        System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName());        try &#123;            Thread.sleep(3000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(Thread.currentThread().getName() + &quot;结束&quot;);    &#125;    public static void main(String[] args) &#123;        // t1和t2对应的this是两个不同的实例，所以代码不会串行        Thread t1 = new Thread(instance1);        Thread t2 = new Thread(instance2);        t1.start();        t2.start();    &#125;&#125;/*我是线程Thread-0我是线程Thread-1Thread-1结束Thread-0结束*/\n\n\n修饰静态方法 : 正确实现了两个线程之间method方法的互斥访问\n\npublic class SynchronizedObjectLock implements Runnable &#123;    static SynchronizedObjectLock instance1 = new SynchronizedObjectLock();    static SynchronizedObjectLock instance2 = new SynchronizedObjectLock();    @Override    public void run() &#123;        method();    &#125;    // synchronized用在静态方法上，默认的锁就是当前所在的Class类，所以无论是哪个线程访问它，需要的锁都只有一把    public static synchronized void method() &#123;        System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName());        try &#123;            Thread.sleep(3000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(Thread.currentThread().getName() + &quot;结束&quot;);    &#125;    public static void main(String[] args) &#123;        Thread t1 = new Thread(instance1);        Thread t2 = new Thread(instance2);        t1.start();        t2.start();    &#125;&#125;/*我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束*/\n\n指定锁对象为类对象public class SynchronizedObjectLock implements Runnable &#123;    static SynchronizedObjectLock instance1 = new SynchronizedObjectLock();    static SynchronizedObjectLock instance2 = new SynchronizedObjectLock();    @Override    public void run() &#123;        // 所有线程需要的锁都是同一把        synchronized(SynchronizedObjectLock.class)&#123;            System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName());            try &#123;                Thread.sleep(3000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            System.out.println(Thread.currentThread().getName() + &quot;结束&quot;);        &#125;    &#125;    public static void main(String[] args) &#123;        Thread t1 = new Thread(instance1);        Thread t2 = new Thread(instance2);        t1.start();        t2.start();    &#125;&#125;/*我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束*/\n\nSynchronized 原理分析字节码层面Synchronized锁在字节码层面本质上是通过monitor指令实现的\n\nmoniterenter: 在对象执行的时候, 使其锁计数器+1\nmoniterexit: 在对象执行的时候, 使其锁计数器-1\n在进入到synchronized代码块的时候, 会尝试获取这个synchronized绑定的对象的moniter\n同一时间只能有一个线程持有一个特定对象的moniter, 也就是不存在同时有多个线程持有相同一个对象的moniter\n每个对象都有一个自己的moniter\n重入性: 同一个线程可以多次获取同一个moniter\n\n\nhappens-before: 监视器锁规则: 对同一个监视器的解锁 happens-before 对该监视器的加锁\n\nJVM中锁的优化JVM中地monitorexit和monitorenter字节码依赖于底层的操作系统的Mutex Lock来实现, 但是使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行, 这种切换的代价是十分昂贵的. 现实中的大部分情况下, 同步方法都是运行在单线程环境, 也就是无锁竞争环境\nsyncronized中的锁会随着竞争情况, 锁逐渐由轻量转为重量, 转变过程\n无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁(mutex)\nMark Word对象头中记录hashcode或者锁信息的字段, Mark Word是实现锁升级的关键, 也是轻量级锁用于CAS的内容\n在64位操作系统中, \n\n\n\n锁的类型\n0~60bit\n61bit\n62~63bit\n\n\n\n无锁\nhashcode\n0\n01\n\n\n偏向锁\n线程ID\n是否持有偏向锁\n01\n\n\n轻量级锁\nlock record的引用\n&#x2F;\n00\n\n\n重量级锁\n指向monitor\n&#x2F;\n10\n\n\nGC标记\n\n\n11\n\n\nlock record是线程私有的数据结构, 存储在线程的栈帧中, 在第一次进入到同步块的时候创建, 用于存储锁对象的mark word副本, 包含两个关键字段\n\ndisplaced_mard_word: 保存锁对象的原始mark word的拷贝(无锁状态下的哈希码, 分代年龄等). 用于解锁的时候回复锁对象的对象头\nowner: 指向当前锁对象的引用, 用于标识该所记录属于哪个对象\n\n偏向锁 biased lock很多时候不仅不存在多线程竞争, 而且总是由同一个线程多次获取, 这种时候的锁释放和获取带来的不必要的性能开销, 偏向锁也是基于这个情景进行的优化(但是这已经是过去式了, 现在还满足这个情景的应用已经很少了, 在JDK15开始, 偏向锁已经是默认关闭了)\n偏向锁使用了一种等待竞争出现才会释放锁的机制\n第一次访问同步代码块\n\n创建lock record到线程的私有栈帧中, 记录下来锁对象的原始的mark record\n\n对锁对象的mark record进行CAS, 期望值是原始的mark record, 新值是偏向锁结构\n\n再次访问这个同步代码块\n\n对象进入到了偏向锁状态, 后续该线程重入的时候不需要重新CAS, 只需要校验线程ID是否一样\n\n\n\n偏向锁的释放和撤销\n释放: 就是正常的退出了同步代码块, 这个时候不会修改锁对象的Mark Word, 将lock record中的onwer置为null\n撤销: 在锁已经偏向, 其他没有持有偏向锁的线程尝试获取锁的时候被动触发\n\nJVM会在全局安全点(STW的时候)暂停持有锁的线程A, 检查其状态, 并遍历线程栈, 将Mark Word重置为无锁状态\n如果已经退出了同步代码块, 则不改变锁级别, 让线程B竞争偏向锁, 重偏向\n如果还在同步代码块中, 说明发生了竞争, 升级为轻量级锁, 线程B通过自旋竞争\n\n\n\n\n例外情况\n\n原持有线程已经终止了, 对象头中的线程ID失效, JVM将锁重置为无锁状态\n调用锁对象的hashcode()方法的时候会导致锁对象直接升级成重量级锁\n批量重偏向, 批量撤销: 太恶心了, 有需要再去了解\n\n\n轻量级锁多个线程近似地可以看作在不同时段获取同一把锁的时候, JVM采用轻量级锁来避免线程的阻塞和唤醒\n当一个线程获取到一个锁对象发现是轻量级锁的时候, 会将Mark Word复制到Displaced Mark Word中\n\n第一个尝试获取锁的线程\n\n通过CAS自旋来尝试获取锁\n\n检查锁对象是不是无锁状态(01状态码)\n\n是无锁状态, 将Mark Word存入Displaced Mark Word\n\n\n尝试CAS\n\n期望值是Displaced Mark Word\n新值是自己线程的lock record的指针\n设置为轻量锁状态\n\n\n失败了说明锁已经被竞争走了\n\n\n锁的释放\n\n在离开同步代码块的时候, 通过CAS将Displaced Mark Word设置回去\n设置为无锁状态\n\n\n其他尝试竞争锁的线程\n\n\n发现状态位是00, 轻量锁状态\n循环检查状态位是00\n\n\n发现状态位是01, 说明是无锁状态\n复制displaced mark word\n尝试CAS\n\n\n\n\n锁的升级\n\n在某个线程自旋次数超过了阈值的时候(不是CAS的次数), 说明有严重的竞争情况, 将锁升级成重量级锁\n\n 自适应轻量级锁\n\n自旋的次数会动态自适应变化, JVM根据自旋获取锁的成功率, 如果成功率高, JVM就会认为该锁自旋锁获取到的可能性很大, 就会增加自旋的次数. 反之自旋很少获取到锁, 就会减少自旋次数, 以防止浪费时间, 速速进入到重量级锁阶段\n重量级锁在存在线程在竞争锁的时候, 并且轻量级锁阶段自旋超过了指定的次数, 就进入到了重量锁阶段\n将mark word更新为指向monitor状态位10\n重量级锁是悲观锁, 也就是获取锁失败的线程会进入到阻塞状态\n重量级锁主要维护两个队列\n\nContention List: 所有请求锁的线程都会被放到这个队列中\nEntry List: 已经被唤醒的队列\nWait List: 被wait的队列, 等待被唤醒\nOwner: 指向获取了锁的线程\n\n虽然维护了队列, 但是JVM并不会按照顺序获取下一个要执行的线程, 而是随机挑选, 是非公平锁\n\n优点: 增大了吞吐量\n缺点: 可能会导致饥饿现象\n\n锁粗化在使用同步锁的时候, 我们会将同步锁的作用范围限制到尽量小的范围, 更有利于锁的释放, 但是如果存在连串的一系列操作都是对一个对象反复加锁和解锁, 频繁的互斥同步操作带来的不必要的性能开销\npublic static String test04(String s1, String s2, String s3) &#123;    StringBuffer sb = new StringBuffer();    sb.append(s1);    sb.append(s2);    sb.append(s3);    return sb.toString();\n\n上面连续的append, JVM会检测到这是一连串针对一个相同对象的加锁解锁, JVM就会将锁的范围粗化到整个一系列操作的外部, 使这三次的append操作都只需要加锁解锁一次\n锁消除JIT会对一些要求同步, 但是被检测到不可能存在共享数据竞争的锁进行消除, JVM会判断再一段程序中的同步明显不会逃逸出去从而被其他线程访问到，那JVM就把它们当作栈上数据对待，认为这些数据是线程独有的，不需要加同步。此时就会进行锁消除\n当然在实际开发中，我们很清楚的知道哪些是线程独有的，不需要加同步锁，但是在Java API中有很多方法都是加了同步的，那么此时JVM会判断这段代码是否需要加锁。如果数据并不会逃逸，则会进行锁消除。比如如下操作：在操作String类型数据时，由于String是一个不可变类，对字符串的连接操作总是通过生成的新的String对象来进行的。因此Javac编译器会对String连接做自动优化。在JDK 1.5之前会使用StringBuffer对象的连续append()操作，在JDK 1.5及以后的版本中，会转化为StringBuidler对象的连续append()操作。\npublic static String test03(String s1, String s2, String s3) &#123;    String s = s1 + s2 + s3;    return s;&#125;\n\n","categories":["Java","Java进阶","JUC并发编程"],"tags":["八股文","面试","并发编程","synchronized","同步锁","对象锁","类锁","可重入锁","偏向锁","轻量级锁","重量级锁"]},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/BlockingQueue/","content":""},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ConcurrentLinkedQueue/","content":""},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/ConcurrentHashMap/","content":""},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/CopyOnWriteArrayList/","content":""},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/3_%E6%A0%88%E8%99%9A%E6%8B%9F%E6%9C%BA/","content":"栈虚拟机虚拟机栈方法调用和执行过程中的数据(如局部变量和中间值)会存储在栈(操作数栈)中, 字节码指令操作这些数据, 然后程序执行逻辑\n\nJVM在执行代码的时候, 会将main方法对应的栈帧压进虚拟机栈, 一个栈帧包括了\n\n局部变量表 : 存在堆中\n方法返回地址\n操作数栈 : 从字节码执行引擎获取指令和数据\n动态链接\n一些附加信息\n\n在Java中每一个线程都有自己的虚拟机栈, 是线程私有的. 方法调用的时候都会创建一个新的栈帧, 该栈被推进虚拟机栈, 成为当前活动栈帧\n\n入栈 : 方法调用的时候, 虚拟机栈会为这个方法分配一个栈帧, 这个栈帧会被压入到虚拟机栈, 成为当前的活动栈帧, PC寄存器指向当前栈帧的指令, 执行方法的指令序列从该地址开始\n出栈 : 方法执行完成以后, 对应的栈帧会被移除, 控制权回到前一个栈帧, 前一个栈帧中的返回值成为当前活动栈帧的一个操作数, 继续执行\n\n操作数栈操作数栈用于保存方法执行时的中间结果, 参数和返回值, 被用于执行各种字节码指令\n比如执行两个数相加的指令就是将两个操作数从操作数栈中弹出, 然后相加, 将结果压入操作数栈中\n操作数栈的生命周期和方法的生命周期是一样的, 方法执行完毕以后, 操作数栈也会被销毁\n"},{"title":"Java类文件结构详解 - 字节码格式与解析","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/2_Java%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/","content":"Java类文件结构一个简单的例子public class Main &#123;    private int m;    private String[][] str;    public int inc() &#123;        return m + 1;    &#125;&#125;\n\n\n反编译以后的结果\n\nClassfile /G:/Desktop/just4learn/src/main/java/com/func/JVM/Main.class  Last modified 2025年3月31日; size 315 bytes  SHA-256 checksum 542e6bc916453b34e2baebf6d02c704a8984922a0a7e42ebc902d174266d1109  Compiled from &quot;Main.java&quot;public class com.func.JVM.Main  minor version: 0  major version: 61  flags: (0x0021) ACC_PUBLIC, ACC_SUPER  this_class: #8                          // com/func/JVM/Main  super_class: #2                         // java/lang/Object  interfaces: 0, fields: 2, methods: 2, attributes: 1Constant pool:   #1 = Methodref          #2.#3          // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Class              #4             // java/lang/Object   #3 = NameAndType        #5:#6          // &quot;&lt;init&gt;&quot;:()V   #4 = Utf8               java/lang/Object   #5 = Utf8               &lt;init&gt;   #6 = Utf8               ()V   #7 = Fieldref           #8.#9          // com/func/JVM/Main.m:I   #8 = Class              #10            // com/func/JVM/Main   #9 = NameAndType        #11:#12        // m:I  #10 = Utf8               com/func/JVM/Main  #11 = Utf8               m  #12 = Utf8               I  #13 = Utf8               str  #14 = Utf8               [[Ljava/lang/String;  #15 = Utf8               Code  #16 = Utf8               LineNumberTable  #17 = Utf8               inc  #18 = Utf8               ()I  #19 = Utf8               SourceFile  #20 = Utf8               Main.java&#123;  private int m;    descriptor: I    flags: (0x0002) ACC_PRIVATE  private java.lang.String[][] str;    descriptor: [[Ljava/lang/String;    flags: (0x0002) ACC_PRIVATE  public com.func.JVM.Main();    descriptor: ()V    flags: (0x0001) ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return      LineNumberTable:        line 14: 0  public int inc();    descriptor: ()I    flags: (0x0001) ACC_PUBLIC    Code:      stack=2, locals=1, args_size=1         0: aload_0         1: getfield      #7                  // Field m:I         4: iconst_1         5: iadd         6: ireturn      LineNumberTable:        line 19: 0&#125;SourceFile: &quot;Main.java&quot;\n\n魔数.class文件的前四个字节 : cafe babe\n版本号紧跟着魔数的四个字节就是副版本号和主版本号0000 0037\n常量池紧接着版本号之后就是常量池, 里面存储了字段, 方法, 类, 接口的符号引用和常量\n常量类型字面量\n\n\nTag\ntag对应的十六进制编码\n类型\n\n\n\nCONSTANT_Integer_info\n0x03\nint 类型字面量\n\n\nCONSTANT_Float_info\n0x04\nfloat 类型字面量\n\n\nCONSTANT_Long_info\n0x05\nlong 类型字面量\n\n\nCONSTANT_Double_info\n0x06\ndouble 类型字面量\n\n\n如public final long ong = Long.MAX_VALUE;, 在字节码中就是05 7f ff ff ff ff ff ff ff\n字符串类型字面量通过tag length stringArray的形式记录数据\n\n\n\nTag\ntag对应的十六进制编码\n类型\n\n\n\nCONSTANT_String_info\n0x08\n字符串字面量\n\n\nCONSTANT_Uft8_info\n0x01\n字符串\n\n\nCONSTANT_Uft8_info的直接存储stringArray, 也代表代码中的字符串常量比如”hello”\n\n而CONSTANT_String_info存储索引, 通过索引找对应的CONSTANT_Uft8_info\ns &#x3D; “hello”\n\n方法类字段类型字面量通过下面这种格式来记录数据\n如果是\n对于CONSTANT_Fieldref_info, CONSTANT_Classref_info, CONSTANT_Methodref_info\nCONSTANT_*ref_info &#123;  u1 tag;  u2 class_index;  u2 name_and_type_index;&#125;\n\n\ntag : 标识符, CONSTANT_Fieldref_info为0x09, CONSTANT_Methodref_info 为0x0a, CONSTANT_InterfaceMethodref_info为0x0b\nclass_index : 是这个字段 | 方法 | 接口方法所在的类信息的索引\nname_and_type_index : 为CONSTANT_NameAndType_info的常量池索引, 拿CONSTANT_Fieldref_info来说就是字段名和字段类型, 拿CONSTANT_Methodref_info就是方法名, 方法参数和返回值类型.\n\n\n\n\ntag\n十六级进制编码\n类型\n\n\n\nCONSTANT_MethodHandle_info\n0x0f\n方法句柄\n\n\nCONSTANT_MethodType_info\n0x10\n方法类型\n\n\nCONSTANT_InvokeDynamic_info\n0x12\n动态调用点\n\n\nCONSTANT_Fieldref_info\n0x09\n字段\n\n\nCONSTANT_Methodref_info\n0x0a\n普通方法\n\n\nCONSTANT_InterfaceMethodref_info\n0x0b\n接口方法\n\n\nCONSTANT_Class_info\n0x07\n类或接口的全限定名\n\n\n访问标记紧跟着常量池后面的就是访问标记, 用来记录这个类的访问信息, 是不是final, 是不是abstract等访问标记\n\n\n\n标记位\n标识符\n描述\n\n\n\n0x0001\nACC_PUBLIC\npublic 类型\n\n\n0x0010\nACC_FINAL\nfinal 类型\n\n\n0x0020\nACC_SUPER\n调用父类的方法时，使用 invokespecial 指令\n\n\n0x0200\nACC_INTERFACE\n接口类型\n\n\n0x0400\nACC_ABSTRACT\n抽象类类型\n\n\n0x1000\nACC_SYNTHETIC\n标记为编译器自动生成的类\n\n\n0x2000\nACC_ANNOTATION\n标记为注解类\n\n\n0x4000\nACC_ENUM\n标记为枚举类\n\n\n0x8000\nACC_MODULE\n标记为模块类\n\n\n比如一个public enum类型的访问标记就是0x4031\n\n0x4000 : 枚举类\n0x0010 : final类型\n0x0020 : 现代JVM的标准标志\n0x00001 : public访问修饰符\n\n类索引, 父类索引, 接口索引这部分用来确定类的继承关系, this_class为当前类索引, super_class为父类的索引, interface_class为接口\n这三个会分别存储指向CONSTANT_Class_info的索引\n字段表一个类中的所有字段会存储在字段表中\nfield_info &#123;    u2 access_flag;    us name_index;    u2 description_index;&#125;\n\n\naccess_flag为字段的访问标记\nname_index指向常量池中的CONSTANT_Utf8_info\ndescrition_index为字段的描述类型索引, 也指向常量池中的CONSATNT_Utf8_info, 针对不同的数据类型, 有不同规则的描述信息\n对于基本数据类型而言, 会使用一个字符来表示, 比如I对应的就是int, B对应的就是byte\n对于引用数据类型来说, 使用L ***;来表示, 比如字符串类型就是Ljava/lang/String;\n对于数组来说, 会用一个前置的[表示, 比如一个String数组就是[Ljava/lang/String;\n\n\n\n方法表和字段表类似, 用来存储方法的信息, 比如方法名, 方法参数, 方法签名等\n\n属性表记录额外信息, 比如常量值属性, 记录的就是final字段的编译时常量值, Code属性 : 方法的字节码指令, 操作数栈大小, 局部变量大小等\n\n\n","categories":["Java","Java进阶","JVM"],"tags":["八股文","面试","JVM","类文件结构","字节码","class文件","常量池","访问标志"]},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/4_%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E8%AF%A6%E8%A7%A3/","content":""},{"title":"JVM类加载机制详解 - 从字节码到内存的完整过程","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/1_JVM%E7%9A%84%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","content":"JVM的类加载机制JVM怎么识别出来是class格式的文件00000000: cafe babe 0000 0034 0022 0700 0201 0019  .......4.&quot;......00000010: 636f 6d2f 636d 6f77 6572 2f6a 6176 615f  com/cmower/java_00000020: 6465 6d6f 2f54 6573 7407 0004 0100 106a  demo/Test......j00000030: 6176 612f 6c61 6e67 2f4f 626a 6563 7401  ava/lang/Object.00000040: 0006 3c69 6e69 743e 0100 0328 2956 0100  ..&lt;init&gt;...()V..00000050: 0443 6f64 650a 0003 0009 0c00 0500 0601  .Code...........00000060: 000f 4c69 6e65 4e75 6d62 6572 5461 626c  ..LineNumberTabl\n\n这是一个class文件在十六进制的内容, 前两个字节cafe babe就是著名的”魔数”, 是JVM识别.class文件的标志(.class只是为了方便给人识别的后缀, 对于程序来说是没有意义的)\n类记载机制类从被加载到JVM, 到卸载出内存, 整个生命周期共有七步\n加载, 验证, 准备, 解析, 初始化, 使用, 卸载\n其中 验证, 准备, 解析 三个步骤统称为连接, 前五个步骤就是JVM的类加载过程\n1. Loading(载入)该阶段将字节码从不同的数据源中(.class文件, jar包…)转化成二进制字节流加载进内存中, 并生成一个代表该类的java.lang.Class对象\n2. Vertification (验证)JVM在该阶段会对二进制字节流进行校验, 只有符合JVM字节码规范的才能被JVM正确执行\n\n确保二进制字节流符合预期(比如以cafe babe开头)\n是否所有的方法都遵循访问控制关键字的限定\n方法调用的参数个数和类型是否正确\n确保变量在使用之前被正确初始化了\n检查变量是否被赋予恰当类型的值\n…\n\n3. Preparation (准备)这个阶段JVM会对类变量(也就是static修饰的变量)分配内存并初始化, 对应数据类型的默认初始值\npublic String str1 = &quot;asd&quot;;public static String str2 = &quot;adada&quot;;public static final String str3 = &quot;asdf&quot;;\n\n\nstr1变量不会被分配内存, 因为不是类变量\nstr2会被分配内存, 但是值是null\nstr3会被分配内存, 同时值是”asdf”\n\nstatic final修饰的变量是常量, 会在准备阶段就赋值\n4. Resolution (解析)该阶段将常量池中的符号引用转化成直接引用\n符号引用\n\n是类, 字段, 方法, 接口等的全限定名, 比如com.func.Person\n在编译阶段生成, 存储在编译后的字节码文件的常量池中\n不依赖于具体的内存地址\n\n直接引用\n\n直接指向目标的指针, 相对偏移量或者能间接定位到目标的句柄\n在运行的时候JVM的解析阶段生成, 也可以是在运行阶段需要使用这个引用的时候生成\n依赖于JVM的具体内存布局, 直接指向了内存地址或者偏移量\n\n不发生动态加载的情况下, 在编译完毕以后, 实际上代码中的引用是会被翻译成符号引用的, 用于唯一索引到对应的类, 接口, 字段, 方法上, 然后在JVM类加载过程中的解析步骤, JVM会将符号引用替换成指向内存中的实例对象的直接引用, 同时因为是静态加载, 就能将一个符号解析的结果缓存起来\n如果有动态加载, 会在需要使用这个引用的时候将符号引用加载成直接引用, 指向内存中的class或者其元数据\n解析阶段解析的内容有\n\n对类和接口的解析\n对类方法的解析\n接口方法的解析\n字段解析\n\n5. Initialization (初始化)在准备阶段, 赋予的值是类型默认值, 在这个阶段会完成为变量赋值代码期望赋予的值, 在初始化阶段执行类构造器方法\n初始化的时机有\n\n创建类实例的时候\n访问类的静态方法或静态字段的时候(除了final常量, 因为它们在编译阶段就被放进了常量池)\n使用java.lang.reflect包的方法对类进行反射调用的时候\n初始化一个类的子类(首先会初始化父类)\nJVM启动的时候, MAIN方法类会被初始化\n\n类加载器JVM通过类加载器和这个类本身一同确定其唯一性, 也就是如果两个类来自于同一个字节码, 但是是通过不同的类加载器加载出来的, 不是同一个类\n类加载器分成四种\n\n引导类加载器 (Bootstrap ClassLoader) : 负责JVM基础核心类库, 比如rt.jar, sum.bott.class.path路径下的类\n扩展类加载器 (Extension ClassLoader) : 负责加载Java扩展库中的类, 比如jre&#x2F;lib&#x2F;ext目录下的类或者有系统属性java.ext.dirs指定位置的类(ClassLoader的类名是PlatformClassLoader)\n系统(应用)类加载器 (System ClassLoader) : 负责加载系统类路径 java.class.path指定的类库, 通常是应用类或者第三方类库(ClassLoader的类名是AppClassLoader)\n用户自定义的类加载器, 通过继承java.lang.ClassLoader来实现\n\n双亲委派模型简单来说就是, 类加载器在加载一个类的时候, 会首先尝试将这个类委派给自己的父加载器去加载, 只有在父加载器无法加载此类的时候, 子加载器才会尝试自己的加载, 同时这个委派过程是递归的, 也就是如果我们要使用应用类加载器去加载一个类, 最后会递归到引导类加载器加载\n这种机制能确保不会重复加载类, 同时保证了类加载器之间的优先级关系, 保护了Java核心API不会被恶意替换\n","categories":["Java","Java进阶","JVM"],"tags":["八股文","面试","JVM","字节码","class文件","类加载机制","魔数","双亲委派","类加载器"]},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/5_%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E6%A0%88%E5%B8%A7%E7%BB%93%E6%9E%84/","content":"栈帧内存结构局部变量表存储方法的参数和局部变量, 由基本数据类型和对象引用(每个方法都有一个特殊的指针this, 也就是每个方法的最小的局部变量的数量是1个)构成\n在编译的时候, 局部变量表的最大容量就已经确定了, 通过方法的Code属性的Maximum Local variables. \n同时局部变量的容量最小单位是slot(槽位), 一个槽位可以容纳32bit(4byte)的数据类型, 也就是一个double(64bit)类型的变量, 占用两个slot\npublic void slot(int age)&#123;    double d = 10.0;&#125;\n\n这个方法的局部变量表大小是4\n同时局部变量的数量是会在运行的时候发生变化的(因为变量会在运行的时候随着作用域被创建和销毁)\npublic void test() &#123;    &#123; // 注释中的是代码运行到这一行的时候, 局部变量表的大小        // 1        String name = &quot;hello&quot;;        // 2    &#125;    // 1    &#123;        // 1        int age = 10;        // 2    &#125;&#125;\n\n操作数栈栈结构, 用于存储数据和和中间计算结果\n和局部变量表一样, 操作数栈的最大大小在编译的时候也被确定了, 在方法的Code属性中 Maximum stack size, 因为操作数的占用的槽位是确定的, 字节码指令的栈效应是可预测的, 也就能计算出来这个方法需要用到的最大的操作数栈深度\n当一个方法开始执行的时候, 操作数栈是空的, 在运行的时候, 随着指令的运行, 会不断向操作数栈中压入数据和取出数据执行操作\n动态链接关联到方法所属了类的常量池, 支持多态方法的核心机制\n每个栈帧都包含了一个指向运行时常量池中该栈帧所属方法的引用, 持有这个引用的目的时为了支持方法调用过程中的动态链接\n\n方法区是JVM运行时内存区域, 属于逻辑定义\n运行时常量池时方法区的一部分, 用于存放编译期间生成的各种字面量个符号引用-在类加载后进入运行时常量池\n\n从字节码的角度来看, 多态地调用方法是完全一样的, 但是最后调用的方法不一样\nman.sayHello()（第 10 行）和 woman.sayHello()（第 12 行）对应的字节码都是invokevirtual #6 &lt;com/.../DynamicLinking$Human.sayHello\n关键在于invokevirtual指令入手, 这个指令在运行的时候解析过程可以分成以下几步\n\n找到操作数栈顶的元素所指向的对象的实际类型, 记作C\n找到以后, 进行访问权限校验, 通过则返回这个方法的直接引用, 否则java.lang.IllegalAccessError\n否则按照继承关系向上找C的父类\n如果始终没有找到合适的方法, 抛出java.lang.AbstractMethodError\n\n方法返回地址记录方法结束后控制流应该返回的位置\n方法执行以后有两种方式退出\n\n正常退出, 有可能将返回值传递给上层方法的调用者, 方法是否有返回值和返回值的类型根据返回的字节码指令来定 ireturn 用于返回 int 类型，return 用于 void 方法；还有其他的一些，lreturn 用于 long 型，freturn 用于 float，dreturn 用于 double，areturn 用于引用类型。\n异常退出, 如果没有得到妥善的处理, 这种时候不会给上层的调用者提供返回值\n\n方法正常退出的时候, PC计数器的值会作为返回地址, 栈帧中很可能会保存这个计数器的值, 异常退出时则不会\n方法退出以后就是将当前活动栈帧出栈, 然后\n\n恢复上层方法的局部变量表和操作数栈\n把返回值压入调用者栈帧的操作数栈中\n调整PC计数器的值, 找到下一条要执行的指令\n\n附加信息虚拟机规范允许具体的虚拟机实现增加一些规范里没有描述的信息到栈帧中, 例如与调试相关的信息, 这部分信息完全取决于具体的虚拟机的实现. 实际开发中, 一般会把动态链接, 方法返回地址与附加信息归为一类, 称为栈帧信息\n"},{"title":"JVM运行时数据区详解 - 内存结构与分配机制","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/6_%E6%B7%B1%E5%A6%82%E7%90%86%E8%A7%A3%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/","content":"JVM运行时数据区程序计数器每个线程都有自己的私有的PC(Program Counter), \n线程执行的是非本地方法, PC指向下一条将要运行的指令(准确来说是, 在执行指令的时候, PC指向下一条将要运行的指令, 在其他任意时刻, 指向的是下一条要运行的指令)\n线程执行的是本地方法的时候, PC的值是undefined, 因为本地方法不是在JVM中运行的, 往往是通过C&#x2F;C++实现\n虚拟机栈这个在深入理解栈帧里面有详细说明\n本地方法栈区别于虚拟机栈, 本地方法栈为虚拟机使用到的本地方法服务\n堆堆区是所有线程共享的一块区域, 用来存储对象(静态变量在堆中)\nJava中的几乎所有对象都是在堆中存储的\n\n为什么不是所有?\n\n现代JVM默认开启逃逸分析, 如果某些方法中的对象或者引用没有在方法之外被使用过(也就是没有逃逸), 这个时候就会将对象存储在虚拟机栈中的局部变量空间\n堆区最容易出现的错误就是OOM(Out of Memory), 有两种表现形式\n\nOutOfMemoryError : GC Overhead Limit Exceed: 当JVM花太长时间执行垃圾回收还没有回收到多少内存的时候就会发生\njava.lang.OutOfMemoryError: Java heap space: 堆中的空间不足够申请的新的对象, 和配置的虚拟机的堆内存有关\n\n字符串常量池在堆区中, 在jdk1.6的时候在永久代中, 从1.7开始就被迁移到了堆区\n垃圾回收为了进行高效的垃圾回收, 虚拟机把堆内存在逻辑上分成三块 (分代的唯一理由就是优化GC性能)\n\n新生代 : 新对象和没有达到一定年龄的对象都在新生代\n老年代 : 被长时间使用的对象, 老年代的内存空间应该比年轻代要大\n元空间 : 像一些方法中的操作临时对象等\n\n新生代创建新对象的时候会被分配到年轻代内存区域, 直到这个区域的空间被占满或者达到某个阈值, 就会执行垃圾收集. 这种垃圾收集被称作 Minor GC.\n年轻代被分成了三个部分, 伊甸园(Eden Memory), 两个幸村区(Survivor Memory, 被称为from&#x2F;to或s0&#x2F;s1). 默认比例是8:1:1\n\n大多数新创建的对象都在Eden内存空间\n当Eden空间被对象填充时, 会执行Minor GC, 并将所有的幸存者对象移动到另一个幸存者空间\nMinor GC检查幸存者对象, 并将它们移动到另一个幸存者空间, 所以总是有一个幸存者空间是空的\n如果幸存者空间满了, 无法容纳从Eden区存活下来的对象, 这些存活的对象会直接被提升到老年代, 即使还没有达到晋升需要的年龄, 如果进一步老年代空间也不能容纳, 就会触发Full GC, 导致整个Java堆内存都被回收\n经过多次GC循环后存活下来的对象被移动到老年代, 通常这是通过设置年轻一代对象的阈值来是实现的, 然后它们才有资格提升到老年代\n\n老年代旧的一代内存包含那些经过许多轮小型GC后仍然存活的对象, 通常垃圾收集是在老年代内存满的时候执行的, 老年代垃圾收集被称为 主GC(Major GC)\n大对象直接进入到老年代(需要大量连续内存的对象), 能避免在Eden区和Survivor区之间发生大量的内存拷贝\n\n对象在堆内的生命周期\n当创建一个对象的时候, 对象会被优先分配到新生代的Eden区, 此时JVM会给对象定义一个对象年轻计数器 (-XX:MaxTenuringThreshold)\n当Eden空间不足的时候, JVM将会执行新生代的垃圾回收\nJVM会把存货的对象转移到Survivor中, 并对象年龄+1\n对象在Survivor中同样也会经历Minor GC, 每经历一次以后年龄+1\n\n\n年龄达到15次以后(默认标志)就会被分配到老年代\n当分配的对象超过了 -XX:PetenureSizeThreshold, 对象会直接被分配到老年代, 也就是大对象\n\n方法区(永久代&#x2F;元空间)永久代和元空间都是对于方法区的一个实现\n永久代是在JVM内存中的, 元空间直接使用的是操作系统的内存而不是JVM内存\n在元空间数据增长的时候, 会从操作系统申请内存, 也就是在这一步, 元空间增长也会导致操作系统层面的OOM\n内部结构方法区用于存储已被虚拟机加载的类型信息, 常量, 即时编译器编译后的代码缓存等\n.class文件中有常量池, 在运行的时候, 将class文件中的常量池加载到内存中\n类型信息对于每个加载的类型, JVM都必须在方法区存储以下类型信息\n\n类型的全限定类名\n类型的直接父类全限定类名\n类型的修饰符\n类型直接接口的一个有序列表\n\n字段信息\nJVM必须在方法区中保存类型的所有字段的相关信息和声明顺序\n字段的相关信息 : 字段名称, 字段类型, 字段的修饰符(这里也能从Java类文件结构看到)\n\n方法信息\n方法名称\n方法参数的数量和类型\n方法的返回类型\n方法的修饰符\n方法的字符码, 操作数栈, 局部变量表及大小\n异常表\n\n","categories":["Java","Java进阶","JVM"],"tags":["八股文","面试","JVM","运行时数据区","程序计数器","虚拟机栈","堆内存","方法区","内存模型"]},{"title":"JVM垃圾回收机制深入解析 - GC算法与原理详解","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/7_%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/","content":"深入理解JVM中的垃圾回收机制判断一个对象是否可以被回收引用计数法给对象添加一个引用计数器, 当对象增加一个引用的时候计数器加1, 引用失效的时候计数器减1, 当计数器等于0的时候该对象可回收\n但是这个方法无法解决两个对象循环引用的情况, 这种情况两个对象的引用计数器永远不为0\n也正是这个致命的原因, Java不使用引用计数法\n可达性分析算法从GC Roots为起始点进行搜索, 能够达到的对象都是存活的, 不可达的对象回收, 更具体地说, GC Roots实际上是现在可用的需要用的引用的集合, 通过这些引用我们就能达到我们目前需要使用的所有对象, 从而判定出来不可达的对象就是不可用的, 需要回收的\nGC Roots一般包含以下内容\n\n虚拟机栈中引用的对象\n本地方法栈中引用的对象\n方法区中类静态属性引用的对象\n方法区中常量引用的对象\n\n引用类型强引用被强引用关联的对象不会被回收\n使用new一个新对象的方式创建强引用\nObject obj = new Object();\n\n软引用被软引用关联的对象只有在内存不够的情况下才会被回收\n使用SoftReference类来创建软引用\nObject obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null;\n\n弱引用被弱引用关联的对象, 会在下一次垃圾回收的时候被回收\n使用WeakReference来创建弱引用\nObject obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null;\n\n虚引用和对象被回收的时机无关, 被虚引用关联的对象唯一的特殊点就是被回收的时候会收到一个系统通知\n通过PhantomReference\nObject obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj);obj = null;\n\n垃圾回收算法1. 标记- 清除\n将存活的对象标记, 清理掉没有被标记的对象\n不足\n\n标记和清除的效率不高\n会产生大量的不连续内存碎片\n\n2. 标记 - 整理\n让所有存活的对象都向一端移动, 清除掉端边界外以外的内存\n3. 复制\n将内存划分成两块, 每次只使用其中一块, 当这一块用完了, 就将这块上还存活的对象复制到另一块上, 对这一块进行清理\n现代虚拟机都通过这种方法来回收新生代\n4. 分代收集根据对象存活周期将内存划分成几块, 不同块采用不同的收集算法\n\n新生代 : 复制算法\n老年底 : 标记-清除或标记整理算法\n\n垃圾收集器单线程与多线程 : 垃圾处理器只使用一个线程还是多个线程垃圾收集\n串行和并行 : 垃圾收集程序会阻塞用户程序, 并行指垃圾收集程序和用户程序同时执行\n1. Serial收集器串行单线程的收集器, 拥有最高的单线程收集效率\n是Client模式下的默认新生代垃圾收集器, 因为用户桌面应用场景下, 分配给虚拟机管理的内存一般不是很大, 而Serial收集器在收集小内存(几十兆或一两百兆)时候的表现很不错, 可以将阻塞时间控制在100多毫秒以内\n2. ParNew收集器Serial收集器的多线程版本\nServer模式下的虚拟机首选的新生代收集器, 除了性能原因主要是除了Serial只有它能和CMS收集器配合工作\n默认开启的线程数量与CPU数量相同, 可以使用-XX:ParallelGCThreads参数来设置线程数\n3. Parallel Scavenge收集器多线程收集器\n比起其他收集器关注缩短垃圾收集的时候用户线程阻塞的时间, 它的目标是达到一个可控制的吞吐量, 吞吐量优先收集器(CPU运行用于代码时间&#x2F;总时间)\n阻塞时间越短越适合需要和用户交互的程序, 高吞吐量则可以高效利用CPU时间, 尽快完成程序, 适合在后台运算不需要太多交互的任务\n缩短停顿时间是以牺牲吞吐量和新生代空间换取的, 新生代空间变小, 垃圾回收变频繁, 吞吐量下降\n4. Serial Old收集器Serial收集器的老年代版本, 也是给Client模式下的虚拟机使用, 如果是在Server模式下, 它有两个用途\n\n作为CMS收集器的后备预案, 在并发收集产生Concurrent Mode Failure时使用\n在 JDK 1.5 以及之前版本(Parallel Old 诞生以前)中与 Parallel Scavenge 收集器搭配使用\n\n5. Parallel Old 收集器Parallel Scavenge收集器的老年代版本, 注重吞吐量和CPU资源敏感的场合, 都可以优先考虑Parallel Scvenge + Parallel Old收集器\n6. CMS收集器(Concurrent Mark Sweep), Mark Sweep指的是标记 - 清除算法\n\n初始标记: 仅仅是标记一下GC Roots能够直接关联的对象, 速度很快, 需要停顿\n并发标记: 进行GC Roots Tracing的过程, 在整个回收过程中耗时最长, 不需要停顿\n重发标记: 为了修正并发标记期间因为用户程序继续运行导致的标记产生了变动的那一部分对象的标记, 需要停顿\n并发清除: 不需要停顿\n\n缺点\n\n吞吐量低: 低停顿时间的代价就是低吞吐量\n无法处理浮动垃圾: 浮动垃圾指的是并发清除阶段, 因为用户线程继续运行而產生的垃圾, 這些垃圾只能下一次GC的時候才能回收, 因為浮動垃圾的存在, 因此需要預留一部分內存, 而不是像其他的收集器那樣等待老年代快滿了再回收. 如果預留的內存不夠存放浮動垃圾, 就會出現Concurrent Mode Failure 這個時候就會啟動Serial Old來代替CMS, 並且觸發一次Full GC\n空间碎片导致无法找到足够大的连续空间分配大对象, 不得不提前触发一次Full GC\n\n7. G1收集器一款面向服务端的垃圾收集器\nG1收集器将堆分成多个大小相等的独立区域, 新生代和老年代不再隔离\n每个小空间单独进行垃圾回收, 通过这个区域概念, 使得可预测的停顿时间模型成为可能. 通过记录每个区域垃圾回收时间和所获得的空间, 并维护一个优先列表, 每次根据允许的收集时间, 优先回收价值最大的区域\n 每个区域都有一个Remembered Set, 用来记录这个区域对象的引用对象所在的区域, 从而实现了局部可达性分析, 在做可达性分析的时候不再需要全堆扫描\nG1收集器运作大致分成\n\n初始标记\n并发标记\n最终标记 :  为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。\n筛选回收 : 会停顿用户线程, 首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率\n\n优点\n\n空间整合: 整体来看是基于“标记 - 整理”算法实现的收集器，从局部(两个 Region 之间)上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。\n\n可预测的停顿: 能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。\n\n\n内存分配和回收策略Minor GC, Major GC, Full GC\n部分收集: 不是完整收集整个Java堆的垃圾收集\n新生代收集 (Minor GC&#x2F; Young GC): 只是新生代的垃圾收集\n老年代收集 (Major GC&#x2F;Old GC): 只是新生代的垃圾收集\n只有CMS GC有单独收集老年代的行为\n很多时候Major GC会和Full GC混用\n\n\n\n\n混合收集 (Mixed GC): 收集整个新生代和部分老年代\n只有G1\n\n\n整堆收集 : 收集整个Java堆和方法区的垃圾\n\n空间分配担保在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。\n如果不成立的话虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那么就要进行一次 Full GC。\nFull GC的触发条件\n调用System.gc(), 建议虚拟机执行Full GC, 但是不一定会执行\n老年代空间不足 : 可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。\nConcurrent Mode Failure : 会触发Full GC\n空间分配担保失败\n\n","categories":["Java","Java进阶","JVM"],"tags":["八股文","面试","JVM","垃圾回收","GC","可达性分析","引用计数","GC Roots","标记清除","复制算法","标记整理"]},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/8_%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/","content":""},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/9_JVM%E8%B0%83%E4%BC%98/","content":"JVM调优1. 新生代中Eden区域和Survivor比例调优默认的比例是8:1:1\n需要调整的情况\n过早的晋升现象频繁发生, 说明Survivor空间不足\nMinor GC频繁异常: 说明Eden区域太小了, 频繁填满Eden区域, 较少但耗时长的Minor GC说明Eden区域太大了\n老年代频繁Full GC: 可能是因为对象过早晋升导致老年代填充过快\n应用特性不匹配: 应用程序主要产生大量短生命周期对象, 就需要更大的Eden, 中等生命周期对象, 需要更大的Survivor\n\n参数通过-XX:SurvivorRatio来设置, 比如-XX:SurvivorRatio=6设置Eden:S1:S2 &#x3D; 6:2:2\n通过监控GC频率变化情况和对象晋升率变化\n"},{"title":"JVM基础 - JDK、JRE、JVM关系详解","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/JVM/","content":"JVM, JDK, JRE之间的关系JDK\nJava Development Kit : Java开发工具包\n\n\n里面包含了JRE, 有开发工具包括编译工具(javac.exe), 打包工具(jar.exe)等工具\n\nJRE\nJava Runtime Environment : Java运行环境\n\n\n是JDK的子集, JRE提供了库, Java虚拟机, 和其他组件\n\nJVM\nJava Virtual Machine : Java虚拟机\n\n\n一个虚拟出来的计算机, 负责把Java程序生成的字节码文件, 解释成具体系统平台上的机器指令\n\nClient模式, Server模式\nJVM的不同启动模式\n\n\nClient模式, 启动速度更快, 用于运行GUI交互程序A\nJIT的编译阈值较高, 倾向于解释运行\n编译优化的程度更低, 更适合于注重启动性能而非长期运行性能\n\n\nServer模式, 启动速度慢, 但是运行起来更快. 用于运行服务器后台程序\nJIT的编译阈值更低, 倾向于编译运行, \n编译优化的程度更高, 能执行更全面的优化, 比如方法内联, 循环展开, 逃逸分析等\n因为执行了更多的编译优化, 长期运行的性能是更好的\n\n\n\nJVM结构和执行器\nClass Loader : 类装载器是用于记载类文件的一个子系统, 其主要功能是 \nloading(加载), linking(链接), initialization(初始化)\n\n\nJVM MEmory Areas \n方法区\n堆区\n栈区\n程序计数器\n\n\nInterpreter (解释器) : 通过预定义的JVM指令到机器指令映射, JVM解释器可以将每个字节码转化为相应的本地指令, 直接执行字节码, 不做任何优化\nJIT Compiler(即时编译器) : JIT执行一段代码而不是一句代码, 有了足够的上下文, 我们就有空间优化这段代码到机器码, 通过JIT我们能获取优化后的机器码 (默认开启)\n\n类加载本章要点\nJVM类字节码 : 源代码通过编译器编译成字节码, 再通过类加载子系统进行加载到JVM中运行\nJVM字节码增强技术 : 对现有字节码进行修改或者动态生成字节码文件的技术, 也是实现代理模式对等的核心机制\nJVM类加载机制 : 详解Java类的加载过程\n\n","categories":["Java","Java进阶","JVM"],"tags":["八股文","面试","JVM","JDK","JRE","Java虚拟机","Client模式","Server模式","JIT编译"]},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/JVM/JVM%E5%9F%BA%E7%A1%80-%E7%B1%BB%E5%AD%97%E8%8A%82%E7%A0%81/","content":"类字节码里有什么?\n在初入JVM之际, 并且计算机的基础不够的前提下, 深入地了解JVM不会是一个明智的选择, 会在细节中迷失, 在旅途的开始, 更值得关注的是自子而下的结构以及各个部分的作用, 它们共同决定了什么\n\n字节码文件的作用是什么\n什么是字节码文件? 就是.class结尾的文件\n\n\nclass文件是java代码和cpu能执行的指令之间的中间层\n\njava代码经过编译器以后, 会被编译成class文件\nclass文件再被交给JVM读取执行, 而JVM会根据具体的平台将字节码翻译成具体的指令\n\n\nJVM已经不再支持Java了, 衍生出来了很多的基于JVM的编译语言\n\nKotlin : 通过kotlinc编译器 -&gt; 字节码文件\nGroovy : 通过grooxy编译器 -&gt; 字节码文件\n\n\n\nClass文件的结构属性\n我们只会分析一个简单的案例, 从而知道一个class文件大概有什么内容\n\n属性结构介绍\n魔数和class文件版本 : 每个class文件的前四个字节被称为魔数, 值为(0xcafebabe), 它的作用是确定这个文件是一个class文件, 起到一个标识符的作用, 再后两位分别是JDK的小版本号, 大版本号\n常量池 : class文件的资源仓库, 存储的资源有 : 变量的属性, 类型, 名称; 方法的属性,, 类型, 名称等\n访问标志 : 表示该类的属性和访问类型, 是接口还是类, 访问类型是不是public, 类型是否被标记为final\n类索引, 父类索引, 接口索引 : class文件靠类索引, 父类索引, 接口索引这三项来确定这个类的继承关系\n字段表属性 : 用于描述接口或类中声明的变量, 比如变量的作用域(public,…), 是否是静态变量, 是不是final, 数据类型等\n方法表属性 : 描述的是方法的类型作用域等\n属性表属性 : 描述的是特殊的属性. 比如字段表或方法表中的特殊的属性等\n\n字节码文件信息\n前三行都是一些基础的元信息, 简单易懂\npublic class com.func.JVM.Main : 说明该类的全限定类名\nminor version : 0 小的版本号是0\nmajor version : 61 大的版本号是17()\n\n"},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E6%96%B0%E7%89%B9%E6%80%A7/JDK14%E6%96%B0%E7%89%B9%E6%80%A7/","content":""},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E6%96%B0%E7%89%B9%E6%80%A7/JDK8-Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/","content":""},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E6%96%B0%E7%89%B9%E6%80%A7/JDK8-Optional%E7%B1%BB/","content":"Optional"},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E6%96%B0%E7%89%B9%E6%80%A7/JDK8-Stream%E6%B5%81/","content":"Stream流Stream配合Lambda表达式, 能极大便利程序员操作集合\n"},{"title":"Wrench项目解析01 - 动态配置中心(DCC)实现原理","url":"/2025/07/08/Project/wrench/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/1-DCC/","content":"1-DCC 动态配置中心的实现1. 项目结构\ndynamic.config.center.config: 项目的propeties以及自动装配Bean对象\nDynamicConfigCenterAutoConfig: 这个Bean对象用于在bean对象初始化(也就是Bean对象生命周期: 赋值的后一步)后执行特定的代码, 这里就是扫描并处理DCCValue注解\nDynamicConfigCenterAutoProperties: DCC的properties配置文件, 里面定义了DCC有什么需要配置的内容\nDynamicConfigCenterRegisterAutoProperties: 里面定义了Redis需要配置的内容, 并且给出默认值\nDynamicConfigCenterRegisterAutoConfig: 根据上面的两个Properties中的内容装配Redisson, DynamicConfigCenterService, DynamicConfigCenterAdjustListener, DynamicConfigCenterRedisTopic这四个Bean对象\n\n\ndomain: 领域层, 关注扫描DCCValue已经将topic中的值从Redis中读取并注入到程序中某个字段的业务\nmodel.AttributeVO: Topic装载的值, 记录了字段名和需要注入的值\nservice.DynamicConfigCenterService: 提供了\n解析Bean对象中的DCCValue注解, 并尝试将这个值设置到Redis中并注入到某个field中(如果不是初始化的情况, 也就是Redis中已经存在这个值的时候, 就不用注入), 已经将所有用DCCValue注解标注的bean对象都用map存储起来\nlistener调用的服务, 将更新后的Redis中的值注入到程序对应字段中\n\n\n\n\n\n2. 程序串行的执行过程\n在启动SpringBoot以后, 所有的Bean对象都会在初始化以后, 执行被我们重写了的postProcessAfterInitialization(Object bean, String beanName), 截获这个对象以后, 执行DynamicConfigCenterService中的processDCCAnnotations(Object bean), 下面是详细的执行过程\n首先需要解代理(具体的原因在[项目细节]里面有), 因为这里的bean对象可能是代理后的对象\n从解代理以后的class中扫描有没有字段被@DCCValue修饰\n将DCCValue中的key如果不存在于Redis中, 说明这个字段是第一次被扫描, 这个时候将DCCValue中的默认值存到Redis中. 如果存在则取出来最新的值\n将c步骤中获取到要注入的值注入到对应的field中\n将这对key(这里的key是经过了system_attributeName拼接后的), 和对应的原始bean对象存到线程安全Map里面\n\n\n在测试程序中我们通过在AutoConfig里面装配的dynamicConfigCenterRedisTopic发布消息\nAdjustListener订阅了这个消息, 在监听到消息以后, 执行 dynamicConfigCenterService.adjustAttributeValue(attributeVO)将值注入到对应的Bean对象中\n获取key, 从processDCCAnnotations存入的dccBeanGroup中读取出来需要的注入的Bean对象\n更新Redis中的值, 并将这个value注入到对应的field中\n\n\n\n3. 项目细节类已经被代理了, 如果回退到原来的类?要回答这个问题就需要回头看到代理是怎么实现的, 我们才能在实现中捕捉到这件事情是不是可行的\npublic interface TargetSource extends TargetClassAware &#123;\t@Override\t@Nullable\tClass&lt;?&gt; getTargetClass();\tboolean isStatic();\t@Nullable\tObject getTarget() throws Exception;\tvoid releaseTarget(Object target) throws Exception;&#125;\n\nSpring在创建代理JDK动态代理的对象的过程中会将目标类的信息保存到AdviseSupport(继承自TargetSource), 通过这个类我们就能获取到原始的类和实例\n而如果是使用CGLIB动态代理, 因为CGLIB代理是通过继承实现的, 只需要getSuperClass()就能获取到原先的类\n获取代理类的原始class通过AopUtils.getTargetClass()方法\npublic static Class&lt;?&gt; getTargetClass(Object candidate) &#123;\t\tAssert.notNull(candidate, &quot;Candidate object must not be null&quot;);\t\tClass&lt;?&gt; result = null;\t\tif (candidate instanceof TargetClassAware) &#123;\t\t\tresult = ((TargetClassAware) candidate).getTargetClass();\t\t&#125;\t\tif (result == null) &#123;\t\t\tresult = (isCglibProxy(candidate) ? candidate.getClass().getSuperclass() : candidate.getClass());\t\t&#125;\t\treturn result;\t&#125;\n\n所有使用JDK动态代理被代理的类都是继承了TargetSource的, TargetSourc继承TargetClassAware, 所以能通过检查是不是继承自TargetClassAwar来识别这个类是不是代理类\n在确定类是代理类以后, 通过TargetClassAware中的getTargetClass()方法获取该代理类的原始类\n如果这个result为空, 说明是通过CGLIB动态代理的或者压根就没被代理, 如果是CGLIB代理的返回父类, 反之返回本身的类就行\n获取代理对象的原始对象通过 AopProxyUtils.getSingletonTarget()实现\npublic static Object getSingletonTarget(Object candidate) &#123;    if (candidate instanceof Advised) &#123;        TargetSource targetSource = ((Advised) candidate).getTargetSource();        if (targetSource instanceof SingletonTargetSource) &#123;            return ((SingletonTargetSource) targetSource).getTarget();        &#125;    &#125;    return null;&#125;\n\nAdvised继承自TargetAware, SingletonTargetSource是一种特殊的TargetSource, 单例模式的目标对象继承SingletonTargetSource而不是TargetSource\n\n先判断candidate是不是代理对象: if (candidate instanceof Advised) \n判断是不是单例类型: if (targetSource instanceof SingletonTargetSource) \n\n不同于获取原始类的class, 针对CGLIB和JDK动态代理有不同的处理方式, 对于获取原对象, 只有存储下来原对象, 并在需要的时候返回这一种处理方式\n为什么这样的回退代理的功能这是在注解开发中非常重要的一环, 因为在动态代理的过程中可能会丢失原对象的注解信息\n在JDK代理中\nJDK动态代理基于接口实现, 生成的代理类继承自java.lang.reflect.Proxy, 代理对象的实际类型不再是原始类, 是动态生成的代理类\n\nJDK代理众所周知只能代理接口中定义的方法, 如果注解是加在实现类上的, 而不是接口上的, 代理对象就无法访问这些注解\n\n\n在CGLIB中\nCGLib生成的是原始类的子类\n\n虽然会继承父类的注解，但在某些框架处理中仍可能出现问题\n\n\n所以在注解驱动开发中, 识别类是不是代理类, 并将类回退到原始类是个必要的工作, 防止类因为代理而导致注解丢失\n多层代理问题如果一个类被多层代理, 使用AopUtils.getTargetClass()实际上只能获取到”上一层“的Class, 而不是最原始的Class, 这个时候就需要使用AopProxyUtils.ultimateTargetClass(), 这也算是xfg项目中的一个小bug\n","categories":["项目实战","Wrench","中间件"],"tags":["Redis","动态配置中心","DCC","Spring Boot","自动装配","配置管理"]},{"title":"Wrench项目解析02 - 动态限流组件实现","url":"/2025/07/08/Project/wrench/%E8%BF%87%E7%A8%8B%E7%AC%94%E8%AE%B0/3-%E5%8A%A8%E6%80%81%E9%99%90%E6%B5%81/","content":"动态限流组件程序的串行执行过程\n@RateLimiterAccessInterceptor注解到需要拦截的方法上\n\n@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface RateLimiterAccessInterceptor &#123;    String key() default &quot;all&quot;;    // 限制频次: 每秒请求次数    double permitsPerSecond();    // 黑名单拦截: 多少次限制以后加入到黑名单, 0代表不做限制    double blacklistCount() default 0;    // 拦截后执行的方法    String fallbackMethod();&#125;\n\n\nRateLimiterAOP对象拦截所有被@RateLimiterAccessInterceptor注解的方法\n通过第一节的DCC来动态配置限流组件的状态(打开还是关闭)\n执行黑名单过滤, 在黑名单中, 执行注解中的fallbackMethod\n如果该用户不在黑名单中, 则通过令牌桶限流\n如果用户获取令牌失败, 也就是超过了限定的QPS(注解中的permitsPerSecond), 则进行限流\n将用户的被限流次数+1(如果用户被限流次数超过了注解中的blacklistCount, 就会执行黑名单过滤了)\n执行注解中的fallbackMethod\n\n\n\n\n\n技术细节\nfallbackMethod必须定义在被注解的方法所在的类上, 不能跨类, 因为是通过反射获取到这个方法的\n获取Cache的key通过反射从方法的入参中获取, 不能通过filedValue = BeanUtils.getProperty(arg, attr);获取, 因为使用了lombok对于uid这样的字段, 生成的get方法是getuid, 而使用IDEA生成的标准的get方法是getUid, 使用lombok的时候会无法获取到属性的值, 所以需要通过反射获取\n\n","categories":["项目实战","Wrench","中间件"],"tags":["动态限流","限流组件","令牌桶","黑名单","AOP","注解拦截"]},{"title":"ArrayList源码深度解析 - 动态数组实现原理","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/ArrayList/","content":"ArrayList创建ArrayListArrayList(int initialCapacity)public ArrayList(int initialCapacity) &#123;        if (initialCapacity &gt; 0) &#123;            this.elementData = new Object[initialCapacity];        &#125; else if (initialCapacity == 0) &#123;            this.elementData = EMPTY_ELEMENTDATA;        &#125; else &#123;            throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+                                               initialCapacity);        &#125;    &#125;\n\n在初始化容量是有效的前提下, ArrayList会在构造函数就进行分配内存\nArrayList()public ArrayList() &#123;        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA(&#123;&#125;);    &#125;\n\n如果是无参构造, 则会在第一次add的时候初始化elementData, 为其分配内存\n向ArrayList中添加元素整个的堆栈过程图示堆栈过程图示：add(element)└── if (size == elementData.length) // 判断是否需要扩容    ├── grow(minCapacity) // 扩容    │   └── newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1) // 计算新的数组容量    │   └── Arrays.copyOf(elementData, newCapacity) // 创建新的数组    ├── elementData[size++] = element; // 添加新元素    └── return true; // 添加成功\n\nadd()方法的源码/** * 将指定元素添加到 ArrayList 的末尾 * @param e 要添加的元素 * @return 添加成功返回 true */public boolean add(E e) &#123;    ensureCapacityInternal(size + 1);  // 确保 ArrayList 能够容纳新的元素    elementData[size++] = e; // 在 ArrayList 的末尾添加指定元素    return true;&#125;\n\n会先调用exsureCapacityInternal(size + 1)来确保ArrayList能容纳新的元素\n然后将新的元素添加到末尾\nensureCapacityInternal(size + 1)/** * 确保 ArrayList 能够容纳指定容量的元素 * @param minCapacity 指定容量的最小值 */private void ensureCapacityInternal(int minCapacity) &#123;    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 如果 elementData 还是默认的空数组        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); // 使用 DEFAULT_CAPACITY 和指定容量的最小值中的较大值    &#125;    ensureExplicitCapacity(minCapacity); // 确保容量能够容纳指定容量的元素&#125;\n\n先判断現在的elmentData還是不是默認的空數組\n如果是則需要擴容的容量是minCapacity = max(size + 1, DEFAULT_Capacity(==10))\n最後調用ensureExplicitCapacity(minCapacity)執行擴容\nensureExplicitiCapacity(minCapacity)/** * 检查并确保集合容量足够，如果需要则增加集合容量。 * * @param minCapacity 所需最小容量 */private void ensureExplicitCapacity(int minCapacity) &#123;    // 检查是否超出了数组范围，确保不会溢出    if (minCapacity - elementData.length &gt; 0)        // 如果需要增加容量，则调用 grow 方法        grow(minCapacity);&#125;\n\n如果最小容量超过了现在的数组的容量就执行扩容grow(minCapacity)\ngrow(minCapacity)/** * 扩容 ArrayList 的方法，确保能够容纳指定容量的元素 * @param minCapacity 指定容量的最小值 */private void grow(int minCapacity) &#123;    // 检查是否会导致溢出，oldCapacity 为当前数组长度    int oldCapacity = elementData.length;    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 扩容至原来的1.5倍    if (newCapacity - minCapacity &lt; 0) // 如果还是小于指定容量的最小值        newCapacity = minCapacity; // 直接扩容至指定容量的最小值    if (newCapacity - MAX_ARRAY_SIZE &gt; 0) // 如果超出了数组的最大长度        newCapacity = hugeCapacity(minCapacity); // 扩容至数组的最大长度    // 将当前数组复制到一个新数组中，长度为 newCapacity    elementData = Arrays.copyOf(elementData, newCapacity);&#125;\n\n进入到这一步说明数组的大小是小于指定的容量(size+1, 或者是指定的容量)的, 或者这是个空数组\n新的数组大小等于1.5倍原来的数组大小\n如果新的数组大小还是小于指定容量的最小值就会让新的数组大小直接就等于minCapacity\n如果超出了数组的最大长度, 就会扩容至数组的最大长度\n将当前数组复制到一个新的数组中\n向指定位置插入一个元素add(int index, E element)/** * 在指定位置插入一个元素。 * * @param index   要插入元素的位置 * @param element 要插入的元素 * @throws IndexOutOfBoundsException 如果索引超出范围，则抛出此异常 */public void add(int index, E element) &#123;    rangeCheckForAdd(index); // 检查索引是否越界    ensureCapacityInternal(size + 1);  // 确保容量足够，如果需要扩容就扩容    System.arraycopy(elementData, index, elementData, index + 1,            size - index); // 将 index 及其后面的元素向后移动一位    elementData[index] = element; // 将元素插入到指定位置    size++; // 元素个数加一&#125;\n\n\n检查数组越界\n调用ensureCapacityInternal(size+1), 确保容量足够, 如果不够就会执行扩容\n调用System.arraycopy(elementData, index, elemrntData, index + 1, size - index)执行将index及其后面的元素向后移动一位\nelementData : 要复制的源数组\nindex : 源数组中要复制的起始位置\nelementData : 要复制到的目标数组\nindex + 1 : 复制到目标数组的起始位置\nsize - index : 要复制的元素\n\n\n将元素插入到指定的位置\nsize++\n\n更新ArrayList中的元素set(int index, E element)/** * 用指定元素替换指定位置的元素。 * * @param index   要替换的元素的索引 * @param element 要存储在指定位置的元素 * @return 先前在指定位置的元素 * @throws IndexOutOfBoundsException 如果索引超出范围，则抛出此异常 */public E set(int index, E element) &#123;    rangeCheck(index); // 检查索引是否越界    E oldValue = elementData(index); // 获取原来在指定位置上的元素    elementData[index] = element; // 将新元素替换到指定位置上    return oldValue; // 返回原来在指定位置上的元素&#125;\n\n删除Array中的元素remove(int index)/** * 删除指定位置的元素。 * * @param index 要删除的元素的索引 * @return 先前在指定位置的元素 * @throws IndexOutOfBoundsException 如果索引超出范围，则抛出此异常 */public E remove(int index) &#123;    rangeCheck(index); // 检查索引是否越界    E oldValue = elementData(index); // 获取要删除的元素    int numMoved = size - index - 1; // 计算需要移动的元素个数    if (numMoved &gt; 0) // 如果需要移动元素，就用 System.arraycopy 方法实现        System.arraycopy(elementData, index+1, elementData, index,                numMoved);    elementData[--size] = null; // 将数组末尾的元素置为 null，让 GC 回收该元素占用的空间    return oldValue; // 返回被删除的元素&#125;\n\nremove(Object o)/** * 删除列表中第一次出现的指定元素（如果存在）。 * * @param o 要删除的元素 * @return 如果列表包含指定元素，则返回 true；否则返回 false */public boolean remove(Object o) &#123;    if (o == null) &#123; // 如果要删除的元素是 null        for (int index = 0; index &lt; size; index++) // 遍历列表            if (elementData[index] == null) // 如果找到了 null 元素                fastRemove(index); // 调用 fastRemove 方法快速删除元素                return true; // 返回 true，表示成功删除元素    &#125; else &#123; // 如果要删除的元素不是 null        for (int index = 0; index &lt; size; index++) // 遍历列表            if (o.equals(elementData[index])) // 如果找到了要删除的元素                fastRemove(index); // 调用 fastRemove 方法快速删除元素                return true; // 返回 true，表示成功删除元素    &#125;    return false; // 如果找不到要删除的元素，则返回 false&#125;\n\nfastRemove(int index)/** * 快速删除指定位置的元素。 * * @param index 要删除的元素的索引 */private void fastRemove(int index) &#123;    int numMoved = size - index - 1; // 计算需要移动的元素个数    if (numMoved &gt; 0) // 如果需要移动元素，就用 System.arraycopy 方法实现        System.arraycopy(elementData, index+1, elementData, index,                numMoved);    elementData[--size] = null; // 将数组末尾的元素置为 null，让 GC 回收该元素占用的空间&#125;\n\n对比remove(int index)区别是\n\n不用检查index越界\n不需要返回删除的元素\n\n确实是fast了一点吧(虽然不多)\n查找ArrayList中的元素indexOf(Object o)/** * 返回指定元素在列表中第一次出现的位置。 * 如果列表不包含该元素，则返回 -1。 * * @param o 要查找的元素 * @return 指定元素在列表中第一次出现的位置；如果列表不包含该元素，则返回 -1 */public int indexOf(Object o) &#123;    if (o == null) &#123; // 如果要查找的元素是 null        for (int i = 0; i &lt; size; i++) // 遍历列表            if (elementData[i]==null) // 如果找到了 null 元素                return i; // 返回元素的索引    &#125; else &#123; // 如果要查找的元素不是 null        for (int i = 0; i &lt; size; i++) // 遍历列表            if (o.equals(elementData[i])) // 如果找到了要查找的元素                return i; // 返回元素的索引    &#125;    return -1; // 如果找不到要查找的元素，则返回 -1&#125;\n\n没有找到元素的时候返回-1, 找到的时候返回元素的索引\nLastIndex(Object o)/** * 返回指定元素在列表中最后一次出现的位置。 * 如果列表不包含该元素，则返回 -1。 * * @param o 要查找的元素 * @return 指定元素在列表中最后一次出现的位置；如果列表不包含该元素，则返回 -1 */public int lastIndexOf(Object o) &#123;    if (o == null) &#123; // 如果要查找的元素是 null        for (int i = size-1; i &gt;= 0; i--) // 从后往前遍历列表            if (elementData[i]==null) // 如果找到了 null 元素                return i; // 返回元素的索引    &#125; else &#123; // 如果要查找的元素不是 null        for (int i = size-1; i &gt;= 0; i--) // 从后往前遍历列表            if (o.equals(elementData[i])) // 如果找到了要查找的元素                return i; // 返回元素的索引    &#125;    return -1; // 如果找不到要查找的元素，则返回 -1&#125;\n\n和indexOf的区别就是一个从前往后找, 一个从后往前找\ncontains(Object o)public boolean contains(Object o) &#123;    return indexOf(o) &gt;= 0;&#125;\n\n总结\nremove(Object o)和indexOf(Object o)因为要找到第一个和o相等的元素, 所以需要区分o是null和不是null的两种情况\n是null : 使用&#x3D;&#x3D;判断两个对象相等\n不是null : 使用equals()判断两个元素相等\n\n\ngrow()中新的数组大小遵循下面的规则\n默认是原来数组大小(elementData.length)的1.5倍\n如果还是小于需要的最小容量(minCapacity)就会直接等于最小容量\n如果这个新的大小超过了数组的最大大小, 就会是数组的最大大小\n使用arrays.copy函数copy\n\n\n涉及到数组的迁移, 都是使用System.arraycopy(elementData, index+1, elementData, index,                numMoved);函数\n如果是根据index查询删除增加元素, 方法中的第一步都是检查数组索引是不是越界了\n\n","categories":["Java","Java进阶","Java集合框架"],"tags":["八股文","面试","ArrayList","动态数组","扩容机制","数组复制","集合框架","List接口"]},{"title":"HashMap源码解析 - 数据结构与核心算法详解","url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/HashMap/","content":"HashMaphash方法原理hash(Object key)static final int hash(Object key) &#123;    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;\n\n这段代码就是计算存进来的元素的hash值的函数\npublic V put(K key, V value) &#123;    return putVal(hash(key), key, value, false, true);&#125;\n\n这个函数将key Object的hashcode异或hashcode逻辑右移16得到最终的hash值\n如果要通过这个hash值计算出来桶的位置, 则通过(n - 1) &amp; hash, 这样就是hash值对n取余后的结果, 因为在数组长度是2的n次方的时候, 取余运算和与运算的结果是一样的(因为在长度是2的n次方的时候, length - 1后会除了第n位全是1, 就能达到取余的效果)\nHashMap中会调用取模运算的地方putValfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123;    // 数组    HashMap.Node&lt;K,V&gt;[] tab;    // 元素    HashMap.Node&lt;K,V&gt; p;    // n 为数组的长度 i 为下标    int n, i;    // 数组为空的时候    if ((tab = table) == null || (n = tab.length) == 0)        // 第一次扩容后的数组长度        n = (tab = resize()).length;    // 计算节点的插入位置，如果该位置为空，则新建一个节点插入    if ((p = tab[i = (n - 1) &amp; hash]) == null)        tab[i] = newNode(hash, key, value, null);&#125;\n\ngetNodefinal Node&lt;K,V&gt; getNode(int hash, Object key) &#123;    // 获取当前的数组和长度，以及当前节点链表的第一个节点（根据索引直接从数组中找）    Node&lt;K,V&gt;[] tab;    Node&lt;K,V&gt; first, e;    int n;    K k;    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;            (first = tab[(n - 1) &amp; hash]) != null) &#123;        // 如果第一个节点就是要查找的节点，则直接返回        if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))            return first;        // 如果第一个节点不是要查找的节点，则遍历节点链表查找        if ((e = first.next) != null) &#123;            do &#123;                if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    return e;            &#125; while ((e = e.next) != null);        &#125;    &#125;    // 如果节点链表中没有找到对应的节点，则返回 null    return null;&#125;\n\nif (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))是HashMap的经典判断e元素和key对应的元素是不是同一个元素的语句\n\n先比较两个key的hash值, 如果相等\n进一步比较两个key是不是值相等,\nkey &#x3D;&#x3D; null 的时候用&#x3D;&#x3D;判断\nkey !&#x3D; null的时候用equals判断\n\n\n\n扰动函数hash ^ (hash &gt;&gt;&gt; 16)\n用来混合原来哈希值的高位和低位, 让低位的随机性变大了, 参杂了部分高位的特征, 增大了低位的随机性\n\n为什么使用异或呢\n\n因为异或是位级别的均匀分布, 如果是与运算就会导致最后的计算结果中0偏多, 如果是或运算, 就会导致1增多\nHashMap的扩容机制JDK7中的resize方法// newCapacity为新的容量void resize(int newCapacity) &#123;    // 小数组，临时过度下    Entry[] oldTable = table;    // 扩容前的容量    int oldCapacity = oldTable.length;    // MAXIMUM_CAPACITY 为最大容量，2 的 30 次方 = 1&lt;&lt;30    if (oldCapacity == MAXIMUM_CAPACITY) &#123;        // 容量调整为 Integer 的最大值 0x7fffffff（十六进制）=2 的 31 次方-1        threshold = Integer.MAX_VALUE;        return;    &#125;    // 初始化一个新的数组（大容量）    Entry[] newTable = new Entry[newCapacity];    // 把小数组的元素转移到大数组中    transfer(newTable, initHashSeedAsNeeded(newCapacity));    // 引用新的大数组    table = newTable;    // 重新计算阈值    threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;\n\n\n如果原来的容量就是MAXIMUM_CAPACITY, 这个时候容量就是Integer.MAX, 返回, 因为Integer.MAX &#x3D; 2 \\* MAXIMUN_CAPACITY - 1, 这样扩容就刚好就是扩容了一倍\n用新的容量初始化一个新的Entry数组\n将小的数组也就是桶数组迁移到新的数组中\n引用新的大数组\n重新计算最大容量 &#x3D; min ( newCapacity * loadFactor, MAXIMUN_CAPACITY + 1)\n\nnewCapacity是怎么计算的int newCapacity = oldCapacity &lt;&lt; 1;if (newCapacity &gt;= DEFAULT_INITIAL_CAPACITY &amp;&amp; oldCapacity &gt;= DEFAULT_INITIAL_CAPACITY) &#123;    if (newCapacity &gt; MAXIMUM_CAPACITY)        newCapacity = MAXIMUM_CAPACITY;&#125; else &#123;    if (newCapacity &lt; DEFAULT_INITIAL_CAPACITY)        newCapacity = DEFAULT_INITIAL_CAPACITY;&#125;\n\n在正常情况下新的容量是旧的容量的两倍\n后面的代码就是在保证newCapacity的范围是[DEFAULT_INITIAL_CAPACITY, MAXIMUM_CAPACITY]\nJDK8中的resize()方法final Node&lt;K,V&gt;[] resize() &#123;    Node&lt;K,V&gt;[] oldTab = table; // 获取原来的数组 table    int oldCap = (oldTab == null) ? 0 : oldTab.length; // 获取数组长度 oldCap    int oldThr = threshold; // 获取阈值 oldThr    int newCap, newThr = 0;    if (oldCap &gt; 0) &#123; // 如果原来的数组 table 不为空        if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧            threshold = Integer.MAX_VALUE;            return oldTab;        &#125;        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; // 没超过最大值，就扩充为原来的2倍                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)            newThr = oldThr &lt;&lt; 1; // double threshold    &#125;    else if (oldThr &gt; 0) // initial capacity was placed in threshold        newCap = oldThr;    else &#123; // zero initial threshold signifies using defaults        newCap = DEFAULT_INITIAL_CAPACITY;        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);    &#125;    // 计算新的 resize 上限    if (newThr == 0) &#123;        float ft = (float)newCap * loadFactor;        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?                  (int)ft : Integer.MAX_VALUE);    &#125;    threshold = newThr; // 将新阈值赋值给成员变量 threshold    @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;)        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 创建新数组 newTab    table = newTab; // 将新数组 newTab 赋值给成员变量 table    if (oldTab != null) &#123; // 如果旧数组 oldTab 不为空        for (int j = 0; j &lt; oldCap; ++j) &#123; // 遍历旧数组的每个元素            Node&lt;K,V&gt; e;            if ((e = oldTab[j]) != null) &#123; // 如果该元素不为空                oldTab[j] = null; // 将旧数组中该位置的元素置为 null，以便垃圾回收                if (e.next == null) // 如果该元素没有冲突                    newTab[e.hash &amp; (newCap - 1)] = e; // 直接将该元素放入新数组                else if (e instanceof TreeNode) // 如果该元素是树节点                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 将该树节点分裂成两个链表                else &#123; // 如果该元素是链表                    Node&lt;K,V&gt; loHead = null, loTail = null; // 低位链表的头结点和尾结点                    Node&lt;K,V&gt; hiHead = null, hiTail = null; // 高位链表的头结点和尾结点                    Node&lt;K,V&gt; next;                    do &#123; // 遍历该链表                        next = e.next;                        if ((e.hash &amp; oldCap) == 0) &#123; // 如果该元素在低位链表中                            if (loTail == null) // 如果低位链表还没有结点                                loHead = e; // 将该元素作为低位链表的头结点                            else                                loTail.next = e; // 如果低位链表已经有结点，将该元素加入低位链表的尾部                            loTail = e; // 更新低位链表的尾结点                        &#125;                        else &#123; // 如果该元素在高位链表中                            if (hiTail == null) // 如果高位链表还没有结点                                hiHead = e; // 将该元素作为高位链表的头结点                            else                                hiTail.next = e; // 如果高位链表已经有结点，将该元素加入高位链表的尾部                            hiTail = e; // 更新高位链表的尾结点                        &#125;                    &#125; while ((e = next) != null); //                    if (loTail != null) &#123; // 如果低位链表不为空                        loTail.next = null; // 将低位链表的尾结点指向 null，以便垃圾回收                        newTab[j] = loHead; // 将低位链表作为新数组对应位置的元素                    &#125;                    if (hiTail != null) &#123; // 如果高位链表不为空                        hiTail.next = null; // 将高位链表的尾结点指向 null，以便垃圾回收                        newTab[j + oldCap] = hiHead; // 将高位链表作为新数组对应位置的元素                    &#125;                &#125;            &#125;        &#125;    &#125;    return newTab; // 返回新数组&#125;\n\n计算新的阈值和新的容量, 主要是分作第一次初始化(无参构造还是在创建对象的时候指定了大小)还是后续扩容的情况来分情况计算\n\n获取原来的数组和数组容量, 以及原来的阈值\n如果原来的数组不为空, 说明已经完成了对于数组的初始化\n原来的数组大小已经超过了最大的数组大小了, 这个时候就步扩充了, 将阈值修改为oldTab, 然后直接返回, 随它碰撞去了, 已经扩不动了\n没超过最大值, newCap &#x3D; oldCap &lt;&lt; 1, 并且newCap也没有超过最大值的话, newThr &#x3D; oldThr &lt;&lt; 1\n\n\n原来的数组为空, 说明是第一次初始化数组\n如果oldThr &gt; 0, 说明用户在创建对象的时候指定数组的容量, 这个时候newCap &#x3D; oldThr(用户指定的大小)\n如果用户在创建对象的时候使用的是无参构造, 这个时候初始化容量和扩容阈值newCap &#x3D; DEFAULT_INITIAL_CAPACITY, newThr &#x3D; (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY)\n\n\n如果newThr &#x3D;&#x3D; 0, 说明是第一次初始化的情况, 并且用户指定了数组的容量, 计算出来新的阈值, 并且判断数组的容量和这个阈值是不是超过了最大容量, 如果超过了newThr &#x3D; Integer.MAX_VALUE\n\n计算出来新的阈值和新的容量以后的扩容操作了\n\n将新的阈值给成员变量threshold, 创建新的数组(大小是newCap)\n将旧的元素迁移到新的数组中, 遍历每个table中的桶\n如果桶中的元素不是null\n没有下一个元素, 说明该位置没有发生哈希冲突, 计算这个元素新的index放到新的数组中, 将旧数组的元素置null, 方便GC回收\n如果有下一个元素, 并且下一个元素是树节点, 将该树节点分裂成两个链表\n如果有下一个元素, 并且下一个元素是链表节点, 说明通过了拉链法解决了哈希冲突, 这个时候通过(e.hash &amp; oldCap) == 0来判断出来链表中的节点应该放在低位链表(原来的位置的链表)中还是放在高位链表中(新的位置 &#x3D;&#x3D; oldCap + j该元素的原来的位置), 这里插入元素用的是尾插法\n\n\n\n\n\n\n解释最后高位链表低位链表\n\n现在有一个桶, 它的后面接得是链表, 说明发生了hash冲突, 不同的hash &amp; (oldCao - 1)后的值一样, 我们现在要重新计算其中的节点在新的数组中的位置, 就会有两种情况\n\n需要变化index的, 由于这个hash % newCap &#x3D;&#x3D; newIndex\n不需要变化index的, 因为hash % newCap &#x3D;&#x3D; oldIndex\n\n对于不需要变化index的, 说明这个hash值&amp; newCap(n+1位) - 1和&amp; oldCap(n位) - 1的结果是一样的, 也就是这个hash值的第n位是0, 这样才会&amp;0和&amp;1没有区别\n对于需要变化index的, 对应下来就是这个hash值的第n位是1, 这样才会&amp;1和&amp;0有区别, 同时这个区别就是index值在原来的基础上第n位也变成1了, 那么这个时候的index值 &#x3D;&#x3D; oldIndex(第n位等于0) + oldCap(这个数字就是只有第n位 &#x3D; 1, 其他都是0)\n因此我们能够通过e.hash &amp; oldCap &#x3D;&#x3D; 0, 也就是判断段e.hash的第n位是不是0来直接得出新的index\n\n如果&#x3D;&#x3D;0, 说明index不变\n如果&#x3D;&#x3D;1, 说明newIndex &#x3D; oldIndex + oldCap\n\n负载因子为什么是0.75加载因子 &#x3D; 填入哈希表中的数据个数 &#x2F; 哈希表的长度\n\n加载因子越小，填满的数据就越少，哈希冲突的几率就减少了，但浪费了空间，而且还会提高扩容的触发几率；\n加载因子越大，填满的数据就越多，空间利用率就高，但哈希冲突的几率就变大了。\n\n最后的结果就是为了减少哈希冲突发生的概率，当 HashMap 的数组长度达到一个临界值的时候，就会触发扩容，扩容后会将之前小数组中的元素转移到大数组中，这是一个相当耗时的操作。\n这个临界值 &#x3D; 初始容量 * 加载因子\n这个负载因子 &#x3D;&#x3D; 0.75是通过二项分布计算出来的\n具体的计算过程在加载因子为什么是0.75\n最后计算出来的值实际上是0.693, 考虑到HashMap的容量必须是2的n次幂, 0.75能保证与容积的乘积为整数\n树化\n体积考虑：TreeNodes约为普通节点大小的两倍，因此只在必要时使用\n使用条件：只有当桶(bin)中的节点数量达到一定阈值(TREEIFY_THRESHOLD)时才转换成树形结构\n退化条件：当树变得太小(由于移除操作或调整大小)时，会转换回普通的链表结构\n\n哈希分布与泊松分布这段文字指出，在哈希码分布良好的情况下，树结构很少被使用。在理想情况下，随机哈希码条件下，桶中节点的频率分布遵循泊松分布。\n泊松分布的作用泊松分布在这里用于:\n\n模型化碰撞概率：描述各个桶中节点数量的概率分布\n理论基础：为HashMap的性能分析提供数学依据\n预测分析：帮助预测在随机哈希码条件下，桶大小的分布情况\n\n参数解释\n参数λ约为0.5(在默认负载因子0.75的条件下)\n公式: P(k) &#x3D; e^(-λ) * λ^k &#x2F; k!\n其中P(k)是桶中恰好有k个节点的概率\ne是自然对数的底数\nλ是期望值(平均每个桶中的节点数)\nk是节点数量\nk!是k的阶乘\n\n\n\n概率分布表文中给出了当λ&#x3D;0.5时不同k值的概率:\n\n空桶(k&#x3D;0): 约60.65%\n1个节点(k&#x3D;1): 约30.33%\n2个节点(k&#x3D;2): 约7.58%\n3个节点(k&#x3D;3): 约1.26%\n\n这些数字表明:\n\n大多数桶是空的或只有少量节点\n桶中有8个或更多节点的概率非常小(不到千万分之一)\n\n线程不安全\n多线程扩容下会死循环(JDK7扩容的时候使用头插法导致的)\n多线程下put会导致元素丢失\nput和get并发时会导致get到null值\n\n死循环假设有一个链表 A-&gt;B-&gt;null，两个线程同时进行扩容：\n\n线程1遍历到节点A，此时被挂起\n线程2完成整个扩容过程，链表变成 B-&gt;A-&gt;null（注意头插法导致顺序反转）\n线程1被唤醒，继续执行，但它仍然认为A后面是B，将B插入到新链表头部\n结果形成了 B-&gt;A-&gt;B…的环形链表\n\n多线程put会导致元素丢失多线程同时执行 put 操作时，如果计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,               boolean evict) &#123;    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;    // 步骤①：tab为空则创建    if ((tab = table) == null || (n = tab.length) == 0)        n = (tab = resize()).length;    // 步骤②：计算index，并对null做处理    if ((p = tab[i = (n - 1) &amp; hash]) == null)        tab[i] = newNode(hash, key, value, null);    else &#123;        Node&lt;K,V&gt; e; K k;        // 步骤③：节点key存在，直接覆盖value        if (p.hash == hash &amp;&amp;            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            e = p;        // 步骤④：判断该链为红黑树        else if (p instanceof TreeNode)            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);        // 步骤⑤：该链为链表        else &#123;            for (int binCount = 0; ; ++binCount) &#123;                if ((e = p.next) == null) &#123;                    p.next = newNode(hash, key, value, null);                    //链表长度大于8转换为红黑树进行处理                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st                        treeifyBin(tab, hash);                    break;                &#125;                // key已经存在直接覆盖value                if (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    break;                p = e;            &#125;        &#125;        // 步骤⑥、直接覆盖        if (e != null) &#123; // existing mapping for key            V oldValue = e.value;            if (!onlyIfAbsent || oldValue == null)                e.value = value;            afterNodeAccess(e);            return oldValue;        &#125;    &#125;    ++modCount;    // 步骤⑦：超过最大容量 就扩容    if (++size &gt; threshold)        resize();    afterNodeInsertion(evict);    return null;&#125;\n\n问题出现在步骤 ②\nif ((p = tab[i = (n - 1) &amp; hash]) == null)    tab[i] = newNode(hash, key, value, null);\n\nput和get并发时会导致get到null线程 1 执行 put 时，因为元素个数超出阈值而导致出现扩容，线程 2 此时执行 get，就有可能出现这个问题。\n table &#x3D; newTab 之后，线程 2 中的 table 此时也发生了变化，此时去 get 的时候当然会 get 到 null 了，因为元素还没有转移。\n小结HashMap 是线程不安全的主要是因为它在进行插入、删除和扩容等操作时可能会导致链表的结构发生变化，从而破坏了 HashMap 的不变性。具体来说，如果在一个线程正在遍历 HashMap 的链表时，另外一个线程对该链表进行了修改（比如添加了一个节点），那么就会导致链表的结构发生变化，从而破坏了当前线程正在进行的遍历操作，可能导致遍历失败或者出现死循环等问题。\n","categories":["Java","Java进阶","Java集合框架"],"tags":["八股文","面试","数据结构","扩容机制","集合框架","HashMap","哈希表","红黑树","hash算法"]},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/LinkedHashMap/","content":"LinkedHashMapLinkedHashMap是怎么实现的维持插入顺序的Entry添加了before和afterstatic class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123;    Entry&lt;K,V&gt; before, after;    Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;        super(hash, key, value, next);    &#125;&#125;\n\n继承了HashMap的Node, 在里面添加了before指向前一个元素和after指向后一个元素\n插入顺序LinkedHashMap并没有重写HashMap的put方法, 而是重写了put()方法中调用的内部方法newNode()\n\nHashMap的\n\nNode&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;    return new Node&lt;&gt;(hash, key, value, next);&#125;\n\n\nLinkedHashMap的\n\nHashMap.Node&lt;K,V&gt; newNode(int hash, K key, V value, HashMap.Node&lt;K,V&gt; e) &#123;    LinkedHashMap.Entry&lt;K,V&gt; p =            new LinkedHashMap.Entry&lt;&gt;(hash, key, value, e);    linkNodeLast(p);    return p;&#125;\n\n在LinkedHashMap中在添加元素的时候, 会将新的节点添加到链表的尾部\n\nlinkNodeLast(Entry)\n\n/** * 将指定节点插入到链表的尾部 * * @param p 要插入的节点 */private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123;    LinkedHashMap.Entry&lt;K,V&gt; last = tail; // 获取链表的尾节点    tail = p; // 将 p 设为尾节点    if (last == null)        head = p; // 如果链表为空，则将 p 设为头节点    else &#123;        p.before = last; // 将 p 的前驱节点设为链表的尾节点        last.after = p; // 将链表的尾节点的后继节点设为 p    &#125;&#125;\n\n\n\n访问顺序维护访问顺序就是如果我访问了&lt;A, A_value&gt;那么这个节点就会被放到第一个,如果这个时候遍历LinkedHashMap就会发现这个节点被提到了第一个元素\n如果要维护访问顺序, 就要在声明的时候指定三个参数\nLinkedHashMap&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;(16, .75f, true);\n\n\n16 : 初始容量\n.75f : 负载因子\ntrue : 要LinkedHashMap维护访问顺序\n\n也就是实现了一个LRU缓存\n怎么实现的访问顺序void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125;\n\nafterNodeAccess()会在调用get()方法以后被调用, afterNodeInsertion()会在调用put()方法以后被调用, afterNodeRemoval()会在调用remove()方法以后被调用\nafterNodeAccess/** * 在访问节点后，将节点移动到链表的尾部 * * @param e 要移动的节点 */void afterNodeAccess(HashMap.Node&lt;K,V&gt; e) &#123; // move node to last    LinkedHashMap.Entry&lt;K,V&gt; last;    if (accessOrder &amp;&amp; (last = tail) != e) &#123; // 如果按访问顺序排序，并且访问的节点不是尾节点        LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;        p.after = null; // 将要移动的节点的后继节点设为 null        if (b == null)            head = a; // 如果要移动的节点没有前驱节点，则将要移动的节点设为头节点        else            b.after = a; // 将要移动的节点的前驱节点的后继节点设为要移动的节点的后继节点        if (a != null)            a.before = b; // 如果要移动的节点有后继节点，则将要移动的节点的后继节点的前驱节点设为要移动的节点的前驱节点        else            last = b; // 如果要移动的节点没有后继节点，则将要移动的节点的前驱节点设为尾节点        if (last == null)            head = p; // 如果尾节点为空，则将要移动的节点设为头节点        else &#123;            p.before = last; // 将要移动的节点的前驱节点设为尾节点            last.after = p; // 将尾节点的后继节点设为要移动的节点        &#125;        tail = p; // 将要移动的节点设为尾节点        ++modCount; // 修改计数器    &#125;&#125;\n\n简单来说就是会将访问的节点移动成尾节点\nafterNodeInsertion/** * 在插入节点后，如果需要，可能会删除最早加入的元素 * * @param evict 是否需要删除最早加入的元素 */void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest    LinkedHashMap.Entry&lt;K,V&gt; first;    if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; // 如果需要删除最早加入的元素        K key = first.key; // 获取要删除元素的键        removeNode(hash(key), key, null, false, true); // 调用 removeNode() 方法删除元素    &#125;&#125;\n\n删除头节点\n"},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/Queue/","content":"ArrayDequeQueue是个接口,  继承自Collection, 除了Collection的接口方法外, 额外提供了\n\n\n\n\nthrows Exception\nReturns special value\n\n\n\nInsert\nadd(e)\noffer(e)\n\n\nRemove\nremove()\npoll()\n\n\nExamine\nelement()\npeek()\n\n\nDeque和Queue的接口基本一样, 只不过提供了两头的方法, 也就是能操作两端, 原本add只是在队尾插入元素, 在Deque中就有addFirst和addLast两套方法, 其他的方法也是一样, 提供了两套方法, 使用栈的时候首选ArrayDeque, 因为Stack是个很粗糙的线程安全类, 效率不高\nArrayDeque 又实现了 Deque 接口（Deque 又实现了 Queue 接口）\n方法剖析这里只针对ArrayDeque, 底层使用数组实现, head指向头元素所在位置, tail指向尾端第一个可以插入的空位,  这个数组中不允许存放null\naddFirst(E e)\n通过head &#x3D;&#x3D; tail来判断队列满\n\nif (e == null)     throw new NPE();elements[(head-1 + head) % (elements.length - 1)] = e; // 实际上的代码并不是这个, 但是实现的功能是这个if (head == tail)    dequeCapacity(); // 将数组的容量扩大成原来的两倍\n\n\n真正的避免数组越界的方法 : elements[head &#x3D; (head - 1) &amp; (elements.length - 1)] &#x3D; e\n我们要处理的实际上就只是head - 1以后 &#x3D;&#x3D; -1 的情况\n-1在计算机中存储的实际上是它的补码全11111….\n而elements.length - 1(我们这里deque的长度只会是2的倍数)这个时候的length - 1也是全是1, 保证了在这里取模运算的正确性\n\n\n如果deque的长度不是2的倍数会发生什么? 我们假设长度是10 (1010)\nhead &#x3D;&#x3D; 0的时候, 这个时候head - 1 &#x3D;&#x3D; (1111_1111)_2 &amp; (1010) &#x3D; 1010, 这个时候的结果是正确的\nhead !&#x3D; 0 的时候, 假设head - 1 &#x3D;&#x3D; 1, 这个时候我们预期取模后的结果是1(0001),但是 0001 &amp; 1010 &#x3D; 0000 (0)_10 出现了错误\n-1在计算机中存储的是全1保证了在head - 1 &#x3D;&#x3D; -1 的时候运算出来的值是length - 1, elements.length 是 2 的幂次, length - 1的二进制是全1, 保证了head - 1 !&#x3D; -1 的时候计算出来的结果是head - 1\n\n\n\ndoubleCapacity()会将deque以head为分界线将数组内容划分为两部分, head的后一部分包含head, 这个部分在新的数组中的前一半,  前一部分划分到后一部分, 空间问题是在插入元素之后进行的\n\nassert head == tail;int n = elements.length;int p = head; // head所在索引前面的元素数量int r = n - p; // head(包括head)后面的元素数量int newCapacity = n &lt;&lt; 1; // 将数组的大小扩充为原来的两倍if (newCapacity &lt; 0) // 整数溢出    throw new IllegalStateException(&quot;deque too big&quot;);Object a[] = new Object[newCapacity];System.arraycopy(elements, p, a, 0, r); // 复制右半部分System.arraycopy(elements, 0, a, r, p); // 复制左半部分elements = (E[]) a;head = 0;tail = n;\n\nPriorityQueueJava中的堆是 小顶堆, 元素的顺序可以通过构造时传入的比较器实现(Comparator)\n\n\nleftNo &#x3D; parentNo * 2 + 1\nrightNo &#x3D; parentNo * 2 + 2\nparentNo &#x3D; (nodeNo-1) &#x2F; 2\n\n方法剖析siftup(int k, E x)\n我们在数组尾部新增了一个元素以后, 因为这个新增的元素是任意的, 我们为了维护循环不变式, 我们需要重新调整数组中元素, 我们将这个从数组的尾部, 将元素逐步向上直到找到合适的位置称作上浮\n\n这个函数的作用是 从k位置开始, 以x为参照,  插入一个元素 (k位置之后的元素不会受到影响), 向堆中插入一个元素\n\n将最后一个元素和parent进行对比, 如果比parent小则上浮, else break\n\n\nprivate void siftup(int k, E x) &#123;    while (k &gt; 0)&#123; // 等效于k != 0, 没有parent了        int parent = (k - 1) &gt;&gt;&gt; 1; // parentNo = (childNo - 1) / 2        Object e = queue[parent];        if (comparator.compare(x, (E) e)) &gt; 0) // x &gt; e, 也就是child &lt; parent的时候            break; // found right place        queue[k] = (E) queue[parent];        k = parent;    &#125;    queue[k] = x;&#125;\n\nsiftdown(int k, E x)\n删除了顶部的最小的元素以后, 这个时候堆的形式也遭到了破坏, 我们将最后一个元素上提到顶元素, 这个时候再将这个元素下沉到合适的位置\n\n这个方法的作用是 : 从指定的位置开始, 将x逐层向下与当前节点的左右孩子中的较小的那个交换位置, 知道x 小于等于左右孩子中的任何一个为止\n\nprivate void siftDown(int k, E x) &#123;    int half = size &gt;&gt;&gt; 1;    while (k &lt; half)&#123; // if k &gt;= half 说明这个节点不再有child节点了        int child = (k &lt;&lt; 1) + 1; // leftChildNo = parentNo * 2 + 1        int right = child + 1;        Object c = queue[child];        if (comparator.compare((E) c, (E) queue[right]) &gt; 0) left &gt; right            c = queue[child = right];        if (comparator.compare(x, (E) c) &lt;= 0) // x &lt;= child            break;        queue[k] = queue[child];        k = child;    &#125;    queue[k] = x; // 没有child了, 或者已经找到合适的位置了&#125;\n\noffer(E e)private boolean offer(E e) &#123;    if (e == null)        throw new NPE();    int i = size;    if (i &gt; queue.length)        grow(i+1); // 扩容   \tsize = i + 1;    if (i == 0) // 队列为空的时候        queue[0] = e;    else         shif(i, e);    return true;&#125;\n\npoll()public E poll()&#123;    if (size == 0)         return null;    int s = --size;    modCount++;    E result = (E) queue[0];\tE x = (E) queue[s];    queue[s] = null;    if (s != 0)         siftDown(0, x);    return result;&#125;\n\n\n\nremove(Object o)\n这个方法更加特殊一点, 需要分成删除的元素是不是最后一个元素考虑, 是最后一个元素, 则直接删除, 如果不是最后一个元素, 就要执行siftDown(从删除点开始, 最后一个元素为参照)\n\nHashMap方法详解hashstatic final int hash(Object key) &#123;    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;\n\n\n最后的异或操作保证了hashcode的高16位也能在计算桶的索引的时候也能发挥作用\n所以通过异或操作将hashcode的高16位和低16位混合\n\nput(K key, V value)这个方法直接调用的putVal内部函数, 将hash(key), key, value传进去\nputVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)"},{"url":"/2025/07/08/Java/Java%E8%BF%9B%E9%98%B6/Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6/TreeMap/","content":"TreeMapTreeMap实现了元素根据key进行排序public V put(K key, V value) &#123;    Entry&lt;K,V&gt; t = root; // 将根节点赋值给变量t    if (t == null) &#123; // 如果根节点为null，说明TreeMap为空        compare(key, key); // type (and possibly null) check，检查key的类型是否合法        root = new Entry&lt;&gt;(key, value, null); // 创建一个新节点作为根节点        size = 1; // size设置为1        return null; // 返回null，表示插入成功    &#125;    int cmp;    Entry&lt;K,V&gt; parent;    // split comparator and comparable paths，根据使用的比较方法进行查找    Comparator&lt;? super K&gt; cpr = comparator; // 获取比较器    if (cpr != null) &#123; // 如果使用了Comparator        do &#123;            parent = t; // 将当前节点赋值给parent            cmp = cpr.compare(key, t.key); // 使用Comparator比较key和t的键的大小            if (cmp &lt; 0) // 如果key小于t的键                t = t.left; // 在t的左子树中查找            else if (cmp &gt; 0) // 如果key大于t的键                t = t.right; // 在t的右子树中查找            else // 如果key等于t的键                return t.setValue(value); // 直接更新t的值        &#125; while (t != null);    &#125;    else &#123; // 如果没有使用Comparator        if (key == null) // 如果key为null            throw new NullPointerException(); // 抛出NullPointerException异常            Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; // 将key强制转换为Comparable类型        do &#123;            parent = t; // 将当前节点赋值给parent            cmp = k.compareTo(t.key); // 使用Comparable比较key和t的键的大小            if (cmp &lt; 0) // 如果key小于t的键                t = t.left; // 在t的左子树中查找            else if (cmp &gt; 0) // 如果key大于t的键                t = t.right; // 在t的右子树中查找            else // 如果key等于t的键                return t.setValue(value); // 直接更新t的值        &#125; while (t != null);    &#125;    // 如果没有找到相同的键，需要创建一个新节点插入到TreeMap中    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); // 创建一个新节点    if (cmp &lt; 0) // 如果key小于parent的键        parent.left = e; // 将e作为parent的左子节点    else        parent.right = e; // 将e作为parent的右子节点    fixAfterInsertion(e); // 插入节点后需要进行平衡操作    size++; // size加1    return null; // 返回null，表示插入成功&#125;\n\n\n检查根节点是不是空\n如果根节点是空, 检查key的类型是否合法(compare(key, key)), 然后创建一个新的节点, root &#x3D; newEntry\nsize &#x3D; 1, return null表示插入成功\n\n\n根节点不是空, 就要找到插入的位置\n尝试获取比较器, 如果有比较器, 在比较的部分通过传进来的比较器进行比较, 如果没有比较器, 说明key必须实现了Comparable接口, 将key强转成Comparator类型, 然后进行比较\n比较这个key和当前节点的key(t.key)之间的大小\n如果key更大, 说明接下来要向右查找, t &#x3D; t.right\n如果key更小, 说明接下来要向左查找, t &#x3D; t.left\n如果key &#x3D;&#x3D; t.key, 直接更新t的值\n\n\n没有找到相同的键, 创建一个新的节点, 让parent(t的父节点, 因为最后出循环的条件是t &#x3D;&#x3D; null)的孩子为新的节点\n最后调用fixAfterInsertion(e), 插入节点后进行平衡操作\n\n"},{"url":"/2025/07/08/Java/Spring/Spring%20AI/Spring%20AI%E6%A6%82%E8%A7%88/","content":"Spring AI解决的核心问题 : Connecting your enterprise Data and APIs with AI Models\nModel\n支持的模型类型\n\nChat Completion\n\nEmbedding\n\nText to Image\n\nAudio Transcription\n\nText to Speech \n\nModeration\n\n\n\n结构化输出: 将AI模型的输出能直接映射到需要的POJO类\n\n支持主要的矢量数据库 (RAG)\n\n允许模型请求执行客户端工具和函数(MCP)\n\nAI模型评估\n\nAdvisor: 封装重复的生成式AI模式, 转换发送到和传出语言模型的数据, 并提供各种模型和用例的可移植性\n\nChatClient:\n\n\n"},{"title":"Spring AI - 人工智能核心概念解析","url":"/2025/07/08/Java/Spring/Spring%20AI/AI%E6%A6%82%E5%BF%B5/","content":"Models我们按照输入和输出的内容, 将模型分成四大类\n\nPrompt 基于自然语言输入, 用于知道AI模型生成特定的内容\n\n用户设定的规则\n输出的格式\n不同角色的不同输入\n\n创建高效的提示词, 包括建立请求的上下文并将其中的各个部分替换成特定用户的输入的值\nTell me a &#123;adjective&#125; joke about &#123;content&#125;\nEmbeddingEmbedding的工作原理是将文本, 图像, 视频转换成浮点数向量\n通过计算两段文本向量之间的数值距离, 应用程序可以衡量两个向量也就是两个内容之间的相似度\n常用于实现RAG (Retieval Augmented Generation: 检索增强生成)  \nStructured Output简单来说就是对于怎么让AI的输出按照固定的格式的技术\nBring Your Data &amp; APIs to the AI Model\nPrompt Stuffing : 将数据嵌入到提供给模型的提示中, 典型的应用之一就是RAG\nTool Calling: 工具调用, 允许AI使用外部系统API的工具\n\nRAGRAG可以分成两个阶段\n\n将非结构化的数据加载到矢量数据库中\n将文档按照内容的语义边界来拆分成多个部分\n将文档的各个部分进一步拆分成大小为AI Token limit下的更小部分\n\n\n处理用户输入\n针对用户的输入, 从向量数据库中取出来相似的文档片段放入到AI的提示词中\n\n\n\nTool Calling简单来说就是给了LLM调用工具, 访问最新的数据, 修改数据的功能\n\n对于MCP服务的服务方, 需要注册好服务\n对于客户端\n在chat请求的时候包含工具的定义: 输入参数的名称, 描述和方案\n调用工具\n处理返回, 将其作为附加上下文生成响应\n\n\n\nEvaluating AI responses用于评估AI系统的输出, 确保最终应用程序的准确性和有用性\n","categories":["Java","Spring","Spring AI"],"tags":["Spring AI","人工智能","Models","Prompt","Embedding","AI概念"]},{"title":"Spring Boot Starter实现原理详解 - 自动装配机制深度解析","url":"/2025/07/08/Java/Spring/SpringBoot/Spring%20Boot%20Starter%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84/","content":"怎么实现一个Spring Boot Starter实现一个最小的Spring Boot StarterSpringBoot是怎么实现的自动装配?在程序的入口类上有@SpringBootApplication\n默认情况下Spring Boot会扫描这个注解所在目录和所有子目录\n扫描的内容就是@Component注解, 所有被扫描到的都会被注册成一个singleton(单例)\n@Confuguration@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Configuration &#123;    @AliasFor(        annotation = Component.class    )    String value() default &quot;&quot;;    boolean proxyBeanMethods() default true;&#125;\n\n根据源码不难发现实际上这个注解就是Component注解的别名\n最简单的Starter现在我们就已经能实现一个最简单的starter了\n@Configurationpublic class RestTemplateConfig &#123;    @Bean    public RestTemplate restTemplate()&#123;        return  new RestTemplate();    &#125;&#125;\n\n通过这个starter自动装配了restTemplate对象\nSpring Factories上面的Starter有一个和我们日常使用中的Spring Boot提供的Starter最大的区别: 我们的Starter配置类必须在@SpringBootApplication所在目录或者子目录中\n这很明显不符合我们日常通过maven导入jar包使用其他的starter提供的bean对象的实际场景\nSPI机制SPI : Service Provider Interface, SPI通过对模块之间基于接口编程, 不对实现类进行硬编码, 模块装配的时候不在程序中指明, 而是通过一种服务发现机制, 通过为某个接口寻找服务实现的机制, 将配装配的控制权移到程序之外, 就像IOC的思想\n第一步: 定义接口 (制定服务的标准)public interface PaymentService &#123;    void pay(double amount);&#125;\n\n第二步: 创建实现类 (提供具体的服务)public class AlipayService implements PaymentService &#123;    public void pay(double amount) &#123;        System.out.println(&quot;使用支付宝支付：&quot; + amount);    &#125;&#125;public class WechatPayService implements PaymentService &#123;    public void pay(double amount) &#123;        System.out.println(&quot;使用微信支付：&quot; + amount);    &#125;&#125;\n\n第三步: 配置文件 (也就是服务发现的提供者)在META-INF&#x2F;services目录下创建文件, 文件名就是接口的全限定名\n# 文件名：META-INF/services/com.example.PaymentServicecom.example.AlipayServicecom.example.WechatPayService\n\n第四步: 使用ServiceLoader加载ServiceLoader&lt;PaymentService&gt; loader = ServiceLoader.load(PaymentService.class);for (PatmentService service : loader) &#123;    service.pay(100.0);&#125;\n\nSpring Boot中的SPI机制Spring Boot也实现了类似的机制, 通过一个Loader加载所有jar包中的META-INF&#x2F;spring.factories文件\n而这个文件中就写有需要装配的类的全限定名\n# META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.example.MyAutoConfiguration,\\com.example.AnotherAutoConfiguration\n\nSpring Boot通过spring-core中的SpringFactoriesLoader类, 检索这个文件, 并解析获取类名列表, 从而加载这些配置类中的Bean\npublic final class SpringFactoriesLoader &#123;    public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;;    private static final Log logger = LogFactory.getLog(SpringFactoriesLoader.class);    private static final Map&lt;ClassLoader, MultiValueMap&lt;String, String&gt;&gt; cache = new ConcurrentReferenceHashMap();    private SpringFactoriesLoader() &#123;&#125;    public static &lt;T&gt; List&lt;T&gt; loadFactories(Class&lt;T&gt; factoryClass, @Nullable ClassLoader classLoader) &#123;        Assert.notNull(factoryClass, &quot;&#x27;factoryClass&#x27; must not be null&quot;);        ClassLoader classLoaderToUse = classLoader;        if (classLoader == null) &#123;            classLoaderToUse = SpringFactoriesLoader.class.getClassLoader();        &#125;        List&lt;String&gt; factoryNames = loadFactoryNames(factoryClass, classLoaderToUse);        if (logger.isTraceEnabled()) &#123;            logger.trace(&quot;Loaded [&quot; + factoryClass.getName() + &quot;] names: &quot; + factoryNames);        &#125;        List&lt;T&gt; result = new ArrayList(factoryNames.size());        Iterator var5 = factoryNames.iterator();        while(var5.hasNext()) &#123;            String factoryName = (String)var5.next();            result.add(instantiateFactory(factoryName, factoryClass, classLoaderToUse));        &#125;        AnnotationAwareOrderComparator.sort(result);        return result;    &#125;    public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) &#123;        String factoryClassName = factoryClass.getName();        return (List)loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList());    &#125;    private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123;        MultiValueMap&lt;String, String&gt; result = (MultiValueMap)cache.get(classLoader);        if (result != null) &#123;            return result;        &#125; else &#123;            try &#123;                Enumeration&lt;URL&gt; urls = classLoader != null ? classLoader.getResources(&quot;META-INF/spring.factories&quot;) : ClassLoader.getSystemResources(&quot;META-INF/spring.factories&quot;);                LinkedMultiValueMap result = new LinkedMultiValueMap();                while(urls.hasMoreElements()) &#123;                    URL url = (URL)urls.nextElement();                    UrlResource resource = new UrlResource(url);                    Properties properties = PropertiesLoaderUtils.loadProperties(resource);                    Iterator var6 = properties.entrySet().iterator();                    while(var6.hasNext()) &#123;                        Entry&lt;?, ?&gt; entry = (Entry)var6.next();                        String factoryClassName = ((String)entry.getKey()).trim();                        String[] var9 = StringUtils.commaDelimitedListToStringArray((String)entry.getValue());                        int var10 = var9.length;                        for(int var11 = 0; var11 &lt; var10; ++var11) &#123;                            String factoryName = var9[var11];                            result.add(factoryClassName, factoryName.trim());                        &#125;                    &#125;                &#125;                cache.put(classLoader, result);                return result;            &#125; catch (IOException var13) &#123;                throw new IllegalArgumentException(&quot;Unable to load factories from location [META-INF/spring.factories]&quot;, var13);            &#125;        &#125;    &#125;    private static &lt;T&gt; T instantiateFactory(String instanceClassName, Class&lt;T&gt; factoryClass, ClassLoader classLoader) &#123;        try &#123;            Class&lt;?&gt; instanceClass = ClassUtils.forName(instanceClassName, classLoader);            if (!factoryClass.isAssignableFrom(instanceClass)) &#123;                throw new IllegalArgumentException(&quot;Class [&quot; + instanceClassName + &quot;] is not assignable to [&quot; + factoryClass.getName() + &quot;]&quot;);            &#125; else &#123;                return ReflectionUtils.accessibleConstructor(instanceClass, new Class[0]).newInstance();            &#125;        &#125; catch (Throwable var4) &#123;            throw new IllegalArgumentException(&quot;Unable to instantiate factory class: &quot; + factoryClass.getName(), var4);        &#125;    &#125;&#125;\n\n2.x和3.x factories文件之间的区别在2.x版本中\n# META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.example.MyAutoConfiguration,\\com.example.AnotherAutoConfiguration\n\n3.x版本后换成了imports文件\n# META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.importscom.example.MyAutoConfigurationcom.example.AnotherAutoConfiguration\n\n总结spring.factories用键值对的方式记录了所有需要加入容器的类，EnableAutoConfigurationImportSelector的selectImports方法返回的类名，来自spring.factories文件内的配置信息，这些配置信息的key等于EnableAutoConfiguration，因为spring boot应用启动时使用了EnableAutoConfiguration注解，所以EnableAutoConfiguration注解通过import注解将EnableAutoConfigurationImportSelector类实例化，并且将其selectImports方法返回的类名实例化后注册到spring容器。\n以上内容是springboot获得这些类的方式，如果你想要实现自己的自动配置，就将你的类通过键值对的方式写在你的spring.factories即可，注意，值是你的自动配置类，键必须是org.springframework.boot.autoconfigure.EnableAutoConfiguration\n拓展条件注释Spring Boot允许我们通过条件注释在对默认配置不满意的时候能创建自己的配置类覆盖自动配置\nClass 条件@ConditionalOnClass(SomeService.class): 只有在这个SomeService.class文件存在的时候创建这个配置类\n@ConditionalOnMissingBean(SomeService.class): 只有在这个SomeService.class文件不存在的时候创建这个配置类\n必须使用 name 来引用类\nimport org.springframework.boot.autoconfigure.AutoConfiguration;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@AutoConfiguration// Some conditions ...public class MyAutoConfiguration &#123;\t// Auto-configured beans ...\t@Configuration(proxyBeanMethods = false)\t@ConditionalOnClass(SomeService.class)\tpublic static class SomeServiceConfiguration &#123;\t\t@Bean\t\t@ConditionalOnMissingBean\t\tpublic SomeService someService() &#123;\t\t\treturn new SomeService();\t\t&#125;\t&#125;&#125;\n\nBean类条件ConditionalOnMissingBean: 只有在这个Bean不存在的时候才创建这个Bean\n@ConditionalOnBean: 只有在这个Bean存在的时候才创建这个Bean\nvalue 属性按类型指定 Bean，或使用 name 按名称指定 Bean\nimport org.springframework.boot.autoconfigure.AutoConfiguration;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.context.annotation.Bean;@AutoConfigurationpublic class MyAutoConfiguration &#123;\t@Bean\t@ConditionalOnMissingBean\tpublic SomeService someService() &#123;\t\treturn new SomeService();\t&#125;&#125;\n\nProperty 条件@ConditionalOnProperty 注解允许基于 Spring 环境属性添加配置。使用 prefix 和 name 属性指定需要检查的属性。默认情况下，任何存在且不等于 false 属性都会被匹配\n如果在 name 属性中给出了多个名称，则所有属性都必须通过测试才能匹配条件\nResource 条件@ConditionalOnResource 注解允许仅在特定资源存在时才包含配置。可以使用常用的 Spring 约定来指定资源，如下例所示： file:/home/user/test.dat\n","categories":["Java","Spring","SpringBoot"],"tags":["八股文","面试","自动装配","SpringBoot","Starter","SPI机制","spring.factories","条件注解","Configuration"]},{"title":"SpringBoot核心功能详解","url":"/2025/07/08/Java/Spring/SpringBoot/SpringBoot/","content":"1. 加载外部配置1.1 application.properties这是springboot默认的加载的外部配置, 是java常用的properties类型的文件, 采用键值对的形式存储值, 通过object.filed的方式创建对象\nspring.application.name=sb3-003-external-configmyapp.username=jackmyapp.email=jack@123.commyapp.age=30\n\n1.2 bean对象获取配置文件中的值\n通过@Value(“${key:defult}”)的形式获取配置文件中的值\n\n@Service(&quot;UserService&quot;)public class UserServiceImpl implements UserService &#123;    @Value(&quot;$&#123;myapp.username&#125;&quot;)    private String username;    @Value(&quot;$&#123;myapp.email&#125;&quot;)    private String email;    @Value(&quot;$&#123;myapp.age&#125;&quot;)    private Integer age;    @Value(&quot;$&#123;myapp.passwd:123456&#125;&quot;)    private String passwd;    @Override    public void printInfo()&#123;        String str = String.join(&quot;,&quot;, username, email, String.valueOf(age), passwd);        System.out.println(str);    &#125;&#125;\n\n1.3 springboot扫描配置文件中的顺序\n使用springboot initializr初始化的项目, application.properties文件存放在resource也就是项目的根路径下, 这个路径实际上是优先级最低的路径, 最容易被覆盖的路径\n\n扫描的顺序\n\ncurrent directory: .&#x2F;config&#x2F; : 这个路径是项目的根路径, 或是命令行的所在的当前目录, 会在当前目录的config文件夹中找, 这个是优先级最高的位置\n如果没有找到application.properties会继续找application.yml如果两个文件都没找到才会去找接下来的文件夹\n\n\ncurrent directory: .&#x2F;: 在当前目录中找\nclasspath: &#x2F;config&#x2F;: 如果在工作目录没有找到, 就回去类路径中找, 首先会在resource的config文件夹中找, 先从类路径的 &#x2F;config&#x2F;中找\nclasspath: &#x2F; : 如果没有在类路径的config文件夹中找到了, 就会从类路径中找\n\n\n\n1.4 使用YAML加载配置文件\nYAML是大小写敏感的配置文件, 键和值之间使用一个冒号和空格分隔\n\n递进关系采用换行 + 空格分隔\n\nproperties文件中这么配置\n\n\nmyapp.name=123myapp.count=1\n\n那么yml文件中就需要这么配置\n\nmyapp:     name: 123    count: 1\n\n\nyml 使用#注解\nyml中的数组\n\nimport: [element1, element2]# 第二种方式import:    - element1    - element2\n\n1.5 配置文件合并\n在配置的内容越来越多的时候, 显然将所有的内容都放在一个文件中是一种不合适的选择, 我们这个时候就有了分文件管理的需求, 就像mabatis中的mapper, 我们并不是将所有的mapper都放在一个文件, 而是在中心配置文件中将所有的配置文件import\n\n1.5.1 properties配置方法使用 spring.config.import 将需要的配置文件导入, 配置文件之间使用逗号隔开\n\ncore\n\nspring.application.name=sb3-003-external-configspring.config.import=classpath:application-mysql.properties.properties, classpath:application-redis.properties.properties\n\n\napplication-mysql\n\nspring.datasource.username=rootspring.datasource.password=root\n\n\napplication-redis\n\nspring.data.redis.host=localhostspring.data.redis.port=6322\n\n1.5.2 yaml配置方法使用 spring: config : import:  方法\n\ncore\n\nspring:  config:    import:      - classpath:application-mysql.properties.properties      - classpath:application-redis.properties.properties\n\n\napplication-mysql\n\nspring:  datasource:    username: root    password: 789789\n\n\napplication-redis\n\nspring:  data:    redis:      host: localhost      port: 6379\n\n1.5.3 测试代码@Value(&quot;$&#123;spring.datasource.username&#125;&quot;)private String username;@Value(&quot;$&#123;spring.datasource.password&#125;&quot;)private String password;@Value(&quot;$&#123;spring.data.redis.host&#125;&quot;)private String host;@Value(&quot;$&#123;spring.data.redis.port&#125;&quot;)private String port;\n\n1.6 多环境切换\n这个功能用于切换不同情境下的不同配置文件\n\n一般来说, 有四种方式环境文件\n\n开发环境的配置文件, 一般叫 application-dev\n测试环境的配置文件 : application-test\n预生产环境的配置文件 :  application-preprod\n生产环境的配置文件 : application-prod\n\n有两种方式指定环境\n\n在application.properties文件中添加上spring.profiles.active=prod\n也可以在运行jar包的时候, 添加上--spring.profiles.active=prod命令行参数\n\nspring:  profiles:      active: mysqlspring:  datasource:    username: root    password: 789789\n\n\n需要额外说明的是, 实际上这个的命名是随意的, 只要是application-name, 后面的name都可以被视作一种环境而被springboot识别\n\n1.7 将配置信息绑定到bean上简单bean的绑定\n现在我有一个yaml配置文件, 现在需要将他绑定到一个bean实例上\n\napp:  name: jack  age: 30  email: jack@123.com\n\n\n说明 \n\n\n@Configuration注解用于将这个类纳入IoC容器管理\n\n其中的参数用于指明不需要代理类的生成, 这样能提高效率\n也可以使用@Component注解来将这个类纳入IoC容器管理\n\n\nConfigurationProperties(prefix) 用于指明这个类它的前缀, 也就是这个类是配置文件中的哪个类\n\njava\n\n\n@Configuration(proxyBeanMethods = false)@ConfigurationProperties(prefix = &quot;app&quot;)@Datapublic class MyApp &#123;    private String name;    private Integer age;    private String email;&#125;\n嵌套bean绑定\nyaml\n\napp:  name: jack  age: 30  email: jack@123.com  address:    city: BJ    street: ChaoYang    zipcode: 123456\n\n\njava\n\n@Configuration(proxyBeanMethods = false)@ConfigurationProperties(prefix = &quot;app&quot;)@Datapublic class MyApp &#123;    private String name;    private Integer age;    private String email;    private Address address;&#125;@Configuration@ConfigurationProperties(prefix = &quot;address&quot;)@Datapublic class Address &#123;    private String zipcode;    private String city;    private String  street;&#125;\n\n另外的两种将类纳入IoC容器管理的方式\n这两种方式都是在SpringBoot程序的入口, 带有@SpringBootApplication的类上注解的\n\n\n@ConfigurationPropertiesScan\n\n@ConfigurationPropertiesScan(basePackages = &quot;org.springboot.sb3003externalconfig.bean&quot;)@SpringBootApplication\n\n\n@EnableConfiguration\n\n@EnableConfigurationProperties(MyApp.class)@SpringBootApplication\n\n将配置绑定在bean的Map&#x2F;List&#x2F;Array属性上\n其实还是和正常的bean是一样的处理方式, 只不过需要额外地创建对应的子类\n\n\n现在我们需要将这些yml配置信息绑定到一个bean配置类上\n\n#数组names:  - jackson  - lucy  - lili#List集合products:   - name: 西瓜    price: 3.0  - name: 苹果    price: 2.0#Map集合vips:  vip1:    name: 张三    age: 20  vip2:    name: 李四    age: 22\n\n@ConfigurationProperties@Datapublic class AppBean &#123;    private String[] names;    private List&lt;Product&gt; products;    private Map&lt;String, Vip&gt; vips;&#125;@Dataclass Product &#123;    private String name;    private double price;&#125;@Dataclass Vip &#123;    private String name;    private Integer age;&#125;\n\n将配置信息绑定到外部类上\n需求并不总是是我们要将配置信息绑定到一个我们创建的可以修改的类上, 这个类很可能是由第三方提供的字节码文件, 并不可以修改\n\n\n情景模拟\n\n\n配置文件\n\naddress:  city: TJ  street: XiangYangLu  zipcode: 11111111\n\n\n类\n\n@Datapublic class Address &#123;    private String zipcode;    private String city;    private String  street;&#125;\n\n\n现在我们怎么将配置信息绑定到Address类上, 并创建相应的bean, 使用@Bean和@ConfigurationProperties组合\n\n@Configurationpublic class ApplicationConfig &#123;    @Bean    @ConfigurationProperties(prefix = &quot;address&quot;)    public Address getAddress()&#123;        return new Address();    &#125;&#125;\n\n\n需要额外注意, 这个工厂方法上面需要有@Configuration注解, 以纳入容器管理\n\n测试代码\n\n\n@Autowiredprivate Address address;@Testvoid contextLoads() &#123;    System.out.println(address);&#125;\n\n如何将外部的, 非application中的配置信息加载到配置类上@Configuration : 将这个类纳入容器管理@ConfigurationProperties : 将配置文件中的值赋值给Bean对象@PropertySource : 指定额外的配置文件\n\n在resources目录下新建a目录，在a目录下新建b目录，b目录中新建group-info.properties文件，进行如下的配置：\n\ngroup.name=ITgroup.leader=LaoDugroup.count=20\n\n\njava\n\n@ConfigurationProperties(prefix = &quot;group&quot;)@PropertySource(&quot;classpath:a/b/group-info.properties&quot;)@Datapublic class Group &#123;    private String name;    private String leader;    private Integer count;&#125;\n\n1.8 @ ImportResource注解\n现在我们有了三种配置Bean的方式    1. 通过xml文件配置    2. 通过@Service,  @Controller, @Component, @Configuration等注解配置    3. 通过@Bean + @ConfigurationProperties注解配置我们已经介绍了后两种在springboot中的体现, @ImportResource就是实现第一种的方式\n\n\n使用方法 : 通过在程序入口类(带有@SpringBootApplication的类上)注解, 引入xml文件, 从而创建bean\n\n@ImportResource(&quot;classpath:/config/applicationContext.xml&quot;)@SpringBootApplicationpublic class Sb3003ExternalConfigApplication\n\n\nxml文件\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;bean id=&quot;person&quot; class=&quot;org.springboot.sb3003externalconfig.bean.Person&quot;&gt;        &lt;property name=&quot;name&quot; value=&quot;jackson&quot;/&gt;        &lt;property name=&quot;age&quot; value=&quot;20&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;\n\n\nPerson类\n\n@Datapublic class Person &#123;    private String name;    private Integer age;&#125;\n\n\n这种方式能在外部只提供了xml文件的时候综合项目, 创建Bean的方式\n\n1.9 Environment\nSpring其实已经提供了我们访问应用程序环境信息的接口Environment , 这里使用也是通过这个类获取环境信息\n\nEnvironment对象封装的信息有 :    1. Active Profiles : 当前激活的配置文件列表, 主要是用于获取环境配置文件的相关信息 ( 如开发环境, 测试环境等 )    2. System Properties : 系统属性, 通常是操作系统级别的属性, 比如操作系统名称, java版本等    3. System Environment Variables : 系统环境变量, 通常是由操作系统提供的, 可以启动应用程序时设定的特定的值    4. Command Line arguments : 应用程序启动的时候传递给主方法的参数    5. Properties Sources : 包含了从不同源加载的所有属性\n\n示例代码\n\n@Autowired// 注入的方式获取对象private Environment environment;void contextLoads() &#123;    // 直接使用环境对象    String[] activeProfiles = environment.getActiveProfiles();    for (String activeProfile : activeProfiles) &#123;        System.out.println(&quot;activeProfile = &quot; + activeProfile);    &#125;    //  获取配置信息    String city = environment.getProperty(&quot;address.city&quot;);    System.out.println(&quot;city = &quot; + city);&#125;\n\n1.10 面向切面编程在SpringBoot中的面向切面编程和在Spring中的基本一致, 只是导入依赖的形式, 这里是引入一个starter启动器, 接下来给出示例以后主要说明和传入如的参数JoinPoint和ProceedJoinPoint相关的内容\n\n详细的内容说明, 参照[[Spring#12. 面向切面编程AOP]]\n\n引入AoP编程\n添加上相关的starter即可\n\n&lt;!--aop启动器--&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;\n\n示例\n实现AoP的流程    1. 创建切面类        1. 为切面类添加@Component注解, 将类纳入IoC容器管理        2. 添加@Aspect注解, 表明这是一个切面类    2. 添加代理方法    3. 为方法编织切入点\n\n\n示例代码\n\n@Component@Aspectpublic class LogAspect &#123;    private DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss SSS&quot;);    @Before(&quot;execution(* org.springboot.sb3003externalconfig.service..*(..))&quot;)    public void sysLog(ProceedingJoinPoint joinPoint)&#123;        System.out.println(&quot;切面编织成功&quot;);        StringBuilder log = new StringBuilder();        LocalDateTime now = LocalDateTime.now();        String strNow = formatter.format(now);        log.append(strNow);        log.append(&quot;:&quot;);        log.append(joinPoint.getSignature().getName());        log.append(&quot;(&quot;);        Object[] args = joinPoint.getArgs();        for (int i = 0; i &lt; args.length; i++) &#123;            log.append(args[i]);            if (i &lt; args.length -1)                log.append(&quot;, &quot;);        &#125;        log.append(&quot;)&quot;);        System.out.println(log);    &#125;&#125;\n\n\n重点 : ProceedJoinPoint和JoinPoint这两个类都是切面类中的方法可以传入的参数, 其中ProceedJoinPoint是JoinPoint的子类, JoinPoint是个接口\n\n通过JoinPoint, 我们能获取到和执行的方法相关的参数, 比如方法名, 类名等\n而ProceedJoinPoint进一步实现了proceed()方法, 从而能在方法中运行原方法\n该类是只能在@Arround类型的方法中使用, 其他的情景使用会导致切面错误, 无法正常产生代理类, 但是现在并不会出现GPT所说的编译错误, 运行和编译的时候并不会主动报错\n\n\n\nMyBatis集成原本怎么集成和使用MyBatis\n首先创建mybatis-config.xml文件, 用来存放核心配置\n关键配置有数据库连接是否池化\nDataSource\ndatabase url\ndatabase driver\ndatabase name\ndatabase password\n\n\nmappers resource\nenable underscore-to-camel-case\n\n\n创建mapper.xml文件, 里面添加CRUD方法\n实体类\nmapperDao接口\n\nspringboot中的集成核心配置文件\nspringboot中不需要再额外创建xml文件进行配置, 直接在application.properties中配置即可\n\n# mybatis数据源配置spring.datasource.username=rootspring.datasource.password=rootspring.datasource.url=jdbc:mysql://localhost:3306/springbootspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.type=com.zaxxer.hikari.HikariDataSource\n\n接口Mapper类\n无变化\n\nmapper.xml文件\n这个文件现在能通过MyBatisX插件简化开发过程\n在下载了以后, 在接口的方法上alt + enter上就能生成mapper的框架部分, 只需要自己填好sql语句即可\n\n驼峰映射和mapper.xml文件的导入\n同样是在application.properties文件中配置\n\n# 告诉MyBatis Mapper.xml文件的位置mybatis.mapper-locations=classpath:mapper/*.xml# 开启驼峰自动映射mybatis.configuration.map-underscore-to-camel-case=true\n\n添加Mapper的扫描\n最后在SpringBoot的入口程序上添加如下的注解, 来完成Mapper接口的扫描\n\n  @MapperScan(&quot;org.springboot.sb3004ssm.repository&quot;)@SpringBootApplicationpublic class Sb3004SsmApplication\n\nLombokLombok常用注解\n@Data之类的就不额外说明了\n\n@Value\n这个注解是用来创建不可修改类的, 简单来说就是创建各个属性都被final关键字修饰的类\n\n@Valuepublic class Person &#123;    private String name;    private Integer age;    private Long id;&#125;\n\n\n这个类这个时候只有getter, hascode, toString, equal方法, 没有setter方法, 通过这个方式实现不可修改\n\n@Builder\n这是GoF23中设计模式之一, 本质上是为了解决参数很多的构造方法在创建对象的时候的繁杂, 我们想让这些参数可以以此分开来添加到类中, 而不是在构造方法的时候一口气注入, 同时这种方式又有别于已经创建以后再setter, 这是在创建之前进行的行为\n\n\n没有使用注解的时候手敲的代码\n注意这个时候的constructor是私有的\n\n\n\npackage org.springboot.sb3004ssm.model;import lombok.AllArgsConstructor;import lombok.Data;import lombok.Value;import java.io.PrintWriter;@Datapublic class Person &#123;    private String name;    private Integer age;    private Long id;    private Person(String name, Integer age, Long id) &#123;        this.age = age;        this.id = id;        this.name = name;    &#125;    public static PersonBuilder builder()&#123;        return new PersonBuilder();    &#125;    public static class PersonBuilder &#123;        private String name;        private Integer age;        private Long id;        public PersonBuilder name(String name)&#123;            this.name = name;            return this;        &#125;        public PersonBuilder age(Integer age) &#123;            this.age = age;            return this;        &#125;        public PersonBuilder id(Long id) &#123;            this.id = id;            return this;        &#125;        public Person build()&#123;            return new Person(this.name, this.age, this.id);        &#125;    &#125;    public static void main(String[] args) &#123;        PersonBuilder builder = Person.builder();        Person fang = builder.name(&quot;fang&quot;).age(212).id(2L).build();        System.out.println(fang);    &#125;&#125;\n\n\n使用了注解的方案\n\n@Builder@Datapublic class Person &#123;    private String name;    private Integer age;    private Long id;    public static void main(String[] args) &#123;        PersonBuilder builder = Person.builder();        Person fang = builder.name(&quot;fang&quot;).age(212).id(2L).build();        System.out.println(fang);    &#125;&#125;\n\n\n不难从IDEA的structure中看出来, Builder还提供了@Data, 和一个私有的全参构造方法\n\n@Singular\n这个方式是辅助Builder设计模式使用的, 是为了解决如果类中有List类型, 我们怎么实现一个一个添加的问题\n\n@Builder@Datapublic class Person &#123;    private String name;    private Integer age;    private Long id;    @Singular(&quot;addMate&quot;)    private List&lt;String&gt; mate;    public static void main(String[] args) &#123;        PersonBuilder builder = Person.builder();        Person fang = builder.name(&quot;fang&quot;).age(212).id(2L).addMate(&quot;test&quot;).addMate(&quot;mate&quot;).build();        System.out.println(fang);    &#125;&#125;\n\n@Slf4j\n这其实是一类日志注解, 这个注解会为我们自动创建日志类, 这样在类中我们就能直接调用日志类\n\n实际上我们有三种选择, 这个根据实际的需求选择\n\n@Slf4j\n\n@Log4j\n\n@Log4j2\n\n这几个注解的实质实现就是为我们在类中创建一个日志类, 那么这里有的前提就是我们已经导入了框架以及日志的具体实现, 并完成了对日志框架的配置\n\n这里是按照教程使用的Slf4j日志框架和logback日志实现\n\n\n&lt;!--Slf4j日志规范--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;    &lt;version&gt;2.0.16&lt;/version&gt;&lt;/dependency&gt;&lt;!--Slf4j日志实现：logback--&gt;&lt;dependency&gt;    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;    &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;    &lt;version&gt;1.5.11&lt;/version&gt;&lt;/dependency&gt;\n\n\nTestCode\n\n@Slf4j@Builder@Datapublic class Person &#123;    private String name;    private Integer age;    private Long id;    @Singular(&quot;addMate&quot;)    private List&lt;String&gt; mate;    public static void main(String[] args) &#123;        log.info(&quot;实验成功&quot;);        PersonBuilder builder = Person.builder();        Person fang = builder.name(&quot;fang&quot;).age(212).id(2L).addMate(&quot;test&quot;).addMate(&quot;mate&quot;).build();        System.out.println(fang);    &#125;&#125;\n\n\nMyBatis逆向\nMyBatis逆向指的是, 通过数据库的表反向生成Mapper接口文件, 实体类以及Mapper.xml文件, 这样就不再需要自己写繁琐的CRUD, 只需要建表就能一键完成剩下的内容\n\n安装插件和准备数据源\n在IDEA的plugins中搜索安装Free MyBatis Tool插件\n在IDEA中连接上数据库和需要的库\n右键表, 这个时候能看到MyBatis-Generator的选项\n在里面配置好路径和名称即可, 接下来就会生成对应的内容\n\n测试程序\ntestcode\n\npublic static void main(String[] args) &#123;\tConfigurableApplicationContext applicationContext = SpringApplication.run(Sb3004SsmApplication.class, args);\tPersonMapper personMapper = applicationContext.getBean(&quot;personMapper&quot;, PersonMapper.class);\tSystem.out.println(personMapper);\tSystem.out.println(personMapper.selectByPrimaryKey(2));\tPerson person = new Person(null, &quot;fangh&quot;, &quot;123445&quot;, &quot;1292-02-13&quot;);\tSystem.out.println(&quot;插入语句 : &quot; + personMapper.insert(person));\tint count = personMapper.deleteByPrimaryKey(1);\tSystem.out.println(count);\tpersonMapper.selectAll().forEach(person1 -&gt; &#123;\t\tSystem.out.println(person1);\t&#125;);\tapplicationContext.close();&#125;\n\n\n到此MyBatis的所有整合都已经完成了\n\n","categories":["Java","Spring","SpringBoot"],"tags":["Java","MyBatis","SpringBoot","外部配置","Bean"]},{"title":"SpringMVC核心概念与实践","url":"/2025/07/08/Java/Spring/SpringMVC/SpringMVC/","content":"SpringMVC1. RESTful与注解上的细节1.1 类上的ResultMapping注解\n类上的ResultMapping注解, 会让类中方法的resultMapping从类上的路径开始\n\n不过这个时候注意返回的html路径问题, 访问的根路径是templates文件夹, 如果在里面有子文件夹, 注意写全文件夹\n\nUser\n\n\n@RequestMapping(&quot;/product&quot;)@Controllerpublic class UserController &#123;    @RequestMapping(&quot;/detail&quot;)    public String toDetail()&#123;        return &quot;/product/detail&quot;;    &#125;&#125;\n\n\nProduct\n\n@RequestMapping(&quot;/user&quot;)@Controllerpublic class ProductController &#123;    @RequestMapping(&quot;/detail&quot;)    public String toDetail()&#123;        return &quot;/user/detail&quot;;    &#125;&#125;\n\n1.2 value属性详解value接受的是String数组也就是允许多个url映射到同一个控制器上\n@RequestMapping(&quot;/user&quot;)@Controllerpublic class ProductController &#123;    @RequestMapping(&#123;&quot;/detail&quot;, &quot;/detail1&quot;&#125;)    public String toDetail()&#123;        return &quot;/user/detail&quot;;    &#125;&#125;\n\nAnt风格\n其实就是路径支持模糊匹配\n\n\n* : 代表任何0 ~ N个任意字符\n\n** : 代表任何0 ~ N个任意字符, 包括路径分隔符\\ (只能放在url末尾, 并且左右两边不能有除了\\以外的任意字符)\n\n? : 代表一个任意字符\n\n?\n\n\n@RequestMapping(&quot;/x?z/detail&quot;)public String toDetail()&#123;    System.out.println(&quot;模糊匹配页面正在解析&quot;);    return &quot;/ant&quot;;&#125;\n\n\n*\n\n@RequestMapping(&quot;/x*z/detail&quot;)public String toDetail()&#123;    System.out.println(&quot;模糊匹配页面正在解析&quot;);    return &quot;/ant&quot;;&#125;\n\n\n**\n\n@RequestMapping(&quot;/xz/detail/**&quot;)public String toDetail()&#123;    System.out.println(&quot;模糊匹配页面正在解析&quot;);    return &quot;/ant&quot;;&#125;\n\n1.3 RESTful\n实际上是一种将提交表单的信息放在URL上的一种规范, 和传统的login?username&#x3D;123&amp;passwd&#x3D;231的形式不一样, RESTful直接将信息用路径分隔符分隔开 login&#x2F;123&#x2F;231, 这是一种更现代和常用的方法\n\n\n使用步骤  1.在ReauestMapping上添加用{}包裹起来的占位符,  2.在方法的形参上添加@PathVatiable(“占位符”), 以此将表单中的值传递给 参数\n\n@RequestMapping(&quot;/table/&#123;username&#125;/&#123;passwd&#125;&quot;)public String toTable(@PathVariable(&quot;username&quot;) String username,                      @PathVariable(&quot;passwd&quot;) String passwd)&#123;    System.out.println(username);    System.out.println(passwd);    return &quot;RESTful&quot;;&#125;\n\n1.4 表单提交\n可以指定Mapping的method属性来指定表单提交的方式\nSpringMVC也提供了更简洁的方式来实现, 只需要指定对应的mapping就行\n\n@PostMapping(&quot;/login&quot;)public String doPost()&#123;    return &quot;login&quot;;&#125;\n\n&lt;form th:action=&quot;@&#123;/login&#125;&quot; method=&quot;get&quot;&gt;    用户名 : &lt;input type=&quot;text&quot; name=&quot;username&quot;/&gt;&lt;br/&gt;    密码 :  &lt;input type=&quot;text&quot; name=&quot;passwd&quot;/&gt; &lt;br/&gt;            &lt;input type=&quot;submit&quot; value=&quot;登录&quot;/&gt;&lt;/form&gt;\n\n\nGetMapping：要求前端必须发送get请求\n\nPutMapping：要求前端必须发送put请求\n\nDeleteMapping：要求前端必须发送delete请求\n\nPatchMapping：要求前端必须发送patch请求\n\n\n\n 如果方法错误, 会返回405请求方法错误\n\n1.5 GET和POST什么时候用POST, 什么时候用GET\n如果需要像服务器提交数据, 则使用POST\n需要从服务器获取数据, 则使用GET方法\n如果需要上传大数据量的内容, 只能使用POST方法, 因为他有请求体这个可以承载大数据量的载体\n需要上传敏感数据的时候, 也推荐使用POST方法, 它不会将表单回显在URL上\n\nGET方法的特殊之处\nGET方法会先走浏览器的缓存, 如果没有才会走服务器\n这个时候如果不想走缓存, 可以通过在URL最后添加上时间戳来解决\n\n\n大部分不指明的请求都是GET请求, 比如获取网页图标之类的\nPOST不支持缓存\n\n1.6 RequestMapping注解的Param属性\nHTTP code 400 : 请求参数的格式不正确导致的, 接下来就会出现\n\n\n通过指定RequestMapping中的params参数, 能实现对于提交内容的格式的限制, 下面是四种常用的用法\n需要注意的是, 下面的四种情况, 相互之间是有交集的, 有交集的时候的行为不可预测, 故不要写出这样的代码\n\n// 只有两个参数都填入的时候才符合格式@RequestMapping(value = &quot;/login&quot;, method = &#123;RequestMethod.POST, RequestMethod.GET&#125;, params = &#123;&quot;username&quot;, &quot;passwd&quot;&#125;)public String testParam()&#123;    System.out.println(&quot;两个参数都填入了&quot;);    return &quot;login&quot;;&#125;// username 需要为空, passwd不能为空@RequestMapping(value =  &quot;/login&quot;, method = &#123;RequestMethod.POST, RequestMethod.GET&#125;, params = &#123;&quot;!username&quot;, &quot;passwd&quot;&#125;)public String testParam2()&#123;    System.out.println(&quot;只有密码填入的时候&quot;);    return &quot;login&quot;;&#125;// username 需要=admin, passwd为root的时候@RequestMapping(value =  &quot;/login&quot;, method = &#123;RequestMethod.POST, RequestMethod.GET&#125;, params = &#123;&quot;username=admin&quot;, &quot;passwd=root&quot;&#125;)public String testParam3()&#123;    System.out.println(&quot;admin用户登录&quot;);    return &quot;login&quot;;&#125;// username 需要!=admin, passwd为root的时候@RequestMapping(value =  &quot;/login&quot;, method = &#123;RequestMethod.POST, RequestMethod.GET&#125;, params = &#123;&quot;username!=admin&quot;, &quot;passwd&quot;&#125;)public String testParam4()&#123;    System.out.println(&quot;非admin用户登录&quot;);    return &quot;login&quot;;&#125;\n\n1.7 RequestMapping注解的headers属性认识headers属性headers和params原理相同，用法也相同。 当前端提交的请求头信息和后端要求的请求头信息一致时，才能映射成功。 请求头信息怎么查看？在chrome浏览器中，F12打开控制台，找到Network，可以查看具体的请求协议和响应协议。在请求协议中可以看到请求头信息，例如：  请求头信息和请求参数信息一样，都是键值对形式，例如上图中：\n\nReferer: http://localhost:8080/springmvc/ 键是Referer，值是http://localhost:8080/springmvc/\n\nHost: localhost:8080 键是Host，值是localhost:8080\n\n\n\nheaders属性的用法和params属性是一样的用法\n注意：如果前端提交的请求头信息，和后端要求的请求头信息不一致，则出现404错误！！！\n2.  从请求中获取值&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;用户注册&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;用户注册&lt;/h3&gt;&lt;hr&gt;&lt;form th:action=&quot;@&#123;/register&#125;&quot; method=&quot;post&quot;&gt;    用户名：&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br&gt;    密码：&lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br&gt;    性别：        男 &lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;1&quot;&gt;        女 &lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;0&quot;&gt;        &lt;br&gt;    爱好：        抽烟 &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;smoke&quot;&gt;        喝酒 &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;drink&quot;&gt;        烫头 &lt;input type=&quot;checkbox&quot; name=&quot;hobby&quot; value=&quot;perm&quot;&gt;        &lt;br&gt;    简介：&lt;textarea rows=&quot;10&quot; cols=&quot;60&quot; name=&quot;intro&quot;&gt;&lt;/textarea&gt;&lt;br&gt;    &lt;input type=&quot;submit&quot; value=&quot;注册&quot;&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n\n2.1 在servlet中在servlet中, 获取值需要从request的param中获取\n@PostMapping(value=&quot;/register&quot;)public String register(HttpServletRequest request)&#123;    // 通过当前请求对象获取提交的数据    String username = request.getParameter(&quot;username&quot;);    String password = request.getParameter(&quot;password&quot;);    String sex = request.getParameter(&quot;sex&quot;);    String[] hobbies = request.getParameterValues(&quot;hobby&quot;);    String intro = request.getParameter(&quot;intro&quot;);    System.out.println(username + &quot;,&quot; + password + &quot;,&quot; + sex + &quot;,&quot; + Arrays.toString(hobbies) + &quot;,&quot; + intro);    return &quot;success&quot;;&#125;\n\n2.2 通过RequestParam获取@PostMapping(&quot;/register&quot;)public String register(        @RequestParam(&quot;username&quot;) String username,        @RequestParam(&quot;password&quot;) String passwd,        @RequestParam(&quot;sex&quot;) String sex,        @RequestParam(&quot;hobby&quot;) String[] hobby,        @RequestParam(&quot;intro&quot;) String intro,        @RequestParam(&quot;age&quot;) int age)&#123;    System.out.println(&quot;username = &quot; + username);    System.out.println(&quot;passwd = &quot; + passwd);    System.out.println(&quot;sex = &quot; + sex);    System.out.println(&quot;hobby = &quot; + Arrays.toString(hobby));    System.out.println(&quot;intro = &quot; + intro);    System.out.println(&quot;age = &quot; + age);    return &quot;success&quot;;&#125;\n\n2.3 RequestParam注解的required属性和default属性顾名思义 : \n\nrequired &#x3D; true的时候, 这个参数不能没有提交, 和在RequeatMapping中的param属性一样, 如果为false, 则可以为空, 这个时候对应的形参值是0\ndefault &#x3D; value : 如果这个参数没有传入或者为空字符串的时候, 填入的值\n\n2.4 RequestParam是可以省略的\n如果形参的名字和表单中的参数名是相同的, 这个时候就能省略\n如果是spring 6, 需要有额外的设置\n需要在pom.xml上加上以下内容\n\n\n\n&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;            &lt;version&gt;3.12.1&lt;/version&gt;            &lt;configuration&gt;                &lt;source&gt;21&lt;/source&gt;                &lt;target&gt;21&lt;/target&gt;                &lt;compilerArgs&gt;                    &lt;arg&gt;-parameters&lt;/arg&gt;                &lt;/compilerArgs&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n\n\n\n实验代码\n\n@PostMapping(&quot;/register&quot;)    public String register(            String username,            String passwd,            String sex,            String[] hobby,            String intro,            Integer age    )&#123;        System.out.println(&quot;username = &quot; + username);        System.out.println(&quot;passwd = &quot; + passwd);        System.out.println(&quot;sex = &quot; + sex);        System.out.println(&quot;hobby = &quot; + Arrays.toString(hobby));        System.out.println(&quot;intro = &quot; + intro);        System.out.println(&quot;age = &quot; + age);        return &quot;success&quot;;    &#125;\n\n2.5 通过传递javabean用于接收request传回的参数\n也是需要javabean的属性名是和表单的key名对应才能成功赋值\n\n经过实验\n\n实际实例顺序为先实例化对象(无论有参无参), 再通过setter赋值\n也就是javabean对象必须提供有参构造或者setter中的一种\n\n\n实验代码\n\n\npublic class User &#123;    private String username;    private String password;    private String sex;    private String[] hobby;    private String intro;    public void setUsername(String username) &#123;        System.out.println(&quot;走的setter方法&quot;);        this.username = username;    &#125;    public void setPassword(String password) &#123;        this.password = password;    &#125;    public void setSex(String sex) &#123;        this.sex = sex;    &#125;    public void setHobby(String[] hobby) &#123;        this.hobby = hobby;    &#125;    public void setIntro(String intro) &#123;        this.intro = intro;    &#125;    public User(String username, String password, String sex, String[] hobby, String intro) &#123;        System.out.println(&quot;走了有参构造&quot;);        this.username = username;        this.password = password;        this.sex = sex;        this.hobby = hobby;        this.intro = intro;    &#125;    @Override    public String toString() &#123;        return &quot;User&#123;&quot; +                &quot;username=&#x27;&quot; + username + &#x27;\\&#x27;&#x27; +                &quot;, password=&#x27;&quot; + password + &#x27;\\&#x27;&#x27; +                &quot;, sex=&#x27;&quot; + sex + &#x27;\\&#x27;&#x27; +                &quot;, hobby=&quot; + Arrays.toString(hobby) +                &quot;, intro=&#x27;&quot; + intro + &#x27;\\&#x27;&#x27; +                &#x27;&#125;&#x27;;    &#125;&#125;    @PostMapping(&quot;/register&quot;)    public String register(User user)&#123;        System.out.println(&quot;user = &quot; + user);        return &quot;success&quot;;\n\n2.6 获取请求中hearder和cookie中的值\n设置cookie\n\n&lt;script type=&quot;text/javascript&quot;&gt;    function sendCookie()&#123;        document.cookie= &quot;id=12312312; expires=Thu&quot;;        document.location = &quot;/springmvc/register&quot;;    &#125;&lt;/script&gt;&lt;button onclick=&quot;sendCookie()&quot;&gt;向服务器发送Cookie&lt;/button&gt;\n\n\n通过@RequestHeader获取头信息, 里面的value是需要获取的头的信息的key\n\n通过@CookieValue获取cookie中的信息, 里面的value是需要获取的cookie的key\n\n测试代码\n\n\n@RequestMapping(value = &quot;/register&quot; , method = &#123;RequestMethod.GET, RequestMethod.POST&#125;)public String register(User user,                       @RequestHeader(&quot;Referer&quot;) String Referer,                       @CookieValue(&quot;id&quot;) String cookie_id)&#123;    System.out.println(&quot;user = &quot; + user);    System.out.println(&quot;Referer = &quot; + Referer);    System.out.println(&quot;cookie = &quot; + cookie_id);    return &quot;success&quot;;&#125;\n\n3. domain in SpringMVC3.1 Three domain in Servlet\nRequest domain : only live in one HttpRequest Object Instance\n\nSession Domain : live in one Session, begin in the Browser opening, end of Browser close\n\nSo at this domain you can save cookie\n\n\nApplication Domain : live with the Server, with begin, with end\n\nAll domain Objects always have three methods\n\n\n// 向域中存储数据void setAttribute(String name, Object obj);// 从域中读取数据Object getAttribute(String name);// 删除域中的数据void removeAttribute(String name);\n\n3.2 在SpringMVC中的请求域\n可以通过设置映射器的接收为ModelMap, Map, Model三种类型的时候, 这三种类型都能当作HttpRequest来设置和获取请求域中的数据\n\n其中Map方法特殊一点, 其他的都还是Servlet中Attribute那一套\n\n\n@RequestMapping(&quot;/testDomainForModel&quot;)public String toView(Model model)&#123;    model.addAttribute(&quot;testRequestScope&quot;, &quot;这是通过Model加载到Request的请求域里的内容&quot;);    return &quot;view&quot;;&#125;@RequestMapping(&quot;/testDomainForModelMap&quot;)public String toView(Map&lt;String, Object&gt; map)&#123;    map.put(&quot;testRequestScope&quot;, &quot;这是通过map加载到Request请求域里的内容&quot;);    return &quot;view&quot;;&#125;@RequestMapping(&quot;/testDomainForMap&quot;)public String toView(ModelMap modelMap)&#123;    modelMap.addAttribute(&quot;testRequestScope&quot;, &quot;这是通过ModelMap加载到Request的请求域里的内容&quot;);    return &quot;view&quot;;&#125;\n\n3.3 通过ModelAndView请求域中的数据\n这个时候需要在方法中实例化ModelAndView\naddObject -&gt; 添加请求域中的数据\nsetViewName -&gt; 添加视图\n返回ModelAndView , 这个时候返回的就不是String了\n\n@RequestMapping(&quot;/testDomainForModelAndView&quot;)public ModelAndView toView()&#123;    ModelAndView modelAndView = new ModelAndView();    modelAndView.addObject(&quot;testRequestScope&quot;, &quot;这是通过ModelAndView加载到Request请求域里的内容&quot;);    modelAndView.setViewName(&quot;view&quot;);    return modelAndView;&#125;\n\n3.4 Session域对象\nthymeleaf显示session中的内容\n\n\n通过${session.&lt;session-key&gt;}\n\n&lt;div th:text=&quot;$&#123;session.testSessionScope&#125;&quot;&gt;&lt;/div&gt;&lt;div th:text=&quot;$&#123;session.x&#125;&quot;&gt;&lt;/div&gt;&lt;div th:text=&quot;$&#123;session.y&#125;&quot;&gt;&lt;/div&gt;\n\n\n\n使用Servlet的原生API解决\n\n\n传入HttpSession对象\n在其中setAttribute\n\n@RequestMapping(&quot;/testSessionScope&quot;)public String testSession(HttpSession session)&#123;    session.setAttribute(&quot;testSessionScope&quot;, &quot;value of x&quot;);    return &quot;view&quot;;&#125;\n\n\n\n通过ModelMap类\n\n这个时候需要在类的@Controller上面添加上@SessionAttributes({&lt;session-key1&gt;, &lt;session-key2&gt;})的注解, 用于提前声明ModelMap中的哪些值是session域中的对象\n@SessionAttributes(&#123;&quot;x&quot;, &quot;y&quot;&#125;)@Controllerpublic class RequestDomainController &#123;    @RequestMapping(&quot;/testSessionWithMap&quot;)    public String testSessionWithMap(ModelMap map)&#123;        map.addAttribute(&quot;x&quot;, &quot;value of x&quot;);        map.addAttribute(&quot;y&quot;, &quot;value of y&quot;);        return &quot;view&quot;;    &#125;&#125;\n\n3.5 Application域对象\n通过${application.&lt;application-key&gt;}的形式获取参数\n\n\n一般就是采用Servlet原生API实现\n\n\n方法添加形参HttpServletRequest request\n通过request的getServletContext()方法获取对象\n向其中存取数据 (数据的key不能有-在中间)\n\n@RequestMapping(&quot;/testApplication&quot;)public String testApplication(HttpServletRequest request)&#123;    ServletContext servletContext = request.getServletContext();    servletContext.setAttribute(&quot;applicationkey&quot;,&quot;application-value&quot;);    return &quot;view&quot;;&#125;\n\n4. View4.1 视图支持配置\n一直要复制的springmvc文件中就是为了实现对于视图的配置\n\n&lt;!--视图解析器--&gt;&lt;bean id=&quot;thymeleafViewResolver&quot; class=&quot;org.thymeleaf.spring6.view.ThymeleafViewResolver&quot;&gt;    &lt;!--作用于视图渲染的过程中，可以设置视图渲染后输出时采用的编码字符集--&gt;    &lt;property name=&quot;characterEncoding&quot; value=&quot;UTF-8&quot;/&gt;    &lt;!--如果配置多个视图解析器，它来决定优先使用哪个视图解析器，它的值越小优先级越高--&gt;    &lt;property name=&quot;order&quot; value=&quot;1&quot;/&gt;    &lt;!--当 ThymeleafViewResolver 渲染模板时，会使用该模板引擎来解析、编译和渲染模板--&gt;    &lt;property name=&quot;templateEngine&quot;&gt;        &lt;bean class=&quot;org.thymeleaf.spring6.SpringTemplateEngine&quot;&gt;            &lt;!--用于指定 Thymeleaf 模板引擎使用的模板解析器。模板解析器负责根据模板位置、模板资源名称、文件编码等信息，加载模板并对其进行解析--&gt;            &lt;property name=&quot;templateResolver&quot;&gt;                &lt;bean class=&quot;org.thymeleaf.spring6.templateresolver.SpringResourceTemplateResolver&quot;&gt;                    &lt;!--设置模板文件的位置（前缀）--&gt;                    &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/templates/&quot;/&gt;                    &lt;!--设置模板文件后缀（后缀），Thymeleaf文件扩展名不一定是html，也可以是其他，例如txt，大部分都是html--&gt;                    &lt;property name=&quot;suffix&quot; value=&quot;.html&quot;/&gt;                    &lt;!--设置模板类型，例如：HTML,TEXT,JAVASCRIPT,CSS等--&gt;                    &lt;property name=&quot;templateMode&quot; value=&quot;HTML&quot;/&gt;                    &lt;!--用于模板文件在读取和解析过程中采用的编码字符集--&gt;                    &lt;property name=&quot;characterEncoding&quot; value=&quot;UTF-8&quot;/&gt;                &lt;/bean&gt;            &lt;/property&gt;        &lt;/bean&gt;    &lt;/property&gt;&lt;/bean&gt;\n\n\n其中最重要的内容就是指定了View是Thymeleaf的\n这样的配置, 有利于OCP开闭原则\n\n4.2 SpringMVC 支持的常见视图Spring MVC支持的常见视图包括：\n\nInternalResourceView：内部资源视图（Spring MVC框架内置的，专门为JSP模板语法准备的）\nRedirectView：重定向视图（Spring MVC框架内置的，用来完成重定向效果）\nThymeleafView：Thymeleaf视图（第三方的，为Thymeleaf模板语法准备的）\nFreeMarkerView：FreeMarker视图（第三方的，为FreeMarker模板语法准备的）\nVelocityView：Velocity视图（第三方的，为Velocity模板语法准备的）\nPDFView：PDF视图（第三方的，专门用来生成pdf文件视图）\nExcelView：Excel视图（第三方的，专门用来生成excel文件视图）\n\n4.3 实现视图机制的核心接口\n前面的大多数内容都是对于View视图相关功能的实现的说明, 这里仅做了解, 给出相关文件链接[[第5章 视图View#实现视图机制的核心接口]]\n\n4.4 逻辑视图名到物理视图名\n逻辑视图名 : return的视图名\n物理视图名 : 实际视图文件的完整可寻路径\n这些转化也是在springmvc中进行了配置\n\n&lt;bean id=&quot;thymeleafViewResolver&quot; class=&quot;org.thymeleaf.spring6.view.ThymeleafViewResolver&quot;&gt;    &lt;property name=&quot;characterEncoding&quot; value=&quot;UTF-8&quot;/&gt;    &lt;property name=&quot;order&quot; value=&quot;1&quot;/&gt;    &lt;property name=&quot;templateEngine&quot;&gt;        &lt;bean class=&quot;org.thymeleaf.spring6.SpringTemplateEngine&quot;&gt;            &lt;property name=&quot;templateResolver&quot;&gt;                &lt;bean class=&quot;org.thymeleaf.spring6.templateresolver.SpringResourceTemplateResolver&quot;&gt;                    &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/templates/&quot;/&gt;                    &lt;property name=&quot;suffix&quot; value=&quot;.html&quot;/&gt;                    &lt;property name=&quot;templateMode&quot; value=&quot;HTML&quot;/&gt;                    &lt;property name=&quot;characterEncoding&quot; value=&quot;UTF-8&quot;/&gt;                &lt;/bean&gt;            &lt;/property&gt;        &lt;/bean&gt;    &lt;/property&gt;&lt;/bean&gt;\n\n\n&lt;property name=&quot;prefix&quot; value=&quot;/web-inf/templates/&quot;/&gt; : 这行指明要为逻辑视图名添加上前缀 &#x2F;web-inf&#x2F;templates&#x2F;&lt;property name=&quot;suffix&quot; value=&quot;.html&quot;/&gt; : 这行指明要为逻辑视图名添加上后缀 .html\n\n所以如果逻辑视图名是 “view”, 则最后的物理视图名是 “&#x2F;web-inf&#x2F;templates&#x2F;view.html”\n\n4.5 重定向和转发\n转发 : 浏览器向服务端发送了一个请求以后, 服务端在内部自发地将请求传递给另一个地址\n所以这个时候浏览器上显示的地址是不会发生变化的\n通过这种方式我们是能够访问到WEB-INF中隐藏的资源的\n\n\n重定向 : 同样是浏览器向服务端发送了一个请求以后, 服务端告诉浏览器, 你接下来再去访问这个地址\n所以这个时候能实现跨域, 因为实际上就是重新填写了一次URL\n\n\n\nforward : 实现转发\n简单来说只需要在return的内容上加上 forward:&lt;target&gt;\n\n@Controllerpublic class ForwardController &#123;    @RequestMapping(&quot;/a&quot;)    public String toA()&#123;        return &quot;forward : /b&quot;;    &#125;    @RequestMapping(&quot;/b&quot;)    public String toB() &#123;        System.out.println(&quot;实现了转发&quot;);        return &quot;b&quot;;    &#125;&#125;\n\nredirect\n和forward一样, 将forward改成redirect就行\n\n@RequestMapping(&quot;/a&quot;)public String toA()&#123;    return &quot;redirect:/b&quot;;&#125;@RequestMapping(&quot;/b&quot;)public String toB() &#123;    System.out.println(&quot;实现了转发&quot;);    return &quot;b&quot;;&#125;\n\n4.6 mvc namespace下的一些配置\n需要引入的配置\n\n需要在命名空间添加\nxmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;http://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc.xsd\n\n\n这些配置都是配置在springmvc.xml文件中的\n\nview-controller\n这个功能主要是为了简化一些静态页面的配置, 这些页面的Controller代码往往只是一个return,  通过这个代码的配置能直接实现URL到页面的配置\n\n使用这个之前需要额外配置&lt;mvc:annotation-driven&#x2F;&gt;\n\n\n&lt;mvc:annotation-driven/&gt;&lt;mvc:view-controller path=&quot;/&quot; view-name=&quot;index&quot;/&gt;\n\n静态资源相关配置\n静态资源一般并不是放在WEB-INF中的, 而是直接放在webapp里面的\n\n但是我们现在直接访问静态资源会报错\n\n因为我们之前在web.xml中的配置\n\n\n\n&lt;servlet&gt;    &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;    &lt;init-param&gt;        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;        &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;    &lt;/init-param&gt;    &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;    &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;    &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;\n\n\n我们让所有jsp之外的请求都走DispatchServlet, 这个时候访问静态资源也会走这条路径, 就会404报错\n可以通过开启Servlet处理静态资源的功能\n\n&lt;!--开启默认Servlet处理--&gt;&lt;mvc:default-servlet-handler&gt;\n\n\n这个时候就能正常将请求交给Servlet处理, 这里的逻辑是先交给DispatchServlet处理, 发现它处理不了以后, 就会交给Servlet处理\n\n\n也可以使用mvc:resources标签配置静态资源\n\n&lt;!-- 开启注解驱动 --&gt;&lt;mvc:annotation-driven /&gt;&lt;!-- 配置静态资源处理 --&gt;&lt;mvc:resources mapping=&quot;/static/**&quot; location=&quot;/static/&quot; /&gt;\n\n\n表示但凡路径的开始是&#x2F;static, 那么就会去从&#x2F;static文件夹中找\n\n","categories":["Java","Spring","SpringMVC"],"tags":["Java","Controller","SpringMVC","RESTful","RequestMapping"]},{"title":"Spring中的设计模式","url":"/2025/07/08/Java/Spring/Spring%E4%B8%AD%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/Spring%E4%B8%AD%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","content":"1. 工厂模式2. GoF之代理模式 (结构型设计模式)2.1 代理模式简介为什么需要代理模式间接访问\n在程序中A和B无法直接交互, 可以通过代理C完成A &lt;-&gt; C &lt;-&gt; B以完成交互\n\n增强功能\n程序的功能需要增强时, 可以通过套一层代理模式, 让代理模式实现额外的功能\n使代码更灵活, 遵循OCP\n\n保护\n程序中, 目标需要被保护时, 我们可能需要控制访问权限,  增加额外的控制逻辑\n\n代理模式中的角色![[image (1).png]]\n\n目标类 (真实主题)\n代理类 (代理主题)\n代理类和目标类的公共接口 (抽象主题) : 客户端在使用代理类的时候就像在使用目标类, 所以代理类和目标类要实现共同的接口\n\n2.2 静态代理业务场景三种解决模式\n继承式\n\n\n优点\n相较于将代码直接重新复制黏贴到代理类上, 不用修改源代码, 符合OCP开闭原则\n\n\n缺点\n采用继承式关系, 代码耦合度高\n需要为每个实现类编写代理类, 类膨胀\n\n\n\npublic class OrderServiceProxy extends OrderServiceImpl&#123;    @Override    public void Insert() &#123;        long start = System.currentTimeMillis();        super.Insert();        long end = System.currentTimeMillis();        System.out.println(&quot;耗时&quot; + (end - start) + &quot;ms&quot;);    &#125;    @Override    public void Delete() &#123;        long start = System.currentTimeMillis();        super.Delete();        long end = System.currentTimeMillis();        System.out.println(&quot;耗时&quot; + (end - start) + &quot;ms&quot;);    &#125;    @Override    public void Update() &#123;        long start = System.currentTimeMillis();        super.Update();        long end = System.currentTimeMillis();        System.out.println(&quot;耗时&quot; + (end - start) + &quot;ms&quot;);    &#125;&#125;\n\n\n静态代理式\n\n\n实现\n在代理类创建目标类的属性, 在公共接口中调用目标类的方法, 从而完成代理\n\n\n优点\n相对比与继承式, 关联式关系代码耦合度更低\n符合OCP开闭原则\n\n\n缺点\n类膨胀, 一个接口对应一个接口类, 再加上目标类, 类膨胀迅速, 开发维护困难\n\n\n\npublic class OrderServiceProxy implements OrderService&#123;    private OrderServiceImpl service;    public OrderServiceProxy(OrderServiceImpl service) &#123;        this.service = service;    &#125;    @Override    public void Insert() &#123;        long begin = System.currentTimeMillis();        service.Insert();        long end = System.currentTimeMillis();        System.out.println(&quot;耗时&quot; + (end - begin) + &quot;s&quot;);    &#125;    @Override    public void Delete() &#123;        long begin = System.currentTimeMillis();        service.Delete();        long end = System.currentTimeMillis();        System.out.println(&quot;耗时&quot; + (end - begin) + &quot;s&quot;);    &#125;    @Override    public void Update() &#123;        long begin = System.currentTimeMillis();        service.Update();        long end = System.currentTimeMillis();        System.out.println(&quot;耗时&quot; + (end - begin) + &quot;s&quot;);    &#125;&#125;\n2.3 动态代理三种动态代理技术\nJDK : 通过共同接口实现代理, 缺点是只能代理接口\nCGLIB : 通过继承完成代理, 所以不能用于代理有final关键字修饰的类, 安东尼是能代理类, 也能代理接口\n\nJDK动态代理\n使用步骤\n\n\n创建目标对象\n通过Proxy.newProxyInstance(类加载器, 接口类型, 调用处理器) 创建代理对象\n实现调用处理器, 并将其传入\n\n\n代码\n\n\nClient\n\n// 目标对象        OrderService target = new OrderServiceImpl();        // 代理对象        OrderService proxy = (OrderService) ProxyUtil.newProxyInstance(target);        proxy.Delete();        proxy.Insert();        proxy.Update();\n\n\nProxyUtil\n\npublic static Object newProxyInstance(Object target) &#123;        return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new TimerInvocationHandler(target));    &#125;\n\n\nHandler\n\npublic class TimerInvocationHandler implements InvocationHandler &#123;    private Object target;    public TimerInvocationHandler(Object target) &#123;        this.target = target;    &#125;    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        long begin = System.currentTimeMillis();        Object retValue = method.invoke(target, args);        long end = System.currentTimeMillis();        System.out.println(&quot;耗时&quot; + (end - begin) + &quot;s&quot;);        return retValue;    &#125;&#125;\nCGLIB动态代理\n实现步骤\n\n\n创建增强器对象\n为其设置父类和回调接口\n创建回调接口类, 并传入\n通过增强器对象创建代理类\n\n\n代码\n\n\nClient\n\npublic static void main(String[] args) &#123;    // 创建增强器    Enhancer enhancer = new Enhancer();    enhancer.setSuperclass(OrderServiceImpl.class);    // 设置回调接口    enhancer.setCallback(new TimerMethodInterceptor());    OrderServiceImpl proxy = (OrderServiceImpl) enhancer.create();    proxy.Delete();    proxy.Insert();    proxy.Update();&#125;\n\n\nInteterceptor\n\npublic class TimerMethodInterceptor implements MethodInterceptor &#123;    @Override    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123;        long begin = System.currentTimeMillis();        Object retValue = methodProxy.invokeSuper(o, objects);        long end = System.currentTimeMillis();        System.out.println(&quot;耗时&quot; + (end - begin) + &quot;s&quot;);        System.out.println(&quot;method = &quot; + method);        System.out.println(&quot;methodProxy = &quot; + methodProxy);        return retValue;    &#125;&#125;","categories":["Java","Spring","设计模式"],"tags":["八股文","面试","Java","Spring","设计模式","代理模式","工厂模式","静态代理","动态代理","JDK代理","CGLIB代理"]},{"title":"Redis过期删除策略和内存淘汰策略","url":"/2025/07/08/middle_ware/Redis/%E5%8A%9F%E8%83%BD/%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/","content":"Redis过期删除策略和内存淘汰策略Redis如何设置过期时间?\n给已有的key设置过期时间\n\n\nexpire &lt;key&gt; &lt;time&gt;  : 单位是s, 在time秒后过期\npexpire &lt;key&gt; &lt;time&gt; : 单位是ms, 在time毫秒以后过期\nexpireat &lt;key&gt; &lt;timestamp&gt; : 在timestamp(精确到秒)时刻后过期\npexpireat &lt;key&gt; &lt;timestamp&gt; : 在timestamp(精确到毫秒)时刻后过期\n\n\n在创建可以的时候设置过期时间\n\n\nset &lt;key&gt; &lt;value&gt; ex &lt;time&gt;\nset &lt;key&gt; &lt;value&gt; px &lt;time&gt;\nsetex &lt;key&gt; &lt;time&gt; &lt;value&gt;\n\n\n查看某个key过期时间还剩多少\n\n\nttl key\n\n\n取消key的过期时间\n\n\nPERISIST &lt;key&gt; : 取消key的过期时间, 也就是key被持久化了, persist就是持久化的意思\n\nRedis使用的过期删除策略是什么?Redis中可以为key设置过期时间, Redis中有单独的一张表用于记录每个key的过期时间\n对于删除操作, Redis中有 懒惰删除 和 定期删除 两种策略\n\n懒惰删除 : Redis会在下一次使用到这个key的时候, 先去检查这个key是不是再过期时间表中, 如果在并且已经过期了, 就会将这个key删除, 也就是从内存中释放\n优点 : 对CPU时间友好, 占用CPU的时间更少\n缺点 : 对缓存不友好, 没有被使用到的key会一直占用内存, 即使它已经过期了\n\n\n定期删除 : 为了补足上面懒惰删除中某些没有被使用的过期key会一直占用内存的问题, Redis还有定期删除的设置, Redis会定期抽取一定数量的key, 并检查它们是不是过期了, 过期了就删除. 如果(过期的key &#x2F; 所有检查的key) &gt; 25%, 就会立马开启下一轮检查, 因为这个时候说明redis中有很多过期的key. 否则则等待下一轮检查. 同时为了避免这个删除循环过度, 导致线程卡死, redis中对于每一轮还有时间限制, 如果超过最大时间(默认25ms), 也会退出等待下一轮检查\n优点 : 能清理过期的且使用频率低的key, 对内存友好, 同时最大时间的设置, 也能限制这个操作占用过多的cpu时间\n缺点 : 执行的频率和时间难以把握\n\n\n\nRedis持久时, 对过期键会如何处理?\n对于RDB(Redis Database)文件\n\nRDB文件生成阶段 : 生成的时候会对key进行过期检查, 过期键不会被写入\nRDB文件加载阶段 : 需要从主节点和从节点分情况讨论\n主节点 : 会进行键的过期检查, 如果键过期了, 就不会加载进Redis中\n从节点 : 不会检查, 会将RDB文件中的内容全部重新加载进Redis中, 但是主从节点进行数据同步时候, 从服务器中的数据会被清空, 所以从节点中的过期键也不会造成什么影响\n\n\n\n对于AOF(Append Only)文件\n\nAOF文件生成阶段 : 如果持久化的时候, 数据库中的某个过期键还没有被删除, 就会保留这个键, 等到过期键被删除的时候, 会显式地追加一条DEL删除指令.\nAOF文件重写阶段 : 执行AOF重写的时候, 会对Redis中键进行检查, 已经过期的键不会保存到重写后的AOF文件\n\n主从模式下, Redis怎么处理过期键从服务器不会对过期键做任何处理, 而是在主服务器会对键进行过期检查, 发现键是过期以后, 会在AOF文件中追加一条DEL指令, 同步到所有的从库, 从库通过执行这条DEL指令来删除过期键\n内存淘汰策略有几种在内存满了以后, 会触发Redis的内存淘汰策略, 可以通过设置redis的maxmemory参数设置\n\n在64位系统中, 如果设置maxmemory &#x3D; 0, 即代表不限制redis使用内存\n在32位系统中, 如果设置maxmemory &#x3D; 0, 最大的内存是3GB\n\n内存淘汰策略可以大致分为 不进行数据淘汰策略, 进行数据淘汰策略两类\n\n不进行数据淘汰策略 : 就是简单的在内存满了(超过设置的最大内存)以后, 不淘汰任何数据, 不再提供服务, 直接返回错误\n进行数据淘汰的策略 : 又可以再分成两类, 全局淘汰和只在设置了过期时间的键中进行淘汰\n全局淘汰 : allkeys_random : 全局随机淘汰键, allkeys_lru : 全局LRU淘汰, allkeys_lfu : 淘汰整个键值中最少使用的键\n只在设置了过期时间的键中进行淘汰 : volatile_random : 随机淘汰设置了过期时间的键, volatile_lru : 淘汰最久未被使用的键, volatile_lfu : 淘汰使用次数最少的键, volatile_ttl : 淘汰过期时间更早的键\n\n\n\nRedis中的LRU与LFU\nLRU : Least Recently Used : 最近最少使用\n\nLRU最大的问题是需要维护一个所有数据对象大链表, 以及每次在访问数据项的时候都需要移动链表项, 这两个操作的开销都很大所以在Redis中的LRU是一种 近似LRU, 从而减小LRU算法的开销\n\n为每个redis数据对象添加一个时间戳属性, 用于记录数据的, 记录数据 最后一次访问时间\nRedis在执行缓存淘汰策略的时候, 通过 随机采样的方式淘汰数据, 每次随机抽取5个数据(可以配置), 然后淘汰掉其中的时间戳最久远的一个数据项但是LRU无法解决 缓存污染 的问题\n\n\nLFU : Least Frequently Used : 最近最不常用\n\nRedis记录每个数据项的使用次数\n\nlru : 24bit\n\n在LRU算法中, 这个24bit的数据记录最近一次访问的时间戳在LFU算法中, 高16位存储最近访问时间, 低8位存储访问次数\n在redis中, 同一时间内, 只会使用一种方式解释lru属性, 在运行期间一般不会随意切换淘汰策略\n\n如果从LRU -&gt; LFU : 会将redis对象的lru值初始化(一般是5)\n如果从LFU  -&gt; LRU : 会用新的解释策略解释lru的值\n\n","categories":["中间件","Redis","功能特性"],"tags":["Redis","过期删除","内存淘汰","LRU","LFU","缓存策略"]},{"title":"Spring框架核心概念详解","url":"/2025/07/08/Java/Spring/Spring_/Spring/","content":"2. IoC注入2.1 set注入\n在代码中, 创建setXxx的方法\n在需要创建依赖的Bean里创建Property属性, 添加name和ref\nname填入xxx(set方法后面的单词的首字母小写结果)\nref 填入需要注入的实际的bean的id, 这里的注入, 可以理解为一种向set方法里传参\n\n\n\n2.2 构造注入\n是在创建对象的时候注入, 和set注入的时机不一样\n需要有参构造方法\n\n2.3 注入过程说明\n设置依赖注入的过程\n\n\n编写xml文件, 在其中添加bean, 并设置id与绑定class\n向对应的bean中注入数据\n在主程序中获取\n\n\nxml文件\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;bean id=&quot;userDao&quot; class=&quot;com.func.spring.dao.UserDao&quot;&gt;&lt;/bean&gt;    &lt;bean id=&quot;vipDao&quot; class=&quot;com.func.spring.dao.VipDao&quot;&gt;&lt;/bean&gt;    &lt;!--构造注入--&gt;    &lt;!--参数名和索引均不指定, 让spring自己做类型匹配--&gt;    &lt;bean id=&quot;csbean3&quot; class=&quot;com.func.spring.service.CustomService&quot;&gt;        &lt;constructor-arg ref=&quot;userDao&quot;&gt;&lt;/constructor-arg&gt;        &lt;constructor-arg ref=&quot;vipDao&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;!--根据构造方法的参数名字注入--&gt;    &lt;bean id=&quot;csbean2&quot; class=&quot;com.func.spring.service.CustomService&quot;&gt;        &lt;constructor-arg name=&quot;userDao&quot; ref=&quot;userDao&quot;&gt;&lt;/constructor-arg&gt;        &lt;constructor-arg name=&quot;vipDao&quot; ref=&quot;vipDao&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;!--根据索引注入--&gt;    &lt;!--ref填入的是ben的id--&gt;    &lt;bean id=&quot;customService&quot; class=&quot;com.func.spring.service.CustomService&quot;&gt;        &lt;constructor-arg index=&quot;0&quot; ref=&quot;userDao&quot;&gt;&lt;/constructor-arg&gt;        &lt;constructor-arg index=&quot;1&quot; ref=&quot;vipDao&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;&lt;/beans&gt;\n\n\njava文件\n\npublic void testConstructor()&#123;    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);    CustomService customService = applicationContext.getBean(&quot;customService&quot;, CustomService.class);    customService.save();    ApplicationContext applicationContext1 = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);    CustomService customService1 = applicationContext1.getBean(&quot;csbean2&quot;, CustomService.class);    customService1.save();    ApplicationContext applicationContext2 = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);    CustomService customService2 = applicationContext2.getBean(&quot;csbean3&quot;, CustomService.class);    customService2.save();&#125;\n\n2.4 set注入专题2.4.1 内部bean和外部bean\n通过在外部新建一个bean, 然后另一个bean通过设置ref属性的引入方式称为外部引入\n\n通过在该bean中嵌套另一个bean的方式称为内部bean\n\n\n&lt;!--外部bean, 通过ref引用--&gt;&lt;bean id=&quot;oderDao&quot; class=&quot;com.func.spring.dao.OderDao&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;oderServ1&quot; class=&quot;com.func.spring.service.OderService&quot;&gt;    &lt;property name=&quot;oderDao&quot; ref=&quot;oderDao&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--内部bean, 通过嵌套生成--&gt;&lt;bean id=&quot;oderServ2&quot; class=&quot;com.func.spring.service.OderService&quot;&gt;    &lt;property name=&quot;oderDao&quot;&gt;        &lt;bean class=&quot;com.func.spring.dao.OderDao&quot;&gt;&lt;/bean&gt;    &lt;/property&gt;&lt;/bean&gt;\n\n2.4.2 注入简单类型\n有哪些属于简单类型\n\n\nSpring源码中对简单类型的界定\n\npublic class BeanUtils&#123;        //.......        /**\t * Check if the given type represents a &quot;simple&quot; property: a simple value\t * type or an array of simple value types.\t * &lt;p&gt;See &#123;@link #isSimpleValueType(Class)&#125; for the definition of &lt;em&gt;simple\t * value type&lt;/em&gt;.\t * &lt;p&gt;Used to determine properties to check for a &quot;simple&quot; dependency-check.\t * @param type the type to check\t * @return whether the given type represents a &quot;simple&quot; property\t * @see org.springframework.beans.factory.support.RootBeanDefinition#DEPENDENCY_CHECK_SIMPLE\t * @see org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#checkDependencies\t * @see #isSimpleValueType(Class)\t */\tpublic static boolean isSimpleProperty(Class&lt;?&gt; type) &#123;\t\tAssert.notNull(type, &quot;&#x27;type&#x27; must not be null&quot;);\t\treturn isSimpleValueType(type) || (type.isArray() &amp;&amp; isSimpleValueType(type.getComponentType()));\t&#125;\t/**\t * Check if the given type represents a &quot;simple&quot; value type: a primitive or\t * primitive wrapper, an enum, a String or other CharSequence, a Number, a\t * Date, a Temporal, a URI, a URL, a Locale, or a Class.\t * &lt;p&gt;&#123;@code Void&#125; and &#123;@code void&#125; are not considered simple value types.\t * @param type the type to check\t * @return whether the given type represents a &quot;simple&quot; value type\t * @see #isSimpleProperty(Class)\t */\tpublic static boolean isSimpleValueType(Class&lt;?&gt; type) &#123;\t\treturn (Void.class != type &amp;&amp; void.class != type &amp;&amp;\t\t\t\t(ClassUtils.isPrimitiveOrWrapper(type) ||\t\t\t\tEnum.class.isAssignableFrom(type) ||\t\t\t\tCharSequence.class.isAssignableFrom(type) ||\t\t\t\tNumber.class.isAssignableFrom(type) ||\t\t\t\tDate.class.isAssignableFrom(type) ||\t\t\t\tTemporal.class.isAssignableFrom(type) ||\t\t\t\tURI.class == type ||\t\t\t\tURL.class == type ||\t\t\t\tLocale.class == type ||\t\t\t\tClass.class == type));\t&#125;        //........&#125;\n\n通过源码分析得知，简单类型包括：\n\n基本数据类型\n基本数据类型对应的包装类\nString或其他的CharSequence子类\nNumber子类\nDate子类\nEnum子类\nURI\nURL\nTemporal子类\nLocale\nClass\n另外还包括以上简单值类型对应的数组类型。\n\n\n给简单类型注入, 使用value属性赋值, 而不是ref, ref给对象属性赋值, 需要特别注意的是简单类型中的Date类型\n\n    &lt;bean id=&quot;spv&quot; class=&quot;com.func.spring.bean.SimpleValue&quot;&gt;        &lt;property name=&quot;i1&quot; value=&quot;213&quot;/&gt;        &lt;property name=&quot;i2&quot; value=&quot;123&quot;/&gt;        &lt;property name=&quot;b1&quot; value=&quot;false&quot;/&gt;        &lt;property name=&quot;b2&quot; value=&quot;true&quot;/&gt;        &lt;property name=&quot;c1&quot; value=&quot;c&quot;/&gt;        &lt;property name=&quot;c2&quot; value=&quot;d&quot;/&gt;        &lt;property name=&quot;string&quot; value=&quot;fung&quot;/&gt;        &lt;property name=&quot;season&quot; value=&quot;SPRING&quot;/&gt;        &lt;property name=&quot;clazz&quot; value=&quot;java.lang.String&quot;/&gt;        &lt;!--如果要把Data当成简单类型, 输入需要满足特定的格式--&gt;        &lt;!--value后面的日期字符串格式不能随便写，必须是Date对象toString()方法执行的结果--&gt;        &lt;!--实际开发中, 一般不会将Data当成简单类型--&gt;&lt;!--        &lt;property name=&quot;birth&quot; value=&quot;Fri Sep 30 15:26:38 CST 2022&quot;/&gt;--&gt;    &lt;/bean&gt;\n\n2.4.3 简单类型的注入的经典应用\n用于配置配置文件\n\n&lt;bean id=&quot;dataSource&quot; class=&quot;com.func.spring.jdbc.MyDataSource&quot;&gt;        &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt;        &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;        &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt;        &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3360/spring6&quot;/&gt;    &lt;/bean&gt;\n\n2.4.4 注入数组\n在&lt;property&gt;下再添加一组&lt;array&gt;标签即可 , 然后在里面添加数据\n\n&lt;bean id=&quot;w1&quot; class=&quot;com.func.spring.bean.Woman&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;蔡徐坤&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;w2&quot; class=&quot;com.func.spring.bean.Woman&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;陈立农&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;w3&quot; class=&quot;com.func.spring.bean.Woman&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;及格&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;qian&quot; class=&quot;com.func.spring.bean.YuQian&quot;&gt;    &lt;property name=&quot;habits&quot;&gt;        &lt;array&gt;            &lt;value&gt;抽烟&lt;/value&gt;            &lt;value&gt;喝酒&lt;/value&gt;            &lt;value&gt;烫头&lt;/value&gt;        &lt;/array&gt;    &lt;/property&gt;    &lt;property name=&quot;women&quot;&gt;        &lt;array&gt;            &lt;ref bean=&quot;w1&quot;/&gt;            &lt;ref bean=&quot;w2&quot;/&gt;            &lt;ref bean=&quot;w3&quot;/&gt;        &lt;/array&gt;    &lt;/property&gt;&lt;/bean&gt;\n\n2.4.5 Set集合, Map集合, Properties类型注入\nSet\n\n&lt;!--测试Set--&gt;&lt;property name=&quot;addr&quot;&gt;    &lt;set&gt;        &lt;value&gt;ff&lt;/value&gt;        &lt;value&gt;ff&lt;/value&gt;        &lt;value&gt;df&lt;/value&gt;        &lt;value&gt;ff&lt;/value&gt;    &lt;/set&gt;&lt;/property&gt;\n\n\nMap\n\n&lt;!--测试Map--&gt;&lt;property name=&quot;phones&quot;&gt;    &lt;map&gt;        &lt;entry key=&quot;1&quot; value=&quot;110&quot;/&gt;        &lt;entry key=&quot;2&quot; value=&quot;120&quot;/&gt;        &lt;entry key=&quot;3&quot; value=&quot;119&quot;/&gt;    &lt;/map&gt;&lt;/property&gt;\n\n\nProperties\n\n    &lt;!--测试Properties--&gt;    &lt;property name=&quot;properties&quot;&gt;        &lt;props&gt;            &lt;prop key=&quot;username&quot;&gt;root&lt;/prop&gt;            &lt;prop key=&quot;password&quot;&gt;root&lt;/prop&gt;            &lt;prop key=&quot;url&quot;&gt;jdbc:mysql://localhost:3306:/spring&lt;/prop&gt;            &lt;prop key=&quot;driver&quot;&gt;com.mysql.cj.jdbc.Driver&lt;/prop&gt;        &lt;/props&gt;    &lt;/property&gt;&lt;/bean&gt;\n\n2.4.6 注入特殊字符与null\n特殊字符 : 两种方式, 一种是换成转义字符, 还有一种解决方式是使用!&lt;[CDATA[]]&gt;\n\n\n代码\n\n    &lt;bean id=&quot;math&quot; class=&quot;com.func.spring.bean.MathBean&quot;&gt;        &lt;!--会报错--&gt;&lt;!--        &lt;property name=&quot;data&quot; value=&quot;2 &lt; 3&quot;/&gt;--&gt;        &lt;!--转义--&gt;&lt;!--        &lt;property name=&quot;data&quot; value=&quot;2 &amp;lt; 3&quot;/&gt;--&gt;        &lt;!--CDATA方式, 其中的value标签需要额外写出来--&gt;        &lt;property name=&quot;data&quot;&gt;            &lt;value&gt;&lt;![CDATA[2 &lt; 3]]&gt;&lt;/value&gt;        &lt;/property&gt;    &lt;/bean&gt;\n\n\n转移字符表\n\n\n\n\n特殊字符\n转义字符\n\n\n\n&gt;\n&amp;gt;\n\n\n&lt;\n&amp;lt;\n\n\n‘\n&amp;apos;\n\n\n“\n&amp;quot;\n\n\n&amp;\n&amp;amp;\n\n\n\n注入null与空字符\n\n&lt;bean id=&quot;cat&quot; class=&quot;com.func.spring.bean.Cat&quot;&gt;        &lt;!--默认不写的时候, 值就是null--&gt;        &lt;!--手动设置的方法--&gt;&lt;!--        &lt;property name=&quot;name&quot;&gt;--&gt;&lt;!--            &lt;null/&gt;--&gt;&lt;!--        &lt;/property&gt;--&gt;        &lt;!--空字符串--&gt;        &lt;property name=&quot;name&quot; value=&quot;&quot;/&gt;&lt;!--        &lt;property name=&quot;name&quot;&gt;--&gt;&lt;!--            &lt;value/&gt;--&gt;&lt;!--        &lt;/property&gt;--&gt;    &lt;/bean&gt;\n\n\n2.5 基于命名空间的注入和配置复用\n命名空间的引入, 可以简化配置的过程\n\n\np命名空间, 能简化set注入的过程\n\n\n在XML头部信息中添加p命名空间的配置信息：xmlns:p&#x3D;”http://www.springframework.org/schema/p&quot;\n提供setter方法\n\n&lt;!--p命名空间注入--&gt;&lt;bean id=&quot;dog&quot; class=&quot;com.func.spring.bean.Dog&quot; p:age=&quot;123&quot; p:name=&quot;虎牙&quot;&gt;&lt;/bean&gt;\n\n\nc命名空间注入, 简化了构造注入的过程\n\n\n需要在xml配置文件头部添加信息：xmlns:c&#x3D;”http://www.springframework.org/schema/c“\n需要提供构造方法。\n\n&lt;!--c命名空间注入--&gt;&lt;bean id=&quot;dog&quot; class=&quot;com.func.spring.bean.Dog&quot; c:age=&quot;12&quot; c:name=&quot;lichengxing&quot; &gt;&lt;/bean&gt;\n\n\nutil命名空间与配置复用 : 通过设置该命名空间能让一份properties被多处引用配置\n\n\n在xml中进行如下设置![[images&#x2F;Pasted image 20241224140647.png]]\n\n&lt;!-- util命名空间, 让配置复用--&gt;&lt;util:properties id=&quot;prop&quot;&gt;    &lt;prop key=&quot;username&quot;&gt;root&lt;/prop&gt;    &lt;prop key=&quot;password&quot;&gt;root&lt;/prop&gt;    &lt;prop key=&quot;url&quot;&gt;jdbc:mysql://localhost:3306/spring&lt;/prop&gt;    &lt;prop key=&quot;driver&quot;&gt;com.mysql.cj.jdbc.Driver&lt;/prop&gt;&lt;/util:properties&gt;&lt;!--c命名空间注入--&gt;&lt;bean id=&quot;dog&quot; class=&quot;com.func.spring.bean.Dog&quot; p:age=&quot;12&quot; p:name=&quot;lichengxing&quot; &gt;    &lt;property name=&quot;properties&quot; ref=&quot;prop&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;dog1&quot; class=&quot;com.func.spring.bean.Dog&quot; p:age=&quot;2&quot; p:name=&quot;Lichengxing&quot;&gt;    &lt;property name=&quot;properties&quot; ref=&quot;prop&quot;/&gt;&lt;/bean&gt;\n\n2.6 基于XML的自动装配\n我们可以不用ref来主动设置bean的注入的参数, 通过该功能, XML能够自动出装配参数\n\n\nbyName : 通过参数名自动装配, 但这里的参数名实际上是对应的setter方法的名字\n\n\n设置autowrite属性为byName\n\n&lt;bean id=&quot;cs&quot; class=&quot;com.func.spring.service.CustomService&quot; autowire=&quot;byName&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;vipDao&quot; class=&quot;com.func.spring.dao.VipDao&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;userDao&quot; class=&quot;com.func.spring.dao.UserDao&quot;&gt;&lt;/bean&gt;\n\n\nbyType : 通过参数类型自动装配, 通过这种方式, 实例化的bean可以不设置id\n\n\n设置为byType\n\n&lt;bean class=&quot;com.func.spring.dao.VipDao&quot;&gt;&lt;/bean&gt;&lt;bean class=&quot;com.func.spring.dao.UserDao&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;cs&quot; class=&quot;com.func.spring.service.CustomService&quot; autowire=&quot;byType&quot;&gt;&lt;/bean&gt;\n\n2.7  XML装配外部资源文件\n建立外部资源文件\n\nusername=rootpassword=rooturl=jdbc:mysql://localhost:3306/springdriver=com.mysql.cj.jdbc.Driver\n\n\n在bean中引入\n\n\n修改xml约束, 增加context相关内容\n导入外部资源\n引用外部资源\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;    &lt;context:property-placeholder location=&quot;jdbc.properties&quot;/&gt;    &lt;bean id=&quot;prop&quot; class=&quot;com.func.spring.jdbc.MyDataSource&quot;&gt;        &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot;/&gt;        &lt;property name=&quot;driver&quot; value=&quot;$&#123;driver&#125;&quot;/&gt;        &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt;        &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;\n\n3. Bean的作用域3.1 Bean作用域之单例和多例\n默认情况下\n\n\n在默认情况下Spring是单例的, 创建实例的时机是在启动容器的时候创建的, 即在new完ClassPathXmlApplicationContext之后即创建完毕, 后面再getBean, 获取到的都是同一个实例\n\n\n设置为原型&#x2F;多例的情况\n\n\n通过设置bean的属性scope为prototype, 这个时候创建对象为多例\n创建对象的时机时在getbean的时候创建\n\n\nxml\n\n&lt;bean id=&quot;scope&quot; class=&quot;com.func.spring.bean.SpringBean&quot; scope=&quot;prototype&quot;&gt;&lt;/bean&gt;\n\n\n3.2 自定义scope\n自定义xml : 这里只是简单提了一下, 这个自定义的scope是直接用的Spring中内置好的类实现的\n\n&lt;bean id=&quot;scope&quot; class=&quot;com.func.spring.bean.SpringBean&quot; scope=&quot;ThreadScope&quot;&gt;&lt;/bean&gt;&lt;bean class=&quot;org.springframework.beans.factory.config.CustomScopeConfigurer&quot;&gt;    &lt;property name=&quot;scopes&quot;&gt;        &lt;map&gt;            &lt;entry key=&quot;ThreadScope&quot;&gt;                &lt;bean class=&quot;org.springframework.context.support.SimpleThreadScope&quot;/&gt;            &lt;/entry&gt;        &lt;/map&gt;    &lt;/property&gt;&lt;/bean&gt;\n\n\n测试代码\n\n@Testpublic void testThreadScope()&#123;    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;spring-bean.xml&quot;);    SpringBean scope = applicationContext.getBean(&quot;scope&quot;, SpringBean.class);    System.out.println(scope);    SpringBean scope1 = applicationContext.getBean(&quot;scope&quot;, SpringBean.class);    System.out.println(scope1);    new Thread(new Runnable() &#123;        @Override        public void run() &#123;            SpringBean scope2 = applicationContext.getBean(&quot;scope&quot;, SpringBean.class);            System.out.println(scope2);            SpringBean scope3 = applicationContext.getBean(&quot;scope&quot;, SpringBean.class);            System.out.println(scope3);        &#125;    &#125;).start();&#125;\n\n4. GoF之工厂模式5. Bean5.1 Bean的四种实例化方法5.1.1 通过构造方法的实例化\n就是先前创建bean实例的方式, 直接创建对应的bean, 就会通过对应class的无参构造方法实例化对象\n\n5.1.2 通过简单工厂模式实例化\n步骤\n创建工厂类, 创建产品类\n在工厂类中添加简单工厂方法, 用于获取对应的产品\n工厂方法需要是public static 类型的, 返回对应产品的新的实例\n在xml文件中声明产品类的bean, 设置的class是工厂类, 并添加factory-mothod属性, 填写内容是产品对应工厂方法的名字\n\n\n\n\n最后的对象, 其实是自己new出来的\n\npublic class StarFactory &#123;    public static Star get()&#123;        return new Star();    &#125;&#125;@Datapublic class Star &#123;    private String name;&#125;\n\n&lt;bean id=&quot;StarBean&quot; class=&quot;com.func.spring.StarFactory&quot; factory-method=&quot;get&quot;&gt;&lt;/bean&gt;\n\n5.1.3 通过factory-bean实例化\n通过工厂方法模式实例化 : 每个产品对应一个工厂角色\n\n\n步骤\n创建对应的产品类和工厂类\n创建对应的工厂方法(不是static的, 也因此, 需要指定工厂类)\n在xml中声明工厂类bean\n通过设置factory-bean为工厂类bean, factory-method为对应的工厂方法, 来实例化新的bean\n\n\n\npublic class Gun &#123;&#125;public class GunFactory &#123;    public Gun get()&#123;        return new Gun();    &#125;&#125;\n\n&lt;bean id=&quot;GunFactory&quot; class=&quot;com.func.spring.GunFactory&quot;&gt;&lt;/bean&gt;&lt;bean id=&quot;gun&quot; factory-method=&quot;get&quot; factory-bean=&quot;GunFactory&quot;&gt;&lt;/bean&gt;\n\n5.1.4 通过FactoryBean接口实例化\n实质上是对第三种方法的简化, 通过实现接口来简化第三种方案\n\n\n步骤\n创建产品类和工厂类\n工厂类继承FactoryBean&lt;&gt;接口, 并实现其中的方法\n在getObject()中返回new的产品实例\n在xml中声明产品bean, 但是其class填写工厂类\n\n\n\npublic class Person &#123;    public Person()&#123;        System.out.println(&quot;调用了Person的无参构造&quot;);    &#125;public class PersonFactory implements FactoryBean&lt;Person&gt; &#123;    @Override    public Person getObject() throws Exception &#123;        System.out.println(&quot;调用了Person的工厂方法&quot;);        return new Person();    &#125;    @Override    public Class&lt;?&gt; getObjectType() &#123;        return null;    &#125;    @Override    public boolean isSingleton() &#123;        return FactoryBean.super.isSingleton();    &#125;&#125;\n\n&lt;bean id=&quot;person&quot; class=&quot;com.func.spring.PersonFactory&quot;&gt;&lt;/bean&gt;\n\n5.1.5 Bean工厂实例化方法的实际运行\n通过Bean工厂实例化, 来实现对于Date这一属性的赋值\n\n\n先创建Date工厂\n在工厂的getObject方法中, 返回规定了格式的Date对象\n返回对应format的Date对象\n在xml实例化\n\n@Datapublic class Student &#123;    private Date birth;&#125;@NoArgsConstructor@AllArgsConstructor@Datapublic class DateFactory implements FactoryBean&lt;Date&gt; &#123;    private String strDate;    @Override    public Date getObject() throws Exception &#123;        SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-mm-dd&quot;);        Date birth = sdf.parse(this.strDate);        return birth;    &#125;    @Override    public Class&lt;?&gt; getObjectType() &#123;        return null;    &#125;&#125;\n\n&lt;bean class=&quot;com.func.spring.DateFactory&quot; id=&quot;date&quot;&gt;    &lt;property name=&quot;strDate&quot; value=&quot;1980-11-20&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;stu&quot; class=&quot;com.func.spring.Student&quot;&gt;    &lt;property name=&quot;birth&quot; ref=&quot;date&quot;/&gt;&lt;/bean&gt;\n\n6. Bean的生命周期6.1 Bean的生命周期之五步\n调用bean的无参构造方法创建bean\n为bean赋值\n调用bean的init()方法, 初始化bean\n使用bean\n销毁bean, 调用bean的destroy()方法 : 发生在容器关闭的时候\n\npublic class User &#123;    private String name;    public User()&#123;        System.out.println(&quot;第一步: 构造bean&quot;);    &#125;    public void setName(String name) &#123;        System.out.println(&quot;第二步: 为bean赋值&quot;);        this.name = name;    &#125;    public void initBean()&#123;        System.out.println(&quot;第三步: 初始化bean&quot;);    &#125;    public void destroyBean()&#123;        System.out.println(&quot;第五步: 销毁bean&quot;);    &#125;&#125;\n\n\n容器的关闭需要将ApplicationContest类型强转为ClassPathXmlApplicationContext后才能调用close()方法\n\n@Testpublic void testLifeCycleFive()&#123;    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;beans.xml&quot;);    User user = applicationContext.getBean(&quot;user&quot;, User.class);    System.out.println(&quot;第四步: 使用bean&quot; + user);    ClassPathXmlApplicationContext context = (ClassPathXmlApplicationContext) applicationContext;    context.close();&#125;\n\n\n需要人为创建和绑定初始化和销毁方法\n\n&lt;bean id=&quot;user&quot; class=&quot;com.func.spring.User&quot; init-method=&quot;initBean&quot; destroy-method=&quot;destroyBean&quot;&gt;    &lt;property name=&quot;name&quot; value=&quot;张三&quot;/&gt;&lt;/bean&gt;\n\n\n6.2 Bean生命周期之七步\n通过bean后处理器, 在初始化前后添加了两个周期\n\n\n创建对象实现后处理器接口, 并重写其中的方法\n在xml文件中实例化, 这个实现了后处理接口的对象, 这个后处理器的作用范围是整个配置文件\n\npublic class BeanProcessor implements BeanPostProcessor &#123;    @Override    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        System.out.println(beanName + &quot; &quot; + bean + &quot; 在初始化前执行了后处理器中的before方法&quot;);        return BeanPostProcessor.super.postProcessBeforeInitialization(bean, beanName);    &#125;    @Override    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;        System.out.println(beanName + &quot; &quot; + bean + &quot; 在初始化前执行了后处理器中的after方法&quot;);        return BeanPostProcessor.super.postProcessAfterInitialization(bean, beanName);    &#125;&#125;\n\n&lt;bean class=&quot;com.func.spring.BeanProcessor&quot;&gt;&lt;/bean&gt;\n\n6.3 Bean的生命周期之十步\n添加三部分别在\n\n\nbean后处理器的before方法之前 : 对应的接口有BeanClassLoaderAware, BeanFactoryAware, BeanNameAware\nbean后处理器的before方法之后 : 对应的接口有InitializingBean\nbean销毁之前, 即destroy方法调用之前 : 对应的接口有DisposableBean\n\npublic class User implements BeanClassLoaderAware, BeanFactoryAware, BeanNameAware, InitializingBean, DisposableBean &#123;    private String name;    public User()&#123;        System.out.println(&quot;第一步: 构造bean&quot;);    &#125;    public void setName(String name) &#123;        System.out.println(&quot;第二步: 为bean赋值&quot;);        this.name = name;    &#125;    public void initBean()&#123;        System.out.println(&quot;第三步: 初始化bean&quot;);    &#125;    public void destroyBean()&#123;        System.out.println(&quot;第五步: 销毁bean&quot;);    &#125;    @Override    public void setBeanClassLoader(ClassLoader classLoader) &#123;        System.out.println(&quot;Bean的类加载器是&quot; + classLoader);    &#125;    @Override    public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123;        System.out.println(&quot;生产bean的工厂是&quot; + beanFactory);    &#125;    @Override    public void setBeanName(String name) &#123;        System.out.println(&quot;bean的名字是&quot; + name);    &#125;    @Override    public void afterPropertiesSet() throws Exception &#123;        System.out.println(&quot;执行了 afterPropertiesSet() 方法&quot;);    &#125;    @Override    public void destroy() throws Exception &#123;        System.out.println(&quot;执行了销毁bean前的会执行的方法&quot;);    &#125;&#125;\n\n6.4 生命周期之不同作用域\n只有单例的bean实例, Spring才会全程管理\n如果是多例的bean. Spring只会管理到使用bean那一步, 后续的两步DisposableBean接口对应的Destroy方法和bean实例的销毁方法都不会再由Spring管理\n\n6.5 如何让自己new的对象给Spring管理\n如何在半途中将自己new的对象交给Spring管理\n\n\nnew一个自己的对象\n通过DefaultListableBeanFactory类, 注册单例, 并通过这个类从容器中获取bean\n\npublic void testRegisterBean()&#123;    User user = new User();    System.out.println(user);    DefaultListableBeanFactory factory = new DefaultListableBeanFactory();    factory.registerSingleton(&quot;userBean&quot;,user);    User user1 = factory.getBean(&quot;userBean&quot;, User.class);    System.out.println(user1);&#125;\n\n7. Bean的循环依赖\n什么情况是循环依赖\n\n\n当对象A中有属性B, 同时对象B中也有属性A, 那么这个在通过Spring实例化的时候, 就出现了循环依赖\n\n7.1 通过setter实例化的bean对象\n只有Setter + singleton的组合, 才能即使产生了循环依赖, 但是也能成功实例化\n\n\n为什么这个组合能成功, 但是prototype却会创建失败\n\n\nSpring在创建单例的实例的过程中采取先”曝光”, 后赋值的形式, 这对于Spring来说是两个阶段\nSpring会在第一个阶段将所有的单例的bean先通过无参构造方法创建好, 再进行曝光\n在第二个阶段再进行赋值操作, 这样在赋值的时候, 就能成功的将创建好的对象传入\n同时, 根据上面的原理, 我们可以知道, 相互依赖的两个对象, 其实只要有一个对象是单例的, 就能成功实例化\n\n@AllArgsConstructor@Datapublic class Husband &#123;    private String name;    private Wife wife;    @Override    public String toString() &#123;        return &quot;Husband&#123;&quot; +                &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; +                &quot;, wife=&quot; + wife.getName() +                &#x27;&#125;&#x27;;    &#125;&#125;@AllArgsConstructor@Datapublic class Wife &#123;    private String name;    private Husband husband;&#125;        ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;spring1.xml&quot;);        Husband husband = applicationContext.getBean(&quot;husband&quot;, Husband.class);        System.out.println(husband);\n\n7.2 通过有参构造器实例化bean对象\n根据上面的原理, 其实能得出, 如果是通过有参构造器实例化bean对象, 那么怎么样都是不能够成功创建的\n\n7.3 Bean的循环依赖之源码分析\n通过分析Spring源码, 能得出Spring通过三级缓存完成了提前曝光的过程\n\n\n一级缓存 : 缓存的是完整的单例Bean对象, 已经完成了赋值\n二级缓存 : 缓存的是没有进行赋值的单例Bean对象\n三级缓存 : 缓存的是单例Bean对象的工厂对象, 这个对象也是被提前曝光的对象\nSpring在getSingleton()方法中, 从第一级逐级访问来查看该层缓存有没有保存对应的bean对象\n\n8.回顾反射机制[[javaAdvance#44. 反射]]\n9. 手写spring框架9.1 创建相关类\n创建ApplicationContext接口, 并在其中添加getBean(String beanId)方法\n创建实现类\n\n9.2 创建bean实例并存储到map中\n创建map集合用于存储beans\n解析xml文件, 并将解析获取到的类调用无参构造方法后实例化到beanMap中\n使用SAXReader.read从Resource文件夹中获取resourse路径对应的xml文件的文本流\n利用第一步获取到的document对象, 从中获取到根标签, 并从中获取到所有一级子标签List -&gt; beanNodes\n从一级子标签获取id和class属性, 通过class属性填写的类路径实例化bean, 并以id为名字存入beanMap中\n\n\n以此完成了一级存储和曝光\n\n9.3 给bean的属性赋值\n遍历beanNodes\n获取id属性, 以对应beanMap中的实例, 获取所有的property子标签properties, 以完成赋值\n通过properties获取属性name和value(或ref)\n通过name, 拼接出set方法的方法名\n通过反射获取到set方法\n调用set方法赋值, 通过属性是value还是ref, 判断是简单类型还是引用类型\n是简单类型\n获取到类中对应name的field的类型\n通过switch case语句, 完成对value的类型转换\n调用set方法将值注入\n\n\n非简单类型\n直接从beanMap中通过ref的名字获取到对应对象的引用\n调用set方法将值注入\n\n\n\n\n\n9.4 完整源码/** * @author 方天宇 * @version 1.0 * @className ClassPathXmlApplicationContext * @date 2024/12/26 */public class ClassPathXmlApplicationContext implements ApplicationContext &#123;    // Map用于存储bean    private Map&lt;String, Object&gt; beanMap = new HashMap&lt;&gt;();    /**     * 构造方法解析xml文件, 并创建所有的实例bean, 以此实现曝光     * @param resource xml文件的资源路径     */    public ClassPathXmlApplicationContext(String resource) &#123;        try &#123;            SAXReader saxReader = new SAXReader();            Document document = saxReader.read(ClassLoader.getSystemClassLoader().getResourceAsStream(resource));            // 获取到所有的bean标签            List&lt;Element&gt; beanNodes = document.getRootElement().elements();            // 遍历标签            beanNodes.forEach(beanNode -&gt; &#123;                String id = beanNode.attributeValue(&quot;id&quot;);                String className = beanNode.attributeValue(&quot;class&quot;);                // 通过反射机制创建对象, 并放入map集合中                try &#123;                    Class&lt;?&gt; clazz = Class.forName(className);                    // 创建新的实例                    Constructor&lt;?&gt; constructor = clazz.getConstructor();                    Object bean= constructor.newInstance();                    // 将新的实例添加到Map集合中                    beanMap.put(id, bean);                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;);        // 给bean的属性赋值, 将创建对象和赋值这两阶段分开进行, 以此实现曝光        beanNodes.forEach(beanNode -&gt;&#123;            String id = beanNode.attributeValue(&quot;id&quot;);            List&lt;Element&gt; properties = beanNode.elements(&quot;property&quot;);            properties.forEach(property -&gt; &#123;                try &#123;                    String propertyName = property.attributeValue(&quot;name&quot;);                    String value = property.attributeValue(&quot;value&quot;);                    String ref = property.attributeValue(&quot;ref&quot;);                    // 获取属性类型                    Class&lt;?&gt; propertyType = beanMap.get(id).getClass().getDeclaredField(propertyName).getType();                    // 获取set方法                    String setMethodName = &quot;set&quot; + propertyName.toUpperCase().charAt(0) + propertyName.substring(1);                    Method setMethod = beanMap.get(id).getClass().getDeclaredMethod(setMethodName, propertyType);                    // 获取set方法                    Object propertyValue = null;                    if (value == null) &#123;                        // 非简单类型                        setMethod.invoke(beanMap.get(id), beanMap.get(ref));                    &#125;                    if (ref == null) &#123;                        // 简单类型                        String propertySimpleName = propertyType.getSimpleName();                        // 将值从String转为对应的简单类型                        switch (propertySimpleName) &#123;                            case &quot;int&quot; : case &quot;Integer&quot; :                                propertyValue = Integer.valueOf(value);                                break;                            case &quot;double&quot; : case &quot;Double&quot;:                                propertyValue = Double.valueOf(value);                                break;                            case &quot;float&quot;: case &quot;Float&quot;:                                propertyValue = Float.valueOf(value);                                break;                            case &quot;long&quot; : case &quot;Long&quot; :                                propertyValue = Long.valueOf(value);                                break;                            case &quot;short&quot; : case &quot;Short&quot;:                                propertyValue = Short.valueOf(value);                                break;                            case &quot;boolean&quot;: case &quot;Boolean&quot;:                                propertyValue = Boolean.valueOf(value);                                break;                            case &quot;char&quot; : case &quot;Character&quot; :                                propertyValue = value.charAt(0);                                break;                            default:                                propertyValue = value;                       break;                        &#125;                        setMethod.invoke(beanMap.get(id), propertyValue);                    &#125;                &#125; catch (Exception e) &#123;                   e.printStackTrace();                &#125;            &#125;);        &#125;);        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    @Override    public Object getBean(String beanId) &#123;        return beanMap.get(beanId);    &#125;&#125;\n10. IoC注解式开发10.1 回顾注解开发10.1.1注解的意义\n在Spring中引入注解的目的是为了简化繁琐的配置过程\n\n10.1.2 注解中属性的定义\n代码\n\n @Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface Component &#123;    String value();&#125;\n\n\n说明\n\n\n类型 : @interface\n字段 : 是未来可以在注解中填写的内容, 会被存放在这个注解类中, 未来也可以通过获取到这个注解类从而获取到其中的值\n元注解\n上面的@Target和@Retention都被称为元注解, 是用来修饰注解的注解\n@Retention : 注解的保持性策略, 规定了注解什么时候可以被反射机制读取, 定义了注解的生命周期, 在什么时候可以访问\nSOURCE : 注解只在源码中保存, 编译时会被丢弃, 用于编译检查工具\nCLASS(默认) : 注解会保留在.class文件中, 但运行的时候无法通过反射获取, 用于编译器和工具使用(Lombok)\nRUNTIME : 注解会一直保留到运行的时候, 可以通过反射获取\n\n\n@Target : 注解可以修饰的位置, 也就是注解可以放在什么东西上面, 有方法, 类, 属性…\n\n\n\n10.1.3 通过反射机制读取注解\n设置包名, 获取到包的绝对路径\n获取到包下面的所有的文件流\n以流的方式载入, forEach遍历 (流式获取更多的是代码规范, 实际上直接遍历files也是可以的)\n通过文件名以及包名, 获取到完整的类路径名\n反射获取类, 检查该类是否有该注解\n从类中获取注解. 解析注解\n通过注解创建实例并存入map中\n\n\n\n10.1.4 完整代码HashMap&lt;String, Object&gt; beanMap = new HashMap&lt;&gt;();String packageName = &quot;com.func.spring&quot;;String packagePath = packageName.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;);URL url = ClassLoader.getSystemClassLoader().getResource(packagePath);System.out.println(url);File f = new File(url.getPath());File[] files = f.listFiles();Arrays.stream(files).forEach(file -&gt; &#123;    String fileName = file.getName();    String className = packageName + &quot;.&quot; +  fileName.split(&quot;\\\\.&quot;)[0];    System.out.println(className);    try &#123;        Class&lt;?&gt; clazz = Class.forName(className);        if (clazz.isAnnotationPresent(Component.class)) &#123;            Component component = clazz.getAnnotation(Component.class);            String value = component.value();            Constructor&lt;?&gt; constructor = clazz.getConstructor(String.class);            Object o = constructor.newInstance(value);            beanMap.put(value, o);        &#125;    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;);System.out.println(beanMap);\n\n10.2 Bean的注解种类\n四种注解类型 : 通过观察源码, 其实可以得出, 另外三种注解类型, 其实只是@Component的别名, 所以不同类的注解更多的是为了增强可读性\n\n\n@Component\n@Service\n@Controller\n@Repository\n\n\n源码\n\n@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Indexedpublic @interface Component &#123;    String value() default &quot;&quot;;&#125;\n\n\n注解只能放在类上, 可以通过反射获取\n\n10.3 注解的使用10.3.1 使用注解\n添加注解, 填入的value就是BeanId\n\n@Component(&quot;user&quot;)public class User &#123;    @Value(&quot;UserName&quot;)    private String name;&#125;\n\n\nXML中扫描含有注解的类\n\n\n先要添加context命名空间\n指定要扫描的包\n如果有多个包, 可以用 , 隔开, 或者填入父包的地址\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans       xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd                            http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;        &lt;context:component-scan base-package=&quot;com.func.spring&quot; use-default-filters=&quot;true&quot;&gt;                &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Component&quot;/&gt;&lt;/context:component-scan&gt;&lt;/beans&gt;\n10.3.2 选择性实例化Bean\n我们可以选择化实例某一类的注解\n\n&lt;context:component-scan base-package=&quot;com.func.spring&quot; use-default-filters=&quot;true&quot;&gt;        &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Component&quot;/&gt;&lt;/context:component-scan&gt;\n\n\nuse-default-filters\ntrue使用默认的过滤器, 相当于不过滤, 所有注解bean还是会被实例化\nfalse不使用…, 会不初始化所有的注解bean\n\n\nexclude-filter(include-filter) \n需要排除(添加)的注解的种类, 填入种类的注解bean会被不实例化(实例化)\n\n\n\n10.4 负责注入的注解\n简单类型的注入\n\n\n在属性名上填写 @Value, 通过这种方式, 可以不些setter方法\n在属性对应的setter方法上 @Value\n在构造方法的参数列表对应属性前填入 @Value\n\n\n代码\n\n\n属性名\n\n@Service(&quot;vip&quot;)public class Vip &#123;    @Value(&quot;vipN&quot;)    private String name;&#125;\n\n\n构造方法\n\n@Component(&quot;user&quot;)public class User &#123;//    @Value(&quot;UserName&quot;)    private String name;    public User(@Value(&quot;方&quot;) String name) &#123;        this.name = name;    &#125;\n\n\n非简单类型\n\n\n通过AutoWrited注入\n\n\n使用和@Vaule一样, 不过AutoWrited是自动装配, 和之前的xml中的auto-write一样\n不过是byType\n如果不写, Spring也会自动帮你装配非简单类型, 只不过这需要该类只有一个构造方法, 不然会报错\n\n\n@Qualifier\n\n\n如果想通过byName自动装配\n需要再额外配合上@Qualifier(“name”) 注解来进行匹配\n\n\n@Resource\n\n\n属于JDK拓展包, 需要额外导入\n是通过byName方式找到bean的\n\n&lt;dependency&gt;  &lt;groupId&gt;javax.annotation&lt;/groupId&gt;  &lt;artifactId&gt;javax.annotation-api&lt;/artifactId&gt;  &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;\n\n\n代码\n\n@Resource(name = &quot;vip&quot;)private Vip vip;\n10.5 全注解式开发\n不再通过xml配置文件, 而是通过配置类配置\n\n\n配置类\n\n@Configuration@ComponentScan(&#123;&quot;com.func.spring&quot;&#125;)public class Spring6Configuration &#123;&#125;\n\n\n加载配置类\n\nAnnotationConfigApplicationContext annotationConfigApplicationContext = new AnnotationConfigApplicationContext(Spring6Configuration.class);Object user = annotationConfigApplicationContext.getBean(&quot;user&quot;);System.out.println(user.toString());\n\n11. GoF之代理模式[[Spring中的设计模式#2. GoF之代理模式 (结构型设计模式)]]\n12. 面向切面编程AOP12.1 AOP的介绍什么是AOP\n是OOP的延申拓展, 在面对对象基础上, 进一步提取出来公共组件和行为\n这样的公共组件, 我们也称为程序的横切面, 所以AOP是一种面向横切面编程的思想, 这样的公共组件有 (日志记录, 权限控制, 事务管理等)\n不同于通过公共工具类的方式实现这种提取, AOP采取了更自动化的方式 : 代理模式\n\nAOP和代理模式\n代理模式可以看作是AOP的实现, 通过动态的代理, 可以很轻松的实现AOP, 会自动的在我们需要的位置增强代码\n同时最关键的是, 这是一种非侵入式的实现, 遵守了OCP开闭原则\n\nSpring 中的 AOP\nSpring中主要通过JDK 动态代理和cglib代理实现\n如果代理的是接口类, 或者代理的类实现了接口, 使用JDK\n没有实现接口的类, 则使用的是cglib实现\n也可以在后续的配置文件中指定实现方式\n\n\n\n12.2 AOP相关术语\n目标对象 Target\n被织入的对象\n\n\n代理对象 Proxy\n一个目标对象被织入通知后产生的新的对象\n\n\n织入 Weaving\n把通知应用到目标对象上的过程\n\n\n通知 Advice\n也叫增强, 就是具体要织入的代码\n种类有\n环绕通知\n前置通知\n后置通知\n异常通知\n最终通知\n\n\n\n\n切点 Pointcut\n织入了切面的方法\n\n\n连接点 Joinpoint\n可以织入切面的位置, 种类和通知的种类对应\n\n\n\n12.3 切点表达式切点表达式用于定义通知被切入的方法\n切入点表达式语法格式：\nexecution([访问控制权限修饰符] 返回值类型 [全限定类名]方法名(形式参数列表) [异常])\n访问控制权限修饰符：\n\n可选项。\n没写，就是4个权限都包括。\n写public就表示只包括公开的方法。\n\n返回值类型：\n\n必填项。\n*表示返回值类型任意。\n\n全限定类名：\n\n可选项。\n两个点“..”代表当前包以及子包下的所有类。\n省略时表示所有的类。\n\n方法名：\n\n必填项。\n*表示所有方法。\nset*表示所有的set方法。\n\n形式参数列表：\n\n必填项\n() 表示没有参数的方法\n(..) 参数类型和个数随意的方法\n(*) 只有一个参数的方法\n(*, String) 第一个参数类型随意，第二个参数是String的。\n\n异常：\n\n可选项。\n省略时表示任意异常类型。\n\n12.4 使用Spring的AOP配置\n导入依赖spring-aspects\n在xml文件中添加context和aop的命名空间\n\n复用和执行顺序\n可以将切点复用, 提取出来, 被修饰的方法并不会真的被执行, 只是给一个方这个方法的位置,  设置@Pointcut注解\n可以通过设置@order(整数)来控制切面的执行顺序, 数字越小优先级越高\n\n步骤\n创建与编写切面类\n配置配置文件\n\n代码切面类@Aspect@Componentpublic class MyAspect &#123;    @Pointcut(&quot;execution(* com.func.spring.aop.OrderService.*(..))&quot;)    public void pointcut()&#123;&#125;    @Before(&quot;pointcut()&quot;)    public void beforeAdvice()&#123;        System.out.println(&quot;前置通知&quot;);    &#125;    @Around(&quot;pointcut()&quot;)    public void aroundAdvice(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123;        System.out.println(&quot;环绕通知开始&quot;);        // 执行目标方法        proceedingJoinPoint.proceed();        System.out.println(&quot;环绕通知开始&quot;);    &#125;    @AfterReturning(&quot;pointcut()&quot;)    public void afterAdvice()&#123;        System.out.println(&quot;后置通知&quot;);    &#125;    @AfterThrowing(&quot;pointcut()&quot;)    public void throwingAdvice()&#123;        System.out.println(&quot;异常通知&quot;);    &#125;    @After(&quot;pointcut()&quot;)    public void finalAdvice()&#123;        System.out.println(&quot;最终通知&quot;);    &#125;&#125;\n\nxml配置文件&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;       http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd       http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd       http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;    &lt;context:component-scan base-package=&quot;com.func.spring.aop&quot;/&gt;    &lt;!--使用cglib方式动态代理--&gt;    &lt;aop:aspectj-autoproxy expose-proxy=&quot;true&quot;/&gt;    &lt;!--生成代理对象--&gt;    &lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt;&lt;/beans&gt;\n\n\nproxy-target-class : 默认为false, 这个时候就是介绍AOP的时候说明的动态代理顺序, 如果为true则全程使用cglib执行动态代理\nexpose-proxy : 为true的时候, 但是带有@Aspect注解的bean都会生成代理对象\n问题背景 : 如果在目标类的方法中调用了另一个方法, 这个时候目标方法内部的自己的其他方法, 是该类自己调用的, 因为不是通过代理对象调用的, 增强逻辑将不会生效\n这个时候, 想让那个内部执行的自己的方法也执行增强逻辑, 就可以让这个参数为true, 暴露代理对象, 然后通过当前线程获取代理对象, 在内部调用中使用代理对象, 从而触发增强逻辑public void insert()&#123;    System.out.println(&quot;正在插入数据&quot;);    OrderService proxy = (OrderService) AopContext.currentProxy();    proxy.delete();    System.out.println(&quot;proxy = &quot; + proxy);    System.out.println(&quot;this = &quot; + this);&#125;\n\n这种方式是带有一定的侵入性的\n\n\n\n\n\n执行结果\n不带有异常的\n\ntext环绕通知开始前置通知aspect2环绕通知开始aspect2前置通知正在添加数据aspect2后置通知aspect2最终通知aspect2环绕通知开始后置通知最终通知环绕通知开始\n\n\n带有异常的\n\ntext环绕通知开始前置通知aspect2环绕通知开始aspect2前置通知正在添加数据aspect2异常通知aspect2最终通知异常通知最终通知\n\n总结\n如果实现了环绕通知, 因为环绕通知需要能够在方法的执行前后都进行通知, 所以有环绕通知后, 方法的执行需要手动调用\n\n@Around(&quot;pointcut()&quot;)public void aroundAdvice(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123;    System.out.println(&quot;环绕通知开始&quot;);    // 执行目标方法    proceedingJoinPoint.proceed();    System.out.println(&quot;环绕通知开始&quot;);&#125;\n\n\n执行顺序 : 其实看运行结果和环绕执行的机制很容易知道, 不再赘述\n如果有异常, 那么后置方法是不会执行的, 因为没有return这个环节, 但是最终通知是会执行的, 因为该类型的通知, 其实是被放到finally&#123;&#125;代码块中执行的\n\n全注解开发\n在注解类上再加个@EnableAspectJAutoProxy()的注解就行\n代码\n\n@Configuration@ComponentScan(&quot;com.func.spring.aop&quot;)@EnableAspectJAutoProxy(exposeProxy = true)public class SpringConfiguration &#123;&#125;\n\n12.5 xml开发(不推荐)\n只给出实例代码\n\n &lt;bean id=&quot;timer&quot; class=&quot;com.func.spring.aop.TimerAspect&quot;/&gt;&lt;bean id=&quot;order&quot; class=&quot;com.func.spring.aop.OrderService&quot;/&gt;    &lt;!--aop配置--&gt;&lt;aop:config&gt;    &lt;!--切面表达式--&gt;    &lt;aop:pointcut id=&quot;pointcut&quot; expression=&quot;execution(* com.func.spring.aop.OrderService.* (..))&quot;/&gt;    &lt;!--切面--&gt;    &lt;aop:aspect ref=&quot;timer&quot;&gt;        &lt;aop:around method=&quot;time&quot; pointcut-ref=&quot;pointcut&quot;/&gt;    &lt;/aop:aspect&gt;&lt;/aop:config&gt;\n\n12.6 应用案例[[Spring6_语雀版讲义#15.5 AOP的实际案例：事务处理]][[Spring6_语雀版讲义#15.6 AOP的实际案例：安全日志]]\n13. Spring对事务的支持 (JdbcTemplate)[[Spring6_语雀版讲义#16.1 事务概述]]\n14. Spring6整合Junit5[[Spring6_语雀版讲义#十七、Spring6整合JUnit5]]\n15. Spring6集成Mabatis[[Spring6_语雀版讲义#十八、Spring6集成MyBatis3.5]]\n16. Spring中的八大模式[[Spring6_语雀版讲义#十九、Spring中的八大模式]]\n","categories":["Java","Spring","框架基础"],"tags":["AOP","Spring","IoC","DI","Bean管理","依赖注入","面向切面编程"]},{"title":"Redis RDB快照持久化详解","url":"/2025/07/08/middle_ware/Redis/%E6%8C%81%E4%B9%85%E5%8C%96/RDB/","content":"RDB快照RDB快照是怎么实现的和AOF文件记录的是操作命令不同, RDB文件是直接记录的某一个瞬间的Redis中的内存数据, 是实际的数据\n\nAOF记录的是操作命令\nRDB记录的是二进制数据\n\n因此, 在恢复数据的时候, RDB的效率高于AOF\n快照是怎么生成的Redis提供了两个命令来生成快照\n\nsave命令 : 是在主进程进行的, 也就是会阻塞主进程\nbgsave命令 : 在后台子进程执行, 避免了阻塞主进程\n\nRDB的加载工作是服务器在启动的时候自动加载的, 并没有额外的命令对应\n可以通过配置redis.conf文件来定时自动执行RDB快照记录, 默认会提供以下的配置\nsave 900 1save 300 10save 60 10000\n\n\n900秒内, 对数据库至少进行了1次修改\n300秒内, 对数据库至少进行了10次修改\n60秒内, 对数据库至少进行了10000次修改\n\n这里虽然标识的是save, 但是实际上执行的是bgsave命令\nRDB是全量快照, 所以开销很高, 不能频繁进行, 使用RDB快照恢复, 一般来说在服务器宕机以后, 有更高的风险丢失更多的数据\nRDB和AOF合体执行RDB的时候, 如果是在后台进程执行, 这个时候如果主进程修改了数据, 会触发写时复制, 这个时候主进程和bgsave后台子进程之间的数据会出现不一致, RDB只会保留修改前的数据\nAOF和RDB各有优缺点\n\nAOF恢复速度更慢, 但是开销更小\nRDB恢复速度更快, 但是执行的开销更大\n\n所以在Redis4.0以后, 给出了综合了两种方案的混合方案 : 混合使用AOF日志和内存快照, 也叫混合持久化\n如果要开启这个功能, 在redis的配置文件中配置这个选项为yes\naof-use-rdb-preamble yes\n\n混合持久化在AOF日志重写的时候发生\n在执行AOF日志重写的时候, 会在子进程中将和主进程共享的内容以RDB的形式存储到AOF文件中, 主线程处理的写命令会被记录在重写缓冲区中, 在之后会以AOF方式写入到AOF文件中, 写完通知主进程将新的含有RDB格式和AOF格式的AOF文件替换成旧的AOF文件\n\n","categories":["中间件","Redis","持久化"],"tags":["Redis","持久化","RDB","快照","bgsave","数据恢复"]},{"title":"Redis AOF持久化机制详解","url":"/2025/07/08/middle_ware/Redis/%E6%8C%81%E4%B9%85%E5%8C%96/aof/","content":"AOF持久化什么是AOF持久化AOF持久化是Redis持久化数据的一种方式, 通过每进行写命令, 将这条命令写入到AOF appendonly.aof文件中, 这样在Redis重启的时候, 就能通过重新执行aof文件中的写命令恢复数据\n AOF持久化需要在redis.conf主动开启\n//redis.confappendonly yes // 默认关闭appendfilename &quot;appendonly.aof&quot; // AOF持久化文件名\n\n写入到AOF文件中的命令会经过再一次的编码\nRedis执行写AOF日志的时机\n执行写日志的时机是在Redis执行客户端发送过来的命令之后, 这样做有两大好处\n\n不会阻塞当前命令的执行, 但是实际上会阻塞下一条命令的执行\n如果先执行写入日志, 在命令错误以后, 就需要将命令从AOF文件中删除, 带来了额外的开销, 如果在写日志中进行检查, 就会带来额外的检查开销, 而先执行命令, 就能在命令错误的时候不再写入到AOF日志中\n\n但是这个时机也带来了问题\n\n执行写操作和记录日志是两个过程, 也就是会出现AOF磁盘文件和缓存中Redis的数据出现不一致的时候, 在这个时候服务器宕机了, 就会有数据丢失的风险\n不会阻塞当前写命令的执行, 但是会阻塞下一条命令的执行, 因为执行写入日志的操作是在主线程进行的, 如果此磁盘压力大, 写盘速度慢, 就会造成阻塞\n\n三种写回策略\n前面的两个问题 : 数据丢失和阻塞下一条命令的执行, 两个风险的共性就是和写入磁盘的时机高度相关, 磁盘I&#x2F;O才是写入日志最为耗时的部分\n如果写入磁盘的时机越及时, 那么数据不一致的时间就越短, 但是相对应的越容易造成阻塞\n如果写入磁盘的时机越晚, 那么数据不一致的时间就越长, 但是就越不容易造成对于下一条命令的阻塞(造成阻塞的是fsync()的调度)\nRedis有三种写回策略, 在redis.conf文件中的appendfsync中可以进行选择\n\nAlways : 总是在执行完写命令以后, 同步将数据写入到硬盘中\nEverysec : 每次执行完写操作以后, 就会先将命令写入到AOF文件的内核缓冲区中, 然后每隔一秒将缓冲区中的内容写入到硬盘中\nNo : Redis不再自己控制将缓冲区中的内容写入到硬盘中, 而是交给操作系统决定, 每次执行完写命令以后, 就只是将命令写入到AOF文件的内核缓冲区中\n\n这三种策略是怎么实现的这三种策略本质上都是在通过控制fsync()函数的使用时机\n当应用程序向文件中写入数据的时候, 内核通常会先将数据复制到内核缓冲区中, 然后排入队列, 然后由内核决定什么时候写入硬盘\n\n但是如果应用程序向文件中写入数据以后, 希望能立马将数据写入到硬盘中, 就能调用fsync()函数, 这样内核就会立马将数据写入到硬盘中\n\nAlways策略就是每次写入AOF文件数据以后, 就立马执行fsync()函数\nEverysec策略会创建一个异步的任务, 每秒执行一次fsync()函数\nNo策略不执行fsync函数\n\nAOF 重写机制在不断执行写命令的过程中, 会不断向AOF文件中追加内容, 时间久了以后, AOF文件的内容会越来越庞大, 这个时候使用AOF文件恢复会耗时很久\nRedis为了避免AOF文件越写越大,  会在AOF文件的大小超过了设定的阈值以后, 执行AOF文件重写机制\n在重写时, Redis读取当前数据库中的所有键值对, 每一个键值对用一条命令记录到新的AOF文件中, 记录完了以后, 就用新的AOF文件替换掉旧的AOF文件\n\n为什么不复用旧的AOF文件, 而是创建一个新的AOF文件, 然后覆盖\n\n因为如果重写失败, 就会对旧的AOF文件造成污染, 导致数据无法恢复\nAOF 后台重写触发AOF重写的时候, 需要读取数据库中的所有的键值对, 这个过程是很耗时的, 不能放在主线程执行\nRedis的重写AOF过程是由后台子进程 bgrewriteaof (backround rewrite aof)来完成\n\n避免了阻塞主进程\n使用了子进程而不是子线程, 不需要使用锁机制来保证数据安全, 而是通过父子进程的写时复制保证数据安全, 隔离性更好的同时, 避免复杂的锁机制(redis的主进程是单线程的, 引入锁机制会带来极大的破坏), 虽然创建子进程的内存开销实际上是比创建子线程更大的, 但是相比于安全性和引入锁机制导致的诸多问题, 这点牺牲是完全值得的\n\n\n什么是写时复制\n\n在执行fork()函数以后, 创建子进程, 理论上来说, 只有子线程之间是共享内存的, 但是实际上, 创建子进程的时候, 操作系统会把页表也复制过去, 父子进程共享相同的物理内存, 这样能减少物理内存的开销和创建子进程的开销, 同时这些内存的权限都会变成只读\n当两个进程中其中一个进程发起写操作以后, CPU就会发生缺页中断, 由于违反权限导致, 操作系统会在缺页异常处理函数中进行物理内存的复制(复制一个内存页的内存), 重新设置内存的映射关系, 将父子进程的内存读写权限设置为可读写, 最后进行写操作\n\n所以bgrewriteaof进程会在两个阶段阻塞父进程\n\n创建子进程的途中, 要复制父进程的页表等数据结构\n创建完子进程以后, 两个进程有修改共享数据, 发生写时复制, 这个时候也会阻塞主进程\n\n从Redis的角度来说\n\n在子进程执行重写的过程中, 主进程依然可以正常处理命令\n但是如果主进程修改了已经存在的key-value, 就会发生写时复制, 如果这是一个big key就会有阻塞主进程的风险\n\n\n如果主进程修改了已经存在的key-value, 此时这个key-value在主进程和子进程中数据不一致了怎么办\n\nRedis设置了一个AOF重写缓冲区\n在重写AOF启动以后, 当Redis执行完一个写命令以后, 会同时将这个写命令写入到AOF缓冲区和AOF重写缓冲区\n当子进程完成了AOF重写工作, 会向主进程发送一条信号\n主进程收到信号以后, 调用信号处理函数\n\n将AOF重写缓冲区中的所有内容追加到新的AOF文件中\n新的AOF文件的进行改名, 覆盖现在的AOF文件\n\n","categories":["中间件","Redis","持久化"],"tags":["Redis","持久化","数据恢复","AOF","日志"]},{"title":"Redis Big-Key对持久化的影响及处理方案","url":"/2025/07/08/middle_ware/Redis/%E6%8C%81%E4%B9%85%E5%8C%96/big-key%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86/","content":"Big-Key对持久化的影响对AOF日志写入的影响Big-Key对AOF日志写入的影响是在执行fsync()函数的时候, big-key会导致长时间的阻塞\n这里得分三种情况讨论, 也就是AOF选用的三种策略\n\nAlways : 这个时候每写入一条命令就会立刻同步执行fsync(), big-key会造成阻塞\nEverysec : 因为fsync()是异步执行的, 所以不会造成阻塞, 没有影响\nNo : 同样不会有影响\n\n对AOF重写和RDB的影响对这两个过程的影响主要是在两个过程中\n\n创建子进程的时候需要复制页表, big-key会导致页表的增大, 最后延长了fork的时间\n在执行修改big-key的时候, 写时复制会导致的长时间的阻塞复制\n\n除了持久化方面的影响, 其他方面的影响\n客户端阻塞超时, 阻塞工作线程 : 操作big-key的时候会比较耗时\n引发网络阻塞 : 每次获取big-key的时候产生的网络流量较大\n内存分布不均匀: 在slot分片均匀情况下, 会出现数据和查询倾斜的情况, 部分big-key的Redis节点占用内存多, QPS也较大\n\n如何避免big-key呢\n在设计阶段将big-key切分成一个个小的key\n定期检查Redis是否存在big-key, 如果存在, 使用unlink进行异步删除, 使用del会阻塞主线程\n\n","categories":["中间件","Redis","持久化"],"tags":["Redis","持久化","RDB","AOF","Big-Key","性能优化"]},{"title":"Redis数据结构详解","url":"/2025/07/08/middle_ware/Redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/Redis%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"Redis 数据结构SDSSDS的出现主要是为了解决C语言字符串的三个问题\n\n需要O(n)的时间复杂度获取字符串的长度\n无法动态拓展缓冲区\n二进制不安全(原本的c语言字符串只能存储文本)\n\nSDS的结构\n\nalloc : 分配的空间长度, 通过这个属性 alloc - len能获取到剩余的空间\nflags : sds的类型, sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64用处在节省内存空间那里\n\nO(1)获取字符串的长度SDS中会额外记录字符串的长度\n二进制安全原本的C语言风格字符串是通过\\0来标识字符串的结尾, 现在通过len长度来标识字符串的结尾, 这样也就没有二进制不安全的缺陷, 能够存储二进制文件\n动态扩容和ArrayList之类的集合类一样, 会在缓冲区空间不足的时候, 自动进行扩容\nhisds hi_sdsMakeRoomFor(hisds s, size_t addlen)&#123;    ... ...    // s 目前的剩余空间已足够，无需扩展，直接返回    if (avail &gt;= addlen)        return s;    //获取目前 s 的长度    len = hi_sdslen(s);    sh = (char *)s - hi_sdsHdrSize(oldtype);    //扩展之后 s 至少需要的长度    newlen = (len + addlen);    //根据新长度，为 s 分配新空间所需要的大小    if (newlen &lt; HI_SDS_MAX_PREALLOC)        //新长度&lt;HI_SDS_MAX_PREALLOC 则分配所需空间*2 的空间        newlen *= 2;    else        //否则，分配长度为目前长度 +1MB        newlen += HI_SDS_MAX_PREALLOC;       ...&#125;\n\n\n当申请的最小空间 &lt; 1MB的时候, 会申请两倍的最小空间\n当申请的最小空间 &gt;&#x3D; 1MB的时候, 会申请最小空间 + 1MB的内存空间\n\n在拓展SDS内存空间之前还会检查 [未使用空间]的大小, 如果不够SDS分配修改需要的空间, 还会执行分配SDS额外的 [未使用空间]\n这样做的好处是能减少内存分配的次数, 就像建立了一个内存的缓冲池一样\n节省内存空间SDS中的flags属性标识了这个flags的类型有五种类型 : sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64\n这五种类型之间的区别就是SDS头的len和alloc属性的数据类型(长度)不一样\nstruct __attribute__ ((__packed__)) sdshdr16 &#123;    uint16_t len;    uint16_t alloc;     unsigned char flags;     char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123;    uint32_t len;    uint32_t alloc;     unsigned char flags;    char buf[];&#125;;\n\n不同的len和alloc的长度, 限定了这个字符串的长度\n这样的设计能够灵活地适应不同长度的字符串, 有效减少占用的内存空间\n同时__attribute__ ((__packed__))还能阻止编译过程的优化对齐导致的结构体中的属性不紧凑, 从而进一步的节省内存空间, 按照实际占用的字节数对齐\n链表就是简单的双向链表\ntypedef struct listNode &#123;    //前置节点    struct listNode *prev;    //后置节点    struct listNode *next;    //节点的值    void *value;&#125; listNode;\n\ntypedef struct list &#123;    //链表头节点    listNode *head;    //链表尾节点    listNode *tail;    //节点值复制函数    void *(*dup)(void *ptr);    //节点值释放函数    void (*free)(void *ptr);    //节点值比较函数    int (*match)(void *ptr, void *key);    //链表节点数量    unsigned long len;&#125; list;\n\n\n优势和缺陷优点\n\n双向的链表, 获取某个节点的前置或者后置节点的时间复杂度是O(1)\n获取头尾节点的时间复杂度是O(1)\n获取节点数量的时间复杂度是O(1)\n数据的类型是void*, 所以能够保存不同类型的数据\n\n缺陷\n\n申请的内存是不保证连续的, 不能很好地利用CPU缓存 (因此有了压缩列表)\n前驱后置节点带来了额外的内存开销\n\n压缩列表为了节省内存而开发的, 连续内存块组成的顺序型数据结构\n\n\nzlbytes : 整个压缩列表占用的字节数\n\nzltail : 记录压缩列表尾部的节点距离起始地址的偏移量, 用于快速访问尾部节点\n\nzllen : 记录压缩列表的节点数量\n\nzlend : 标志压缩列表的结束点, 固定值 0xFF\n\nentry : 压缩列表的节点\n\nprevlen : 记录前一个节点占用的字节数, 用于从后往前遍历\nencoding : 记录了数据数据类型和长度\ndata : 记录了当前节点的实际数据\n\n\n\nprevlen和encoding这两个节点是根据数据的大小和类型动态分配内存空间\n\n prevlen \n\n\n如果前一个节点的长度(这里包括三个属性) 小于254字节,prevlen属性占用1个字节\n如果前一个节点的长度大于等于254字节, prevlen属性占用5个字节\n\n\nencoding\n\nencoding会根据存储的数据类型和长度动态分配内存空间, 主要分为字符串和整数两类\n\n如果是整数会根据整数的长度存储不同内容, encoding属性占用一个字节\n如果是字符串, 会根据字符串的长度分配内存, encoding存储字符串的长度, 长度小于等于63&#x2F;小于等于2^14-1&#x2F;小于等于2^32-1, 分别分配1字节&#x2F;2字节&#x2F;5字节的空间进行编码\n\n连锁更新压缩列表新增某个元素或者修改某个元素的时候, 如果内存空间不够, 就需要更新节点重新分配内存. 但是当更新的节点较大的时候, 可能会导致后续元素的prevlen都发生变化, 从1字节变化到5字节, 引起连锁更新\n\n缺陷\n访问元素本质上是O(n)的时间复杂度, 如果节点数量多了以后, 性能会下降\n\n同时连锁更新的问题会影响写入性能\n\n\n也是针对这些设计上的缺陷, 后面引入了quicklist和listpack\n哈希表Redis中的哈希表采用的是链式哈希来解决哈希冲突\nHash的结构哈希表数据结构\ntypedef struct dictht &#123;    //哈希表数组    dictEntry **table;    //哈希表大小    unsigned long size;      //哈希表大小掩码，用于计算索引值    unsigned long sizemask;    //该哈希表已有的节点数量    unsigned long used;&#125; dictht;\n\n哈希表表项数据结构\ntypedef struct dictEntry &#123;    //键值对中的键    void *key;      //键值对中的值    union &#123;        void *val;        uint64_t u64;        int64_t s64;        double d;    &#125; v;    //指向下一个哈希表节点，形成链表    struct dictEntry *next;&#125; dictEntry;\n\n\n简单来说dictht中存有table和size属性, table指向dictEntry表, 也就是hash映射表, 每个表项也指向dictEntry也就是真实的数据\ndictEntry中的value使用 联合体存储, 这样在存储数值型value的时候, 可以直接存在hash表中, 不需要额外创建一个指针\n哈希冲突从key到table中的索引的转换过程 : hash(key) % size如果两个不同的key在经过转换以后得到了相同的索引, 这个时候就发生了哈希冲突链式哈希就是将, 被分配到同一个哈希桶上的多个节点用单向链表链接起来\n链式哈希有个明显的缺点, 就是hash表的查找性能会向O(n)退化在这个时候, 就要进行rehash, 重新建立hash表\nrehash\nRedis是怎么进行的rehash\n\ntypedef struct dict &#123;    …    //两个 Hash 表，交替使用，用于 rehash 操作    dictht ht[2];     …&#125; dict;\n\nRedis为一个hash表数据类型会建立两个哈希表(dickht)\n执行的过程\n\n为第二个hash表分配内存, 一般是原来的两倍\n将表1的数据拷贝到表二中\n拷贝完成以后, 将表1释放, 将表2设置为表1, 重新创建一个空的表2\n\n\n渐进式rehash\n\n如果像上面一样进行rehash, 一次性将所有节点都重新拷贝到新的hash表中, 那么在hash表的节点数量很多的时候, 拷贝的开销很大, 这个时候就会造成redis主线程的阻塞\n所以在Redis中, rehash采用了 渐进式rehash, 不再一次性完成, 而是在需要rehash的时候, 进入到rehash时期, 在这个时期内\n\n不再对原hash表1进行插入操作, 所有的新增项, 将所有的项插入到表2\n不是一次性迁移, 而是在执行插入, 更新, 查询, 删除的时候, 将整个hash桶上的key-value迁移到表2上\n在执行查询操作的时候, 会优先从表1中查询, 如果没有查询到, 会从表2中查询\n\n\n什么时候进行rehash呢?\n\n根据负载因子来看 : 负载因子 &#x3D; 哈希表中保存的节点数量 &#x2F; 哈希表的大小\n\n如果负载因子 &gt;&#x3D; 1, 并且没有进行bgsave与bgwriteaof的时候, 进行rehash操作\n如果负载因子 &gt; 5, 不管是不是在执行AOF重写或者RDB快照, 都会执行rehash操作\n\n整数集合整数集合是Set数据类型在存储的数据类型是整数, 并且元素数量不多的时候, 采用的底层实现, 之所以采用这个实际查询性能是O(n)的数据结构, 是因为其紧凑连续的内存布局, 能减少内存的占用, 同时能有效利用CPU的缓存局部性, 实际的性能并不差\n数据结构typedef struct intset &#123;    //编码方式    uint32_t encoding;    //集合包含的元素数量    uint32_t length;    //保存元素的数组    int8_t contents[];&#125; intset;\n\n虽然contents数组的类型是int8_t, 但是实际上contents的类型由encoding来决定\n\nencoding的值为INT_SET_ENC_INT16的时候contents的类型为int16_t\nencoding的值为INT_SET_ENC_INT32的时候contents的类型为int32_t\nencoding的值为INT_SET_ENC_INT64的时候contents的类型为int64_t\n\n升级操作当存入了数据长度大于encoding中的编码的时候, 会进行升级操作, 修改encoding, 并将数组中所有元素的类型都进行升级\n\n计算需要的额外的内存空间并进行扩容操作\n数据迁移\n将新的数据存入\n\n\n升级操作能有效地节省内存, 同时又能适应存储大数据的需求一旦升级, 没有降级操作, 删除了大数据也不会降级\n跳表数据结构zset由 跳表 + 哈希表实现, 其中跳表能有效支持范围查询, 而哈希表能提升单点查询的性能, 也是ZSCORE能在O(1)的时间复杂度下查找到一个filed对应的score\ntypedef struct zset &#123;    dict *dict;    zskiplist *zsl;&#125; zset;\n\ntypedef struct zskiplistNode &#123;    //Zset 对象的元素值    sds ele;    //元素权重值    double score;    //后向指针    struct zskiplistNode *backward;      //节点的 level 数组，保存每层上的前向指针和跨度    struct zskiplistLevel &#123;        struct zskiplistNode *forward;        unsigned long span;    &#125; level[];&#125; zskiplistNode;\n\n跳表能在O(logN)的时间复杂度的时间复杂度下进行查询操作, 这里的查询是指基于范围的查找, 比如说我要查找到分数是12-12的节点(基于filed的查找由哈希表实现)跳表之所以能在logN的时间复杂度下查询主要就是因为跳表中的level层高的设计, 让便利链表不再是需要逐个访问, 而是能够跳跃访问\n跳表执行查询的过程跳表执行查询的时候, 会从头节点的最高层开始, 会根据以下两个标准来判断是访问当前层的下一个节点还是访问下一层\n\n如果当前层的下一个节点的权重小于需要查询的权重的时候, 跳表会访问当前层的下一个几点\n如果当前层的下一个节点的权重等于需要查询的权重的时候, 如果下一个节点的SDS值小于需要查询的数据的时候, 会访问下一层的节点\n\n如果都不满足或者当前层指向null, 则访问当前节点的下一层\n\n我们现在要访问abcd 4\n\n从头节点的最高层L2出发, 因为当前层的下一个节点的score &#x3D; 3 &lt; 4, 访问下一个节点\n从该节点的最高层level[2]触发, 访问到null, 访问下一层\n下一层的权重等于4, 但是sds元素的大小 &gt; abcd, 不符合, 访问下一层\nlevel[0]的下一个节点的权重 &#x3D;&#x3D; 4, 同时元素值 &#x3D;&#x3D; abcd, 找到了符合要求的节点\n\n跳表是如何实现的logN的查询在最开始的时候, 看小林coding的图示, 以为跳表只有三层, 那么最快的情况, 需要查询的节点都在最高层, 那么查询时间复杂度也不过是n&#x2F;3, 并没有做到logN\n\n那么怎么设置层高能实现logN的时间复杂度呢?\n\n假设元素的数量是n, 层高为L, 新增一层的概率为p, 我们从执行查询的时候查询路径分析\n想象跳表就是一个金字塔, 一共有L层, P(层高 &gt;&#x3D; n) &#x3D; p^(n-1)\n\n所以P(层高 &gt;&#x3D; 1) &#x3D; 1\nP(层高 &gt;&#x3D; 2) &#x3D; p\nP(层高 &gt;&#x3D; 3) &#x3D; p^2\n…\nP(层高 &gt;&#x3D; N) &#x3D; p^(N-1)\n\n所以节点在第一层的期望是 P(层高&gt;&#x3D;1) - P(层高&gt;&#x3D;2)\n在第i层的期望是P(层高&#x3D;&#x3D;i) &#x3D; P(层高&gt;&#x3D;i) - P(层高&gt;&#x3D;i+1) &#x3D; p^(i-1) - p^i\n**第i层的节点个数是$N * (p^{(i-1)} - p^i) &#x3D; N (1-p)p^{(i-1)}$\n设层高为L, 则$\\sum_{i&#x3D;1}^{L} (p^{(i-1)} - p^i) &#x3D; 1$\n由等比数列的求和公式得 $1-p^L &#x3D; 1$, 但是这个公式只有在L趋近于inf 的时候才成立, 实际上的跳表的高度肯定不是无穷, 所以我们只能使用$N*(1-p)*p^{(L-1)}$这个期望值为1的项来近似1\n所以最后的公式是$\\sum_{i&#x3D;1}^{L} (p^{(i-1)} - p^i) &#x3D; N*(1-p)*p^{(L-1)}$\n$1-p^L &#x3D; N*(p^{L-1} - p^L)$ 得到 **$L &#x3D; log_pN + C$也就是$**L &#x3D; O(log_2N)$\n从查询路径分析时间复杂度\n\n在第i层, 节点出现的概率是$p^{i-1}$\n在第i层, 相邻两个节点之间的距离是$1&#x2F;p^{(i-1)}$\n也就是从第i层出发, 大概每$1&#x2F;p^{(i-1)}$会遇到一个节点\n第i+1层的两个节点之间, 第i层平均有1&#x2F;p个节点\n也就是从第i+1层降到第i层的时候, 我们最多访问1&#x2F;p个节点\n\n所以最后的时间复杂度 &#x3D; O(log_2N) + O(1&#x2F;p) &#x3D; O(log_2N)\n\nRedis中的p是多少\n\n理论上来讲p &#x3D; 1&#x2F;2是查询最快速的值, 但是实际上Redis取得是1&#x2F;4, 这里是内存效率和查询性能的平衡\n由一个节点的期望层高 &#x3D; $\\sum_{i&#x3D;1}^{\\inf} P_{L&gt;&#x3D;i} &#x3D; \\sum_{i&#x3D;1}^{\\inf} p^{(i-1)} &#x3D; 1*(1-p^{inf} ) &#x2F; (1-p) &#x3D; 1&#x2F;(1-p)$\n所以所有节点的期望总层高就是 N * 1&#x2F;(1-p), p越大, 层数越多, 要占用越多的内存\n跳表是的层高设置跳表在创建节点的时候会生成一个[0,1]随机数, 如果随机数的大小 &lt;&#x3D; 0.25, 则层数增加一层, 循环直到最后随机数 &gt; 0.25为止\n创建跳表的头节点的时候, 如果层高的最大限制是64, 创建跳表的头节点的时候会直接创建64层高的头节点\n/* Create a new skiplist. */zskiplist *zslCreate(void) &#123;    int j;    zskiplist *zsl;    zsl = zmalloc(sizeof(*zsl));    zsl-&gt;level = 1;    zsl-&gt;length = 0;    zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL);    for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) &#123;        zsl-&gt;header-&gt;level[j].forward = NULL;        zsl-&gt;header-&gt;level[j].span = 0;    &#125;    zsl-&gt;header-&gt;backward = NULL;    zsl-&gt;tail = NULL;    return zsl;&#125;\n\nZSKIPLIST_MAXLEVEL 定义的是最高的层数，Redis 7.0 定义为 32，Redis 5.0 定义为 64，Redis 3.0 定义为 32。\n为什么使用跳表而不使用平衡树\n跳表在实现和维护上都是更加简单的\n内存开销更小, 每个节点的指针数量期望值为1&#x2F;(1-p) &#x3D; 4&#x2F;3而不是平衡树的2\n更新操作开销更小, BTree在更新节点的时候涉及到复杂的节点分裂合并和平衡操作\n天然支持范围查询, 只需要沿着底层链表遍历就行\n空间局部性更好, 更能利用CPU的高速缓存\n跳表在Redis中采用了连续分配的内存块来存储节点, 而不是和传统的链表一样完全随机分配的链表节点\nB树节点内部是内存是连续的, 但是节点之间内存连续性是不保证的, 同时因为频繁的动态调整节点以维护平衡, 内存碎片和不连续会更进一步\n\n\n\nquicklist这个数据结构的出现主要是为了解决压缩列表的设计缺陷\n\n节点数量多了以后的查询性能差\n节点数量多了以后难以承受的连锁更新\n\n数据结构typedef struct quicklist &#123;    //quicklist 的链表头    quicklistNode *head;      //quicklist 的链表头    //quicklist 的链表尾    quicklistNode *tail;     //所有压缩列表中的总元素个数    unsigned long count;    //quicklistNodes 的个数    unsigned long len;           ...&#125; quicklist;\n\ntypedef struct quicklistNode &#123;    //前一个 quicklistNode    struct quicklistNode *prev;     //前一个 quicklistNode    //下一个 quicklistNode    struct quicklistNode *next;     //后一个 quicklistNode    //quicklistNode 指向的压缩列表    unsigned char *zl;                  //压缩列表的的字节大小    unsigned int sz;                    //压缩列表的元素个数    unsigned int count : 16;        //ziplist 中的元素个数     ....&#125; quicklistNode;\n\n\nquicklist的解决方案就是让压缩列表的节点数量控制在一定数量以内, 在添加一个元素的时候, 会先尝试检查插入位置的压缩列表能不能容纳该元素, 如果不能容纳就会创建一个新的压缩列表, 将新节点添加到新的压缩列表中\nlistpackquicklist并不是解决了压缩列表中的连锁更新的问题, 只是控制了这个问题发生的时候的成本, 而listpack是确实实现了解决连锁更新的问题\n解决方式也很简单, 删除了entry中的prevlen属性将entry修改为\n&lt;encoding-type&gt;&lt;element-data&gt;&lt;element-tot-len&gt;\n\n从原先的\n\npervlen\nencoding\ncontents\n\n变为\n\nencoding\ndata\nbacklen : encoding + data 的长度, 也就是只记录当前entry的元信息, 就不会导致连锁更新的问题\n\n删除prevlen以后listpack是怎么同样实现向前遍历的?                                  当前位置                                     ↓[Header][E1-type][E1-data][E1-backlen][E2-type][E2-data][E2-backlen][EOF]\n\n我们怎么向前遍历E1?\nbacklen的高位会有特殊的编码标识, 我们从当前位置向前读取字节, 也就是想低位读取字节\n\n如果最高位是0（即0xxxxxxx），表示这是一个1字节的backlen，直接表示0-127的长度值\n如果高两位是10（即10xxxxxx），表示这是一个2字节backlen的第一个字节\n如果高三位是110（即110xxxxx），表示这是一个3字节backlen的第一个字节\n如果高四位是1110（即1110xxxx），表示这是一个4字节backlen的第一个字节\n如果高五位是11110（即11110xxx），表示这是一个5字节backlen的第一个字节\n\n第一次读取到了这样的特殊的编码标识, 就说明我们已经读取完了backlen, 就能完整得到backlen的值 \n","categories":["中间件","Redis","数据结构"],"tags":["Redis","数据结构","SDS","字符串","二进制安全"]},{"title":"Redis常用数据类型及应用场景","url":"/2025/07/08/middle_ware/Redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/Redis%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%BA%94%E7%94%A8/","content":"Redis中的数据结构String数据类型详解String类型使用的核心数据结构是SDS(简单动态字符串), 这种存储字符串的方式相比于c原生字符串的优点是\n\n能动态拓展缓冲区, 保证不会在拓展字符串的时候不会缓冲区溢出\n能以O(1)的时间复杂度获取到字符串的长度 : SDS数据结构会记录字符串的长度\n能存储二进制数据 : 不再通过’\\0’作为字符串的结尾标识符, 而是通过len来标记字符串该在什么时候结束, 内部的数据都是以二进制的形式存储, 所以不光能存储文本, 还能存储视频, 图片等数据\n\n这个数据类型的最大存储容量是512M\n这个数据类型内部编码有三种 : 用于存储数字的INT, 存储非数字的embstr, raw\n\nINT : 在string类型中的数据是数字, 并且数字能使用long类型存储, 这个时候就会采用INT内部编码, 会将整数值保存在字符换对象结构里的ptr属性值里\nembstr : 在字符串的长度 &lt;&#x3D; 32字节(不是字符) (redis2.x) 的时候, 会将对象的编码设置成embstr\nraw : 在字符串的长度 &gt; 32字节的时候(redis 2.x), redis会将字符串的编码设置成raw\n\n\n为什么要有raw和embstr两种SDS的编码设置, 两者的区别是什么?\n\nembstr相比于raw编码方式, 是一种更加更加快速的存储方式, 但是可变性更差, 是一种对于存储小字符串的优化方案\n\n通过raw编码的时候, redis会调用两次malloc, 分别为redisObject和SDS分配内存, 这两块内存是不保证连续的\n通过embstr编码, redis只会调用一次malloc, 为redisObject和SDS分配一次内存, 存储在一个连续的空间中, 这个时候CPU Cache的命中率更高, 更符合空间局部性原理\n从embstr的定义和目的也能看出来, embstr实际上是个 不可变 的编码方式, 每当以embstr方式编码的对象发生append实际上会先将字符串类型的编码形式改为raw\n\n\n不同版本的Redis, embstr和raw的边界是不同的\n\n\nredis 2.x : 32字节\nredis 3.0-4.0 : 39字节\nredis 5.0以后 : 44字节\n\n常用指令SET key value# OKGET key# valueSTRLEN key# 5EXISTS key# 1DEL key# 1\n\n\n批量设置\n\nMSET key1 value1 key2 value2 ....# OKMGET key1 key2 ...# 1) value1# 2) value2\n\n\n计数器\n\nSET cnt 1# OKINCR cnt# (integer) 2DECR cnt # (integer) 1INCRBY cnt 2# (integer) 3DECRBY cnt 3# (integer) 0\n\n\n过期时间\n\nEXPIRE key 60 (60s后过期)TTL key# 51SET key value EX 60SETEX key 60 value\n\n\n不存在就插入\n\nSETNX key value# (integer) 1\n\n应用场景缓存对象\n直接缓存对象的JSON串\n\n常规计数\nredis内部因为是单线程的, 能保证对其中数字的加减是原子操作\n\n共享Session一般Session存储在用户登陆的服务器上, 并以此让用户相近的登录不需要再重新登陆, 记录一定量的用户信息, 但是在分布式的语境下, 这个方案将不再适用, 因为用户会被随机分配到不同的服务器上, 那么很可能用户再第二次登陆的时候, 被分配到与第一次登陆的时候不同的服务器, 这个时候就会丢失Session信息\n\n通过设置一个专门的Session Redis实例, 所有的服务器都将Session信息存储在这个实例中, 也通过这个实例获取Session\n\n\n分布式锁通过SET方法的EX参数, 我们能实现这个值有才插入的操作, 通过这个方式, 我们能实现一个分布式的互斥锁SET lock_key unique_value EX PX 10000\n\nunique_value是用于分辨这个锁是由哪个服务器创建的, 只有符合要求的服务器, 也就是携带了unique_value的服务器, 才能正确解锁\nEX : 如果存在则插入\nPX 10000 : 过期时间为10s, 确保不会因为客户端出现网络问题的时候, 锁得不到释放\n当SETNX失败的时候, 说明这个锁已经被别人获取了, 成功SETNX的服务器成功获取到了锁, 只有等待SETNX的服务器删除这个锁, 锁才得到了释放\n\n因为比对unique_value, 如果相同则删除的操作是两个操作, 我们需要通过lua脚本保证两个操作的原子性\n// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then    return redis.call(&quot;del&quot;,KEYS[1])else    return 0end\n\nListList数据结构详解List内部的存储方式有双向链表和压缩链表两种, 最多能存储2^32 -1 个元素, 存储的元素的数据类型是String\n\n如果List的元素数量 &lt; 512(可通过list-max-ziplist-value配置), 并且每个节点的长度 &lt; 64, 就会以压缩链表的形式存储\n如果上面两个条件不是都满足, 就会选用双向链表作为内部存储结构\n\n但是在Redis3.2版本以后, List数据类型的底层数据结构就只由 quicklist来实现了\n常用命令LPUSH key value [value...]RPUSH key value [value...]# 移除并返回RPOP keyLPOP key# 返回范围内的元素, 从strat到end, 从0计数LRANGE key start end# timeout是超时的时间BLPOP key [key...] timeout\n\n应用场景消息队列实现消息队列需保证 消息保序, 处理重复的消息和保证消息的可靠性\n\n消息保序 : List本身就是有序存储的, 我们可以通过生产端 LPUSH/RPUSH, 消费端 RPOP/LPOP的方式来实现消息队列\n但是生产端产生消息的时候, 消费端并不知道, 如果要实现消费端监听消费队列, 使用RPOP就需要使用循环RPOP获取消费队列中的消息. 这样会大幅浪费CPU的性能, 解决方案就是List提供了BRPOP, 阻塞式获取, 如果消息队列中没有消息, 消费端就会阻塞直到获取到消息(可以通过设置timeout来决定阻塞的时间)\n\n\n处理重复的消息 : 只能通过外部传入全局唯一ID来唯一标识信息, 消费端记录消费过的信息, 在消费信息之前检查当前消息的ID是不是存在于已经消费set中\n保证消息的可靠性 : 如果消费端在获取了消息以后出现了错误, 比如断电等, 就会导致消息的丢失, 为了留存消息, List提供了BRPOPLPUSH操作, 在阻塞获取消息以后,还会留存一份备份, 这样如果消费者在阅读了消息但是没有正确处理消息的时候, 能重新从备份List中获取消息\n\n\nList作为消费队列的缺陷\n\nList实现的消费队列无法实现消费组的功能 : 多个消费者消费同一个信息, 但是Stream可以\nHashHash类型实现的是Hash集合, 其value是field : value的集合, 形如field : value&#x3D;[{field1:value1}, {field2:value2}, … , {fieldN:valueN}], 因此Hash特别适合存储对象\n\n什么时候使用String类型存储对象, 什么时候是哦那个Hash存储?\n\nString类型实际上是使用JSON串存储的对象, 所以变动是很不方便的一般对象使用String + JSON存储, 需要频繁变动的部分使用Hash存储\n内部实现\n在元素的数量 &lt; 512个(可以通过hash-max-ziplist-entries来配置), 所有值大小 &lt; 64字节的时候, Hash类型使用压缩列表实现\n在不满足上述情况的条件下, 使用哈希表作为数据结构\n\n在Redis7.0以后, 压缩列表已经弃用了, 被替换成了listpack\n常用命令HSET key field valueHGET key fieldHMSET key field value [field value ...]HMGET key field [field]HLEN keyHGETALL keyHINCRBY key field 10\n\n应用场景购物车对于一个购物车场景, 就是一个很适用的非存储对象的场景\n\nfield : 用户ID\nvalue : (商品ID : 商品购买数量)\n\nSet无序集合, 形如 field : [member1, member2, …, memberN]\n内部实现\n如果元素的数量小于512(默认, 由set-maxintentries配置), 使用整数集合实现\n如果元素的数量大于等于512的时候, 使用哈希表实现\n\n常用命令SADD key member [member...]SREM key member# 获取集合中的全部元素SMEMBERS key member# 集合中的元素数量SCARD key# member在不在key集合中SISMEMBER key member# 从key集合中随机取出count个元素, 不删除SRANDMEMBER key [count]# 从key集合中取出并删除count个元素SPOP key [count]\n\n\n运算操作\n\n# 交集操作SINER key1 key2 [keyn...]SINERSTORE destkey key1 [keyn...]# 并集操作SUNION key1 key2 [keyn...]SUNIONSTORE destkey key1 key2 [keyn...]# 差集操作SDIFF key1 key2SDIFF STORE destkey key1 key2 [keyn...]\n\n应用场景应用场景主要围绕, 无序, 不重复, 支持交集并集等集合操作来构建不过Redis中集合的运算的时间复杂度较高, 在主从集群的场景下, 可能会造成Redis实例的阻塞, 所以一般在从库完成聚合统计\n点赞这个功能就是应用不重复, 使用set记录点赞用户的ID, SCARD来获取到这个文章的所有点赞人数, 通过SET的增删来增删点赞用户的信息\n共同关注这个功能属于应用集合的运算操作, 可以通过交集运算出来两个用户的共同好友等    \n抽奖活动这个功能也是为了应用了不重复的性质, 并且用到了Redis中SRANDOMMEMBER field cnt随机不去除获取cnt个集合中的value, SPOP随机去除获取cnt个集合中的value\nZSET相比于SET就是多了个排序的功能, 是一个有序的集合, 所以一个value现在有两部分(value, score), 通过score来进行排序\n内部实现\n如果元素个数小于128, 并且每个每个元素的大小都小于64字节, 会采用压缩列表实现\n如果不满足上面的情况, 就会使用跳表实现\n\n在Redis7.0以后, 压缩列表已经弃用了, 被替换成了listpack\n常用命令ZADD key score member [[score member]...]ZREM key member [member...]ZSCORE key member\n\n应用场景对于有权重值的表, 我们都能使用ZSET来实现, 相较于SET, ZSET不支持差集集合运算\nBitMapBitMap数据结构详解内部使用String类型存储二进制字节数组\n常用命令\nbitmap基本操作\n\n# 设置偏移量offset位置的值为value(0/1)SETBIT key offset value# 获取偏移量offset位置的值GETBIT key offset# 统计从start位置到end位置之间的1的数量# 这里的start和end是以字节为单位的BITCOUNT key start end\n\n\nbitmap运算操作\n\n# BitMap之间的运算, 也就是二进制数之间的运算, # opreation 执行的运算操作    # AND 与运算    # NOT 非运算, 非运算是唯一一个单目的运算, 后面的key只有一个    # XOR 异或    # OR 或运算# destkey 存储结果的key# key [keys...] 参与运算的key# 参与运算的时候, 较短的key中的空位会被视作0BITOP [operation] [destkey] key [keys...]# key中第一次出现value(0/1)的位置BITPOS key value\n\n应用场景签到统计现在我们需要记录用户在4月的登录情况\n基本操作\n\n用户登录\n\nSETBIT sign uid:sign:100:202504 1\n\n\n用户退出\n\nSETBIT sign uid:sign:100:202504 0\n\n\n统计用户在4月的登录情况\n\nBITCOUNT uid:sign:100:202504\n\n\n获取4月的第一次登陆的日期 ?\n\nBITPOS uid:sign:100:202504\n因为返回的数字是从0开始计数的, 所以最后计算的结果是value + 1\n\n统计连续签到7天的用户总数\n\n使用日期作为key, 用户ID作为offset, 然后将这些key做AND运算, 再统计destkey中的1的个数就能得出最新的七天的用户总数\nBITOP AND destkey day:1 day:2 day:3 ... day:7BITCOUNT destkey\n\nHyperLogLog介绍适用于超大规模的基数统计, 也就是我们需要统计一个集合中有多少不同的元素. 不论统计的数据量有多少, HyperLogLog数据结构都能使用固定的12KB大小的内存完成统计, 但是最后的出来的数量值并不是精确的, 标准误差率是0.81%\n内部实现内部实现主要是数学原理, 以后再说\n常用命令就当作只能添加, 合并, 统计集合中的元素个数的集合操作就行\n# 向HyperLogLog中添加元素PFADD key element [elements...]# 统计HyperLogLog中的元素个数PFCOUNT key# 合并多个HyperLogLog集合PFMERGE destkey sourcekey [sourcekey...]\n\n应用场景 : 百万级网站UV计数UV : Unique Visitor, 独立访客统计一个网站某一段时间的独立访客数量\n\n添加访客 : PFADD uv:202504 user1 user2\n统计访客数量 : PFCOUNT uv:202504\n\nStream这个数据类型实在Redis5.0版本引入的, 就是为专门解决使用Redis作为消息队列的情景, 这个数据类型能自动生成全局唯一ID, 而不再用生产者自己实现\n应用场景 : 消息队列\n生产者添加消息\n\n# 向mymq消息队列插入一条消息# * 表示由redis自己生成全局唯一ID# 生产的消息的key是name, value是xiaolinXADD mymq * name xiaolin&quot;1654254953808-0&quot; # result\n\n添加消息成功以后返回生成的全局ID, ID由两部分组成\n\n1654254953808 : 数据插入的时候, 以毫秒为单位服务器的时间戳\n\n0 : 在这1ms中的第几个消息\n\n消费者消费消息\n\n\nXREAD STREAMS mymq 1654254953808-01) 1) &quot;mymq&quot;   2) 1) 1) &quot;1654254953808-0&quot;         2) 1) &quot;name&quot;            2) &quot;xiaolin&quot;\n\n如果想实现阻塞读, 加上BLOCK [time]选项\n# $表示读取最新的一条消息XREAD BLOCK 10000 STREAMS mymq $(nil)(10.00s)\n\n\nSTREAM支持通过消费组来消费消息, 同一个组内不能消费同一条消息, 但是不同组之间能重复消费同一条消息\n\n创建消费组\n\n\n# 创建消费组group1# 0-0表示从第一条消息开始读XGROUP CREATE mymq group1 0-0XGROUP CREATE mymq group2 0-0\n\n\n通过消费组从队列中读取消息\n\n# 消费组group1中的消费者consumer1从mymq中消费一条消息XREADGROUP GROUP group1 consumer1 COUNT 1 STREAMS mymqXREADGROUP GROUP group1 consumer2 COUNT 1 STREAMS mymqXREADGROUP GROUP group1 consumer3 COUNT 1 STREAMS mymq\n\n\n使用消费组的原因\n\n消费组是组件本身提供的一种可靠的消息分发机制, 通过将一个流中的消息分发给不同组中的消费者, 实现负载均衡, 水平拓展了系统的能力\n\n基于STREAM实现的消费队列, 如何保证消费者在宕机或者故障的时候, 消息不丢失\n\nRedis内部会维护一个Pending list队列, 用于留存消费者阅读的消息, 只有在消费阅读后, 并成功消费发送了ACK给Redis以后, Pending list中留存的消息才会被删除\n可以使用XPENDING命令来查看已经被读取, 但是还没有被确认的消息\nXPENDING mymq group2\n\n如果想查看组内的某个具体的消费者消费了什么数据\nXPENDING mymq group2 - + 10 consumer2\n\n一旦消息已经被consumer2处理了, consumer2就能通过XACK来确认消息, 这个时候内部队列中消息就会被删除掉\nXACK mymq group2 1654256265584-0\n\n\nRedis实现的消息队列和专业的消息队列组件之间的差别\n\n一个专业的消费队列必须实现 : 消息可靠, 消息可堆积两个功能\n\n消息可靠性 : 从生产者生产消息, 队列中间件, 消费者消费消息两个维度考虑消息的可靠性\n\n生产消息的可靠性 : 也就是生产者生产的消息会不会出现丢失的情况, 生产者会不会丢失消息, 取决于消费者对于异常情况的处理, 如果有合适且充足的异常重发机制, 如果没有接收队列中间件的ACK, 就重发消息, 能实现消息可靠\n消费端消息会不会丢失 ? Redis通过内部队列保障了只要消费端没有主动ACK消息, 就仍然能重新消费信息\n队列中间件会不会丢失消息 : 会\nAOF文件的写盘是以秒为单位的, 但是这个操作是异步的, 如果在写盘前redis宕机了, 重启后仍然会出现消息丢失\n主从复制也是异步的, 主从切换的时候也会出现数据的丢失\n\n\n\n\n消息堆积\n\n\nRedis的消息是保存在内存里的, 如果发生了消息堆积, 会有OOM的风险也是为了避免这种风险, Redis可以设置队列的最大长度, 如果队列的长度超过了最大长度, 就会丢失旧的消息, 可见如果设置了队列的最大长度又会带来消息丢失的风险\n但是专业的消息队列组件将消息保存在磁盘中, 就不会有OOM的风险\n","categories":["中间件","Redis","数据类型"],"tags":["Redis","String","Hash","List","Set","ZSet","数据类型","应用场景"]},{"title":"Redis数据库和缓存如何保持一致性","url":"/2025/07/08/middle_ware/Redis/%E7%BC%93%E5%AD%98/Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8C%81%E4%B8%80%E8%87%B4%E6%80%A7/","content":"Redis数据库和缓存如何保证一致性先更新缓存还是先更新数据库注意, 这里说的不是删除缓存, 而是更新缓存, 最后的结论是, 不管是先更新缓存还是先更新数据库, 都会因为并发出现数据库和缓存中数据不一致的情况\n先更新缓存\n先更新数据库\n先更新数据库还是先删除缓存这里的内容在 中的常见缓存更新策略中能看到\n这里是想说下在旁路缓存的方式中, 过期时间的用处\n通过设置过期时间, 能保证在更新一定时间以后, 一定能保证缓存数据和数据库数据的一致性, 因为可能删除缓存这个操作会出现错误\n补充 (一些保护手段)如果业务对缓存的命中率有一定的要求, 这个时候先更新数据库再更新缓存的策略其实是更好的选择, 那么如何在这样的策略下保证数据的一致性呢\n\n在更新缓存前加上一个分布式锁 : 将[更新数据库 + 更新缓存]从线程的角度来看视作一个互斥操作, 这样就能保证数据库和缓存中的数据的一致性\n在更新完缓存以后, 为缓存加上一个较短的过期时间, 这样能兜底保证业务中的数据一致性\n\n如何保证两个操作都能执行成功不论是先删除缓存 + 更新数据库还是先更新数据库 + 删除缓存都会因为第二个操作失败而导致数据不一致\n\n重试机制\n订阅MySQL binlog, 再操作缓存\n\n重试机制引入消息队列, 将需要操作数据加入到消息队列中\n\n如果用户删除缓存操作失败, 就从消息队列中重新读取数据, 然后重新执行删除操作. 删除失败重试, 如果到达一定次数, 向业务层发送报错信息, 这就是重试机制\n如果删除成功就将消息队列中的信息删除\n\n订阅MySQL binlog, 再操作缓存更新数据库成功以后, 会产生一条变更日志, 记录在binlog里面, 可以通过订阅binlog日志拿到具体要操作的数据, 再执行缓存删除. Canal中间件就是基于这个实现的\n\n","categories":["中间件","Redis","缓存"],"tags":["Redis","缓存一致性","数据同步","更新策略","删除策略"]},{"title":"Redis主从复制机制详解","url":"/2025/07/08/middle_ware/Redis/%E9%9B%86%E7%BE%A4/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","content":"主从复制是怎么实现的保证高可用的核心就是多副本构建, 冗余, 这样才能在其中一个实例出现问题的时候, 通过其他的副本恢复服务\nRedis通过主从复制来保证高可用\n构建了多副本以后就需要面临以下问题\n\n如何进行副本和主实例之间的数据同步\n数据的读写是主服务器和副服务器都可以操作的吗\n\n\nRedis的主从复制模式\n\n只有主服务器能写数据, 其他的从服务器只能读数据\n主服务器发生写操作的时候, 会自动将写操作同步给从服务器\n\n第一次同步通过replicaof(Redis5.0之前是slaveof)命令构建主服务器和从服务器之间的关系\n# 服务器B执行这条命令replicaof &lt;服务器A IP&gt; &lt; 服务器A Redis端口号&gt;\n\n接着服务器B就会变成服务器A的从服务器\n主从服务器之间的第一次同步可以分为三步\n\n第一步 : 建立链接, 协商同步\n第二步 : 主服务器同步数据给从服务器\n第三步 : 主服务器发送新写操作给从服务器\n\n\n建立链接, 协商同步从服务器发送 psync命令给主服务器, 表示要进行数据同步\npsync &#123;runID&#125; &#123;offset&#125;\n\nrunID, 每个Redis服务器在启动的时候都会随机获取一个ID来标识自己, 当主从服务器第一次同步的时候, 因为不知道主服务器的runID, 所以是?\noffset, 表示复制的进度, 第一次同步, 设置为-1\n\n主服务器收到了命令以后, 会返回FULLRESYNC作为响应命令 : FULLRESYNC表示采用全量复制的模式\n这个命令同样会带上runID和offset表示主服务器的ID和主服务器的复制进度\n主服务器同步数据给从服务器主服务器在发送完FULLRESYNC以后就会执行bgsave命令生成RDB文件, 然后将文件发送给从服务器\n这个进程是后台进程, 也就是不会阻塞主线程在这个过程执行写命令, 那么生成的快照和主服务器中的实际的数据就产生了偏差\n为了保证主从服务器数据的一致性, 就会将在这三个时间间隙中收到的写操作命令, 写入到replication buffer缓冲区内\n\n在主服务器生成RDB文件期间\n在主服务器发送RDB给从服务器期间\n从服务器加载RDB文件期间\n\n主服务器发送新写操作命令给从服务器在从服务器接收RDB文件并成功加载以后会恢复一个确认消息给从服务器\n接着, 主服务器就将replication buffer中的写操作命令发送给从服务器, 从服务器执行, 这个时候主从服务器之间的数据就一致了\n命令传播在第一次同步以后, 主从服务器之间就会维持一个TCP长连接, 来传播命令\n之后主服务器执行写命令以后, 就会将命令通过这个TCP长连接传播给从服务器, 从服务器执行\n使用长连接是为了避免频繁的TCP连接和断开带来的性能开销\n基于长连接的命令传播\n分摊主服务器的压力在有很多从服务器的时候, 进行全量同步的时候就会有两个问题\n\n通过bgsave生成RDB文件, 主服务器会忙于执行fork(), 从而阻塞主服务器, 使其无法正常处理请求\n传输RDB文件会占用主服务器的带宽, 对主服务器响应命令造成影响\n\n解决方案 : 不让所有的从服务器都直接和主服务器交互, 创建从服务器的从服务器\n\n让一部分从服务器交给充当经理角色的从服务器, 通过在从服务器执行replicaof就行\n增量复制如果主从服务器之间的网络出现了问题等意外情况, 导致主从服务器之间无法正常通信, 而在这期间, 主服务器接受到了写操作命令, 这个时候主从服务器之间的数据就出现了不同步\n在redis2.8之前, 会在重连的时候, 从服务器执行全量复制, 但是全量复制的开销太大了, 后面引入了增量复制 : 只重新复制在断连的时候主线程执行的写操作命令\n\n增量复制会有三个步骤\n\n在从服务器恢复网络以后, 会发送fsync &#123;runID&#125; &#123;offset&#125;命令给主服务器, 这个时候offset的值不是-1\n主服务器用CONTINUE响应命令告诉从服务器接下来采用增量复制的方式同步数据\n主服务器将主从服务器断线期间主服务器执行的写命令传播给从服务器\n\n\n那么主服务器是怎么哪些是要发送的增量数据呢?\n\n\nrepl_backlog_buffer, 是主服务器中的一个环形的缓冲区, 主从服务器断连以后, 可以从中找到差异数据\nreplication offset, 标记上面的环形缓冲区的同步进度, 主从服务器都有各自自己的偏移量, 主服务器用master_repl_offset标记自己写到的位置, 从服务器使用slave_repl_offset标记自己读到的位置\n\n主服务器在进行命令传播的时候, 不仅会将命令传播给从服务器, 还会将命令写入到repl_backlog_buffer中, 这个缓冲区中保存了最近传播的写命令\n从服务器重新连接上主服务器以后, 会通过psync命令发送自己的复制偏移量 slave_backlog_buffer给主服务器, 主服务根据自己的master_backlog_buffer和slave_backlog_buffer进行比对, 来决定执行哪种同步操作\n\n如果从服务器要读取的数据都还存储在环形缓冲区中, 就会采用增量同步的方式\n如果从服务器要读取的数据不在环形缓冲区中, 就会采用全量同步的方式\n\n全量复制的开销是很大的, 为了避免断连的时候发生频繁的全量复制, 尽量将repl_backlog_buffer的大小设置得大一些\nrepl_backlog_buffer &#x3D; second * write_size_per_second\n\nsecond是从服务器断连以后重新连接上主服务器的平均时间\nwrite_size_per_second是主服务器平均每秒产生的写命令数据大小\n\n一般会设置成这样计算出来的两倍\n可以在redis.conf配置文件中设置\nrepl-backlog-size 1mb","categories":["中间件","Redis","集群"],"tags":["Redis","数据同步","主从复制","高可用","副本"]},{"title":"Redis哨兵机制详解","url":"/2025/07/08/middle_ware/Redis/%E9%9B%86%E7%BE%A4/%E5%93%A8%E5%85%B5/","content":"哨兵机制为什么要有哨兵机制在主从集群下, 如果主节点挂了就不能执行写操作, 这个时候就需要手动将从服务器切换成主服务器 SLAVEOF NO ONE同时在从服务器中指定新的主服务器为主服务器, 同时还要通知上游的客户端, 将Redis的主服务器的IP切换成新的主服务器的IP为了解决这个繁琐麻烦的过程, Redis通过哨兵机制, 用一个节点来检测主节点, 如果主节点挂了, 就选举从节点中的一个为新的主节点, 实现主从故障转移\n哨兵机制是怎么工作的哨兵节点主要做三件事\n\n监控 : 哨兵节点节点是怎么监控节点的, 是怎么判断主节点已经故障了\n选主 : 哨兵节点是根据什么规则选择一个新的节点作为主节点的\n通知 : 哨兵节点是怎么把新的主节点的相关信息通知给从节点和客户端的\n\n监控\n怎么监控节点的?\n\n哨兵节点会每隔1s向所有的主从节点发送PING命令, 节点收到PING命令以后会返回一个响应给哨兵节点\n\n如果主从节点不响应的时间超过了down-after-milliseconds, 单位是毫秒, 这个哨兵节点就会将节点标记为 [主观下线]有主观下线也有客观下线, 之所以针对主节点设计主观下线和客观下线两种状态, 是因为可能主节点不响应是主节点的系统压力太大了或者网络发生了阻塞, 并不是主节点发生了阻塞客观下线需要多个哨兵节点一起判断, (哨兵往往是集群部署的, 最少有3台), 通过多个哨兵一起判断, 能有效避免单个哨兵节点因为自己的网络状况而误判主节点故障在哨兵节点标记为主观下线以后, 会向其他的哨兵发送 is-master-down-by-addr命令, 其他的哨兵收到这个命令以后, 就会根据自己和主节点之间的连接状况投票, 如果赞成票的数量超过quorum的配置以后, 就会判断主节点已经客观下线, 然后哨兵节点就要从从节点之中选择下一个主节点\n由哪个哨兵节点来进行故障转移?在有节点判断主从节点主观下线以后,  再通过哨兵集群投票确认主节点已经客观下线以后, 接下来就是选出来一个哨兵节点来进行故障转移, 即选出来一个leader\n在投票之前哪个哨兵节点判断的节点是客观下线的节点, 哪个节点就是leader的候选者, 候选者会向其他的实例发送命令, 表示自己想成为leader来执行主从切换, 并让其他所有的哨兵节点对他进行投票, 如果满足以下两个条件就能成为leader\n\n拿到半数以上的赞成票\n得票数大于等于quorum中的值\n\n\n为什么哨兵的节点数量最少为3个\n\n\n这是能完成哨兵判断节点是客观下线的最少节点数量\n哨兵节点能完成选举出来一个Leader的最少节点数量\n\nquorum的值建议设置为哨兵数量 &#x2F; 2 + 1\n主从故障切换的过程是怎么样的\n选择出来一个从节点作为主节点\n让其他的从节点成为新主节点的从节点\n通知客户端主节点已经更换了\n继续监视原来的故障的旧主节点, 如果旧主节点恢复正常了, 就让旧的主节点成为新主节点的从节点\n\n1. 选出新的主节点选择出来一个新的主节点, 然后哨兵节点下向其发送SLAVEOF NO ONE将其切换成主节点\n\n那么我们该怎么选出来新的主节点呢?\n\n首先我们要排除那些网络状况不好的节点, 这些节点很可能还会发生断连, 这样就会导致频繁的主从切换, 再根据三轮的考察选出来新的主节点\n\n怎么判断节点的网络状况不好呢?\n\nRedis中有个down-after-milliseconds * 10的配置项, 如果主从节点之间断连的时间超过了这个配置的时间, 就会视做认为主从节点已经断连了, 如果有一个节点的断连的次数超过了10次, 就会视作是网络不好的节点\n优先级最高的节点胜出在Redis中有个slave-priority的配置, 能配置节点的优先级, 因为不同的Redis实例对应的物理配置可能是不一样的, 如果有一个Redis的实例的物理机中的物理内存更多, 这个时候我们就可以配置它的优先级更高, 从而能让它在发生主从故障切换的时候更容易称为新的主节点\n复制进度最最快的节点胜出如果有两个节点的优先级是一样的, 这个时候就会进入到下一轮的考察 : 比较两个节点的之间的复制进度\n也就是比较两个节点的slave_repl_offset的值, 谁的值最接近master_repl_offset的值, 谁的复制进度就是最靠前的, 就选为新的主节点\nID号最小的胜出如果还有多个节点之间的复制进度都是一样的, 这个时候就会选出来ID号最小的节点作为新的主节点\n在选举出来新的主节点, 并且发送了SLAVEOF NO ONE的命令以后, 会以每秒一次的频率向其发送INFO命令来查看其切换成主节点的进度(原本是每十秒发送一次INFO), 并观察回复中的角色信息, 当得知角色信息由原本的slave变成了master, 哨兵节点就知道节点已经升级成了主节点\n2. 将从节点指向新的主节点新的主节点出现以后, 哨兵节点会向其他的从节点发送 SLAVEOF &lt;new-ip&gt; &lt;new-port&gt;的命令来让从节点指向新的主节点\n3. 通知客户端主节点已经更换完成主从切换的工作以后, 就会通过Redis的发布者&#x2F;订阅者机制来实现通知客户端\n\n哨兵节点会向+switch-master频道发布新的主节点的IP和端口信息, 然后客户端就能使用新的IP和端口来进行通信了\n4. 将旧主节点转化成从节点哨兵节点还是会继续监视原来的旧的主节点, 当其恢复通信的时候, 就会将其转化成新主节点的从节点\n哨兵集群的组成方式向一个哨兵集群中添加哨兵, 只需要在哨兵节点中发送命令\nsentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;\n\n只需要设置主节点的名字, IP, 端口以及quorum的值, 那么节点之间是怎么相互发现的呢\nRedis的哨兵节点之间是通过Redis的发布者&#x2F;订阅者机制来相互发现的\n在主从集群中, 主节点上有一个__sentinem__:hello频道, 不同的哨兵节点之间就是通过这个频道来相互发现的\n哨兵节点都订阅了这个频道, 在新的哨兵节点加入以后, 就会将自己的IP和端口号发布到这个频道上, 其他的哨兵节点就能从频道上直接获取哨兵节点的IP和端口号\n\n哨兵节点是怎么知道从节点的信息的\n\n哨兵节点每10秒会向主节点发送INOF命令, 主节点接受到这个命令以后, 会将从节点的列表发送给哨兵节点, 哨兵就能通过列表中的从节点的信息, 和每个从节点之间构建连接\n","categories":["中间件","Redis","集群"],"tags":["Redis","高可用","哨兵机制","故障转移","监控","选主"]},{"url":"/2025/07/08/Computer_Science/Algorithm/leetcode/%E5%91%A8%E8%B5%9B/452/","content":"Q1等积子集的划分方案给你一个整数数组 nums，其中包含的正整数 互不相同 ，另给你一个整数 target。\n请判断是否可以将 nums 分成两个 非空、互不相交 的 子集 ，并且每个元素必须  恰好 属于 一个 子集，使得这两个子集中元素的乘积都等于 target。\n如果存在这样的划分，返回 true；否则，返回 false。\n子集 是数组中元素的一个选择集合。\n示例 1：\n输入： nums &#x3D; [3,1,6,8,4], target &#x3D; 24\n输出： true\n**解释：**子集 [3, 8] 和 [1, 6, 4] 的乘积均为 24。因此，输出为 true 。\n示例 2：\n输入： nums &#x3D; [2,5,3,7], target &#x3D; 15\n输出： false\n解释 无法将 nums 划分为两个非空的互不相交子集，使得它们的乘积均为 15。因此，输出为 false。\n提示：\n\n3 &lt;= nums.length &lt;= 12\n1 &lt;= target &lt;= 1015\n1 &lt;= nums[i] &lt;= 100\nnums 中的所有元素互不相同。\n\nQ2 子矩阵的最小绝对差给你一个 m x n 的整数矩阵 grid 和一个整数 k。\n对于矩阵 grid 中的每个连续的 k x k 子矩阵，计算其中任意两个 不同值 之间的 最小绝对差 。\n返回一个大小为 (m - k + 1) x (n - k + 1) 的二维数组 ans，其中 ans[i][j] 表示以 grid 中坐标 (i, j) 为左上角的子矩阵的最小绝对差。\n注意：如果子矩阵中的所有元素都相同，则答案为 0。\n子矩阵 (x1, y1, x2, y2) 是一个由选择矩阵中所有满足 x1 &lt;= x &lt;= x2 且 y1 &lt;= y &lt;= y2 的单元格 matrix[x][y] 组成的矩阵。\n示例 1：\n输入： grid &#x3D; [[1,8],[3,-2]], k &#x3D; 2\n输出： [[2]]\n解释：\n\n只有一个可能的 k x k 子矩阵：[[1, 8], [3, -2]]。\n子矩阵中的不同值为 [1, 8, 3, -2]。\n子矩阵中的最小绝对差为 |1 - 3| = 2。因此，答案为 [[2]]。\n\n示例 2：\n输入： grid &#x3D; [[3,-1]], k &#x3D; 1\n输出： [[0,0]]\n解释：\n\n每个 k x k 子矩阵中只有一个不同的元素。\n因此，答案为 [[0, 0]]。\n\n示例 3：\n输入： grid &#x3D; [[1,-2,3],[2,3,5]], k &#x3D; 2\n输出： [[1,2]]\n解释：\n\n有两个可能的 k × k 子矩阵：\n以 (0, 0) 为起点的子矩阵：[[1, -2], [2, 3]]。\n子矩阵中的不同值为 [1, -2, 2, 3]。\n子矩阵中的最小绝对差为 |1 - 2| = 1。\n\n\n以 (0, 1) 为起点的子矩阵：[[-2, 3], [3, 5]]。\n子矩阵中的不同值为 [-2, 3, 5]。\n子矩阵中的最小绝对差为 |3 - 5| = 2。\n\n\n\n\n因此，答案为 [[1, 2]]。\n\n"},{"title":"TCP三次握手与四次挥手详解 - 连接建立与断开过程","url":"/2025/07/08/Computer_Science/Computer_network/%E8%AE%A1%E7%BD%91%E5%85%AB%E8%82%A1/2_TCP/1_TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/","content":"TCP 三次握手与四次挥手常见面试题TCP基本认识TCP头格式有哪些内容\n\n序列号 : 在建立连接时计算机生成的随机数作为初始值, 通过SYN包传给接收端主机, 每发送一次数据就会累加一次, 用于解决网络包乱序的问题\n\n确认应答号 : 下一次期望收到的数据的序列号, 发送端收到这个确认应答以后, 可以认为在这个序列号之前的数据都已经被正常接受. 用来解决丢包问题\n\n控制位 :\n\nACK : 该位置为1的时候, 确认应答字段变为有效, TCP规定除了最开始建立连接时的SYN包之外, 该位必须为1\nRST : 该位置为1的时候, 表示TCP连接出现异常, 必须强行断开连接\nSYN : 该位置为1的时候, 表示希望建立连接, 需要计算机生成随机值初始化序列号\nFIN : 该位置为1的时候, 表示今后不会再有数据发送过来了, 希望断开连接. 当通信结束希望断开连接的时候, 通信双方的主机之间就可以相互交换FIN位为1 的TCP段\n\n\n\n为什么需要TCP协议? TCP在哪一层IP层提供的服务是不可靠的, 不能保证网络包的交付, 不保证网络包的按序交付, 也不保证网络包中的数据的完整性\nTCP在网络层的上一层传输层, 保证了网络包传输的可靠性, 保证接收端接收的网络包是无损坏, 无间隔, 非冗余和按序的\nTCP是什么TCP是面向连接的, 可靠的, 基于字节流的传输层协议\n\n面向连接 : 必须是一对一的连接, 和UDP可以一个主机同时向多个主机发送消息, 一对多在一个TCP连接中是无法做到的\n可靠的 : 能保证一个报文一定能够到达接收端\n字节流 : 用户发送一个消息给接受端, 操作系统可能会将这个消息分组为多个TCP报文, 如果接收端不知道消息的边界, 是无法有效读出来用户的原消息的. 并且TCP报文是有序的, 当前一个报文没有收到的时候, 即使后面的报文已经收到了, 也不会交给应用层去处理\n\nTCP连接是什么用于保证可靠性和流量控制维护的某些状态信息, 这些信息的组合, 包括Socket, 序列号和窗口大小称为连接\n所以建立一个TCP连接, 客户端和服务端需要在三个信息上达成共识\n\nScoket: 由IP:port组成\n序列号: 用来解决乱序问题\n窗口大小 : 用来做流量控制\n\n\n如何唯一确定一个TCP连接?\n\n源地址 + 源端口, 目标地址 + 目标端口\n源地址和目标地址存在IP头部中, 作用是通过IP协议发送报文给对方主机, IP协议发送报文的粒度是主机\n源端口和目标端口存在TCP头部中, 告诉TCP协议应该把报文发送给哪个进程, TCP协议发送报文的粒度是进程\nTCP和UDP有什么区别呢UDP是通过IP协议实现了无连接的通信服务\n其头部很简单, 只有8字节\n\n目标和源端口 : 4字节\n包长度 : 2字节\n校验和 : 防止收到在网络传输中受损的UDP包, 2字节\n\n两者的区别\n1.连接 : \n\nTCP是面向连接传输的协议, 传输之前需要先建立连接\nUDP是无连接的协议\n\n2.传输对象\n\nTCP只能实现一对一的两点之间的通信\nUDP能实现一对多, 多对一, 多对多的通信\n\n3.可靠性\n\nTCP是可靠交付数据的, 数据可以无差错, 不丢失, 不重复, 按序到达\nUDP不保证可靠交付数据, 但是我们能通过UDP实现一个可靠的传输协议, 比如QUIC\n\n4. 拥塞控制, 流量控制\n\nTCP有, 能保证数据传输的安全性\nUDP没有, 即使网路很拥堵了, 也不会影响UDP发送的速率\n\n5. 首部开销\n\nTCP首部长度在没有使用[可选]的字段的时候是20字节, 使用了还会更长\nUDP首部长度是固定的8字节\n\n6.传输方式\n\nTCP是流式传输, 没有边界\nUDP是一个包一个包发送的, 有边界, 但是会有乱序和丢包\n\n7. 分片不同\n\nTCP根据MSS大小, 如果大于了就会在传输层中分片, 接收方同样在传输层组装TCP数据包\nUDP根据MTU大小分片, 如果大了, 就会在IP层分片, 接收方同样是在IP层组装数据\n\n\n\n\nTCP头部中没有包长度的字段, 而UDP中有呢\n\n其实TCP也是能计算出来负载数据的长度的\n$TCP数据的长度 &#x3D; IP总长度 - IP首部的长度 - TCP首部长度$\nUDP中之所以会将数据作为包来处理, 其实是整个协议栈和API刻意保留了消息边界的设计, 更加强调UDP的独立性\n而TCP中会将数据作为流来处理, 这是一种设计决策上和设计理念上的差异\nTCP和UDP能使用一个端口吗可以\n在数据链路层, MAC地址用来寻找局域网中的主机. 在网路层中, 通过IP地址来寻找网络中互连的主机或者路由器. 在传输层中, 通过端口地址寻址, 为了找到同一计算机中同时通信的不同应用进程\n传输层中的端口号是为了区分不同应用进程的数据包\n在内核中, 传输层协议TCP和UDP是完全独立的软件模块\n当主机收到数据包以后, 根据IP包头协议号字段知道该数据包是TCP还是UDP, 从而交给不同的模块处理. 送给TCP&#x2F;UDP模块的报文, 根据端口号知道送给哪个应用进程处理\nTCP连接建立TCP连接三次建立的过程\n\n服务端先进入到LISTEN状态监听某个端口\n客户端从CLOSE进入到SYN_SENT状态发送第一个报文: SYN报文\n客户端随机初始化序号(client_isn)给序列号\nSYN标志为1, 表明客户端想建立一个连接\n\n\n服务端接收到了SYN报文, 从LISTEN状态进入到SYN_RCVD状态, 发送第二个报文 : ACK + SYN报文\n服务端随机初始化序号(server_isn)给序列号\n把收到的客户端的ISN + 1填入到确认应答号中\nSYN标志为1, 表明服务端想建立一个连接\nACK标志为1, 确认应答字段有效\n\n\n客户端收到了ACK + SYN报文, 从SYN_SENT进入到ESTABLISHED状态, 发送第三个报文 : ACK报文\n将收到的服务端的ISN + 1填入到确认应答号中\n将ACK置1\n\n\n服务端收到了ACK报文以后, 进入到ESTABLISHED状态\n\n第三次握手的时候是可以携带数据的, 前两次握手的时候不能携带数据\n这之后就能相互发送数据了\n如何在linux中查看TCP状态通过netstat -napt命令\n为什么是三次握手, 不是四次或者两次?什么是TCP连接\n\n用于保证可靠性和流量控制而维护的某些状态信息, 这些信息的组合, 包括Socket, 序列号和窗口大小称为连接\n\n所以问题就变成了为什么三次握手才可以初始化Socket, 序列号和窗口大小并建立TCP连接\n\n三次握手才能阻止重复历史连接的初始化(主要原因)\n三次握手才能同步双方的序列号\n三次握手能避免资源浪费\n\n原因一: 避免历史连接TCP连接使用三次握手的首要原因就是为了防止[历史连接]初始化连接造成混乱\n考虑这样的场景, 客户端线发送了SYN (seq &#x3D; 90)的报文, 然后客户端宕机了, 一段时间重启以后, 重新发送了SYN (seq &#x3D; 120)的报文希望重新建立连接, 但是SYN (seq &#x3D; 90)的报文被网络阻塞了, 两个报文最后seq&#x3D;90的先到达, 马上seq&#x3D;120的也到达了服务端\n三次握手是怎么阻止历史连接的\n\n旧SYN(seq=90)先到达, 服务端接收到以后, 向客户端发送ACK + SYN(Ack Num = 90 + 1, Seq Num = 300)报文\n客户端接收到以后, 发现Ack Num和自己期望的Ack Num = 120 + 1不一样, 发起RTS报文终止了连接\n新的SYN(seq=120)到达了服务端, 服务端接收到以后, 向客户端发起了ACK + SYN(Ack Num = 120 + 1, Seq Num = 400)报文\n客户端接收到以后, 发现对上了Ack Num, 返回ACK(Ack Num = 400 + 1, Seq Num = 121)报文\n服务端接收到ACK报文以后, 进入到了连接ESTABLISHED状态, TCP连接建立\n\n如果使用两次握手, 就没有中间状态阻止历史连接, 服务端可能会建立一个历史连接, 造成资源的浪费\n因为是两次连接, 服务端在接收完ACK + SYN报文以后, 就会进入到ESTABLISHED状态, 从服务端的角度来看, 连接就已经建立好了, 这个时候服务端就可以向客户端发送消息了, 但是实际上这是一个[历史连接], 发送的数据完全是无效浪费的,  在客户端接收到ACK + SYN报文以后, 向服务端发送RST报文以后, 连接才会被废除, 服务端白白建立了一个不会被使用的历史连接, 可能会导致数据的丢失, 一定造成了资源的浪费\n\nTIP\n第三次握手最关键的地方在于客户端发送的报文是ACK报文, 如果客户端发送完三次握手报文以后再发送了一些数据, 但是前面的三次握手报文丢失了, 这个时候连接还没有建立数据会丢失吗?\n不会丢失, 因为后面的携带了数据的报文也是ACK报文, 服务端收到以后还是会建立连接, 这也是第三次握手的时候可以接收数据的一个体现\n\n原因二: 同步双方的序列号TCP协议的通信双方, 都必须维护一个序列号\n\n接收方可以通过序列号去除重复的数据\n接收方可以通过序列号按序接收数据包\n可以标识已经发送出去的数据包哪些被对方收到了(根据ACK报文中的序列号知道)\n\n所以TCP不能没有序列号, 就像西方不能没有耶路撒冷\n而TCP协议通信双方初始化序列号的过程可以分成下面四步\n\n发送方 -&gt; 接收方 Seq Num &#x3D; client_isn\n接收方 -&gt; 发送方 Ack Num &#x3D; client_isn + 1来确认已经成功接收\n接收方 -&gt; 发送方 Seq Num &#x3D; server_isn \n发送方 -&gt; 接收方 Ack Num &#x3D; server_isn + 1\n\n接受方和发送方都需要发送一个SYN报文来传递序列号, 另一边都需要发送一个ACK报文来表示自己已经成功收到了, 所以最少有四步, 但是接收方发送Ack Num和Seq Num能合成同一步, 所以最少需要三次握手\n原因三: 避免资源的浪费如果使用两次握手, 服务端就得在发送完SYN + ACK报文以后就进入到ESTABLISHED状态, 为历史连接分配了资源, 浪费资源\n总结为什么是不使用两次握手和四次握手\n\n两次握手 : 没办法可靠得同步双方的序列号, 无法防止历史连接的建立, 会造成双方资源的浪费\n四次握手 : 三次握手就已经能够理论上建立最少可靠连接, 所以不需要更多的连接次数\n\n为什么每次建立TCP连接时, 初始化的序列号都要求不一样\n如果每次建立连接的时候, 客户端和服务端初始化的序列号都是一样的, 很容易出现历史报文被下一个相同四元组的连接接收的问题, 而如果每次建立TCP连接的时候初始序列号都不一样, 就能够区分出来历史报文和现在要接收的报文, 往大程度上避免了历史报文被接收\n为了安全性, 防止黑客伪造相同序列号的TCP报文被接收\n\n初始序列号ISN是如何随机产生的ISN &#x3D; M + F(loaclhost, localport, remotehost, remoteport)\n\nM是一个计时器, 每4微妙 + 1\nF(loaclhost, localport, remotehost, remoteport)是一个由四元组通过hash算法计算出来的随机数值. 可以使用MD5\n\n既然IP层会分片, 为什么TCP层还是需要MSS呢如果只使用IP层的MTU来分片, 就会出现下面的情况\n一个IP数据报长度超过了MTU, 被切分成了多个IP分片, 然后在IP层传输, 其中的一个数据报丢失了, TCP层接收到以后无法组装成一个完整的TCP报文段, 也就无法发送给接收端, 这个时候就会在超时以后触发超时重传机制, 因为整个IP报文才具有确认机制, 所以整个IP报文会被重传\nTCP通过MSS进行数据分段, 每个分段单独封装在TCP报文段中, 形成独立的IP数据报进行传输, 避免了IP层分片. 这使得TCP能单独确认和重传每个分段, 而不会因为单个分段丢失而重传所有数据\n第一次握手丢失了, 会发生什么客户端在发送了SYN报文以后, 进入到SYN_SENT状态\n如果客户端无法在规定的时间内收到服务端的SYN-ACK报文(也就是第二次握手), 就会触发超时重传机制, 重传SYN报文(Seq相同, 表示仍处于同一次TCP连接建立尝试中)\n不同版本的操作系统的中的超时时间是不一样的\n当客户端在1s后没有收到报文, 就会重传 ,重传的次数由tcp_syn_retries来控制\n# cat /proc/sys/net/ipv4/tcp_syn_retries5\n\n第一次超时重传是在1s后, 第二次就是2s, 第三次就是4s, 第四次就是8s, 第五次就是16s, 每次超时时间是上一次的两倍\n第五次超时重传以后, 会继续等待32s, 如果还没有收到SYN-ACK, 就会断开TCP连接\n第二次握手丢失了, 会发生什么如果第二次握手丢失了, 就会导致\n\n客户端认为自己的报第一次握手SYN报文没有发送到服务端, 进行超时重传\n服务端一直没有收到第三次握手, 也触发超时重传\n\n服务端超时重传的策略和第一次握手的, 每次重传的超时时间翻倍策略一样, 配置重传次数的参数是\n# cat /proc/sys/net/ipv4/tcp_synack_retries5\n\n第三次握手丢失了, 会发生什么也是一样的重传, 服务端认为自己的报文丢失了, 超时重传到接收到ACK或者达到最大的重传次数\n什么是SYN攻击, 怎么避免SYN攻击Linux内核会维护一个半连接队列和全连接队列\n正常流程\n\n服务端接收到客户端的SYN报文的时候, 就会创建一个半连接对象放入到半连接队列(SYN队列)中\n接着发送SYN+ACK给客户端\n等到接收到客户端的ACK以后, 从半连接队列中取出来一个半连接对象, 创建一个新的连接对象放入到Accept队列中\n应用通过调用accept()socket接口, 从Accept队列中取出连接对象\n\n攻击者发起SYN攻击, 就是不断使用虚假的IP:port, 然后占满SYN队列, 这样当TCP半连接队列满了以后, 后续再收到的SYN报文就会丢失, 导致客户端无法与服务端建立连接\n解决方法\n\n方式一 : 增大TCP半连接队列\n\n通过增大下面的三个参数\n\nnet.ipv4.tcp_max_syn_backlog\nlisten()函数中的backlog\nnet.core.somaxconn\n\n\n方式二: 开启 net.ipv4.tcp_syncookies\n\n开启这个功能就可以在不使用SYN半连接队列的情况下成功建立连接\n\n当SYN队列满了以后, 后续服务端收到SYN包, 不会丢弃, 而是根据算法计算出来一个cookie值\n将cookie值放入到第二次握手报文的序列号里面, 然后服务端会第二次握手给客户端\n服务端接收到客户端的应答报文时, 会检查这个ACK包的合法性, 如果合法, 将该连接对象放入到Accept队列\n最后应用程序通过调用accept()接口, 从Accept队列中取出连接\n\nnet.ipv4.tcp_syncookies的参数主要有三个值\n\n0值, 表示关闭该功能\n1值, 表示仅当SYN半连接队列放不下的时候, 再启用它\n2值, 无条件开启功能\n\n\n方式三 : 减少SYN+ACK重传次数\n\n减少重传的次数, 就能减少SYN报文在SYN队列中停留的时间\n","categories":["计算机科学","计算机网络","TCP协议"],"tags":["TCP","网络协议","八股文","面试","三次握手","四次挥手","SYN","ACK","FIN","连接建立","连接断开"]},{"url":"/2025/07/08/Computer_Science/Computer_network/%E8%AE%A1%E7%BD%91%E5%85%AB%E8%82%A1/2_TCP/3_TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/","content":"TCP重传, 滑动窗口, 流量控制, 拥塞控制常见的重传机制TCP会在以下两种情况触发重传机制\n\n数据包丢失, 通过序列号判断出来消息丢失了\n确认应答丢失, 通过没有收到ACK来判断消息丢失了\n\n超时重传RTT (Round-Trip Time往返时延)\n\nRTT是数据发送时刻到接受到确认的时刻的差值\n超时重传时间用RTO(Retransmission Timeout 超时重传时间) 表示\n如果超时时间设置得过大或者过小\n\nRTO过大, 重发就慢, 丢了很久才重发, 没有效率\nRTP过小, 会导致可能没有丢失, 只是ACK晚了一点到, 就触发了重发机制, 增加网络拥塞, 导致更多的超时, 导致更多的重发, 最后直接堵死了\n\n在Linux中RTO的计算\n\n需要采样RTT的时间, 然后进行加权平均, 算出来一个平滑RTT值, 而且这个值还是动态变化的, 因为网络状况也是在动态地变化\n除了采用RTT, 还需要采样RTT的波动范围, 避免RTT有一个大的波动的话很难被发现的情况\n\n\n根据这个公式, 越早之前的SRTT, DevRTT, RTT对RTO的影响呈指数级变化(每次变为原来的alpha&#x2F; (1-belta) &#x2F; muim倍),\nSRTT是平滑RTT, DevRTT是平滑RTT和当前RTT之间的差距, 两者能让RTO的计算考虑到历史的网络情况, 同时越近的RTT对RTO的影响越大, DevRTT能保证RTO对最近的大的波动RTT的敏感  \nLinuxα &#x3D; 0.125，β &#x3D; 0.25， μ &#x3D; 1，∂ &#x3D; 4\n如果超时重发的数据, 再次超时的时候, 下次超时重发的时间是上一次的两倍\n快速重传\n快速重传的工作方式就是, 如果收到了三个相同的ACK, 会在定时器过期前, 重传丢失的报文的报文段\n解决了超时时间相对较长的问题\n但是没有解决, 重传的时候, 是重传一个, 还是重传所有的问题\n\n重传一个, 重传的效率很低, 如果有批量丢失的情况, 就需要每个丢失的数据都发送三个ACK才能重发\n重发丢失报文及之后的所有报文, 就很容易有重复报文, 浪费网络资源\n\n于是就有了SACK方法\nSACKSelective Acknowledgment, ACK 选择性确认\n需要在TCP的选项字段里面加一个SACK, 它可以将已收到的数据的信息发送给 [发送方], 这样发送方就可以知道哪些数据收到了, 哪些数据没有收到, 这样就只需要重新传丢失的数据就行\n\n如果要支持SACK, 必须要通信双方都支持, 在Linux下, 可以哦通过net-IP v.tcp_sack参数来打开这个功能 (Linux 2.4后自动打开)\nD-SACKDuplicate SACK 又称D-SACK, 使用SACK来进一步告诉[发送方]有哪些数据被重复接收了\n能够帮助发送方区分\n\n数据包真正丢失\n数据包被网络延迟或者重排序\n确认包ACK丢失导致的重传\n\n从而更精确地识别网络状况, 优化重传策略, 改进拥塞控制\nACK丢包时\n接收方一直没有收到ACK, 后面直接收到返回的ACK 4000, 而这个时候接收到的数据通过SACK可以知道是3000~3500, 这个发送方就知道发送数据没有丢失, 只是应答报文丢失了\n网络延迟\n发送的报文延迟以后, 触发了快速重传, 在重传以后, 被延迟的数据包到达了接收方, 这个时候接受方返回ACK 3000 SACK 10001500, 说明10001500这段被重复接收了, 而这一段之前重传过, 说明这段不是丢失了, 只是延迟了\n\n如果是真的丢失会怎么样\n\n如果是真的丢失, SACK中就不会是已经发送过的数据, 因为一直丢失, 应该只有最后一份数据是成功到达了接收端的\n\n怎么区分是网络延时还是ACK丢包\n\n如果是网络延迟,  那么D-SACK在重传之后的某个时间发送给[发送端], 而不是紧随重传而至, 这就是关键区别\nACK丢包的情况\n\nD-SACK几乎紧随重传后到达(时间差远小于RTT)\n只有重传包被延迟接收\n这种情况下不会错误地认为网络拥塞, 避免不必要地缩减拥塞窗口\n\n网络延迟的情况\n\n原始数据包和重传包之间到达的时间差较大\nD-SACK到达时间表明原始包和重传包之间有明显时间间隔\n调整RTT估算值和重传超时计算, 适应较高的网络延迟\n\n滑动窗口TCP协议中为了保证可靠性, 每发送一条数据报, 都需要收到一个ACK来确认收到了这条数据报, 但是如果每次都是发送一条数据段, 然后必须等待这条数据段收到ACK才能发送下一条数据段, 效率很低, 网络条件越差, 效率越低\n解决方式就是 : 设立缓冲区窗口, 我们能够连续发送数据, 而不需要等待确认应答, 通过窗口大小来控制我们最多无需等待确认应答, 而可以继续发送数据的数量\n窗口大小由接收端的Window字段决定\n如果窗口大小为3, 发送方就能连续发送3个TCP段, 并且中途如果有ACK丢失, 也可以通过下一个确认应答来确认, 比如ACK600丢失了, 但是接收到了ACK700, 这个时候就通过了下一个确认应答来确认了TCP段已经被收到到了, 这个就叫累计确认\n发送方的窗口示例, 分成四个部分\n\n#1 : 已发送并接收到ACK确认数据 (窗口前)\n#2 : 已发送但是没有接受到ACK确认的数据 (窗口中已经发送过的数据)\n#3 : 没有发送, 但是在接收端处理范围内的数据 (窗口中还没有发送但是能发送的数据)\n#4 : 没有发送, 并且不在接收端处理范围内的数据 (窗口后)\n\n\n\n\n\n 程序如何表示发送方的四个部分\n\n\n\nSUN.WND : 窗口的大小\nSUN.UNA (Send Unacknowledged): 指向发送窗口中的已发送但是未收到确认的第一个字节的序列号, 也就是#2部分的第一个字节\nSUN.NXT : 指向未发送但总大小在接收方处理范围内的第一个字节的序列号, 也就是#3的第一个字节\n指向#4的第一个字节通过SND.UNA + SUN.WND来计算出来\n\n可用窗口的大小 &#x3D; SND.WND - (SUN.UNA - SUN.NXT)\n\n接收方的滑动窗口\n\n\n分成三个部分\n\n#1 : 已经成功接收并且确认的数据 (窗口前)\n#2 : 未收到数据但可以接收的数据(窗口)\n#3 : 未收到的数据并且不在窗口范围内的数据 (窗口后)\n\n也是通过指针来划分\n\nRCV.WND : 接收窗口的大小\nRCV.NXT : 期望对方送来的第一个字节的序列号\n指向#4的第一个字节 &#x3D; RCV.NXT + RCV.WND\n\n\n发送窗口和接收窗口总是相等的吗\n\n接收窗口大的大小约等于发送窗口的大小\n滑动窗口的大小不是一成不变的, 会随着网络条件动态变化, 新的接收窗口的大小需要通过TCP头部中的Window字段来告诉对方, 这个过程有时延, 所以接收窗口和发送窗口之间的大小关系是约等于\n流量控制在TCP中发送方会根据接收方的接收能力来调整发送数据的速度, 发送方根据接收方提供的窗口大小调整数据发送的速度\n操作系统缓冲区和滑动窗口之间的关系发送窗口和接收窗口中所存放的字节数都是放在操作系统的缓冲区中的, 而操作系统中的缓冲区会受到操作系统调整\n\n例子一\n\n\n窗口的初始大小是360\n服务端非常地繁忙, 应用层不能及时读取数据\n\n\n\n客户端一次性向服务端发送了140字节的数据\n\n服务端接收了以后将数据放在了缓冲区, 但是应用程序只读取了40字节的数据, 这个时候就有100字节的数据残留在了缓冲区, 接收窗口的大小就变成了260 (360 - 100), 会在返回的ACK中告知Window &#x3D; 260来调整发送窗口的大小\n\n服务端不断积累缓冲区中的数据, 最后导致返回的ACK中的Window &#x3D; 0, 这个时候发送端就无法再发送数据, 也就是发生了窗口关闭\n\n\n\n第二个例子 : 操作系统直接减少了缓冲区的大小\n\n系统资源很紧张, 操作系统直接减少了缓冲区的大小\n\n\n客户端发送了140字节的数据, 发送窗口可用大小变成了220, 接收端接收到了140字节数据以后应用程序一个字节都没有读取, 这个时候操作系统直接减小了缓冲区的大小, 这个时候接收端的窗口大小变成了100字节 (360 - 140 - 120)\n服务端返回ACK并告知Window &#x3D; 100\n但是在ACK到来之前, 这个时候发送窗口可发送的最大字节数是220, 这个时候客户端发送180字节\n这180字节到达接收端以后造成了丢包, 因为接收窗口只有100字节\n而Window &#x3D; 100的消息到达了发送端以后, 发送端的窗口大小变成100, Usable变成了负数 -80 (100 - 180)\n\n为了防止这种错误情况, TCP规定是不允许同时减少缓存又收缩窗口的, 而是采用先收缩窗口, 过段时间再减少缓存, 这样就能避免丢包的情况\n窗口关闭在接收端返回的Window &#x3D; 0的时候就发生了窗口关闭, 会阻止发送方给接收当传递数据, 直到窗口的大小是非0\n发生了窗口关闭以后, 接收端会在处理完数据以后, 发送一个窗口大小为非0的ACK报文, 如果这个报文在网络中丢失了, 就会发生死锁\n\n发送端的发送窗口是0, 等待一个窗口大小为非0的ACK报文\n接收端的接收窗口不是0 ,但是以为自己的ACK报文发过去了, 等待发送端发送TCP段\n\n\nTCP是怎么解决死锁问题?\n\nTCP为每个连接设置一个持续定时器, 只要TCP连接一方收到了对方的0窗口通知, 就启动持续计数器\n如果持续计数器超时, 就会发送窗口探测报文, 对方在确认窗口探测报文的时候, 就会给出自己的接收窗口的大小\n\n如果接收窗口仍为0, 重置持续定时器\n如果接收窗口不是0, 死锁的局面就被打破了\n\n窗口探测的次数一般是3次, 每次间隔大约30~60S, 如果3次过后接收窗口还是0的话, 有的TCP的实现会直接发送RST报文来中断连接\n糊涂窗口综合征如果接收方的应用程序来不及处理缓冲区中的数据, 就会导致接收端的窗口大小越来越小, 最后接收端和发送端的窗口大小都只有几个字节\n最后每次TCP段里面就只有几个字节的数据在传递, 最后发送的数据还没有TCP + IP40个字节大\n\n例子\n\n\n这个问题之所以会发生是因为\n\n接收方能通告一个小的窗口\n发送方能发送小数据\n\n\n怎么让接收方不通告小的窗口呢\n\n窗口大小 &lt; min(MSS, 缓存空间 &#x2F; 2), 通知窗口大小 &#x3D; 0, 阻止对方再发送数据过来\n\n怎么让发送方不能发送小的数据呢\n\nNagle算法, 只有满足下面两个条件之一的时候, 才可以发送数据\n\n要等到可用窗口大小 &gt;&#x3D; MSS, 并且数据的大小&gt;&#x3D; MSS\n收到之前发送数据的ACK回包\n\n如果接收方还是会通知小的窗口, 即使使用Nagle算法也无法避免糊涂窗口综合征, 因为如果接收端回复ACK的速度很快, Nagle算法就不会拼接太多的数据包\n可以在Socket设置TCP_NODELAY选项来关闭这个算法\nsetsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&amp;value, sizeof(int));\n\n拥塞控制流量控制只能保证发送方会根据接收方的接收能力来调整发送数据的速度\n但是网络是共享的, 可能会因为其他主机导致网络拥堵, 发生拥塞\n有了拥塞控制, 就是为了避免[发送方]的数据填满整个网络, 发生了拥塞, TCP会自我牺牲, 降低发送的数据量\n拥塞窗口 cwnd是发送方维护的一个状态变量, 会根据网路的拥塞程度动态变化\n引入了拥塞窗口以后发送窗口swnd &#x3D; min(cwnd, rwnd)\n\n只要网络没有出现拥塞, cwnd增大\n出现了拥塞, 减小\n\n\n怎么知道当前的网络出现了拥塞?\n\n发送方没有在规定的时间内接收到ACK应答报文, 就可以认为网络出现了拥塞\n\n拥塞控制算法有哪些?\n\n\n慢启动\n拥塞避免\n拥塞发生\n快速恢复\n\n慢启动TCP刚建立的时候, 会一点一点提高发送数据包的数量\n慢启动的规则就是 : 每收到一个ACK, cwnd就会 + 1\n假定cwnd和swnd相等(cwnd的单位一般是MSS, swnd和rwnd的单位一般是字节)\n\n连接建立完成以后, 一开始初始化cwnd &#x3D; 1, 表示可以传一个MSS的数据\n\n收到一个ACK的应答确认以后, cwnd &#x3D; 2 (1+1)\n\n收到两个ACK的应答确认以后, cwnd &#x3D; 4(2+2)\n\n收到四个ACK的应答确认以后, cwnd &#x3D; 8(4+4)\n\n\n….\n\n\n可以看出来拥塞窗口在慢启动阶段是指数级增长的\n\n什么时候会增长到头呢\n\n有慢启动门限 ssthresh (slow start threshold)状态变量\n\n当cwd &lt; ssthresh时, 使用慢启动算法\ncwd &gt;&#x3D; ssthresh时, 使用拥塞避免算法\n\n拥塞避免一般来说ssthresh的大小是65535字节\n当进入到拥塞避免算法以后, 每收到一个ACK, cwnd会增长1&#x2F;cwnd, 也就是收到cwnd个ACK以后, cwnd才会增长1\n\n加入ssthresh &#x3D; 8, 当8个ACK到来的时候cwnd才会从8 -&gt; 9\n接下来需要收到9个ACK, 才会从9 -&gt; 10\n\n拥塞避免算法将cwnd的增长从指数级增长变成了线性增长\n这个时候拥塞窗口还是在增长的, 只是变得更慢了, 这么一直增长以后, 网络就会慢慢进入到拥塞状态, 这个时候就会触发重传机制, 就会使用到拥塞发生算法\n拥塞发生有两种重传机制, 快速重传和超时重传, 不同的重传方式, 会有不同的拥塞发生算法\n\n发生超时重传的拥塞发生算法\n\n这种情况TCP认为发生了严重的拥塞, 大部分数据都丢失了才会出现超时重传, 不然就会进入到快速重传\n\nssthresh &#x3D; cwnd / 2\ncwnd &#x3D; 1\n然后重新进入慢启动阶段\n\n这种方式会导致网络突然出现卡顿\n\n发生快速重传的拥塞控制算法\n\n这种情况TCP认为拥塞情况不严重, 大部分数据里面, 只有小部分丢失了\n\nssthresh &#x3D; cwnd / 2\n进入快速恢复算法\n\n快速恢复\n拥塞窗口 cwnd = ssthresh + 3\n重传丢失的数据包\n如果再收到重复的ACK, cwnd + 1\n如果收到新数据的ACK, cwnd = ssthresh, 恢复到之前的状态, 即再次进入拥塞避免状态\n\n\n"},{"title":"TCP四次挥手详解 - 连接断开过程与状态转换","url":"/2025/07/08/Computer_Science/Computer_network/%E8%AE%A1%E7%BD%91%E5%85%AB%E8%82%A1/2_TCP/2_TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/","content":"TCP连接断开TCP四次挥手的过程\n\n客户端打算关闭连接, 客户端发送FIN报文, 进入FIN_WAIT_1状态\n服务端接受到了FIN_WAIT_1报文, 进入CLOSED_WAIT状态, 回复ACK报文, 服务端接受到了ACK报文, 进入到FIN_WAIT_2状态\n服务端发送FIN报文, 进入LAST_ACK状态\n客户端接收到了FIN报文, 客户端发送ACK报文, 进入到TIME_WAIT状态\n服务端在收到ACK报文以后, 进入到CLOSE状态\n客户端在经过2MSL一段时间后, 自动进入到CLOSE状态\n\n主动关闭连接的, 才有TIME_WAIT状态\n为什么挥手需要四次而不是三次?\n关闭连接的时候, 客户端向服务端发送FIN, 仅仅表示客户端不再发送数据了但是还能接收数据\n服务端接收到客户端的FIN报文时, 先回一个ACK报文, 而服务端可能还有数据需要处理和发送, 等服务端不再发送数据的时候, 才发送FIN报文给客户端表示同意关闭现在的连接\n\n但是也有三次, 在被动关闭方TCP挥手的过程中, 如果没有数据要发送, 并且没有开启TCP_QUICKACK(默认没有开启), 就会启用TCP延迟确认机制, 第二次和第三次挥手就会合并\n\nTCP延迟确认机制\n\n\n当有响应数据要发送的时候, ACK会和响应数据一起发送给对象\n当没有响应数据要发送的时候, ACK将会延迟一段时间, 等待是否有响应数据可以一起发送给对方\n如果在延迟等待发送ACK期间, 对方的第二个数据段又到达了, 就会立即发送ACK\n\n第一次挥手丢失会发生什么主动方发送的FIN报文丢失, 主动方在发送报文以后就进入到了FIN_WAIT_1状态, 主动方会在超时时间内没有接收到ACK响应报文而触发超时重传\n超时时间会随着超时次数翻倍\n重发次数通过tcp_orphan_retries参数来控制\n第二次挥手丢失会发生什么被动方接收到了发起方的FIN报文, 进入到CLOSE_WAIT状态\n但是ACK报文是不会重传的, 从发起方的角度来看, 就是自己的第一次挥手丢失了, 就会超时重传第一次挥手\n第三次挥手丢失会发生什么发起方接收到ACK报文以后, 进入到 FIN_WAIT_2状态, 需要接收到被动方发送的FIN报文才能进入到TIME_WAIT状态\n从客户端的角度来看就是一直没有接收到被动方发送的FIN报文, 一直在FIN_WAIT_状态, 从服务端的角度来看, 就是发送的FIN丢失了, 超时重传, 超过了设定的重试次数, 就会从服务端断开连接\n如果主动关闭方使用的关闭函数是close()函数, 它有一个tcp_fin_timeout的参数, 控制了在FIN_WAIT_2阶段的最长时间, 如果超过了这个时间, TCP连接会被强行关闭, 从客户端断开丽娜姐\n如果使用的是shutdown()函数, 那就是死等了\n第四次挥手丢失会发生什么客户端在第三次挥手以后就会进入到TIME_WAIT阶段, 2MSL之后就会从客户端关闭连接\n\n服务端重传FIN报文的次数达到tcp_orphan_retries的最大重传次数的时候, 等待上次等待时间的两倍以后, 就会从服务端断开连接\n客户端进入到TIME_WAIT阶段以后, 开启2MSL的定时器, 如果收到FIN报文, 就会重置定时器, 定时器到了, 就从客户端关闭连接\n\n为什么TIME_WAIT等待的时间是2MSLMSL : Maximum Segment Lifetime, 报文的最大生存时间, 任何报文在网络上存在的最长时间\nMSL与TTL的区别 : MSL的单位是时间, TTL是经过路由跳数\nTTL的值一般是64, Linux将MSL的值设置为30s, 意味着Linux认为数据经过64个路由器的时间不会超过30s, 如果超过了, 就认为报文已经消失在网络中了\nTIME_WAIT等待2倍的MSL, 比较合理的解释是 : 网络中可能存在发送方发送过来的数据包(也就是第三次挥手的FIN包), 接收到这个包的最长可能时间是一个MSL, 然后接收到以后又会给对方响应, 这个最大可接受时间又是一个MSL\n相当于至少允许报文丢失一次, 如果ACK在一个MSL内丢失, 这样被动方重发的FIN会在第2个MSL内到达\n为什么需要TIME_WAIT状态TIME_WAIT是只有主动方才有的状态\n\n防止历史连接中的数据, 被后面相同的四元组连接错误接收\n2MSL的时长能保证历史数据包都已经自然消失在网络中了\n\n\n确保被动关闭连接的一方能正确关闭\n等待足够的时间,  保证自己的ACK是能被对方收到的, 从而帮助其自然关闭\n\n\n\nTIME_WAIT过多有什么危害\n占用系统资源, 比如文件描述符, 内存资源, CPU资源, 线程资源等, 简单来说就是在TIME_WAIT过多会导致资源得不到快速的释放\n占用端口资源, 端口资源是有限的, 一般范围是32768 ~ 61000, 可以通过修改net.ipv4.ip_local_port_range\n如果客户端(主动发起关闭连接方)TIME_WAIT状态过多, 就没办法再向[目的IP, 目的PORT]一样的服务建立连接了, 因为四元组相同\n\n\n\n如何优化TIME_WAIT优化的点在于TIME_WAIT会延缓资源释放的时间, 解决最短等待时间是2MSL的问题\n方式一 : net.ipv4.tcp_tw_reuse和tcp_timestamps\n开启net.ipv4.tcp_te_reuse = 1以后, 可以复用处于TIME_WAIT的socket为新的连接所用\ntcp_twreuse功能只能是客户端(连接发起方), 因为开启了这个功能,  在调用connect()函数的时候, 内核会随机找出来一个time_wait状态超过1s的连接给新的连接复用\n开启这个功能的一个前提是, 需要打开TCP对时间戳的支持\nnet.ipv4.tcp_timestamps = 1(默认为1)引入了时间戳, 就不需要通过等待2MSL来确保历史数据已经消失在网络中, 因为时间戳过期的数据包自然会被丢弃\n方式二: net.ipv4.tcp_max_tw_buckets\n这个值默认是18000. 当系统中处于TIME_WAIT的连接一旦超过这个值, 系统无法为这些新关闭的连接分配TIME_WAIT状态的资源, 会直接关闭资源, 也就是向这些连接发送RST包而不是FIN包\n方式三: 程序中使用SO_LINGER\n通过设置socket的选项, 来设置调用close关闭连接行为\nstruct linger so_linger;so_linger.l_onoff = 1;so_linger.l_linger = 0;setsockopt(s, SOL_SOCKET, SO_LINGER, &amp;so_linger, sizeof(so_linger));\n\n如果l_onoff为非0, 且l_linger的值为0, 调用close以后, 就会立刻发送一个RST报文给对端, 该TCP连接将跳过第四次挥手\n上面的三种方法其实都是在想办法跳过TIME_WAIT状态, 会发生乱七八糟的事情的, 毕竟它设计出来就是为了给下一个TCP连接一个纯净的环境\n如果服务端要避免过多的TIME_WAIT状态的连接, 就永远不要主动断开连接, 让客户端去断开, 由分布在各处的用户端来承受TIME_WAIT\n服务器上出现大量的TIME_WAIT状态的原因有哪些出现大量的TIME_WAIT, 说明TCP连接被频繁关闭, 服务端主动断开了连接, 原因有三\n\n没有开启HTTP长连接\nHTTP长连接超时\nHTTP长连接中的请求数量超过最大值\n\n场景一 : 没有开启HTTP长连接\n客户端和服务端有任意一端发出的HTTP消息头部中的Connection: close, HTTP就不会使用长连接, 也就是每次TCP的连接都是走三次握手, 发送消息, 接收响应, 四次挥手这个流程\n无论是客户端还是服务端中的HTTP消息头部是Connection: close, 都会是服务端主动断开连接\n解决方法也很简单, 让客户端和服务端都开启长连接就行了\n场景二: HTTP连接超时\n为了防止长连接一直占用系统资源, 长连接会有超时时间, 如果长连接超过超时时间都没有发起新的请求, 定时器的时间一道, 长连接就会被关闭\n这个时候解决方法主要是排查网络问题, 看什么原因导致客户端的请求服务端一直没有收到\n场景三: HTTP长连接中的请求数量超过最大值\nWeb服务上一般会有个参数来定义一条HTTP长连接上最大能处理的连接数量, 当超过最大限制的时候, 就会主动关闭连接\n解决方法就是调高keepalive_requests参数就行\n服务器出现大量的CLOSE_WAIT状态的原因有哪些服务端出现大量CLOSE_WAIT状态的连接的时候, 说明服务端的程序没有调用close函数关闭连接\n一个普通的TCP服务端的流程\n\n创建服务端socket, bind绑定端口, listen端口\n将服务端socket注册到epoll\nepoll_wait等待连接到来, 连接到来的时候, 调用accept 从accept队列中获取已连接的socket\n将已连接的socket注册到epoll\nepoll_wait等待事件发生\n对方连接关闭的时候, 调用close\n\n原因一 : 第二步没有做, 没有将socket注册到epoll, 这样有新连接到来的时候, 服务端就没有办法感知这个事件, 也就无法获取到已经连接的socket, 那么也就没有办法对这个socket调用close了\n**原因二: ** 第三步没有做, 当新的连接到来的时候, 没有主动调用accept()获取到该连接的socket, 导致当有大量的客户端断开连接的时候, 服务端无法对该socket调用close()函数关闭连接\n**原因三: ** 第四步没有做, 通过accept获取到已经连接的socket以后, 没有注册到epoll, 导致后续收到FIN报文的时候, 没有办法感知这个事件\n**原因四: ** 在客户端关闭连接以后, 服务端因为代码逻辑问题, 没有执行close()函数\n服务端出现大量的CLOSE_WAIT状态的连接的时候, 通常都是代码出现了问题导致服务端没办法调用close, 这个时候需要顺着一个TCP服务建立的过程逐步排查\n如果已经建立了连接, 但是客户端突然出现故障了怎么办?这里的情景是客户端断开了连接, 但是同时服务端也一直不给服务端发送请求, 这个时候服务端就永远无法感知到客户端宕机这个事件, 也就是服务端的TCP会一直处于ESTABLISH状态\n为了避免这个情况, TCP有对应的保活机制\n定义一个时间段, 如果这个时间段内都没有任何连接相关的活动, TCP保活机制就会开始作用, 每隔一个时间段, 发送一个探测报文, 如果连续几个探测报文都没有得到响应, 则认为当前的TCP连接已经死亡了, 系统内科将错误信息通知给上层应用程序\nnet.ipv4.tcp_keepalive_time=7200 // 保活时间, 如果超过这个时间TCP没有任何的连接相关活动就会触发保活机制net.ipv4.tcp_keepalive_intvl=75  // 每次检测间隔75snet.ipv4.tcp_keepalive_probes=9 // 9次无响应, 认为对方是不可达的, 中断本次连接\n\n也就是在Linux系统中至少需要 7200 + 75*9 &#x3D; 7875秒 (2h11min15sec)才能发现一个死亡连接\n如果应用程序想使用TCP保活机制, 需要通过socket接口设置SO_KEEPALIVE选项才能够生效\nTCP的保活机制比较长, 我们其实也可以基于这个方式自己在Web服务中实现一个心跳机制\n如果已经建立了连接, 但是服务端的进程崩溃了会发生什么TCP的连接信息是由内核维护的, 所以当进程崩溃了以后, 内核需要回收该进程的所有TCP连接资源, 于是内核会发送第一次FIN挥手报文, 后续的挥手过程也是在内核中完成, 并不需要该进程参与\n","categories":["计算机科学","计算机网络","TCP协议"],"tags":["TCP","网络协议","八股文","面试","四次挥手","ACK","FIN","连接断开","TIME_WAIT","状态转换"]},{"url":"/2025/07/08/Computer_Science/Algorithm/bin/%E5%91%A8%E8%B5%9B/452/","content":"Q1等积子集的划分方案给你一个整数数组 nums，其中包含的正整数 互不相同 ，另给你一个整数 target。\n请判断是否可以将 nums 分成两个 非空、互不相交 的 子集 ，并且每个元素必须  恰好 属于 一个 子集，使得这两个子集中元素的乘积都等于 target。\n如果存在这样的划分，返回 true；否则，返回 false。\n子集 是数组中元素的一个选择集合。\n示例 1：\n输入： nums &#x3D; [3,1,6,8,4], target &#x3D; 24\n输出： true\n**解释：**子集 [3, 8] 和 [1, 6, 4] 的乘积均为 24。因此，输出为 true 。\n示例 2：\n输入： nums &#x3D; [2,5,3,7], target &#x3D; 15\n输出： false\n解释 无法将 nums 划分为两个非空的互不相交子集，使得它们的乘积均为 15。因此，输出为 false。\n提示：\n\n3 &lt;= nums.length &lt;= 12\n1 &lt;= target &lt;= 1015\n1 &lt;= nums[i] &lt;= 100\nnums 中的所有元素互不相同。\n\nQ2 子矩阵的最小绝对差给你一个 m x n 的整数矩阵 grid 和一个整数 k。\n对于矩阵 grid 中的每个连续的 k x k 子矩阵，计算其中任意两个 不同值 之间的 最小绝对差 。\n返回一个大小为 (m - k + 1) x (n - k + 1) 的二维数组 ans，其中 ans[i][j] 表示以 grid 中坐标 (i, j) 为左上角的子矩阵的最小绝对差。\n注意：如果子矩阵中的所有元素都相同，则答案为 0。\n子矩阵 (x1, y1, x2, y2) 是一个由选择矩阵中所有满足 x1 &lt;= x &lt;= x2 且 y1 &lt;= y &lt;= y2 的单元格 matrix[x][y] 组成的矩阵。\n示例 1：\n输入： grid &#x3D; [[1,8],[3,-2]], k &#x3D; 2\n输出： [[2]]\n解释：\n\n只有一个可能的 k x k 子矩阵：[[1, 8], [3, -2]]。\n子矩阵中的不同值为 [1, 8, 3, -2]。\n子矩阵中的最小绝对差为 |1 - 3| = 2。因此，答案为 [[2]]。\n\n示例 2：\n输入： grid &#x3D; [[3,-1]], k &#x3D; 1\n输出： [[0,0]]\n解释：\n\n每个 k x k 子矩阵中只有一个不同的元素。\n因此，答案为 [[0, 0]]。\n\n示例 3：\n输入： grid &#x3D; [[1,-2,3],[2,3,5]], k &#x3D; 2\n输出： [[1,2]]\n解释：\n\n有两个可能的 k × k 子矩阵：\n以 (0, 0) 为起点的子矩阵：[[1, -2], [2, 3]]。\n子矩阵中的不同值为 [1, -2, 2, 3]。\n子矩阵中的最小绝对差为 |1 - 2| = 1。\n\n\n以 (0, 1) 为起点的子矩阵：[[-2, 3], [3, 5]]。\n子矩阵中的不同值为 [-2, 3, 5]。\n子矩阵中的最小绝对差为 |3 - 5| = 2。\n\n\n\n\n因此，答案为 [[1, 2]]。\n\n"},{"url":"/2025/07/08/Computer_Science/Computer_network/%E8%AE%A1%E7%BD%91%E5%85%AB%E8%82%A1/2_TCP/6_TCP%E7%9A%84%E7%BC%BA%E7%82%B9/","content":"为什么要基于UDP实现可靠传输 (TCP的缺点)最大的原因就是TCP不是没有缺点的, 只是看似完美, 甚至正是TCP的缺点导致了HTTP2的瓶颈\nTCP有四大缺点\n升级TCP的工作困难TCP协议是在内核中实现的, 应用程序只能使用不能修改, 如果想升级TCP协议, 只能升级内核, 升级内核的成本是很高的(升级, 测试, 考虑兼容性….), 并且如果想使用升级的TCP协议, 需要通信双端都升级, 进一步加大了升级TCP的难度\nTCP建立连接的延迟基于TCP实现的应用层协议, 都需要经过三次握手后\n常用的HTTPS, 甚至需要在TCP三次握手以后, 还需要经过TLS四次握手, 才能进行HTTP数据的传输, 增加了数据传输的延迟\n\n最后最少需要6次握手环节才能开始HTTP数据的传输\nTCP存在队头堵塞TCP队头堵塞的原因 : TCP需要保证数据按序交付\n\n如果TCP发送端发送的某条数据丢失了, 会导致接收窗口的左边界堵塞在丢失的数据上, 不能滑动(右边界还是可以继续滑动的, 使窗口保持原有的大小或根据接收缓冲区空间调整), \n同时使序列号更高的数据接收到了, 但是因为低序列的数据没有接收到, 这些数据也不会交付给应用层, 直到丢失的数据被重传并接收\n\nHTTP&#x2F;2虽然解决的HTTP&#x2F;1.1的队头堵塞问题(如果某一条HTTP数据请求被堵塞了, 没有接收到响应, 后面的请求也只能等待), 但是因为是基于TCP实现的应用层协议, 无法解决TCP的队头堵塞问题\n网络迁移需要重新建立TCP连接因为TCP是通过四元组来确定一条TCP连接的\n如果IP地址发生了变化, 就必须要断开所有的TCP连接, 然后重新建立TCP连接\n"},{"url":"/2025/07/08/Computer_Science/Computer_network/%E8%AE%A1%E7%BD%91%E5%85%AB%E8%82%A1/2_TCP/5_Socket/","content":"Socket编程针对TCP如何进行socket编程\n\n服务端和客户端初始化socket, 得到文件描述符\n服务端调用bind将socket绑定监听IP和端口, 调用listen监听该端口\n服务端调用accept等待客户端连接\n客户端调用connect, 向服务端的地址和端口发起连接请求\n服务端accept返回用于传输的socket的文件描述符\n客户端调用write写入数据, 服务端调用read读取数据\n客户端断开连接, 调用close, 服务端read数据的时候, 就会读取到EOF, 处理完数据以后, 服务端就会调用close\n\n服务端调用accept时, 返回的时一个已经完成连接的socket, 后续用来传输数据\n所以用于监听端口的socket和真正用来传输数据的socket是两个socket, 一个叫做监听socket, 一个叫做已完成连接socket\nlisten的时候参数backlog参数的意义int listen(int socketfd, int backlog)\n\n在早期的linux内核中, backlog是SYN队列的大小\n在Linux内核2.2以后, backlog变成accept队列, 也就是已经完成连接的队列长度\n但是上限值是由内核参数somaxconn的大小决定, 也就是accept &#x3D; min(somaxconn, backlog)\naccept发生在三次握手的哪一步\naccept发生在三次握手的第三次握手成功之后, 会成功返回, connect会在第二次握手成功以后成功返回\n客户端调用close了, 连接是断开的流程是什么\n客户端调用close, 表示没有要发送的数据了, 这个时候客户端发送FIN报文给服务端\n服务端接收到了这个FIN报文, TCP协议栈会为这个报文插入一个文件描述符EOF到接收缓冲区, 应用程序可以调用read来感知到这个FIN包, 这个EOF会被放在已经排队等候的其他已经接收的数据之后, 服务端需要处理这种额外的异常情况, 因为EOF表示之后不会再接收任何数据了, 服务端进入到CLOSE_WAIT状态\n当处理完数据以后接收到EOF就会调用close关闭socket, 这会使服务端发送一个FIN报文给客户端, 然后进入到LAST_ACK状态\n然后就是第四次握手\n\n没有accept, 能建立TCP连接吗可以建立, accept系统调用不参与TCP的三次握手过程, 只是负责从TCP全连接队列中取出来一个已经建立好连接的socket, 用户层能通过这个socket来进行读写操作\n没有listen也能建立TCP连接TCP连接可以是自己连自己的自连接, 也可以是两个客户端同时向对方发出请求, 没有服务端\n"},{"url":"/2025/07/08/Computer_Science/Computer_network/%E8%AE%A1%E7%BD%91%E5%85%AB%E8%82%A1/2_TCP/4_UDP_QUIC/","content":"如何基于UDP实现可靠传输为什么需要基于UDP实现的可靠传输(在我们使用TCP能保证可靠传输的前提下)TCP有四大缺点\n\nTCP的升级很困难\nTCP存在队头堵塞\nTCP建立连接的延迟\n网络迁移需要重建TCP连接\n\nQUIC协议的实现, 也是主要聚焦于解决这些问题\nQUIC是怎么实现可靠传输的拿HTTP3举例说明, 在UDP报文和HTTP消息之间, 有三层协议\n\n\nPacket Header\nQUIC Frame Header\nHTTP3 Frame Header\n\nPacket HeaderPacket Header细分成两种\n\nLong Packet Header 用于首次建立连接\n源连接ID长度, 源连接ID\n目标连接ID长度, 目标连接ID\n\n\nShort Packet Header 用于日常传输数据\n目标连接ID\n编号 Packet Number\n负载数据\n\n\n\nPacket Number是每个报文独一无二的编号, 是严格递增的, 也就是如果Packet N丢失了, 重传的Packet N的Packet Number也不是N了, 而是一个比N大的值\n这样设计的原因, 主要是为了解决TCP协议中, 发生超时重传以后, 客户端无法判断出来是原始报文的响应还是重传报文的响应, 会导致RTT的计算不准(解决方案是忽略被重传过的报文的RTT值)\n同时还能使QUIC支持乱序确认\n所以Packet Number严格递增的好处有\n\n可以更加精确计算出来RTT, 没有TCP重传的歧义性\n可以支持乱序确认\n\n\n\n\n 维护连接状态的意义, 为什么要维护连接, 明明四元组不是已经能唯一确定传输的对象\n\n面向连接可以理解为, 这个协议是会维护连接双方的一些状态信息的, 比如序列号, 窗口大小等, TCP正是通过面向连接, 才实现了可靠的保序的传输, 像HTTP就不是一个面向连接的协议, 因为它一个无状态的协议\n而对于QUIC, 双端通过目标连接的ID来唯一映射到一条连接上\n通过这个连接状态, QUIC实现了\n\n真正的连接迁移, 因为连接的映射不再依赖于四元组, 而是依赖于更加抽象的目标连接ID, 每一个UDP数据段都能通过目标连接ID来找到自己的连接\n状态恢复与0-RTT重连, 会在更快的连接建立说明\n\n\n使用QUIC协议通信的双方是怎么协商出目标连接ID的\n\n在初始建立连接的阶段, 发起方会随机生成一个连接ID(源连接ID, Source Connection ID SCID), 并且会在发送初始包的时候携带这个ID\n被动方接收到这个初始包以后, 也会生成自己的SCID, 并且在回复客户端的时候附带这个ID, 被动方将发起方的SCID作为自己的目标连接ID(Destination Connection ID DCID)放入到回复包中\n最后发起方接收到回复包以后, 就会将被动方的SCID当作自己的DCID\n接下来两者之间的通信就只会有DCID, 用于确认这条消息属于哪个连接\nQUIC Frame Header一个Packer 报文里面可以有多个QUIC Frame报文\n\nFrame有很多种, 这里讨论Stream类型的Frame格式\n\nStream ID : 多个并发传输的HTTP消息, 通过Stream ID加以区别, 和HTTP&#x2F;2的Stream ID类似\nOffset : 类似于TCP协议中的Seq序号, 保证数据的顺序性和可靠性\nLength : 指明了Frame数据的长度\n负载数据\n\n如果数据包 Packet N丢失了, 那么我们是怎么确认重传的Packet N+M是同一个数据包呢\n通过Stream ID + offset, 如果两个数据包的Stream ID + offset都是一致的, 说明就是同一个数据包\nQUIC通过单向递增的Packet Number配合Stream ID 和offset字段信息, 可以支持乱序确认而不影响数据包的正确组装\nQUIC的乱序确认首先我们得看到TCP的累计确认机制\n\n只确认连续序列, 发送方收到ACK 3, 说明接收方收到了1, 2, 3但是不能说明没有收到4,5,…\n缓存失序数据\n确认号表示期望, 表示的是期望收到的下一个TCP段的序列号\n\nQUIC支持乱序确认\n发送方按序发送(按offset的顺序发送)发送窗口中的缓冲区中的30~36数据包(这里的数字是Packet Number)\n31, 32数据包首先被确认(QUIC支持乱序确认, 不需要等待Packet 30被确认)\n在30被接收到以后, 缓冲区收缩为33 ~ 36, 这个时候缓冲区收缩到了阈值, 接收方发送MAX_STREAM_DATA Frame (协商缓存大小的特定帧), 请求增大最大绝对字节偏移量(就是缓冲区最右边的offset, 其实就是在请求发送缓冲区的右边界向右滑动)\n发送缓冲区的右边界向右滑动\n将超时的Packet 33重新变成Packet 42重新发送\n\n为什么能通过Packet Number配合Stream ID和offset来支持乱序确认, 但是TCP却不行呢\n\n\nPacket Number是连接级别的序列号空间(位于传输层, 用于标识每个UDP数据包), offset是Stream级别的序列号空间\n\nQUIC协议通过ACK帧来选择性确认Packet Number, 如果重传了以后出现了重复(通过Stream ID  + offset判断, 会直接丢弃就行)\n\n举例说明一个ACK帧：\n\n最大确认号：100 (已经收到的最大包序号)\n第一个ACK范围：30（表示包70-100已收到）\n间隙1: 10 (与前一个范围间隔10个)\nACK范围1：15（表示包45-59已收到）\n间隙2: 5 (与前一个范围间隔5个)\nACK范围2：10（表示包30-39已收到）\n\n这表示接收方已收到的包序号为：30-39、45-59和70-100，而40-44、60-69的包尚未收到。\n\n\n\n通过选择性确认实现了对于UDP包的乱序确认以及可靠传输\n\n通过StreamID + offset实现了数据包的正确组装\n\n\nQUIC是如何解决TCP队头堵塞的问题的?什么是TCP的队头堵塞问题发送窗口只有窗口中的已发送未收到ACK确认的数据被确认了, 窗口的左边界才会向右滑动, 但是如果其中有一个数据丢失了, 左边界就会阻塞在丢失的数据上, 因为它一直得不到确认\n接收窗口中某个低序号的数据丢失了, 即使高序号的数据接收到了, 窗口的左边界也会被这个丢失的数据阻塞住, 同时也不会将数据交付给应用层, 缓冲区就会被一直占用着\nHTTP&#x2F;2的队头阻塞HTTP&#x2F;2抽象出来了Stream概念, 实现了HTTP的并发传输, 一个Stream就代表HTTP&#x2F;1.1中的一个请求和响应(在HTTP&#x2F;1.1中, 如果有一个HTTP请求阻塞了, 因为HTTP的请求-响应模型, 会导致所有的HTTP请求都被阻塞住)\n在HTTP&#x2F;2中, 不同Stream的帧是可以乱序发送的, 每个帧的头部都会携带Stream ID信息, 但是一个Stream内部的帧必须是严格有序的\n但是HTTP&#x2F;2还是在传输层的TCP协议上实现的应用层协议, 虽然在应用层上解决了不同HTTP请求之间的队头堵塞问题, 但是受限于TCP的队头堵塞问题\n如果有一个Stream中的一个数据丢失了, 会阻塞所有的Stream\n没有队头堵塞的QUICQUIC为每个Stream都分配了一个独立的滑动窗口, 完全解决了队头堵塞问题\n如果Stream 2丢失了一个数据包, 也只会影响Stream 2\nQUIC是怎么做流量控制的TCP的流量控制是让接收方告诉发送方, 自己的接收窗口有多大, 从而让发送方根据接收方的实际接收能力控制发送的数量\nQUIC实现流量控制的方式\n\n通过window_update帧告诉对方自己可以接收的字节数, 这样发送方就不会发送超过这个字节数的数据\n通过BlockFrame告诉对端由于流量控制被阻塞了, 无法发送数据\n\nStream级别的流量控制QUIC的接收窗口的左边界滑动条件取决于接收到的最大偏移字节数\n接收窗口 = 最大窗口数 - 接收到的最大偏移数\n右边界的滑动条件是接受窗口内的已收到并被上层读取的数据超过接收窗口的一半(应用层读取的数据一定是保序的,  所以这部分数据一定是连续的都收到了的)\n如果中途丢失了数据包, 会导致已收到并被上层读取到的数据没有超过接收窗口的一半, 最终右边界无法滑动, 造成阻塞\nConnection级的流量控制整个Connection的可用窗口 &#x3D; 所有Stream的可用窗口大小之和\nQUIC对拥塞控制的改进简单来说就是, QUIC支持很多的拥塞控制算法, 同时因为它更新很方便, 能有比较快的迭代速度迭代拥塞控制算法\n甚至可以根据不同应用设置不同的拥塞控制算法\nQUIC更快的连接建立对于HTTP&#x2F;1.1或者HTTP&#x2F;2, TCP和TLS是分层的, 分别属于内核的传输层和openssl库实现的表示层, 因此很难被合并在一起, 需要分批次来握手, 先TCP握手(1RTT), 再TLS握手(2RTT), 所以需要3RTT的延迟才能传输数据, 就算Session会话复用, 也需要至少2RTT\n但是在HTTP&#x2F;3的QUIC协议并不是与TLS分层,而是在QUIC内部包含了TLS, 在自己的帧中携带TLS里的记录, 再加上QUIC使用的是TLS1.3, 仅需要1个RTT就能同时建立连接和密钥协商, 在第二次连接的时候, 应用数据包可以和QUIC握手信息(连接信息 + TLS信息)一起发送, 达到0-RTT的效果\n\nQUIC迁移连接QUIC协议中的连接不依赖于四元组来确认, 而是依赖于连接ID这个再度抽象了一层的状态来确认连接, 所以在IP切换了以后, 只要仍然有连接ID, TLS密钥等, 依然可以无缝复用原连接, 连接随便迁移\n"},{"title":"HTTP协议常见面试题汇总 - 状态码与请求响应详解","url":"/2025/07/08/Computer_Science/Computer_network/%E8%AE%A1%E7%BD%91%E5%85%AB%E8%82%A1/1_HTTP/HTTP%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/","content":"HTTP常见面试题目HTTP基本概念HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。\nHTTP常见的状态码有哪些1xx类状态码属于提示信息, 基本遇不到\n2xx类状态码表示服务器成功处理了客户端的请求\n\n[200 OK] 是最常见的成功状态码, 表示一切正常, 非HEAD请求, 服务器返回的响应头都会有body数据\n[204 No Content] 也是最常见的状态码, 和200 OK的区别是响应头没有数据\n[206 Partial Content] 应用于HTTP分块下载或断点续传, 表示响应返回的body不是资源的全部, 而是其中的一部分\n\n3xx类状态码表示客户端请求的资源发生了变动, 需要客户端重定向\n\n[301 Moved Permanently] 永久重定向, 请求的资源已经不存在, 浏览器会自动重定向到新的服务器\n[302 Found] 临时重定向, 请求的资源还在, 但是需要用另一个URL来 访问\n\n301和302都会在响应头里面使用字段Location来指明接下来要跳转到的URL地址\n\n[304 Not Modified] 不具有跳转的含义, 表示资源未修改, 重定向已存在的缓存文件, 告诉客户端继续使用缓存文件, 用于缓存控制\n\n4xx类状态码表示客户端发送的报文有误, 服务器无法处理\n\n[400 Bad Request] 请求报文有问题\n[403 Forbidden] 客户端访问禁止访问的资源\n[404 Not Found] 请求的资源不在服务器上\n\n5xx类状态码表示请求报文正确, 但是服务器内部处理错误, 是服务器的错误码\n\n[500 Internal Server Error] 和400一样是个通用笼统的错误码\n[501 Not Implemented] 客户端请求的功能还不支持\n[502 Bad Gateway] 是服务器作为网关或者代理的时候返回的错误码,  访问后端服务的时候出错\n[503 Service Unavailable] 服务器当前很忙, 暂时无法响应客户端\n\nHTTP常见字段有哪些\nHost :  Host: www.A.com 指定访问的域名\n\nContent-Length : Content-Length: 1000 本次回应的长度, 因为使用TCP作为传输协议, 会有粘包的问题, HTTP协议通过设置回车符, 换行符作为HTTP header的边界, 通过Content-Length来作为HTTP body的边界\n\nConnection : Connection : Keep-Alive 客户端要求服务器使用HTTP长连接机制, 以便其他请求复用, 连接会一直持续到客户端或服务器提出断开连接\n\nContent-Type : Content-Type: text/html; Charset=utf-8 用于服务器回应时, 告诉客户端本次数据的格式\n\nAccept :Accept: */* 客户端请求的时候, 可以通过Accept字段声明自己可以接受的数据格式\n\n\nContent-Encoding : Content-Encoding: gzip 说明数据压缩的发放, 表示服务器返回的数据采用了什么压缩格式\n\nAccept-Encoding : Accept-Encoding: gzip, deflate, 客户端请求的时候, 用这个字段说明自己可以接受哪些压缩方法\n\n\n\nGET和POSTGET和POST有什么区别根据RFC规范\n\nGET的语义是从服务器获取指定的资源, \tGET请求的参数一般是放在URL中的, URL必须以ASCII编码, 所以GET请求的参数只有ASCII字符, 同时浏览器会对URL的长度做出限制\nPOST的语义是根据请求负荷对指定的资源做出处理, 浏览器不会对请求体做出限制\n\nGET和POST方法都是安全且幂等的吗在RFC规范语义下, 显而易见的是GET是安全且幂等的,  因为GET请求是只读操作. 所以可以对GET请求的数据做出缓存, 缓存可以放在浏览器上, 也可以放在代理上. 同时在浏览器中GET请求可以保存为书签\n但是实际开发过程中, 并不一定会遵守RFC规范, 如果GET方法执行了写操作, 就不会是安全且幂等的\nHTTP缓存强制缓存浏览器将数据缓存在本地, 强制缓存是由浏览器来决定是否使用缓存\n通过以下两个HTTP响应头部的字段实现\n\nCache-Control : 相对过期时间\nExpires : 绝对过期时间\n\nCache-Control的优先级高于Expires\n\n当服务器第一次请求资源的时候, 服务器会在返回资源的时候同时在响应头部中Cache-Control字段中说明资源的相对过期时间\n浏览器再次请求相同的数据的时候, 就会先将请求资源的时间和Cache-Control中设置的相对过期时间大小来计算出来资源是否过期\n过期了重新请求服务器, 并再次更新Cache-Control\n没有过期则直接使用缓存中的数据\n\n\n\n协商缓存协商缓存就是在强制缓存失败了以后, 和服务器协商是不是真的要不使用缓存, 也就是协商缓存一定要先开启强制缓存, 只有在未命中强制缓存的时候, 才会走协商缓存\n通过两种头部字段来实现\n第一种: 请求头中的If-Modified-Since字段和响应头中的Last-Modified字段实现\n\n响应头中的Last-Modified : 这个响应资源的最后修改时间\n请求头中的If-Modified-Since : 强制缓存过期了以后发现当时的响应头中有Last-Modified声明, 则再次发起请求的时候会携带上If-Modified-Since(这个时候的值就是响应头中的Last-Modified中的值)\n如果最后修改时间大于If-Modified-Since中的值, 说明缓存中资源已经被修改过了, 这个时候就会返回资源, 状态码200 OK\n如果最后修改时间小于等于 If-Modified-Since中的值, 说明缓存中值没有被修改过, 就能继续使用, 返回304 Not Modified, 继续使用缓存中的资源\n\n\n\n第二种: 请求头中的If-None-Match和响应头中的ETag字段\n\n响应头中的ETag: 唯一标识响应资源\n请求头中的If-None-Match: 当资源过期的时候, 浏览器发现当时的响应头中有ETag字段, 就会在If-None-Match子段中携带上当时ETag中的值, 向服务器发起请求, 服务器收到了以后进行比对\n如果相同, 说明资源没有被修改过, 返回304\n如果不同, 返回资源, 200\n\n\n\nETag的优先级高于Last-Modified, 如果服务端返回的响应头部中两个字段都有, 在下次过期的时候, 会优先比对ETag, 如果ETag已经有变化了, 就不会比对Last-Modified了\n\n为什么ETag的优先级更高?\n\n\n没有修改文件内容的前提下, 文件最后修改时间也可能会变(比如修改了文件的权限等)\n有些文件的修改是在秒级以内的, Last-Modified的粒度是秒级的\n有些服务器无法精确获取到文件的最后修改时间\n\nHTTP特性HTTP&#x2F;1.1的缺点在哪里\n无状态 : 常见的解决方法有Cookie技术, Cookie通过在请求和响应报文中写入Cookie信息来控制客户端的状态\n明文传输 : 信息裸奔\n不安全 : \n通信使用明文\n不验证通信方的身份\n无法证明报文的完整性\n\n\n\nHTTP&#x2F;1.1的性能如何从HTTP&#x2F;1.1是基于TCP&#x2F;IP, 并且使用了 [请求-应答] 的通信模式出发\n\n长连接 : 能够复用TCP连接\n\n管道网络传输 : 流水线式发送请求, 发送了第一个请求以后, 不需要等待第一个请求的响应, 可以直接发送第二个请求, 服务器必须按照接收请求的顺序发送对这些管道化请求的响应, 管道解决了请求的队头堵塞, 但是没有解决响应的队头堵塞\n\n队头堵塞 : 请求-应答的通信模式中, 如果某一个请求因为某种原因被阻塞了, 一直没有收到回应, 就会一直阻塞下去, 这个时候后面排队的请求也都一同被阻塞了\n\n\nHTTP&#x2F;2对比HTTP&#x2F;1.1做了哪些改进\n头部压缩\n二进制格式\n并发传输\n服务器主动推送资源\n\n1. 头部压缩HTTP&#x2F;2 会压缩头, 如果你同时发出多个请求, 头部是相似的或者一样的, 协议会帮你消除重复的头部\n使用的HPACK算法 : 客户端和服务器同时维护一张头信息表, 所有的字段都会存入到这张表中, 生成一个索引号, 只发送索引号就行了\n静态表：想象这是一本字典，里面预先定义了最常用的 HTTP 头部字段。比如 “method: GET” 可能是字典中的第 2 号词条。这样，当我们需要发送 “method: GET” 时，只需发送数字 2 即可，接收方查字典就知道是什么意思了。动态表：这是一个在通信过程中不断更新的字典。如果发送了一个新的头部字段，它会被添加到动态表中。下次再发送相同的头部时，只需引用它在表中的索引即可。霍夫曼编码：对于无法通过表查找的值，HPACK 使用霍夫曼编码进一步压缩。霍夫曼编码是一种根据字符出现频率分配短代码的方法，常用字符获得短编码，不常用字符获得长编码。\n举个例子假设我们要发送这样的 HTTP 头部：:method: GET:path: &#x2F;index.htmluser-agent: Mozilla&#x2F;5.0cookie: session&#x3D;abc123第一次发送时，HPACK 会：\n:method: GET 在静态表中找到，发送索引号:path: &#x2F;index.html 的键在静态表中找到，但值需要霍夫曼编码发送user-agent: Mozilla&#x2F;5.0 的键在静态表中找到，值用霍夫曼编码发送，然后添加到动态表cookie: session&#x3D;abc123 也类似处理，添加到动态表\n第二次发送类似的请求时，可能就能直接通过静态表和动态表的索引号引用大部分头部字段，大大减少传输数据量。\n2. 二进制格式传输的内容直接变成了二进制, 这样接收端就不需要再转化了\n3. 并发传输将一个TCP连接进一步细化, 分成多个STREAM, 内部以frame作为STREAM中传输的最小单位, 以二进制压缩格式存放HTTP&#x2F;1中的内容\n不同的HTTP请求用独一无二的STREAM ID来区分, 接收端可以根据Stream ID有序组装成HTTP消息, 不同Stream的帧是可以乱序发送的\n假设我们现在有两个HTTP请求, 在原本的模型, 我们只能发送请求A, 等待请求A响应, 发送请求B, 等待請求B响应\n但是有了Stream机制以后, 我們能將請求A分配給Stream1, 請求B分配給Stream3, 兩個請求同時發送\n然後接收端將ID都是1的frame組裝成一個完整的請求, 將ID都是3的組裝成另一個\n4. 服务器推送在HTTP&#x2F;2中, 服务端也能主动向客户端发送消息\n服务端和接收端能双向建立Stream通道, 然后相互发消息, 服务端建立的Stream必须是偶数号, 服务端建立的Stream必须是偶数号\nHTTP&#x2F;2还是因为TCP的必须保证收到的字节数据是完整且连续的, 所有还是有队头堵塞, 会因为TCP中的某个包而堵塞住\n如何优化HTTP&#x2F;1.1从三点出发\n\n尽量避免发送HTTP请求\n使用缓存, 浏览器中的缓存是将第一次请求以及响应的数据保存在磁盘上, URL作为Key, 响应作为Value\n缓存有强制缓存和协商缓存\n\n\n减少HTTP请求的次数\n减少重定向请求的次数\n重定向的工作交给代理服务器完成\n原本是客户端 -&gt; 代理服务器 -&gt; 源服务器 : 302 Found, Location: url2, 然后在重新客户端 -&gt; 代理服务器 -&gt; 源服务器不过url是url2\n将重定向的工作交给代理服务器以后, 客户端 -&gt; 代理服务器 -&gt; 源服务器 : 302 Found, Location: url2, 代理 服务器 -&gt; 源服务器 url是url2, 访问到资源以后, 响应客户端-&gt;代理服务器的请求, 将资源返回, 减少了消息传递的次数\n\n\n合并请求\n将多个访问小文件的请求合并成一个大的请求, 减少了请求的次数, 减少了重复发送的HTTP头部\n另外由于HTTP&#x2F;1.1是请求响应模型 , 为了防止队头堵塞, 浏览器发送请求一般都是同时发送5-6个请求, 走不同的TCP连接, 合并了请求也能减少TCP握手和慢启动的时间\n合并请求的方式就是合并资源, 以一个大的资源的请求替换多个小的资源的请求. 但是也会带来在请求失败或者资源需要更新的时候, 客户端需要重新下载整个大的资源\n\n\n按需获取\n需要用到的时候才去尝试获取资源, 来减少第一时间发送的HTTP请求\n\n\n\n\n减少HTTP 响应的数据大小\n无损压缩 : gzip, Brotli等, 一般用于发送文本文件, 程序可执行文件等不能有损的文件内容\n有损压缩 : WebP(图片), H264, H265等, 一般用于音视频和图片内容\n\n\n\nHTTP和HTTPSHTTP和HTTPS简单的区别\nHTTP是明文传输, HTTPS在TCP和HTTP网络层之间加入了SSL&#x2F;TLS安全协议, 使得报文能够密文传输\nHTTPS建立连接的过程除了TCP的三次握手, 还需要SSL&#x2F;TLS的握手过程, 才能进行密文的传输\nHTTP的默认端口是80, HTTPS的默认端口是443\nHTTPS需要向CA申请数字证书\n\nHTTPS解决了HTTP的哪些问题\n窃听风险 : 可以从通信链路上获取通信数据\n篡改风险 : 强制植入广告等, 能修改HTTP传输的数据\n冒充风险 : 冒充淘宝网站等\n\n解决方案 : SSL&#x2F;TLS协议\n\n信息加密 : 不再是明文传输\n校验机制 : 校验通信的内容, 防止篡改通信的内容\n身份验证 : 验证网站是真的网站\n\n怎么实现的这三点 ?\n\n混合加密的方式实现信息的加密\n摘要算法实现了完整性, 会为数据生成数据指纹\n将服务器公钥放入到数字证书中, 解决了冒充的风险\n\n1. 混合加密对称加密 : 双方使用相同的密钥进行加密解密, 加密解密速度快\n非对称加密 : 使用一队密钥(公钥和私钥), 一个用于加密数据, 一个用于解密数据, 安全性更好, 但是速度更慢\nHTTPS采用混合加密\n\n通信建立前采用非对称加密的方式交换会话密钥, 后续不再使用非对称加密\n通信过程中全部使用对称加密的会话密钥加密明文数据\n\n2. 摘要算法 + 数字签名为了保证数据不被篡改, 计算机会为传输的内容通过摘要算法来计算内容的哈希值\n通过哈希算法能保证内容不会被篡改, 但是没办法保证[内容 + 哈希值]不会收到篡改, 缺少对客户端收到的消息来源于服务端的证明\n通过非对称加密算法来解决这个问题\n在非对称加密算法里面\n\n公钥加密, 私钥解密 : 保证消息传输安全, 公钥加密的内容别人是无法解密的, 只有私钥的持有者能够解密\n私钥加密, 公钥解密 : 保证消息不会被冒充, 如果这个内容公钥能够解密, 说明就是私钥持有者发送过来的\n\nHTTPS通过私钥加密, 公钥解密来确认消息的身份, 也就是数字签名算法, 对内容的哈希值加密\n3. 数字证书\n使用摘要算法保证消息不会被篡改\n使用数字签名算法保证消息来源的可靠性\n\n但是如果我们伪造一对公私钥, 将客户端的公钥替换成自己伪造的公钥, 这样就能使用自己的私钥发送消息了\n解决办法是引入权威机构来保证公钥的正确性\n\n服务器将自己的公钥注册到CA\nCA用自己的私钥将服务器的公钥数字签名(加密)并颁发数字证书(信息 + 公钥 + 数字签名)\n客户端拿到服务器的数字证书以后, 使用CA的公钥确认服务器的数字证书的真实性\n之后, 从数字证书获取服务器公钥以后, 使用它对报文加密发送\n\n能够信任证书的原因在于**我们能够确信, 能够通过浏览器或者操作系统内置的, 可信的CA公钥揭秘出来的签名只能是由CA私钥加密的, 并且CA公钥无法被未经授权的方式替换或伪造 **\nHTTPS是如何建立连接的? 其间交互了什么SSL&#x2F;TLS协议的基本流程是\n\n客户端向服务器索要并验证服务器的公钥\n双方协商生产 [会话密钥]\n双方使用会话密钥进行加密通讯\n\nTLS的握手阶段设计四次通信, 不同的密钥交换算法握手的流程是不一样的, 常用的有RSA算法和ECDHE算法, 后面讲解的是RSA算法\nTLS协议建立的详细过程\n1.ClientHello\n客户端向服务端发起加密通信请求, 主要发送了以下的信息\n\n客户端支持的TLS版本\n客户端生成的随机数(Client Random), 是后面用于生成会话密钥的条件之一\n客户端支持的密码套件列表, 比如RSA加密算法\n\n2. ServerHello\n服务端响应客户端的加密通信请求\n\n确认TLS的版本, 如果客户端支持的TLS版本服务端都不支持, 就会关闭加密通信\n服务端生成的随机数(Server Random), 也是后面生产会话密钥的条件之一\n确认密钥套件\n服务器的数字证书\n\n3. 客户端回应\n客户端收到服务器的回应以后\n首先, 通过浏览器或者操作系统中的CA公钥对数字证书解密获取其中服务器的公钥, 使用服务器的公钥加密报文, 加密的内容如下\n\n一个随机数(pre-master key), 是后面生产会话密钥的条件之一\n加密通信算法改变通知, 表示随后的信息都将会使用会话密钥加密通信\n客户端握手结束通知, 这一项同时把之前所有内容发送的数据做了摘要供服务端校验\n\n客户端和服务端在客户端回应以后都拥有了三个相同的随机数(ClientRandom, ServerRandom, pre-master key), 通过这三个随机数和两边协商出来的密钥套件, 各自计算出来这次通信的会话密钥\n4.服务端回应\n服务端计算出来这次通信的会话密钥以后, 随后向服务端发送最后的信息\n\n加密算法改变通知, 表示随后的信息都将会使用会话密钥加密通信\n服务端握手结束通知, 表示服务端的握手阶段已经结束了, 这一项同时把之前所有内容发送的数据都做了摘要供客户端校验\n\n这样以后, TLS握手阶段技术, 这之后就是正常的HTTP通信, 只不过内容是使用会话密钥加密以后的内容\n\nRSA算法的缺陷\n\n基于RSA算法的HTTPS有前向安全的问题, 如果服务端的私钥泄露了, 过去被第三方截获的所有的TLS通讯密文都会被破解\n\n客户端校验数字证书的流程是怎么样的\n\n\nCA签发证书的过程可以分成以下的步骤\n\n将持有者的公钥, 用途, 颁发者, 有效时间信息等打包成一个包, 然后通过hash算法生成一个hash value\n再通过CA私钥对hash Value进行加密, 生成Certificate Signature\n然后将hash值和前面的信息包组成一个数字证书\n\n客户端校验的过程如下\n\n通过浏览器或者操作系统内置的CA公钥, 解密Certificate Signature, 得到H1\n然后通过和CA相同的Hash算法计算上面的信息包, 得到H2\n将H1和H2比对, 如果相同, 说明是可信赖的证书\n\nHTTPS的应用数据是怎么保证完整性的TLS在实现上分成了握手协议和记录协议两部分\n\n握手协议就是四次握手怎么双方验证身份, 生成会话密钥的过程\n记录协议就是怎么使用会话密钥加密HTTP的内容的过程\n\nTLS记录协议主要负责消息的压缩, 加密, 数据的认证\n\n具体的过程如下\n\n将消息分割成多个较短的片段, 然后对每个片段进行压缩\n对每个压缩过的片段加上Hash算法计算出来的消息认证码(MAC值), 以此保证消息不会被篡改. 同时为了防止重放攻击, 还在计算消息认证码的时候, 加上了片段的编码(一个独特的编号, 防止攻击者发送之前已经发送过的旧的数据包, 来重复操作)\n然后将压缩过的片段加上消息认证码一起使用对称密码加密\n为加密后的数据添加上数据类型, 版本号, 压缩后的长度组成的报文就是最终的报文数据\n\n有了HTTP为什么还要有RPC应该是有了RPC为什么还要有HTTPRPC(Remote Procedure Call), 远程过程调用, 可以理解为一种对于能直接调用远程的方法的一种调用方式, 可以说是指的一类协议 : 让我们能够像调用本地方法一样调用远端服务器暴露出来的一个方法, 同时屏蔽掉一些网络的细节\nRPC早于HTTP, 早年的时候各个公司自己的客户端和服务端之间通信使用的都是自己造的RPC协议, 但是到了后面,  出现了浏览器, 不光要能访问自家的服务器还要能访问其他公司的服务器, 这个时候就需要一个统一的协议, 就是HTTP\nHTTP和RPC有什么区别服务发现发现服务对应的IP:port就是服务发现\n在HTTP中往往是知道域名, 由DNS解析得到后面的IP地址, 默认80端口\nRPC一般有专门的中间服务来保存服务名和IP信息, 像Consul, Etcd, Redis\n底层连接形式RPC能多个连接池, 维护多个长TCP连接, 就和数据库的连接池一样, 减少建立连接和销毁连接的开销\n传输的内容基于TCP传输的消息, 都是由消息头和消息体两部分组成\n\n消息头中最重要的是长度信息\nBody中存储的内容可以二进制, 数字等都可以\n\n这里也是最大的区别, HTTP中有很多是针对于浏览器设置的内容, 比如302状态码等内容, 但是RPC不用, RPC定制化成都更高, 能够使用体积更小的Protobuf或其他序列化协议去保存结构体数据\n既然有了HTTP协议, 为什么还要有WebSocket?WebSocket是为了解决服务器主动向客户端发送信息这个通信场景\n使用HTTP协议怎么实现服务器主动向客户端发送消息定时轮询客户端每隔一段时间就向服务端发送请求, 看服务端是不是想发送信息给客户端了\n这样的实现其实是伪服务器发送信息给客户端\n这个实现的缺点\n\n服务器想发送数据给客户端有延时, 最极端的情况, 需要等待完整的一个时间间隔才能将数据发送到客户端\n频繁的空请求加重服务器的负担\n\n长轮询HTTP请求是[请求-应答]模式, 在这种模式下, 请求方会阻塞等待响应方给出响应, 我们通过这个模式就能实现一有消息就通知给客户端, 我们设置很长的响应时间, 如果超时了就重新发送请求.\n在等待响应的过程中, 一有消息, 就能成功接受到, 但是这个也就只能适用于扫码等简单的交互场景, 如果有大量的数据需要从服务端主动推送给客户端, 那么就需要使用WebSocket\nWebSocketTCP连接的双端, 同一时间内, 其实双方都能相互主动发送消息, 这就是全双工\n而HTTP&#x2F;1.1, 同一时间内, 只能有一方能主动发送消息, 这就是半双工\n怎么建立WebSocket连接WebSocket使用HTTP协议通讯来进行握手, 协议升级\n在TCP连接建立以后, 通过使用HTTP协议进行通信\n\n如果是普通的HTTP请求, 就老样子\n如果是想建立WebSocket连接, 就会在请求头部中带上些特殊的头\n\nConnection: UpgradeUpgrade: WebSocketSec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\\r\\n\n\n语义是 : 浏览器想升级协议, 升级的协议是WebSocket, 同时带上一段随机生成的Base64编码发送给服务器\n服务器接受到以后, 如果支持这个升级, 就会走WebSocket的握手流程, 根据传来的Base64编码通过某个公开的算法进行变换放在Sec-WebSocket-Accept里面穿回去\nHTTP/1.1 101 Switching Protocols\\r\\nSec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\\r\\nUpgrade: WebSocket\\r\\nConnection: Upgrade\\r\\n\n\n浏览器同样使用某个公开的算法将Base64字符串转化成另一个字符串, 然后进行比较, 如果相同, 握手成功\n之后就使用WebSocket格式来传递数据\nWebSocket格式数据包在WebSocket中被叫做帧\n\n主要关注opcode和Payload两个字段\nopcode 字段 : 用来标识数据的类型\n\n等于1 : text(String)类型\n等于2 : 二进制数据([]byte)\n等于8 : 关闭连接的信号\n\npayload : 存放我们真正传递的数据长度, 单位是字节\n存放长度的字段可以有7bit, 16bit, 64bit长\n通过前面的7bit识别\n\n如果开始的7bit的值是0~125, 那这7bit就代表了payload的值\n如果开始的7bit的值是126, 说明还需要向后读16bit, 后面的16bit才是真正的长度值\n如果开始的7bit的值是127, 说明还需要向后读64bit, 后面的64bit才是真正的长度值\n\npayload字段 : 存放的是传输的数据\n","categories":["计算机科学","计算机网络","HTTP协议"],"tags":["网络协议","八股文","面试","HTTP","状态码","GET","POST","HTTPS","HTTP缓存"]},{"url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/0_MySQL%E4%BC%98%E5%8C%96/","content":"MySQL优化1. MySQL分页优化MySQL是怎么完成一次分页查询的, 性能问题在哪里有两种分页查询语句\nselect * from t_user order by id limit offset, size\n\nselect * from t_user order by id limit size\n\n第二种查询语句, 其实相当于offset &#x3D;&#x3D; 0的情况\n每次执行分页查询的时候, 引擎层首先根据where条件筛选出来符合条件的所有记录, 然后对这些已经筛选的记录order by, 最后应用LIMIT, 从已经筛选出来和排序的结果中取出来指定的offset到offset + size范围的记录\n\n性能问题出在哪里\n\n这里的问题就是, 我们不管size是多少, 我们都需要额外取出来offset条冗余的数据, 这就造成了当offset越来越来的时候, 执行分页查询的开销就越大, 也造成了 limit 1000, 10的开销比limit 100, 10的开销更大\n从where筛选 -&gt; order by 排序 -&gt; limit分页, 其中需要做对前面的offset条数据大量的行扫描和排序再跳过offset条数据\n怎么优化基于主键索引的limit执行优化也就是我们order by的是主键索引\nselect * from t_user order by id limit offset, size\n\n这里其实有两方面的冗余\n\n查出来了最后抛弃的不需要的offset部分的数据\n查出来的抛弃的offset部分的数据中的, 我们实际上只需要他们的id列, 别的列的信息是无用的\n\n基于这两个方面\nselect * from page where id &gt;= (select id from page order by id limit 60000, 1) order by id limit 10\n\n优化的方面有两个\n\n先执行了子查询, 这个子分页查询从引擎层取数据的时候, 只获取了id列, 减少了复制的开销\n对于父查询, 通过id &gt;&#x3D; 子查询出来的id的形式, 不用再使用有offset的分页查询, 能保证需要返回的列中的每一列我们是查询到了的\n\n性能能大概提升一倍\n基于非主键索引的limit执行优化当offset比较小的时候, 过程就比主键索引多了一个回表的过程, 将回表后的数据返回给server层\n但是在offset非常大的时候, 因为server层的优化器在看到非主键索引的600w次回表以后, 发现还不如全表扫描, 这是真性能杀手\n这里优化的关键在于回表操作会导致变成全表扫描, 我们规避掉回表操作就行\nselect * from page t1, (select id from page order by user_name limit 600000, 100) t2 where t1.id = t2.id;\n\n这样就避免了回表操作\n深度分页上面叙述的, 在offset变得巨大的时候, 分页查询的性能急剧下降的问题, 就是深度分页问题, 深度分页问题只能缓解, 不能避免, 出现这个问题的时候, 我们需要追溯到为什么我们的代码会产生深度分页问题来规避\n\n情景一 : 想取出来全表的数据\n\n假如我们有一张大表, 我们想将所有数据取出来\nselect * from page\n\n数据量较大, mysql没办法一次性取出来全部报错, 很容易超时报错\n这个时候就会有人通过limit offset size的形式来分批获取, 但是在哪天数据表变得奇大无比的时候, 就会出现前面的深度分页问题\n这种时候很好解决, 简单来说就是通过where id &gt; 当前获取到的批次的最大id来获取到获取分页数据的起点\nstart_id = 0while(1) &#123;    datas = [select * from page where id &gt; start_id order by id limit 100];    if(datas.length == 0) break    add(datas)    start_id = get_max_id_from(datas)&#125;\n\n\n情景二: 给用户做分页展示\n\n就像搜索引擎下面的翻页功能\n解决方式有两种\n\n限制翻页的上下限, 谁家好人搜索引擎会翻到100多页\n或者做成只能上一页或者只能下一页的形式, 这样就能通过上面的start_id分批获取的方式来得到稳定的查询速度\n\n星球慢查询定位总结\n1、介绍一下当时产生问题的场景（我们当时的一个接口测试的时候非常的慢，压测的结果大概5秒钟） \n2、我们系统中当时采用了运维工具（ Skywalking ），可以监测出哪个接口，最终因为是sql的问题 \n3、在mysql中开启了慢日志查询，我们设置的值就是2秒，一旦sql执行超过2秒就会记录到日志中（调试阶段）\n 4、上线前的压力测试，观察相关的指标 tps &#x2F; qps &#x2F; rt &#x2F; io &#x2F; cpu  \n总结： 慢 SQL 处理思路  \n发现: 系统监控:基于 arthars 运维工具、promethues 、skywalking  mysql 慢日志: 会影响一部分系统性能 慢 SQL 处理 由宏观到微观 \n1、检查 系统相关性能 top &#x2F; mpstat &#x2F; pidstat &#x2F; vmstat 检查 CPU &#x2F; IO 占比，由进程到线程 \n2、检查 MySQL 性能情况，show processlist 查看相关进程 | 基于 MySQL Workbench 进行分析 \n3、检查 SQL 语句索引执行情况，explain 关注 type key extra rows 等关键字 \n4、检查是否由于 SQL 编写不当造成的不走索引，例如 使用函数、not in、%like%、or 等 \n5、其他情况: 深分页、数据字段查询过多、Join 连表不当、业务大事物问题、死锁、索引建立过多 \n6、对于热点数据进行前置，降低 MySQL 的压力 redis、mongodb、memory \n7、更改 MySQL 配置 ， 处理线程设置一般是 cpu * 核心数 的 2 倍，日志大小 bin-log \n 8、升级机器性能 or 加机器 \n9、分表策略，分库策略 \n10、数据归档\n"},{"title":"MySQL索引原理详解 - B+树索引结构深度解析","url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/1_%E7%B4%A2%E5%BC%95/","content":"MySQL索引为什么使用B+树作为索引的数据结构而考虑索引的数据结构的核心考量之二就是\n\n能在尽可能少的磁盘I&#x2F;O中完成查询操作\n要能高效地查询某一个记录, 并且支持范围操作\n\n这样的查找问题, 最直观的第一想法是使用二叉搜索树\n但是二叉搜索树有链化的风险, 接下来的选择就是AVL树和红黑树, 这样是解决了平衡问题, 但是使用二叉平衡树, 每进入到下一层我们都需要进行一次磁盘的I&#x2F;O, 磁盘I&#x2F;O的次数太多了, 我们需要尽可能矮胖的数据结构\n于是我们看向了B树, B树是一个多叉树, 每一层能记录更多的节点, 同样的节点数量, B树更加地矮胖\n但是B树的每个节点都包含了索引+数据, 但是实际上在查找到目标节点之前, 我们读取到的数据实际上是没有用的, 这样会有多余的磁盘I&#x2F;O, 最终我们对B树做了一个升级, 就是B+树\n我们将所有的数据都放在B+树的叶子节点上, 所有的非叶子节点只起到一个检索的作用, 通过这样的设计, 我们得到了一颗”矮胖”的搜索树, 并且搜索树的非叶子节点中只有索引数据, 同时B+树的叶子节点之间使用双向链表连接起来, 原生支持范围搜索.\n最终通过B+树, 我们满足了上述的两个核心考量\n聚簇索引和二级索引\n聚簇索引的叶子节点存放的是实际数据, 所有的完整的用户记录都存放在聚簇索引的叶子节点\n二级索引的叶子节点存放的是主键值\n\nInnoDB在创建聚簇索引的时候选用的列按照以下顺序\n\n如果指定了主键, 就使用主键作为聚簇索引的索引键\n如果没有主键, 就选择第一个不包含NULL值唯一列作为聚簇索引的索引键\n上面两个都没有的情况下, 就会自动生成一个隐式自增ID列作为聚簇索引的索引键\n\n如果某个查询语句使用了二级索引, 但是查询的数据不是主键值的时候, 在二级索引找到主键值以后, 需要去聚簇索引中获取数据行, 这个过程就叫回表. 不过当查询的数据是主键值的时候, 在二级索引中就能找到了, 就不用去聚簇索引中查找, 这个过程就叫索引覆盖\n什么时候需要分库分表了?这个问题其实很明显最后是落在B+的层高在某个行数的时候会增加一层, 最后导致查询效率猛然降低\n首先我们得分析一个B+树的非叶子节点能存储多少数据, 也就是多少索引\n每个B+树的节点都是一个MySQL的数据页, 每个数据页固定16KB的大小, 除去其中的文件头, 页头, 校验信息等元信息, 最后可用的能存放数据的空间大概是15KB. 主键假设是Bigint(8byte), 页号是固定的(4Byte), 一个索引数据的大小就是12byte\n最后一个B+树的节点能存放15 * 1024 &#x2F; 12 &#x3D; 1280行索引\n叶子节点和非叶子节点的结构是一样的, 能存放数据的空间都是15KB\n我们假设每行数据的大小是Y, 则一个叶子节点能放15 * 1024 &#x2F;  Y行数据\n设层高是z, 最后存放的行数是X &#x3D; 1280^z * 15 * 1024 &#x2F;  Y\n在z &#x3D; 3, Y &#x3D; 1KB的时候, X &#x3D; 2.45kw\n在z &#x3D; 3, Y &#x3D; 5KB的时候, X &#x3D; 500w\n所以需要分库分表的行数需要根据每行的具体大小来得出, 一般在z &gt; 3以后就要进行分库分表了, 没增加一层就会导致磁盘I&#x2F;O的次数增加1次\n同时当单表数据库达到某个量级的上限以后, 导致内存无法存储其索引, 使得之后SQL查询会产生磁盘IO, 从而导致性能下降\n索引失效的原因查询条件用上了索引列, 查询过程并不是一定会用上索引\n使用like关键字左或者左右模糊匹配无法走索引也就是使用这样的语句查询的时候\nselect * from t_user where name like %xx(or %xx%)\n\n因为索引B+树是按照索引值有序排序的, 只能根据前缀来比较\n如果使用左&#x2F;左右模糊匹配, 查询结果的前缀会发生变化, 就不知道从哪个索引值开始比较了, 这个时候通过全表扫描的方式来查询\n对索引使用函数也就是\nselect * from t_user where length(name) = 6;\n\n这样的语句执行的时候, 索引会失效\n原因也很简单, MySQL建立的索引中保存的是索引字段的原始值, 而不是经过函数计算后的值\n但是MySQL 8.0开始, 增加了函数索引, 可以针对函数计算后的值建立一个索引\nalter table t_user add key idx_name_length ((length(name)));\n\n执行了这个语句以后, 再执行上面的语句就能走索引了\n对索引进行表达式计算select * from t_user where id + 1 = 10;\n\n理由和上面对索引使用函数一样, MySQL保存的是索引字段的原始值, 而不是表达式计算以后的值\n但是\nselect * from t_user where id = 10 - 1;\n\n这样的语句是能正常生效的\n对索引隐式类型转换phone字段是varchar类型\nselect * from t_user where phone = 130001;\n\n这个时候会全表查询, 因为再MySQL中在等式两边分别是varchar和int类型的时候, 会将字符串类型转换成int类型\n这个语句等同于\nselect * from t_user where CAST(phone AS signed int) = 130001;\n\n这个时候就是第二种情况, 对索引使用函数的情况了\n但是\nselect * from t_user where id = &#x27;1&#x27;;\n\n这样的语句, 因为右边是被转化了的, 所以是能正常走索引的\n联合索引非最左匹配多个普通字段组合在一起创建的索引就叫做联合索引\n创建联合索引的时候, 需要注意索引的顺序 (a,b,c)和(c,b,a)在使用的时候存在差别\n联合索引要能正常使用需要遵循最左匹配原则 : 按照最左优先的方式进行索引的匹配\n如果联合索引是(a,b,c)时候\n\nwhere a &#x3D; 1\nwhere a &#x3D; 1 and b &#x3D; 2\nwhere a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3\n\n这三个语句就能正常使用联合索引\n但是像\n\nwhere b &#x3D; 2\nwhere b &#x3D; 2 and c &#x3D; 1\nwhere c &#x3D; 2\n\n这样的语句就没法走联合索引\n这样的原因是, 在联合索引中, 数据排序的顺序是: 先按照索引第一列排序, 第一列数据相同的时候才会按照第二列排序, 以此类推\n所以如果我们只使用了第二列搜索, 这个时候, 没办法比较第一列数据, 这个时候索引就失效了\n\n对于where a &#x3D; 1 and c &#x3D; 2这样的查询语句, 有没有使用索引呢\n\n严格来说属于索引截断,  不同的MySQL版本, 处理方式会不一样\n5.5及以前, a会走索引, 联合索引找到主键值以后, 再回表, 到主键索引读取数据行, 比对c字段的值\n5.6及以后, 有一个索引下推的功能, 在索引遍历的过程中, 因为c在索引中, 能在索引中判断的条件, 就不要等到回表后再去判断, 能有效减少昂贵的回表操作\nWhere子句中的OR在WHERE子句中, 如果在OR前面的条件列是索引列, 而在OR后面的列不是索引列, 就会造成索引失效\n也就是如果id是索引列\nselect * from t_user where id = 1 or age = 18;\n\n这是因为OR的含义是两个只要满足其中一个就行了, 因此只有一个条件列是索引列是没有意义的\n解决方法就是两个列都成为索引列, 这个时候就会根据索引分别扫描, 在最后将两个结果集进行合并\n模糊查询 like %xxx一定会全表扫描吗select * from t_user where name like &quot;%xxx&quot;;\n\n一定会走全表扫描吗\n需要查询出来的信息只有索引值 + 主键值, 这个时候就不会走全表扫描(type &#x3D; ALL), 而是全扫描二级索引树(type &#x3D; index)\n, 也就是遍历了整颗二叉索引树. 这是因为需要查询的所有数据在二级索引的B+树中就能查到全部结果了, 这个时候就发生了覆盖索引\n\n为什么在要查询的字段中有非索引字段的时候, 就会从全扫描二级索引树变成了全表扫描\n\n因为如果走全扫描二级索引树, 就会变成, 在二叉索引树中找到了以后还要回表才能完成查询的工作, 同时因为是左模糊匹配, 导致并没有利用索引树的有序性快速定位数据\n","categories":["计算机科学","数据库","MySQL"],"tags":["八股文","面试","数据结构","MySQL","索引","B+树","查询优化","磁盘IO","数据库原理"]},{"title":"MySQL事务机制详解 - ACID特性与并发控制","url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/2_%E4%BA%8B%E5%8A%A1/","content":"事务事务有哪些特性\n原子性: 一个事务中的所有操作一起成功, 一起失败\n一致性: 事务操作前后, 数据满足完整性约束, 简单来说就是在并发场景下保证数据的一致性\n隔离性: 数据库允许多个并发事务同时对数据进行读写, 隔离性防止因为事务的交叉执行导致的数据不一致, 每个事务有自己的隔离的数据空间\n持久性: 事务结束以后, 对数据的修改就是永久的\n\nInnoDB通过什么来保证这四个特性呢?\n\n持久性是通过 redo log来保证的\n原子性通过 undo log来保证\n隔离性通过MVCC或者锁机制来保证的\n一致性通过上面三者来共同保证\n\n并行事务导致的问题MySQL在处理并行事务的时候会出现三个问题\n\n脏读: 一个事务读到了另一个未提交事务修改的数据, 就出现了脏读\n不可重复度读: 在一个事务内, 对于同一数据多次读, 读出来的结果不同\n幻读: 在一个事务内, 两次读到的结果集不同(比如这次读到表中有5条数据, 下次读到有6条数据)\n\n事务的隔离级别事务的隔离级别一一对于对于上面的并行事务三大问题的解决, 同时隔离级别越高, 性能效率越低\n\n读未提交: 一个事务没有提交的时候, 它做的修改就能被其他事务看见 (脏读, 不可重复读, 幻读)\n读提交: 一个事务提交以后, 它的修改才能被其他事务看到 (不可重复读, 幻读)\n可重复读: 一个事务执行过程中看到的数据, 一直跟这个事务启动的时候看到的数据一致, 是InnoDB引擎默认隔离级别(幻读)\n串行化: 对记录加上读写锁, 实现事务之间的串行化()\n\nMySQL在可重复读隔离级别下, 可以很大程度避免幻读现象的发生\nRead View与MVCCRead View中的四个字段\ncreator_trx_id: 创建该Read View的事务的事务id\nm_ids: 创建Read View的时候,  当前数据库中”活跃且未提交”的事务id列表\nmin_trx_id: 创建Read View时当前数据库中活跃且未提交的事务id中最小的事务id\nmax_trx_id: 创建Read View时当前数据库中给下一个事务的id值, 也就是max(m_ids) + 1\n\n聚簇索引记录中的两个隐藏列\ntrx_id: 当一个事务对某个聚簇索引记录进行改动的时候, 就会将该事务的id记录在这个隐藏列中\nroll_pointer: 每次对某条聚簇索引改动的时候, 都会把旧版本的记录写入到undo log中. 这个隐藏列是个指针, 指向上一个旧版本记录, 通过它能找到修改前的记录(这样递归下去我们就能找到每个版本的记录)\n\n这两者是怎么共同工作实现MVCC的创建Read View以后, 可以将记录中的trx_id分成三种情况\n\n\ntrx_id &lt; min_trx_id: 这个时候说明这个数据版本是在Read View前已经提交过的事务生成的, 数据对当前事务可见\nmin_trx_id  &lt;&#x3D; trx_id &lt; max_trx_id: 说明这个数据版本是在Read View前创建, 并且那个时刻没有提交的事务修改的, 但是不知道现在该事务有没有提交, 所以需要通过m_ids额外判断\n如果该trx_id存在于m_ids中, 说明事务还没有提交, 这个时候该版本的记录就对当前事务不可见\n如果该trx_id不存在于m_ids中, 说明事务已经被提交了, 该版本对当前事务可见\n\n\ntrx_id &gt;&#x3D; mar_trx_id: 说明这个数据版本是在Read View创建以后才启动的事务, 该版本对当前事务不可见\n\n可重复读是怎么实现的可重复读隔离级别是启动事务时生成一个Read View, 然后整个事务期间都在用这个Read View\n假如事务A(事务id为51)启动了, 紧接着事务B(事务id为52)启动了, 这两个事务创建的Read View如下\n\n在可重复读隔离级别下, 事务A和事务B按照如下顺序执行以下操作\n\n事务B读取余额, 100\n事务A将余额修改为200, 并没有提交事务\n事务B读取余额, 100\n事务A提交事务\n事务B读取余额, 100\n\n事务B在第一次读取到账户余额的时候, 在找到记录以后, 会先看记录的trx_id, 发现trx_id是50, trx_id &lt; min_trx_id, 说明这条记录是在Read View创建前也就是事务B启动前就已经提交了的记录, 所以该版本的记录对于事务B是可见的\n在事务A将余额修改成200以后, 事务B第二次读取账户余额, 这个时候记录中的trx_id &#x3D; 51, roll_pointer指向上一条trx_id&#x3D;50的记录, 事务B发现记录的trx_id在[min_trx_id, max_trx_id)之间, 并且在m_ids列表中, 说明这个记录是还未提交的事务修改的, 事务B会沿着undo log链条向下找, 知道找到trx_id小于事务B的Read View中的min_trx_id值的第一条记录, 所以事务B读到的会是100\n在A提交事务了以后, 因为事务B使用的Read View一直是在开启事务的时候创建的Read View, 这就造成了在B的Read View看来, A中的事务还是没有提交的, 所以還是會和第二次讀一樣, 讀到100\n读提交是怎么工作的读提交隔离级别是在每次读取数据时都会生成一个新的Read View\n所以在事务B的第三次读之前, 事务B生成的Read View m_ids &#x3D; {52}, min_trx_id &#x3D; 52, 这个时候就能读取到trx_id是51的记录了\nMySQL可重复读隔离级别, 完全解决的幻读吗\n针对快照读, 也就是普通的select语句, 是通过MVCC方式解决了幻读, 在可重复读隔离级别下, 事务执行过程中看到的数据, 会和事务启动时看到的数据保持一致\n针对当前读, 也就是select for update语句, 通过 next-key-lock 方式解决了幻读\n\n什么是幻读问题与可重复读问题不同, 幻读问题是在同一次事务中, 相同的查询, 在T1时刻和T2时刻查询到的结果集是不一样的\n\nT1时间执行的结果有5条行记录, 而T2时间执行的结果有4&#x2F;6条行记录, 就发生幻读\n\n快照读是怎么避免幻读的在执行第一个查询语句后, 会创建一个Read View, 后续的查询语句会利用这个Read View在undo log版本链中找到事务开始时的数据, 即使中途插入了其他数据, 也会因为这条新的数据的trx_id大于等于Read View中的min_trx_id而无法查到\n\n但是是没有完全解决幻读问题的\n\n\n在如上的时序图中, 在更新操作的时候, 这条记录的trx_id就变成了事务A的id, 这个时候再执行查询就会出现幻读\n当前读是怎么避免幻读现象的MySQL中除了普通查询, 都是当前读, 比如update, insert, delete,  这些语句执行前都会查询最新版本的数据, 然后再进一步的操作\n通过next-key lock解决的幻读现象\n\n发生幻读现象的场景\n\nT1: 事务A先执行快照读语句: select * from t_user where id &gt; 100得到了三条记录\nT2: 事务B插入一条id&#x3D;200的记录并提交\nT3: 事务A再执行当前读语句, select * from t_user where id &gt; 100 for update, 就会有四条记录\n","categories":["计算机科学","数据库","MySQL"],"tags":["八股文","面试","MySQL","并发控制","事务","ACID","隔离级别","MVCC","redo log","undo log"]},{"url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/3_%E9%94%81/","content":"MySQL锁MySQL"},{"url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/4.%20%E6%97%A5%E5%BF%97/","content":""},{"url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/%E4%BB%80%E4%B9%88%E6%98%AF%E7%B4%A2%E5%BC%95/","content":"MySQL索引什么是索引 ?\n索引就是MySQL数据库的目录, 通过这个目录我们能快速地找到我们要的数据, 就像一本书的目录\n索引能帮助MySQL快速定位到我们要查询的数据, 索引优化的点主要是查询方面的性能\n\n如果不使用索引, MySQL执行查询的过程是怎么样的 ?\nMySQL会执行全表扫描, 找到符合条件的语句\n也是因为这个查询方式, 如果大表不使用索引, 查询的性能是灾难性的\n\n使用MySQL索引的分类\n按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。 \n按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。 \n按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。 \n按「字段个数」分类：单列索引、联合索引\n\n按数据结构分类B+tree索引\nB+tree索引类型是MySQL存储引擎采用最多的索引类型\n\n\n为什么使用B+tree ?  - 核心目的就一个 : B+tree能让我们在最少的磁盘IO次数下, 找到我们要的数据\n\n"},{"url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/MySQL%E4%B8%80%E8%A1%8C%E8%AE%B0%E5%BD%95%E6%97%B6%E6%80%8E%E4%B9%88%E5%AD%98%E5%82%A8%E7%9A%84/","content":"MySQL基础面试题\nMySQL 的 NULL 值会占用空间吗？\nMySQL 怎么知道 varchar(n) 实际占用数据的大小？\nvarchar(n) 中 n 最大取值为多少？\n行溢出后，MySQL 是怎么处理的？\nMySQL的NULL值怎么存放的 ?\n\nMySQL的数据是怎么存储的 ?数据存储在哪?\n在linux中, MySQL的数据会存储在/var/lib/mysql/这个目录下面, 每个数据库会在这个目录下面创立一个文件夹, 文件名就是库名\n里面有db.opt, t_&lt;table_name&gt;.frm, t_&lt;table_name&gt;.ibd三类文件\ndb.opt, 用于存车处当前数据库的默认字符集和字符校验规则\ntable.frm, 这张表的表结构会保存在这个文件. 在MySQL中每建立一张表大都会生成一个.frm文件, 用于记录这个表的元信息, 主要是定义表的结构\ntable.ibd文件 : 记录了表的表数据. 表数据既可以存在共享表空间文件 (ibdata1) 中, 也可以存储在独占表空间文件中(ibd)文件中. 这个行为由参数innodb_file_per_table控制, 若设置参数innobd_file_per_table的值为1, 就会将存储的数据, 索引等信息单独存储在独占表空间, 从5.6版本以后, 这个参数就已经默认设置为1了\n\n\n\n表空间文件的结构是怎么样的表空间由段(segment), 区 (extent), 页(page), 行(row)组成, 这些部分之间的关系可以从下图粗略看出来\nk\n1. 行 (row)数据库中的数据都是以行进行存放的, 每行记录根据不同的行格式, 有不同存储结构后面会详细说明行格式\n2. 页 (page)\n行是记录一次数据的最小单位, 但是数据库与磁盘的交互, 从磁盘中读取数据, 行并不是最小的单位, 不然每IO一次磁盘只能处理一行数据, 效率过于低下\nInnoDB的数据是按[页]为单位进行读写的, 也就是读取一条记录的时候, 并不是只将这行的数据从磁盘IO到内存, 而是将一页的数据IO到内存中 \n默认一页的数据是16KB, 也就是最多能保证16KB的连续空间(空间局部性, 顺序IO的性能高于随机IO)\n页是InnoDB存储引擎磁盘管理的最小单元, 也就是每次读写, 都是最少将一整页的数据读取出来, 再将这一整页的数据刷新回磁盘\n页有很多种种类, 数据页, undo日志页, 溢出页. 数据表中的行记录使用数据页来管理的\n\n3. 区 (extent)\nInnoDB 使用B+tree树来组织数据\n\n使用索引来作为非叶子节点\n有主键则使用主键\n没有主键则使用第一个非空唯一索引作为主键\n再没有就使用隐藏主键\n\n\n每个叶子节点就是一页数据\nB+树每一层之间都是使用双向链表将数据连接起来\n\n\n如果使用页作为单位分配空间, 就无法保证链表中相邻的页的物理位置并不是相邻的, 而对于磁盘随机IO慢于顺序IO\n\n为什么保证逻辑上相邻的页之间物理位置也相邻很重要?\n空间局部性 : 计算机程序在访问一个特定的内存位置以后, 很可能会在不久之访问相邻的内存位置, 这是计算机系统设计的一个基本假设\n空间局部性能提高磁盘的IO性能 : 顺序IO替代随机IO\n显著提高范围查询和顺序扫描的性能\n\n\n\n\n那么怎么解决呢? 我们该怎么保证相邻页数据尽量满足在磁盘中相邻呢\n\n在表中数据量大的时候, 为某个索引分配空间的时候, 就不再按照页为单位分配了, 而是按照区为单位分配, 每个区的大小是1MB, 对于16KB的页来说, 连续的64页会被划分到一个区, 这样就使得链表中相邻的页的物理位置也能相邻, 就能再更大的范围顺序IO了\n\n\n\n4. 段(segment)\n表空间由多个段组成, 一个段由多个页组成. 段一般分成数据段, 索引段, 回滚段段 一组拥有相似用途的页的集合, 是一种逻辑上的结构\n\n\n索引段 : 存放B+树的非叶子节点的区的集合\n\n数据段 : 存放B+树对的叶子节点的区的集合\n\n回滚段 : 存放的是回滚数据的区的集合\n\n在物理存储上\n\n数据段和索引段通常位于同一表空间文件中\n系统表空间\n独立表空间\n\n\n回滚段可以位于\n系统表空间\n专用的UNDO表空间\n临时表空间\n\n\n\n\n\n行格式 (row format)\n行格式就是MySQL存储一行数据的逻辑结构, 一行数据中包含了什么内容, 一条记录的存储结构\n\n\n有四种行格式 : Compact, Dynamic, Compressed, Redundant\nReddundant很古老, 基本不使用了\nCompact和Dynamic以及Compressed相似, Dynamic和Compressed更为紧凑\n\n\n\n\n5.1 以后默认使用Compact, 5.7以后默认使用Dynamic\n\nCOMPACT行格式是怎么样的\n\n可以将一条记录分为 记录的额外信息 和 记录的真实数据 两部分\n\n变长字段长度列表\n在MySQL有像varchar(n)这样的变长的字段, 它们存储的数据的长度是不确定的\n变长字段长度列表就是记录所有(非NULL)的变长字段的长度信息的, 这样我们在后续读取数据的时候才知道读多长\n\n我们用例子说明变长字段长度列表是怎么工作的, 字符集是ascii(所以每个字符占一个字节)\nCREATE TABLE `t_user` (  `id` int(11) NOT NULL,  `name` VARCHAR(20) DEFAULT NULL,  `phone` VARCHAR(20) DEFAULT NULL,  `age` int(11) DEFAULT NULL,  PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB DEFAULT CHARACTER SET = ascii ROW_FORMAT = COMPACT;\n\n这是表中的数据\n\n看第一条记录\nname列 : 值为a, 长度为0x01\nphone列 : 值为123, 长度为0x03\n\n\n变长字段的真实数据的占用的字节数会按照列的顺序 逆序存放 , 所以变成字段长度序列里的内容是 [03, 01]\n同理, 其他两行的变长字段长度序列为\n[04, 02]\n[03]\n\n\n\n\n为什么 变长字段长度列表 需要使用逆序存储 ?\n\n\n记录头信息中指向下一条记录的指针, 指向的是下一条记录的记录头信息, 和真实数据\n\nvarchar(n)中n的最大取值是多少行溢出后, MySQL是怎么处理的"},{"url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/%E6%9C%AA%E7%90%86%E8%A7%A3%E7%9A%84%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","content":"\n行格式的记录信息头中的NULL值列表和变长字段长度列表为什么是逆序存储 ?\n小林code主要关注在逆序存储以后, 同一个字段的内容和长度离得更近了, 能提高CPU缓存的的命中率\nGPT : 这样的设计能让靠后的列删除和更新更高效, 而靠后的列更经常做这个操作\n\n\n\n"},{"url":"/2025/07/08/Computer_Science/Database/MySQL/MySQL%E5%8E%9F%E7%90%86/%E9%97%B4%E9%9A%99%E9%94%81/","content":"间隙锁为什么需要间隙锁\n解决的核心问题是幻读现象 : 在同一次事务中, 两次相同的查询最后的结果却不一样\n\n\n举例说明间隙锁解决幻读现象\n范围问题\n\n事务A : 查询银行账户中所有的余额 &gt; 500的账户, 执行后续业务\n\n事务B : 添加一个余额600的账户 \n\n如果没有间隙锁 : 在执行完查询以后, 执行后续业务之前, 执行了事务B, 这个时候, 事务A中的查询结果其实是错误的, 少查了一个余额 &gt; 500 的账户\n通过间隙锁解决 : 在事务A执行了查询以后, 数据库为除了已经查询到的账户以外的所有范围加上间隙锁, 其他的事务如果在加锁以后进行查询, 会阻塞等待间隙锁释放\n\n\n唯一性检查\n\n事务A : 查询学生表中有没有学号为003的数据, 如果没有则添加这个学生的数据\n\n事务B  : 为学生表添加学号为003的学生的数据, 如果这个学生不存在的话\n\n如果没有间隙锁 : 在事务A执行了查询以后, 事务B将这个学生添加进去了, 然后事务A又添加了一次\n通过间隙锁解决 : 在查询以后事务A为学号索引003加上间隙锁, 事务B在添加的时候碰到了锁, 阻塞等待事务A结束, 事务A结束以后, 事务B再执行添加因为数据库中已经有了数据, 插入失败\n\n\n\n\n\n\n间隙锁保证了查询结果在一次事务中的一致性\n\n什么是间隙锁- \n间隙锁在这里会导致的问题如何解决间隙锁问题"},{"url":"/2025/07/08/Computer_Science/Database/MySQL/MySQLbase/SQL/","content":"1. 数据库概述数据库相关概念DB: 数据库\nDBMS: 数据库管理系统 (Database Management System)\nSQL: 结构化查询语言 (Structured Query Language)\n关系型数据库设计规则\nE - R (entity - relationship, 实体-联系) 模型中有三个主要概念是: 实体集, 属性, 联系集\n\n表的关联关系\n一对一关联\n\n一般用于将一张表拆成两张表, 一张存储常用的, 一张存储不常用的\n\n\n一对多关联\n\n多对一关联\n\n自我引用\n\n\n2. MySQL环境搭建启动和关闭服务\n使用命令行工具\n\n# 启动SQL服务net start MySQL服务名(MySQL80)# 关闭SQL服务net stop MySQL服务名(MySQL80)\n\n登录mysql -h 主机名(localhost) -P 3306 -u root -p密码\n\n\nclient和server在同一台机器上的时候, host其实就是127.0.0.1或者localhost, 所以-hlocalhost可以不写, 同样的, 如果端口号没有做修改, -P 3006也可以不写\n\n原来就有的库\ninformation_schema\n是MySQL自带的数据库, 主要保存MySQL数据库服务器的系统信息, 比如数据库的名称, 数据库表的名称, 字段名称, 存取权限, 数据文件所在的文件夹和系统使用的文件夹等\n\n\nperformance_schema\n是MySQL系统自带的数据库, 可以用来监控MySQL的各类性能指标\n\n\nsys\n主要作用是以一种更容易被理解的形式展示MySQL数据库服务器的各类性能指标, 帮助系统管理员和数据库管理人员监控MySQL的技术性能\n\n\nmysql\n数保存了MySQL数据库服务器运行时需要的系统信息, 比如数据文件夹, 当前使用的字符集, 约束检查信息等\n\n\n\n数据库的简单使用\n创建自己的数据库\n\ncreate database 数据库的名称;\n\n\n该名称不能和存在的数据库重名\n\n\n查看所有的数据库\n\nshow databases;\n\n\n数据库的名称是不区分大小写的\n\n\n使用数据库\n\n use 数据库名;\n\n\n输入同样是不区分大小写的\n\n\n查看某个库的所有表格\n\nshow tables; #  use 到某个数据库中show tables from 数据库名称;\n\n\n创建新的表格\n\ncreate table &lt;table-name&gt;(\tname type,    name type);\n\n\n最后的变量是不能加上” , “, 加上后会报错\n\n\n查看一个表的数据\n\nselect * from &lt;table-name&gt;;\n\n\n添加一条记录\n\ninsert into student value(1, &#x27;张三&#x27;);insert into student value(2, &#x27;李四&#x27;);\n\n\n查看表的创建信息\n\nshow create table &lt;table-name&gt;\\G;#\t查看student表的详细创建信息show create table student\\G;\n\n\n删除表格\n\ndrop table &lt;table-name&gt;;\n\n\n删除数据库\n\ndrop database &lt;database-name&gt;;\n\n编码问题的解决\n查看编码命令\n\nshow variable like &#x27;character_%&#x27;;show variable like &#x27;collation_%&#x27;;\n\n\n修改mysql的数据目录下的my.ini配置文件\n\n[mysql] #大概在63行左右，在其下添加 ... default-character-set=utf8 #默认字符集 [mysqld] # 大概在76行左右，在其下添加 ... character-set-server=utf8collation-server=utf8_general_ci\n\n\n重启服务\n\n\n修改失败\n在8.0版本之前, 默认字符集为latin1, utf8指向utf8mb3. 从8.0开始, 数据库的默认编码为utf8mb4\n\n3. 基础的SELECT语句SQL分类SQL语言在功能上分为三大类\n\nDDL ( Data Definnition Languages - 数据定义语言) , 这些语言定义了不同的数据库, 表, 视图, 索引等数据库对象, 还可以用来创建, 删除和修改数据库和数据表的结构\n主要语句有 CREATE, DROP, ALTER\n\n\nDML ( Data Manipulation Languages - 数据操作语言 ) , 用于添加, 删除, 更新和查询数据库记录, 并检查数据完整性\n主要语句关键词有INSERT, DELETE, UPDATE, SELECT\nSELECT是SQL语言的基础, 最为重要\n\n\nDCL ( Data Control Languages - 数据控制语言 ) , 用于定义数据库, 表, 字段, 用户的访问权限和安全级别\n主要的语句关键字包括GRANT, REVOKE, COMMIT, ROLLBACK, SAVEPOINT等.\n\n\n\nSQL语言的规则和规范\n列的别名, 尽量使用双引号 “” , 而且不建议省略as\n\n关键字不能被缩写和分行\n\n\n大小规范\nMySQL 在Windows 环境是大小写不敏感的\n\nMySQL 在Linux环境是大小写敏感的\n\n数据库名, 表名, 表的别名, 变量名是严格区分大小写的\n关键字, 函数名, 列名(字段名), 列的别名是忽略大小写的\n\n\n推荐的统一书写规范\n\n数据库名, 表名, 表的别名, 字段名, 字段别名等都小写\nSQL关键字, 函数名, 绑定变量等都大小写\n\n\n\n注释#注释文字 (MySQL特有的方式) -- 注释文字 (--后必须有一个空格) /* 多行注释 */\n\n命名规则\n数据库, 表名不得超过30个字符, 变量名限制为29个\n特殊字符里只有_\n不能有任何形式的重名现象\n保持字段名和类型的一致性, 在命名字段并其指定数据类型的时候一定要保证一致性\n\nCREATE TABLE `order`()# 其中order使用``飘号, 因为order和系统关键字或系统函数名等预定义标识符重名了\n\nSELECT id AS &quot;编号&quot; from t_stu;\n\n\n起别名的时候, as可以省略\n如果字段别名中没有空格, 可以省略 “ “\n\n数据导入指令mysql&gt; source &lt;path\\**.sql&gt;\n\n基本的SELECT语句SELECT….SELECT 1; # 没有任何字句SELECT 9/2;# 会返回一个一行一列的结果集, 常用来测试数据库链接是否正常, 是否可以正常使用\n\nSELECT … FROM\n语法 :\nSELECT\t标识选择哪些列FROM\t标识从哪个表中选择\n\n选择全部列 :\nSELECT *FROM departments;\n\n\n一般情况下,  除非需要获取和使用表中的所有字段, 最好不要使用 * 通配符, 会查询到不必要的信息降低程序的运行效率, 优势是, 当不知道,所需要的列的名称的时候, 可以通过它们获取\n\n列的别名\n重命名一个列, 便于计算\n\n紧跟列名, 也可以在列名和别名之间加入关键字AS, 别名使用双引号, 以便在别名中包含空格或特殊的字符并区分大小写\n\n举例\nSELECT last_name AS name, commission_pct commFROM employees;\n\nSELECT last_name &quot;Name&quot;, salary*12 &quot;Annual Salary&quot;FROM employees;\n\n去除重复行默认情况下, 查询会返回全部行, 包括重复行.\nSELECT department_idFROM employees;\n\n使用关键字DISTINCT去除重复行\nSELECT DISTINCT department_idFROM employees;\n\n对于双查询, 会有注意点:\nSELECT DISTINCT department_id, salaryFROM employees;\n\n\n\nDISTINCT 需要放在所有的列名的前面\nDISTINCT其实是对后面所有的列名的组合去重\n\n\n空值参与运算\n所有运算符或列值遇到null值, 运算的结果都为null\n\n查询常数用于增加一个固定的常数列, 可以用这个列作为表的标记\nSELECT &#x27;尚硅谷&#x27; AS corporation, last_name FROM employees;\n\n显示表结构使用DESCRIBE 或 DESC 命令, 表示表结构\nDESCRIBE employees;# 或DESC employees;\n\n 其中, 各个字段的含义分别解释如下:\n\nField: 表示字段名称\nType: 表示字段类型\nNull: 表示该列是否可以存储NULL值\nKey: 表示该列是否已经编制索引, PRI表示该列是表主键的一部分, UNI表示该列是UNIQUE索引的一部分, MUL表示在列中某个给定值允许出现多次\nDefault: 表示该列是否有默认值, 如果有, 那么值是多少\nExtra: 表示可以获取的与给定列有关的附加信息, 例如AUTO_INCREAMENT\n\n过滤数据SELECT &lt;Field1&gt;, &lt;Field2&gt;FROM &lt;table-name&gt;WHERE &lt;condition&gt;\n\n\nWHERE语句需要在FROM语句后面\n\n4. 运算符\n在Java中, +的左右两边如果有字符串, 那么表示字符串的拼接. 但是在MySQL中 + 只表示数值相加. 如果遇上非数值型, 会先尝试转成数值, 如果转失败, 则会以0为计算\n一个数除以整数后, 不管是否能除尽, 结果都为一个浮点数\n除不尽的时候, 小数位数保留四位\n一个数除以0为NULL\n\n比较运算符比较结果为NULL当普通的运算符, 有一个操作数为NULL的时候, 运算的结果为NULL\n安全等于运算符安全等于运算符 ( &lt;&#x3D;&gt; ) 与等于运算符 (&#x3D;) 的作用是相似的, 唯一的区别是 ‘&lt;&#x3D;&gt;’ 可以用来对NULL进行判断. 当两个操作数都为NULL的时候, 返回1\n空运算符判断一个值是否为NULL, 是则返回1\nSELECT NULL IS NULL, ISNULL(NULL);\n\n非空运算符与之相对的, 就有非空运算符(IS NOT NULL)\n最小值运算符语法格式为 : LEAST(值1, 值2, …, 值n).\nSELECT LEAST(&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;), LEAST(1, 2,3);\n\n最大值运算符与最小值运算符相对的就是最大值运算符GREATEST(value1, value2, …,value_n)\nBETWEEN AND运算符使用格式 : \nSELECT D FROM TABLE WHERE C BETWEEN A AND B;\n\nSELECT last_name, salaryFROM employeesWHERE salary BETWEEN 2500 AND 3000;\n\nIN运算符用于判定给定的值是否是IN列表中的一个值\nSELECT &#x27;a&#x27; IN(&#x27;a&#x27;, &#x27;b&#x27;);\n\nSELECT NULL IN(...) # 返回值一定是NULL\n\nNOT IN 运算符LIKE 运算符主要用于匹配字符串, 通常用于模糊匹配, 如果给定的值或匹配条件为NULLL , 则返回条件为NULL\n&quot;%&quot;: 匹配0个或多个字符&quot;_&quot;: 只能匹配一个字符\n\nSELECT first_nameFROM employeesWHERE first_name LIKE &#x27;S%&#x27;;SELECT last_nameFROM employeesWHERE last_name LIKE &#x27;_o%&#x27;;\n\nESCAPE回避特殊符号可以使用转义符\n\n使用情景 : 我现在需要查名字里带有_的人, 这个时候, 我们如何表达_符号就是个问题\n\n\n使用\\作为转移符号的情况 -&gt; 这种情况下, 不需要使用ESCAPE\n\nSELECT job_idFROM jobsWHERE job_id LIKE &#x27;IT\\_%&#x27;;\n\n\n没有使用\\作为转义符号, 这个时候需要使用ESCAPE声明转义字符\n\nSELECT job_idFROM jobsWHERE job_id LIKE &#x27;IT$_%&#x27; ESCAPE &#x27;$&#x27;;\n\nREGEXP运算符同样是用来匹配字符串的, 语法格式为expr REGEXP 匹配条件. 如果expr满足匹配条件, 返回1; 如果不满足, 则返回0. 若expr或匹配条件任意一个为NULL, 则结果为NULL\n匹配规则\n(1)&#x27;^&#x27;匹配以该字符后面的字符开头的字符串(2)&#x27;$&#x27;匹配以该字符前面的字符结尾的字符串(3)&#x27;.&#x27;匹配任何一个单字符(4)&quot;[...]&quot;匹配在方括号内的任何字符. 例如, &quot;[abc]&quot;匹配&quot;a&quot;或&quot;b&quot;或&quot;c&quot;. 为了命名字符的范围, 使用一个&#x27;-&#x27;. &quot;[a-z]&quot;匹配任何字母,&quot;[0-9]&quot;匹配任何数字(5)&#x27;*&#x27;匹配零个或多个在它前面的字符, 例如, &quot;x*&quot;匹配任何数量的&#x27;x&quot;字符, 如[0-9]*表示匹配任何数量数字\n\nSELECT &#x27;ssgaga&#x27; REGEXP &#x27;^s&#x27;, &#x27;shsada&#x27; REGEXP &#x27;a$&#x27;, &#x27;shsaga&#x27; REGEXP &#x27;hs&#x27;;SELECT &#x27;atguigu&#x27; REGEXP &#x27;gu.gu&#x27;, &#x27;atguigu&#x27; REGEXP &#x27;[ab]&#x27;;# 结果全为1\n\n逻辑运算符\n\n\n运算符\n作用\n示例\n\n\n\nNOT 或 !\n逻辑非\nSELECT NOT A\n\n\nAND 或 &amp;&amp;\n逻辑与\nSELECT A AND B\n\n\nOR 或 ||\n逻辑或\nSELECT A OR B\n\n\nXOR\n逻辑异或\nSELECT A XOR B\n\n\n\n!NULL &#x3D;&gt; NULL\nAND前后有NULL的时候返回NULL\nOR当有一个值为NULL, 但另一个值为非0的时候, 返回1, 两个都为NULL的时候返回NULL\n\n\nAND和OR可以一起使用, AND的优先级高于OR\n\n位运算符和CPP中的一致, 不赘述\n5. 排序和分页1. 排序数据排序规则\n使用 ORDER BY子句排序\n\nASC (ascend) :升序\n\nDESC(descend) :降序\n\nORDER BY子句在SELECT语句的结尾\n\n\n\n\n单列排序SELECT last_name, job_id, department_id, hire_dateFROM employeesORDER BY hire_date;\n\nSELECT   last_name,  job_id,  department_id,  hire_date FROM  employees ORDER BY hire_date DESC;\n\n\n\n最后的降序还是升序模式, 在ORDER BY语句的末尾说明\n\n默认升序\n\n\n\n多列排序SELECT last_name, department_id, salaryFROM employeesORDER BY hire_date, salary DESC;\n\n\n可以使用不再SELECT列表中的列排序\n在对多列进行排序的时候, 首先排序的第一列必须有相同的值\n\n2. 分页问题背景背景1: 查询返回的数据太多了, 查看起来很不方便\n背景2: 表里又四条数据, 但是我们只想显示2, 3条数据\n实现规则\nMySQL中使用LIMIT实现分页\n\n格式 :\nLIMIT [位置偏移量, ] 行数\n\n第一个”位置偏移量参数”指示MysQL从哪一行开始显示, 是一个可选参数, 如果不指定, 默认从第一条开始; 第二个参数”行数”只是返回的记录条数\n\n举例\n-- 前十条记录SELECT *FROM employeesLIMIT 0,10;-- 或者SELECT *FROM employeesLIMIT 10;-- 11至20条记录SELECT *FROM employeesLIMIT 10,10;\n\n\nMySQL8.0中可以使用”LIMIT 3 OFFSET 4”, 意思是获取从第五条记录开始后面的三条记录, 和”LIMIT 4, 3;”返回的结果相同\n\n\n分页显示公式: **(当前页数-1)*每页条数, 每页条数 **SELECT *FROM &lt;table&gt;LIMIT(Pageno - 1)*PageSize, PageSize;\n\n\nLIMIT子句必须放在整个SELECT语句的最后\n\n\n好处:\n减少数据表的网络传输量 \n也可以提升查询效率\nSELECT不需要扫描整张表, 只需要检索到一条符合条件的记录即可返回\n\n\n\n作业题目 :\n#1. 查询员工的姓名和部门号和年薪，按年薪降序,按姓名升序显示 #2. 选择工资不在 8000 到 17000 的员工的姓名和工资，按工资降序，显示第21到40位置的数据 #3. 查询邮箱中包含 e 的员工信息，并先按邮箱的字节数降序，再按部门号升序\n\n答案 :\nSELECT last_name, department_id, salary * 12 AS annual_salaryFROM employeesORDER BY annual_salary DESC, last_name ASC;\n\nSELECT last_name, salaryFROM employeesWHERE salary NOT BETWEEN 8000 AND 17000ORDER BY salary DESCLIMIT 20,20;\n\nSELECT last_name,email,department_idFROM employees# where email like &quot;%e%&quot;WHERE email REGEXP &#x27;[e]&#x27;ORDER BY LENGTH(email) DESC, department_id ASC;\n\n6. 多表查询多表查询, 也称关联查询, 指两个或更多个表一起完成查询操作\n前提条件: 这些一起查询的表之间是有关系的 (一对一, 一对多) , 它们之间一定是有关联字段的, 这个关联字段可能建立了外键, 也可能没有建立外键, 比如: 员工表和部门表, 这两个表依靠 “部门编号” 进行关联.\n1. 多表连接 (案例)案例说明#案例: 查询员工的姓名及其部门SELECT last_name, department_nameFROM employees, departments;# 返回的行数有2889行\n\n分析错误情况:\nSELECT COUNT(employee_id) FROM employees; #输出107行 SELECT COUNT(department_id)FROM departments; #输出27行 SELECT 107*27 FROM dual;# 107*27 = 2889\n\n该错误称为笛卡尔积的错误\n笛卡尔积笛卡尔积的作用就是可以把任意表进行连接, 即使这两张不相关.\n最后的结果就是两张表的内容, 两两组合\n案例分析和问题解决\n笛卡尔积的错误会在下面条件下产生\n\n省略了多个表的连接条件 (或关联条件)\n连接条件无效\n所有表中的所有行相互连接\n\n\n为了避开笛卡尔积, 可以在WHERE加入有效的连接条件\n\n加入连接条件后, 查询语法:\nSELECT table1.coolumn, table2.columnFROM table1, table2WHERE table1.column1 = table2.column2; # 连接条件\n\n2. 多表查询分类讲解分类1: 等值连接 vs 非等值连接等值连接简单来说, 就是利用两张不同的表中相等的关联字段连接在一起的就是等值连接, 一般表现形式为一张表的外键和另一张表的主键等值连接 \nSELECT employees.`employee_id`, employees.`last_name`\t,employees.`department_id`, departments.`department_id`,\tdepartments.`department_name`FROM employees, departmentsWHERE employees.`department_id` = departments.`department_id`;\n\n拓展1: 表的别名\n\n使用别名可以简化查询\n\n列明前使用表名前缀可以提高查询效率\nSELECT e.employee_id, e.last_name, e.department_id, \td.department_id, d.location_id FROM employees e , departments dWHERE e.department_id = d.department_id;\n\n\n需要说明的是, 如果我们使用了表的别名, 在查询字段, 过滤条件中就只能使用别名进行替代\n不能使用原来的表名, 否则就会报错\n\n\n阿里开发规范:\n[强制]: 对于数据库中表记录的查询和变更, 只要涉及多个表, 都需要在列名前加上表的别名(或表名) 进行限定\n\n拓展2: 连接多个表\n\n连接n个表, 至少需要n-1个连接条件\n\nSELECT e.`last_name`, d.`department_name`, t.`city`FROM employees e, departments d, locations tWHERE e.`department_id` = d.`department_id` AND d.`location_id` = t.`location_id`;\n\n非等值连接连接的WHERE条件不再是相等, 而是别的逻辑判断\nSELECT e.`last_name`, e.`salary`, j.`grade_level`FROM employees e, job_grades jWHERE e.`salary` BETWEEN j.`lowest_sal` AND j.`highest_sal`;\n\n分类2 : 自连接 vs 非自连接\n当table1和table2本质上是同一张表, 只是用取别名的方式虚拟成两张表以代表不同的意义. 然后两个表再进行内连接, 外连接等查询\n\n题目 : 查询employees表, 返回”Xxx works for Xxx”\nSELECT CONCAT(worker.`last_name`, &#x27; works for &#x27;, manager.`last_name`)FROM employees worker, employees managerWHERE\tworker.`employee_id` = manager.`employee_id`;\n\n\n其实就是我们会为了方便理解, 将一张表虚拟成两张表以代表不同的含义, 然后这两个表, 再通过id等进行等值连接, 最后查询\n\n分类3 : 内连接 vs 外连接\n内连接: 合并具有同一列的两个以上的表的行, 结果集中不包含一个表与另一个表不匹配的行\n\n外连接: 两个表在连接过程中, 除了返回满足连接条件的行以外还返回左 (或右) 表中布满足条件的行, 这种连接成为左 (右) 连接. 没有匹配的行时, 结果表中的相应的列为空(NULL)\n\n如果是左外连接, 则连接条件中的左边的表也称为主表, 右边的表称为从表\n\n如果是右外连接, 则连接条件中的右边的表也称为主表, 左边的表称为从表\n\n\n\n内连接 : 返回满足连接条件的内容, 不满足连接条件的内容不会被返回, 和用WHERE实现的是一致的\n外连接 : 不满足连接条件的内容同样会被返回, 其不满足的部分会填上NULL\n\nSQL92: 使用(+)创建连接\n在SQL92中采用(+) 代表从表所在的位置, 即左或右外连接中, (+)表示哪个是从表\n\nOracle 对 SQL92 支持较好，而 MySQL 则不支持 SQL92 的外连接。\n#左外连接 SELECT last_name,department_name FROM employees ,departments WHERE employees.department_id = departments.department_id(+); #右外连接 SELECT last_name,department_name FROM employees ,departments WHERE employees.department_id(+) = departments.department_id;\n\n而且在 SQL92 中，只有左外连接和右外连接，没有满（或全）外连接。\n\n\nSQL99语法实现多表查询基本语法\n使用JOIN…ON子句创建连接的语法结构:\nSELECT table1.column, table2.column, table3.columnFROM table1\tJOIN table2 ON table1 AND table2 的连接条件\t\tJOIN table3 ON table2 AND table3 的连接条件\n\n嵌套逻辑类似FOR循环\nfor t1 in table1:\tfor t2 in table2:         \tif condition1:\t\t\t\tfor t3 in table3:                     if condition2:                         \toutput t1 + t2 + t3\n\n语法说明:\n\n可以使用ON子句指定额外的连接条件\n这个连接条件是与其他条件分开的\nON 子句使语句具有更高的易读性\n关键字 JOIN, INNER JOIN, CORSS JOIN的含义是一样的, 都表示内连接\n\n\n\n内连接的实现SELECT 字段列表FROM &lt;table-a&gt; INNER JOIN &lt;table-b&gt;ON 关联条件WHERE .....;\n\n题目1 :\nSELECT e.`employee_id`, e.`last_name`, e.`department_id`,\td.`department_id`, d.`location_id`FROM \temployees e JOIN departments dON \t(e.`department_id` = d.`department_id`);\n\n题目2 :\nSELECT e.`last_name`, d.`department_name`, l.`city`FROM employees eINNER JOIN departments dON e.`department_id` = d.`department_id`INNER JOIN locations lON d.`location_id` = l.`location_id`;\n\n外连接左外连接\n语法 :\n# 实现查询结果是ASELECT 字段列表FROM &lt;table-a&gt; LEFT JOIN &lt;table-b&gt;ON 关联条件WHERE 等其他子句;\n\n举例: \nSELECT e.`last_name`, d.`department_name`, d.`department_id`FROM employees eLEFT JOIN departments dON e.department_id = d.`department_id`;\n\n\n左(右) 外连接的特点就是, 从主表(左\\右表)取到的字段名是不会为NULL的, 但是从表的内容可以为NULL\n\n右外连接和左外连接是一样的, 就是换了主表的方向\n\nLEFT JOIN 和 RIGHT JOIN 只存在SQL99及以后的标准中, 在SQL92中不存在, 只能用 (+) 表示\n\n满外连接 ( FULL OUTER JOIN)\n满外连接的结果 &#x3D; 左右表匹配的数据 + 左表没有匹配到的数据 + 右表没有匹配到的数据\nMySQL不支持FULL JOIN, 但是可以用LEFT JOIN UNION RIGHT JOIN代替\n\n7. UNUON的使用合并查询的结果利用UNION关键字, 可以给出多条SELECT语句, 并将它们的结果组合成单个结果集. 合并时, 两个表对应的列数和数据类型必须相同, 并且相互对应. 各个SELECT语句之间使用UNION或UNION ALL关键字分隔\n语法格式:\nSELECT column,... FROM &lt;table1&gt;UNION [ALL]SELECT column,... FROM &lt;table2&gt;\n\n\nUNION 操作符返回两个查询的结果集的并集, 去掉重复的记录\nUNION ALL操作符返回两个查询的结果集的并集, 不去除重复\n\n\n执行UNION ALL语句时所需要的资源比UNION语句少, 如果明确知道合并数据后的结果数据不存在重复数据, 或不需要去除重复的数据, 尽量使用UNION ALL, 提高数据查询的效率\n\n举例 : 查询部门编号&gt;90或邮箱包含a的员工信息\nSELECT e.`last_name`, e.`salary`FROM employees eWHERE e.`department_id` &gt; 90 OR e.`email` REGEXP &quot;[a]&quot;ORDER BY e.salary DESC;\n\nSELECT e.`last_name`, e.`salary`FROM employees eWHERE e.`department_id` &gt; 90UNION SELECT e.`last_name`, e.`salary`FROM employees eWHERE e.`email` REGEXP &quot;[a]&quot;ORDER BY salary DESC;\n\n8. 7种SQL JOINS的实现\n实现七种集合关系\n# 中图 A∩BSELECT employee_id, last_name, department_nameFROM employees e JOIN departments dON e.`department_id` = d.`department_id`;\n\n# 左上图SELECT employee_id, last_name, department_nameFROM employees e LEFT JOIN departments dON e.`department_id` = d.`department_id`;\n\n# 右上图SELECT employee_id, last_name, department_nameFROM employees e RIGHT JOIN departments dON e.`department_id` = d.`department_id`;\n\n# 左中图 A - A∩BSELECT employee_id, last_name, department_nameFROM employees e LEFT JOIN departments dON e.`department_id` = d.`department_id`WHERE d.`department_id` IS NULL;\n\n# 右中图: B-A∩BSELECT employee_id, last_name, department_nameFROM employees e RIGHT JOIN departments dON e.`department_id` = d.`department_id`WHERE e.`department_id` IS NULL;\n\n# 左下图: 满外连接# 左中图 + 右上图  A∪BSELECT employee_id, last_name, department_nameFROM employees e RIGHT JOIN departments dON e.`department_id` = d.`department_id`WHERE e.`department_id` IS NULLUNION ALL SELECT employee_id, last_name, department_nameFROM employees e LEFT JOIN departments dON e.`department_id` = d.`department_id`;\n\n# 右下图# 左中图 + 右真图 A∪B- A∩BSELECT employee_id, last_name, department_nameFROM employees e LEFT JOIN departments dON e.`department_id` = d.`department_id`WHERE d.`department_id` IS NULLUNION ALLSELECT employee_id, last_name, department_nameFROM employees e RIGHT JOIN departments dON e.`department_id` = d.`department_id`WHERE e.`department_id` IS NULL;\n\n9. SQL99语法新特性自然连接SQL99 在SQL92 的基础上提供了一些特殊语法, 比如 NATURAL JOIN用来表示自然连接, 我们可以把自然连接理解为SQL92中的等值连接. 会帮你自动查询两张连接表中的 所有相同字段 , 然后进行 等值连接\nSELECT employee_id, last_name, department_nameFROM employees e NATURAL JOIN departments d;\n\nUSING连接当我们进行连接的时候, SQL99还支持使用USING指定数据表里的 同名字段 进行等值连接. 但是只能配合JOIN一起使用 : \nSELECT employee_id, last_name, department_nameFROM employees e JOIN departments dUSING (department_id);\n\n10. 章节小结我们要 控制连接表的数量. 多表连接就相当于嵌套for循环一样, 非常消耗资源, 会让SQL查询性能下降得很严重, 因此不要连接不必要得表. 在许多DBMS中, 也都会有最大连接表的限制\n\n[强制]  超过三个表禁止join. 需要join的字段, 数据类型保持绝对一致; 多表关联查询时, 保证被关联的字段需要有索引\n即使双表 join 也能注意表索引, SQL性能.\n\n作业【题目】 # 1.显示所有员工的姓名，部门号和部门名称。 # 2.查询90号部门员工的job_id和90号部门的location_id # 3.选择所有有奖金的员工的 last_name , department_name , location_id , city# 4.选择city在Toronto工作的员工的 last_name , job_id , department_id , department_name # 5.查询员工所在的部门名称、部门地址、姓名、工作、工资，其中员工所在部门的部门名称为’Executive’ # 6.选择指定员工的姓名，员工号，以及他的管理者的姓名和员工号，结果类似于下面的格式 employees Emp# manager Mgr# kochhar 101 king 100 # 7.查询哪些部门没有员工 # 8. 查询哪个城市没有部门 # 9. 查询部门名为 Sales 或 IT 的员工信息\n\n# 1 SELECT e.`last_name`, e.`department_id`, d.`department_name`FROM employees e JOIN departments dON e.`department_id` = d.`department_id`;\n\n# 2SELECT e.`job_id`, d.`location_id`FROM employees e JOIN departments dON e.`department_id` = d.`department_id`WHERE e.`department_id` = 90;\n\n# 3SELECT e.`last_name`, d.`department_name`, l.`location_id`, l.`city`FROM employees e, departments d, locations lWHERE e.`department_id` = d.`department_id`AND d.`location_id` = l.`location_id`AND e.`commission_pct` IS NOT NULL;SELECT e.`last_name`, d.`department_name`, l.`location_id`, l.`city`FROM employees eLEFT JOIN departments d ON e.`department_id` = d.`department_id`LEFT JOIN locations lON d.`location_id` = l.`location_id`WHERE e.`commission_pct` IS NOT NULL;\n\n# 4SELECT e.`last_name`, e.`employee_id`, d.`department_id`, d.`department_name`, l.`city`FROM employees eLEFT JOIN departments d ON e.`department_id` = d.`department_id`LEFT JOIN locations lON d.`location_id` = l.`location_id`WHERE l.`city` = &#x27;Toronto&#x27;;\n\n# 5SELECT d.`department_name`, l.`street_address`, e.`last_name`, e.`job_id`, e.`salary`FROM employees eLEFT JOIN departments d ON e.`department_id` = d.`department_id`LEFT JOIN locations lON l.`location_id` = d.`location_id`WHERE d.`department_name` = &#x27;Executive&#x27;;\n\n# 6SELECT worker.`last_name` employees, worker.`employee_id` AS &#x27;Emp#&#x27;, mgr.last_name manager, mgr.employee_id &quot;Mgr#&quot;FROM employees workerLEFT JOIN employees mgrON worker.`manager_id` = mgr.`employee_id`;\n\n# 7SELECT d.`department_name`FROM departments dLEFT JOIN employees eON d.`department_id` = e.`department_id`WHERE e.`department_id` IS NULL;\n\n7. 单行函数1. 函数的理解本章及下一章讲解的是SQL的内置函数\n\nDBMS 之间的差异性很大, 远大于同一个语言不同版本之间的差异. 实际上, 只有很少的函数是被DBMS同时支持的. 大部分DBMS会有自己特定的函数, 这就意味着采用SQL函数的代码可移植性是很差的, 因此在使用函数的时候需要特别注意\n\n函数的分类函数分为 单行函数, 聚合函数 (分组函数)\n单行函数\n\n操作数据对象\n接受参数返回一个结果\n只对一行进行变换\n每行返回一个结果\n可以嵌套\n参数可以是一列或一个值\n\n2. 数值函数基本函数\n\n\n函数\n用法\n\n\n\nABS(x)\n返回x的绝对值\n\n\nSIGN(X)\n返回X的符号. 正数返回1, 负数返回-1, 0返回0\n\n\nPI()\n返回圆周率的值\n\n\nCEIL(x), CEILING(x)\n返回大于或等于某个值的最小整数 : 向上取整\n\n\nFLOOR(x)\n返回小于或等于某个值的最大整数 : 向下取整\n\n\nLEAST(e1, e2, e3….)\n返回列表中的最小值\n\n\nGREATEST(e1,e2,e3…)\n返回列表中的\n\n\nMOD(x,y)\n返回x除以y后的余数\n\n\nRAND()\n返回0 ~ 1的随机值\n\n\nRAND(x)\n返回0~1的随机值, 其中x的值用作种子值, 相同的x值会产生相同的随机数\n\n\nROUND(x)\n返回一个x进行了四舍五入后, 最接近于x的整数\n\n\nROUND(x,y)\n返回一个对x进行了四舍五入后, 最接近x的值, 保留到小数点后y位\n\n\nTRUNCATE(x,y)\n返回数字x截断为y位小数的结果\n\n\nSQRT(x)\n返回x的平方根. 当x的值为负数时, 返回NULL\n\n\n举例 :\nSELECT ABS(-2), ABS(1), SIGN(-2), SIGN(0), PI(), CEIL(9.3), FLOOR(9.3), CEIL(-9.3), FLOOR(-9.3), MOD(12,5);\n\nSELECTLEAST(1,2,23,4,5), GREATEST(1,23,4,4,52,151), RAND(), RAND(2), RAND(2), RAND(3), ROUND(PI()),ROUND(PI(), 2);\n\nSELECT TRUNCATE(PI(), 5), PI(), SQRT(3), SQRT(-3);\n\n角度和弧度互换函数\n\n\n函数\n用法\n\n\n\nRADIANS(x)\n将角度转换弧度, 其中, x为角度值\n\n\nDEGREES(x)\n将弧度转换为角度, 其中, x为弧度值\n\n\nSELECT RADIANS(180), DEGREES(PI());\n\n三角函数\n\n\n函数\n用法\n\n\n\nSIN(x)\n返回x的正弦值, 其中, x为弧度制\n\n\nASIN(x)\n反三角函数, 如果x的值不在-1到1之间, 则返回NULL\n\n\nCOS(x)\n余弦函数\n\n\nACOS(x)\n反余弦函数, 如果x的值不在-1到1之间, 则返回NULL\n\n\nTAN(x)\n返回x的正切值, 即返回正切值为x的值\n\n\nATAN(x)\n返回反正切函数的值\n\n\nATAN2(m,n)\n返回两个参数的反正切值\n\n\nCOT(x)\n返回余切值, 其中, x为弧度制\n\n\n\n三角函数其中的参数都是弧度制参数\n\n针对ATAN2(m,n)的说明, 例如, 有两个点,point(x1,y1)和point(x2,y2), 使用ATAN函数计算反正切值为ATAN((y2-y1)&#x2F;(x2-x1)),  使用ATAN2(M,N)计算反正切值则为(y2-y1, x2-x1). 由使用方式可以看出, 当x2-x1等于0的时候, ATAN(x)函数会报错, 而ATAN2(m,n)函数则仍可以计算\nSELECTSIN(RADIANS(30)), DEGREES(ASIN(1)), TAN(RADIANS(45)), DEGREES(ATAN(1)), DEGREES(ATAN2(1,1));\n\n指数与对数\n\n\n函数\n用法\n\n\n\nPOW(x,y), POWER(x,y)\n返回x的y次方\n\n\nEXP(x)\ne^x\n\n\nLN(x), LOG(x)\n返回以e为底的x的对数\n\n\nLOG10(x)\n返回以10为底的x的对数\n\n\nLOG2(x)\n返回以2为底的x的对数\n\n\n进制之间的转换\n\n\n函数\n用法\n\n\n\nBIN(X)\n返回X的二进制编码\n\n\nHEX(x)\n十六进制\n\n\nOCT(x)\n八进制\n\n\nCONV(x,f1,f2)\n返回f1进制数变成f2进制数\n\n\nCONV(10,2,8) -&gt; 将二进制数(10)转化为八进制数\n3. 字符串函数\n\n\n函数\n用法\n\n\n\nLENGTH(s)\n返回字符串s的字节数, 和字符集有关\n\n\nCONCAT(s1,s2,s3…)\n连接s1,s2,…..,sn为一个字符串函数\n\n\nUPEER(s)\n所有字母大写\n\n\nLOWER(s)\n所有字母小写\n\n\nREVERSE(s)\n返回s反转后的字符串\n\n\nNULLIF(value1, value2)\n比较两个字符串, 如果value1和value2相等, 则返回NULL, 否则返回value1\n\n\nFIND_IN_SET(s1,s2)\n返回字符串s1在字符串s2中出现的位置, s2以逗号为分隔\n\n\nFILED(s,s1,…)\n返回字符串s在字符串列表中第一次出现的位置\n\n\n\n注意 : MySQL中, 字符串的位置是从1开始的\n\nSELECT FIELD(&#x27;mm&#x27;, &#x27;hello&#x27;, &#x27;msm&#x27;, &#x27;ammma&#x27;), FIND_IN_SET(&#x27;mm&#x27;,&#x27;hello,mm,amma&#x27;);\n\nSELECT NULLIF(&#x27;mysql&#x27;,&#x27;mysql&#x27;), NULLIF(&#x27;mysql&#x27;, &#x27;&#x27;);\n\n4. 日期和时间函数获取日期, 时间\n\n\n函数\n用法\n\n\n\nCURDATE(), CURRENT_DATE()\n返回当前日期, 只包含年, 月, 日\n\n\nCURTIME(), CURRENT_TIME()\n返回当前时间, 只包含时分秒\n\n\nNOW() &#x2F; SYSDATE() &#x2F; CURRENT_TIMESTAMP() &#x2F; LOCALTIME() &#x2F; LOCALTIMESTAMP()\n返回当前系统日期和时间\n\n\nUTC_DATE()\n返回UTC (世界标准时间) 日期\n\n\nUTC_TIME()\n返回UTC (世界标准时间) 时间\n\n\nSELECTCURDATE(), CURTIME(), NOW(), UTC_DATE(), UTC_TIME();\n\n\n可以通过 + 0, 将时间类型转化为数字, 比如2021-10-25 + 0 -&gt; 20211025, 以此可以比较时间?\n\n日期和时间戳的转换\n\n\n函数\n用法\n\n\n\nUNIX_TIMESTAMP()\n以UNIX时间戳的形式返回当前时间\n\n\nUNIX_TIMESTAMP(date)\n将时间date以UNIX时间戳的形式返回\n\n\nFROM_UNIXTIME(timestamp)\njiangUNIX时间戳的时间转换为普通格式的时间\n\n\nSELECTUNIX_TIMESTAMP(), FROM_UNIXTIME(UNIX_TIMESTAMP(NOW()));\n\n获取月份, 星期, 星期数, 天数等函数\n\n\n函数\n用法\n\n\n\nYEAR(date) &#x2F; MONTH(date) &#x2F; DAY(date)\n返回具体的日期值\n\n\nHOUR(time)&#x2F; MINUTE(time) &#x2F; SECOND(time)\n返回具体的时间\n\n\nMONTHNAME(date)\n返回月份: January\n\n\nDAYNAME(date)\n返回星期几: MONDAY…\n\n\nWEEKDAY(date)\n返回周几, 周一是0, 周二是1…\n\n\nQUARTER(date)\n返回日期对应的季度, 范围为1 ~ 4\n\n\nWEEK(date) , WEEKOFYEAR(date)\n返回一年中的第几周\n\n\nDAYOFYEAR(date)\n返回一年中的第几天\n\n\nDAYOFMONTH(date)\n返回日期位于所在月份的第几天\n\n\nDAYOFWEEK(date)\n返回周几, 注意周日是1, 周一是2\n\n\n日期的操作函数\n\n\n函数\n用法\n\n\n\nEXTRACT(type FROM date)\n返回指定日期中特定的部分, type指定返回的值\n\n\n\nSELECT EXTRACT(MINUTE FROM NOW());\n\n时间和秒钟转换的函数\n\n\n函数\n用法\n\n\n\nTIME_TO_SEC(time)\n将time转化为秒并返回结果值, 转化公式为: 小时*3600 + 分钟*60 + 秒\n\n\nSEC_TO_TIME(seconds)\n将seconds描述转化为包含小时, 分钟和秒的时间\n\n\nSELECT TIME_TO_SEC(CURTIME()), CURTIME();\n\n计算日期和时间的函数\n\n\n函数\n用法\n\n\n\nDATE_ADD(datetime, INTERVAL expr type), ADDDATE(date, INTERVAL expr type)\n返回与给定日期时间相差INTERVAL时间段的日期时间\n\n\nDATE_SUB(date, INTERVAL expr type), SUBDATE(date, INTERRVAL expr type) , SUBDATE(….)\n返回与date相差INTERVAL时间间隔的日期\n\n\n\nSELECT DATE_ADD(NOW(), INTERVAL 1 DAY) AS col1, DATE_ADD(&#x27;2021-10-21 23:32:12&#x27;, INTERVAL 1 SECOND) AS col2,ADDDATE(&#x27;2021-10-21 23:32:12&#x27;,INTERVAL 1 SECOND) AS col3, DATE_ADD(&#x27;2021-10-21 23:32:12&#x27;,INTERVAL &#x27;1_1&#x27; MINUTE_SECOND) AS col4, DATE_ADD(NOW(), INTERVAL -1 YEAR) AS col5, #可以是负数 DATE_ADD(NOW(), INTERVAL &#x27;1_1&#x27; YEAR_MONTH) AS col6; #需要单引号\n\nSELECT DATE_SUB(&#x27;2021-01-21&#x27;,INTERVAL 31 DAY) AS col1, SUBDATE(&#x27;2021-01-21&#x27;,INTERVAL 31 DAY) AS col2, DATE_SUB(&#x27;2021-01-21 02:01:01&#x27;,INTERVAL &#x27;1 1&#x27; DAY_HOUR) AS col3 FROM DUAL;\n\n\nADDDATE是向前 “+” 上指定的时间\nSUBDATE是向后 “-“ 上指定的时间\n\n\n\n\n函数\n用法\n\n\n\nADDTIME(time1, time2)\n返回time1加上time2的时间, 当time2为一个数字时, 代表的是秒, 可以为负数\n\n\nSUBTIME(time1, time2)\n返回time1减去time2后的时间, 当time2为一个数字的时候,代表的是秒, 可以为负数\n\n\nDATEDIFF(time1, time2)\n返回date1 - date2 的日期间隔天数\n\n\nTIMEDIFF(time1, time2)\n返回time1 - time 的时间间隔\n\n\nFROM_DAYS(n)\n返回从0000年1月1日起, n天以后的日期\n\n\nTO_DAYS(date)\n返回date距离0000年1月1日的天数\n\n\nLAST_DAY(date)\n返回date所在月份的最后一天的日期\n\n\nMAKEDATE(year, n)\n针对给定年根与所在年份中的天数返还一个日期\n\n\nMAKETIME(hour, minute, second)\n将给定的小时, 分钟和秒组合成时间并返回\n\n\nPERIOD_ADD(time, n)\n返回time加上n后的时间\n\n\nSELECT ADDTIME(NOW(), 20), NOW(), SUBTIME(NOW(), 30) , SUBTIME(NOW(), &#x27;1:1:3&#x27;), DATEDIFF(NOW(), &#x27;2021-10-01&#x27;), TIMEDIFF(NOW(), &#x27;2021-10-01 22:10:20&#x27;);\n\nmysql&gt; SELECT SUBTIME(NOW(), &#x27;-1:-1:-1&#x27;);+----------------------------+| SUBTIME(NOW(), &#x27;-1:-1:-1&#x27;) | +----------------------------+| 2019-12-15 22:25:11 \t\t | +----------------------------+\n\nmysql&gt; SELECT MAKEDATE(2020,32); +-------------------+| MAKEDATE(2020,32) |+-------------------+| 2020-02-01 \t\t| +-------------------+\n\n举例 : 查询七天内新增用户的数量由多少\nSELECT COUNT(*) AS numFROM new_userWHERE TO_DAYS(NOW()) - TO_DAYS(regist_time) &lt;= 7;\n\n日期的格式化与解析\n\n\n函数\n方法\n\n\n\nDATE_FORMAT(date, fmt)\n按照字符串fmt格式化日期date\n\n\nTIME_FORMAT(time, fmt)\n按照字符串fmt格式化时间time\n\n\nGET_FORMAT(date_type, format_type)\n返回日期字符串的显示格式\n\n\nSTR_TO_DATE(str, fmt)\n按照字符串fmt对str进行解析, 解析为一个日期\n\n\n上述非GET_FORMAT函数中fmt参数常用的格式符:\n\n\n\n格式符\n说明\n格式符\n说明\n\n\n\n%Y\n4位数字表示数字\n%y\n两位数字表示年份\n\n\n%M\n月名表示月份\n%m\n两位数字表示月份(01,02,03)\n\n\n%b\n缩写的月名\n%c\n数字表示月份 (1,2,3..)\n\n\n%D\n英文后缀表示月中的天数(1st, 2nd, 3rd…)\n%d\n两位数字表示月中的天数(01, 02..)\n\n\n%e\n数字形式表示月中的天数\n\n\n\n\n%H\n两位数字表示小时, 24小时制 (01,02…)\n%h或%l\n两位数字表示小时, 12小时制\n\n\n%i\n两位数字表示分钟\n%S和%s\n两位数字表示秒\n\n\n%W\n一周中的星期名称\n%a\n星期的缩写\n\n\n%w\n数字表示周 (Sun &#x3D; 0)\n\n\n\n\n%j\n以3位数字表示年终的天数(001, 002…)\n%U\n以数字表示年中的第几周, (1,2,3..), 其中Sun为周中的第一天\n\n\n%u\n以数字表示年中的第几周\n\n\n\n\n%T\n24小时制\n%r\n12小时制\n\n\n%p\nAM或PM\n%%\n表示%\n\n\nGET_FORMAT函数中date_type和format_type参数的取值如下:\n\nSELECT DATE_FORMAT(NOW(), &#x27;%H:%i:%s&#x27;);-- 21:18:03\n\nSELECT STR_TO_DATE(&#x27;09/01/2009&#x27;, &#x27;%m/%d/%Y&#x27;);str_to_date(&#x27;09/01/2009&#x27;, &#x27;%m/%d/%Y&#x27;)2009-09-01\n\nSELECT GET_FORMAT(DATE, &#x27;USA&#x27;);# %m.%d.%YSELECT DATE_FORMAT(NOW(), GET_FORMAT(DATE, &#x27;USA&#x27;));\n\nSELECT STR_TO_DATE(&#x27;2020-01-01 00:00:00&#x27;, &#x27;%Y-%m-%d&#x27;);# 2020-01-01\n\n5. 流程控制函数流程处理函数可以根据不同的条件, 执行不同的处理流程, 类似与CPP中的条件控制语句\n\n\n\n函数\n用法\n\n\n\nIF(value, value1, value2)\n如果value的值为TRUE, 返回value1, 否则返回value2 : 就像 ? :语句\n\n\nIFNULL(value1, value2)\n如果value1不为NULL返回value1,否则返回value2\n\n\nCASE WHEN 条件1 THEN 结果1 WHEN 条件2 THEN 结果2…[ELSE resultn] END\n相当于Java的if … else if … else …\n\n\nCASE expr WHEN 常量1 THEN 值1 WHEN 常量值2 THEN 值1 … [ELSE值n] END\n相当于Java的switch … case …\n\n\nSELECT IF(1 &gt; 0, &#x27;正确&#x27;, &#x27;错误&#x27;);\n\nSELECT IFNULL(NULL, &#x27;Hello&#x27;);\n\nSELECT CASE\tWHEN 1 &gt; 0\tTHEN &#x27;1&gt;0&#x27;\tWHEN 2 &gt; 0\tTHEN &#x27;2&gt;0&#x27;\tELSE &#x27;3&gt;0&#x27;\tEND;\n\nSELECT CASE 2\tWHEN 1 THEN  &#x27;我是1&#x27;\tWHEN 2 THEN  &#x27;我是2&#x27;\tELSE &#x27;你是谁&#x27;\tEND;\n\nSELECT employee_id, salary, CASE WHEN salary &gt;= 15000 THEN &#x27;高薪&#x27;\t\t\tWHEN salary &gt;= 10000 THEN &#x27;潜力股&#x27;\t\t\tWHEN salary &gt;=8000   THEN &#x27;屌丝&#x27;\t\t\tELSE &#x27;草根&#x27; END &#x27;描述&#x27;FROM employees;\n\nSELECT CASE WHEN 1 &gt; 0 THEN &#x27;yes&#x27;\t\tWHEN 1 &lt;= 0 THEN &#x27;no&#x27;\t\tELSE &#x27;unknow&#x27;\t\tEND;\n\nSELECT employee_id, 12 * salary * (1 + IFNULL(commission_pct, 0))FROM employees;\n\nSELECT last_name, job_id, salary,\tCASE job_id WHEN &#x27;IT_PROG&#x27; THEN 1.10*salary\t\t    WHEN &#x27;ST_CLERK&#x27;THEN 1.15*salary\t\t    WHEN &#x27;SA_REP&#x27;  THEN 1.20*salary\t\t    ELSE salary\t   END  &quot;REVISD_SALARY&quot;FROM employees;\n\n6. 加密和解密函数可以保证数据库的安全\n\n\n\n函数\n用法\n\n\n\nPASSWORD(str)\n加密str, 41位长的字符串, 加密结果不可逆, 常用于用户密码的加密\n\n\nMD5(str)\n返回字符串str的md5加密后的值, 也是一种加密方式, 若参数为NULL, 则会返回NULL\n\n\nSHA(str)\n从原明文密码str计算并返回加密后的密码字符串, 当参数为NULL时, 返回NULL. SHA加密算法比MD5更加安全\n\n\nENCODE(value, password_seed)\n返回使用password_seed作为加密密码加密value\n\n\nDECODE(value, password_seed)\n返回使用password_seed作为加密密码解密value\n\n\nSELECT PASSWORD(&#x27;mysql&#x27;), PASSWORD(NULL);# PASSWORD()函数在5.7版本以后已经弃用了\n\nSELECT MD5(&#x27;123&#x27;), SHA(&#x27;maysql&#x27;);\n\nSELECT AES_DECRYPT(AES_ENCRYPT(&#x27;str&#x27;,&#x27;str&#x27;),&#x27;str&#x27;);# ENCODE已经被弃用\n\n7. MySQL信息函数内置查看MySQL信息的函数\n\n\n\n函数\n用法\n\n\n\nVERSION()\n返回当前MySQL的版本号\n\n\nCONNECTIUON_ID()\n返回当前MySQL服务器的连接数\n\n\nDATABASE(), SCHEMA()\n返回MySQL命令当前所在的数据库\n\n\nUSER(), CURRENT_USER(), SYSTEM_USER(), SESSION_USER()\n返回当前连接MySQL的用户名, 返回格式为”主机名@用户名”\n\n\nCHARsET(value)\n返回字符集value自变量的字符集\n\n\nCOLLATION(value)\n返回字符串value的比较规则\n\n\nSELECT VERSION(), CONNECTION_ID(), DATABASE(), USER(), CHARSET(&#x27;abc&#x27;), COLLATION(&#x27;abc&#x27;);\n\n8. 其他函数一些难以分类但是重要的函数\n\n\n\n函数\n用法\n\n\n\nFORMAT(value, n)\nn表示四舍五入后保留到小数点后n位\n\n\nINET_ATON(ipvalue)\n将以点分隔的IP地址转化为一个数字\n\n\nINET_NTOA(value)\n将数字形式的IP地址转化为以点为分隔的IP地址\n\n\nBENCHMARK(n, expr)\n将表达式expr重复执行n次, 用于测试MySQL处理expr表达式所耗费的时间\n\n\nCONVERT(value USING char_code)\n将value所使用的字符编码修改为char_code\n\n\nSELECT FORMAT(123.123, 2), INET_ATON(&#x27;192.168.21&#x27;), INET_NTOA(INET_ATON(&#x27;192.168.21&#x27;)), BENCHMARK(12000, MD5(&#x27;mysql&#x27;));\n\nSELECT CHARSET(&#x27;mysql&#x27;), CHARSET(CONVERT(&#x27;mysql&#x27; USING &#x27;utf8&#x27;));\n\n作业【题目】 # 1.显示系统时间(注：日期+时间) # 2.查询员工号，姓名，工资，以及工资提高百分之20%后的结果（new salary） # 3.将员工的姓名按首字母排序，并写出姓名的长度（length） # 4.查询员工id,last_name,salary，并作为一个列输出，别名为OUT_PUT # 5.查询公司各员工工作的年数、工作的天数，并按工作年数的降序排序 # 6.查询员工姓名，hire_date , department_id，满足以下条件：雇用时间在1997年之后，department_id 为80 或 90 或110, commission_pct不为空 # 7.查询公司中入职超过10000天的员工姓名、入职时间 # 8.做一个查询，产生下面的结果 &lt;last_name&gt; earns &lt;salary&gt; monthly but wants &lt;salary*3&gt;# 9.使用case-when，按照下面的条件： job grade AD_PRES A ST_MAN B IT_PROG C SA_REP D ST_CLERK E\n\n# 1SELECT NOW();# 2SELECT last_name, employee_id, salary, salary * 1.2 AS &quot;new salary&quot;FROM employees;# 3SELECT last_name, LENGTH(last_name) AS LENGTHFROM employeesORDER BY last_name;# 4SELECT CONCAT(employee_id, &#x27;,&#x27;,  last_name, &#x27;,&#x27;,  salary) AS OUT_PUTFROM employees;# 5SELECT last_name, YEAR(NOW()) - YEAR(hire_date) years, DATEDIFF(NOW(), hire_date)FROM employeesORDER BY years DESC;# 6SELECT last_name, hire_date, department_idFROM employees# where year(hire_date) &gt; 1997 WHERE DATE_FORMAT(hire_date,&#x27;%Y&#x27;) &gt;= &#x27;1997&#x27;AND department_id IN (80, 90, 110) AND commission_pct IS NOT NULL;# 7SELECT last_name, hire_date, DATEDIFF(NOW(), hire_date)FROM employeesWHERE DATEDIFF(NOW(), hire_date) &gt; 10000;# 8SELECT CONCAT(&#x27;&lt;&#x27;, last_name, &#x27;&gt; &#x27;, &#x27;earns &lt;&#x27;, TRUNCATE(salary,0), &#x27;&gt; monthly but wants &lt;&#x27;, salary*3, &#x27;&gt;&#x27;) AS &quot;Dream Salary&quot;FROM employees;# 9SELECT last_name, job_id, CASE job_id\tWHEN &#x27;AD_PRES&#x27; THEN &#x27;A&#x27;\tWHEN &#x27;ST_MAN&#x27;  THEN &#x27;B&#x27;\tWHEN &#x27;IT_PROG&#x27; THEN &#x27;C&#x27;\tWHEN &#x27;SA_REP&#x27;  THEN &#x27;D&#x27;\tWHEN &#x27;ST_CLERK&#x27;THEN &#x27;E&#x27;\tEND AS &quot;Grade&quot;FROM employees;\n\n8. 聚合函数对数据进行汇总的函数\n聚合函数介绍\n什么是聚合函数\n\n聚合函数作用于一组数据, 并对一组数据返回一个值\n\n聚合函数类型\nAVG()\nSUM()\nMAX()\nMIN()\nCOUNT()\n\n\n聚合函数不能嵌套使用\n\nAVG, SUM可以对数值类数据使用\n比如, 不能对varchar()类型的使用\nMIN和MAX函数可以对任意数据类型的数据使用\n可以比较日期\nCOUNT函数\nCOUNT(*)返回表中记录总数, 适用于任何数据类型\n\nSELECT COUNT(*)FROM employeesWHERE department_id = 90;\n\n\nCOUNT(expr)返回expr不为空的记录总数\n\nSELECT COUNT(commission_pct)FROM employeesWHERE department_id = 90;\n\n\n问题: 用count(*), count(1), count(列名)谁好呢?\ncount(*), count(1)比count(列名)\n\n问题: 能不能使用count(列名)替换count(*)?\n不要使用 count(列名)来替代 count(*) ， count(*) 是 SQL92 定义的标准统计行数的语法，跟数\n据库无关，跟 NULL 和非 NULL 无关。\n说明：count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。\n\n\nGROUP BY基本使用可以使用GROUP BY子句将表中的数据分为若干组\nSELECT column, group_function(column)FROM &lt;table&gt;[WHERE condition][GROUP BY group_by_expression][GROUP BY column]\n\n\nWHERE一定放在FROM后面\n\nSELECT department_id, AVG(salary)FROM employeesGROUP BY department_id;\n\n包含在 GROUP BY子句中的列不必包含在SELECT列表中\nSELECT  AVG(salary)FROM employeesGROUP BY department_id;\n\n使用多个列分组SELECT department_id, job_id, SUM(salary)FROM employeesGROUP BY department_id, job_id;\n\nGROUP BY中使用WITH ROLLUP使用这个关键字以后, 能计算查询出的所有记录的综合, 即统计记录数量\nSELECT department_id,job_id , AVG(salary)FROM employeesGROUP BY department_id, job_id WITH ROLLUP;\n\n\n表示’小计’, 我们有一个销售数据表，包含年份、季度和销售额，\n年份   季度   总销售额\n2023   Q1     10002023   Q2     12002023   Q3     11002023   Q4     13002023   NULL   4600    – 2023年的小计2024   Q1     11002024   Q2     13002024   NULL   2400    – 2024年的小计NULL   NULL   7000    – 总计\n年度小计 : 当季度列为NULL时, 对应行显示该年度的总销售额\n总计行 : 当年份和季度都为NULL时, 显示所有年份和季度的总销售额\n\n\n当使用ROLLUP时, 不能同时使用ERDER BY子句进行结果排序, 即两个语句是互斥语句\n\nHAVING语句基本使用过滤分组: HAVING子句\n适用情况:\n\n行已经被分组\n使用了聚合函数\n满足HAVING子句中条件的分组将被显示\nHAVING 不能单独使用, 必须要跟 GROUP BY一起使用\n\nSELECT department_id, MAX(salary)FROM employeesGROUP BY department_idHAVING\tMAX(salary)&gt;10000;\n\n\n其实就是针对GROUP BY + WHERE后面条件语句不能使用聚合函数的补充\n\nWHERE和HAVING的对比区别1 : WHERE可以直接使用表中的字段作为筛选条件, 但不能使用分组中的计算函数作为筛选条件; HAVING 必须要和GROUP BY配合使用, 可以把分组计算的函数和分组作为筛选条件\n在查询语法结构中, WHERE语句在GROUP BY之前, 无法对分组结果进行筛选. 另外, WHERE排除的记录不再包括在分组中\n区别2 : 如果需要通过连接从关联表中获取需要的数据, WHERE是先筛选后连接, 而HAVING是先连接后筛选\n\n\n\n\n优点\n缺点\n\n\n\nWHERE\n先筛选数据再关联, 执行效率高\n不能对分组中的计算函数进行筛选\n\n\nHAVING\n可以使用分组中的计算函数\n在最后的结果集中进行筛选, 执行效率较低\n\n\n开发中的选择:\n两者并不是相互排斥的, 我们可以在一个查询中同时使用WHERE和HAVING. 包含分组统计函数的条件使用HAVING, 普通条件使用WHERE\nSELECT的执行过程查询的结构# 方式1:SELECT ...FROM ...WHERE 多表的连接条件AND  不包含组函数的过滤条件GROUP BY ...HAVING 包含组函数的过滤条件ORDER BY ... ASC/DESCLIMIT ...\n\n# 方式2:SELECT ...FROM ... JOIN ...ON 多表连接的条件JOIN ...ON ...WHERE 不包含组函数的过滤条件AND/OR 不包含组函数的过滤条件GROUP BY ...HAVING 包含组函数的过滤条件ORDER BY .... ASC?DEsCLIMIT ...\n\nSELECT 的执行顺序1. 关键字的顺序是不能颠倒的\nSELECT ... FROM ... WHERE ... GROUP BY ... HAVING ... ORDER BY ... LIMIT\n\n2. SELECT语句的执行顺序\nFROM -&gt; WHERE -&gt; GROUP BY -&gt; HAVING -&gt; SELECT 字段 -&gt; DISTINCT -&gt; ORDER BY -&gt; LIMIT\n\n在SELECT语句执行这些步骤的时候, 每个步骤都会产生一个虚拟表, 然后将这个虚拟表传入下一个步骤中作为输入, 需要注意的是, 这些步骤隐含在SQL的执行过程中, 对于我们来说是不可见的\nSQL的执行原理SELECT 是先执行 FROM 这一步的。在这个阶段，如果是多张表联查，还会经历下面的几个步骤：\n​\t1. 首先先通过 CROSS JOIN 求笛卡尔积，相当于得到虚拟表 vt（virtual table）1-1； \n​\t2. 通过 ON 进行筛选，在虚拟表 vt1-1 的基础上进行筛选，得到虚拟表 vt1-2； \n​\t3. 添加外部行。如果我们使用的是左连接、右链接或者全连接，就会涉及到外部行，也就是在虚拟\n表 vt1-2 的基础上增加外部行，得到虚拟表 vt1-3。\n当然如果我们操作的是两张以上的表，还会重复上面的步骤，直到所有表都被处理完为止。这个过程得\n到是我们的原始数据。\n当我们拿到了查询数据表的原始数据，也就是最终的虚拟表 vt1 ，就可以在此基础上再进行 WHERE 阶 \n段 。在这个阶段中，会根据 vt1 表的结果进行筛选过滤，得到虚拟表 vt2 。\n然后进入第三步和第四步，也就是 GROUP 和 HAVING 阶段 。在这个阶段中，实际上是在虚拟表 vt2 的\n基础上进行分组和分组过滤，得到中间的虚拟表 vt3 和 vt4 。\n当我们完成了条件筛选部分之后，就可以筛选表中提取的字段，也就是进入到 SELECT 和 DISTINCT \n阶段 。\n首先在 SELECT 阶段会提取想要的字段，然后在 DISTINCT 阶段过滤掉重复的行，分别得到中间的虚拟表\nvt5-1 和 vt5-2 。\n当我们提取了想要的字段数据之后，就可以按照指定的字段进行排序，也就是 ORDER BY 阶段 ，得到\n虚拟表 vt6 。\n最后在vt6的基础上，取出指定行的记录，也就是 LIMIT 阶段 ，得到最终的结果，对应的是虚拟表\nvt7 。\n当然我们在写 SELECT 语句的时候，不一定存在所有的关键字，相应的阶段就会省略。\n同时因为 SQL 是一门类似英语的结构化查询语言，所以我们在写 SELECT 语句的时候，还要注意相应的\n关键字顺序，所谓底层运行的原理，就是我们刚才讲到的执行顺序\n作业【题目】 #1.where子句可否使用组函数进行过滤? #2.查询公司员工工资的最大值，最小值，平均值，总和 #3.查询各job_id的员工工资的最大值，最小值，平均值，总和 #4.选择具有各个job_id的员工人数 # 5.查询员工最高工资和最低工资的差距（DIFFERENCE） # 6.查询各个管理者手下员工的最低工资，其中最低工资不能低于6000，没有管理者的员工不计算在内 # 7.查询所有部门的名字，location_id，员工数量和平均工资，并按平均工资降序 # 8.查询每个工种、每个部门的部门名、工种名和最低工资\n\n# 2SELECT MAX(salary), MIN(salary), AVG(salary), SUM(salary)FROM employees;\n\n# 3SELECT job_id, MAX(salary), MIN(salary), AVG(salary), SUM(salary)FROM employeesGROUP BY job_id;\n\n# 4SELECT job_id, MAX(salary), MIN(salary), AVG(salary), SUM(salary)FROM employeesGROUP BY job_id;\n\n# 5SELECT MAX(salary) - MIN(salary) DIFFERENCEFROM employees;\n\n# 6SELECT MAX(salary) - MIN(salary) DIFFERENCEFROM employees;\n\n# 7SELECT d.`department_name`, d.`location_id`, COUNT(employee_id), AVG(e.`salary`)FROM employees e RIGHT JOIN departments dON e.`department_id` = d.`department_id`GROUP BY department_name, location_idORDER BY MIN(e.`salary`) DESC;\n\n\n当SELECT 语句中同时有聚合列和非聚合列的时候一定要有GROUP BY\n因为这个时候, 非聚合列的一行数据是无法和聚合列的一行数据对应的\n\n# 8SELECT e.`job_id`, d.`department_name`, MIN(salary)FROM employees e RIGHT JOIN departments dON e.`department_id` = d.`department_id`GROUP BY  d.`department_name`, e.`job_id`;\n\n9. 子查询需求分析与问题解决实际问题谁的工资比 Abel 高 ? &#x3D;&gt; Abel 的工资是多少\n# 自连接SELECT e2.`salary`, e1.`salary`FROM employees e1, employees e2WHERE e1.`last_name` = &#x27;Abel&#x27;AND e2.`salary` &gt; e1.salary\n\n# 子查询SELECT salaryFROM employeesWHERE salary &gt; (\tSELECT salary\tFROM employees\tWHERE last_name = &#x27;Abel&#x27;\t);\n\n子查询的基本使用\n子查询的基本语法结构\nSELECT select_listFROM &lt;table&gt;WHERE expr operator\t\t\t\t(SELECT select_list                FROM &lt;table&gt;);\n\n子查询 (内查询) 在主查询之前一次执行完成\n\n子查询的结果被主查询 (外查询) 使用\n\n注意事项\n\n子查询要包含在括号内\n将子查询放在比较条件的右侧\n单行操作符对应单行子查询, 多行操作符对应多行子查询\n\n\n\n子查询的分类分类方式1:\n按查询的结果返回一条还是多条记录, 将子查询分为单行子查询, 多行子查询\n分类方式2:\n按内查询是否被执行多次, 将子查询划分为相关(或关联)子查询和不相关(或非关联)子查询\n子查询只是作为条件进行执行, 只运行一次, 这种查询叫做不相关子查询\n采用循环的方式, 先从外部查询开始, 每次都传入子查询进行查询, 然后再将结果反馈给外部, 这种嵌套的执行方式就是相关子查询\n单行子查询题目: 查询工资大于149号员工工资的员工的信息\nSELECT last_name, salaryFROM employeesWHERE salary &gt; (\tSELECT salary\tFROM employees\tWHERE employee_id = 149); \n\n题目: 返回job_id与141号员工相同, salary比143员工多的员工姓名, job_id和工资\nSELECT last_name, job_id, salaryFROM employeesWHERE job_id = (\tSELECT job_id\tFROM employees\tWHERE employee_id = 141)AND salary &gt; (\tSELECT salary\tFROM employees\tWHERE employee_id = 143);\n\n题目 : 查询与141号或174员工的manager_id和department_id相同的其他员工的employee_id, manager_id, department_id\n不成对比较 : \nSELECT employee_id, manager_id, department_idFROM employeesWHERE manager_id IN\t(SELECT manager_id\t\tFROM employees\t\tWHERE employee_id IN (141,174))AND department_id IN\t(SELECT department_id\t\tFROM employees\t\tWHERE employee_id IN (141,174));\n\n成对比较 :\nSELECT employee_id, manager_id, department_idFROM employeesWHERE (manager_id, department_id) IN\t(SELECT manager_id, department_id\t\tFROM employees\t\tWHERE employee_id IN (141, 174))AND employee_id NOT IN (141, 174);\n\nHAVING 中的子查询\n首先执行子查询\n向主查询中的HAVING子句返回结果\n\n题目: 擦汗寻最低工资大于50号部门最低工资的部门id和其他最低工资\nSELECT department_id, MIN(salary)FROM employeesGROUP BY department_idHAVING MIN(salary) &gt;\t(SELECT MIN(salary)\t\tFROM employees\t\tWHERE department_id = 50);\n\nCASE中的子查询题目：显式员工的employee_id,last_name和location。其中，若员工department_id与location_id为1800 \n的department_id相同，则location为’Canada’，其余则为’USA’\nSELECT employee_id, last_name, \t(CASE department_id\tWHEN (SELECT department_id\t\tFROM departments\t\tWHERE location_id = 18000)\tTHEN &#x27;Canada&#x27;\tELSE &#x27;USA&#x27; END) location\tFROM employees\n\n子查询中的空值问题SELECT last_name, job_id FROM employees WHERE job_id =     (SELECT job_id         FROM employees         WHERE last_name = &#x27;Haas&#x27;);\n\n\n子查询不返回任何行\n\n非法使用子查询SELECT employee_id, last_name FROM employees WHERE salary =     (SELECT MIN(salary) FROM employees      GROUP BY department_id);\n\n\n错误代码 : 1241Subquery returns more than 1 row\n\n\n多行子查询使用单行比较符\n\n多行子查询\n也称为集合比较子查询\n内查询返回多行\n使用多行比较操作符\n\n多行比较操作符\n\n\n操作符\n含义\n\n\n\nIN\n等于列表中的任何一个\n\n\nANY\n需要和单行比较操作符一起使用, 和子查询返回的某个值进行比较\n\n\nALL\n需要和单行比较操作符一起使用, 和子查询返回的所有值比较\n\n\nSOME\n实际上式ANY的别名, 作用相同, 一般常使用ANY\n\n\n\nANY操作符: ANY表示”与子查询返回的任何一个值比较”。如果比较结果有一个为真，则整个表达式为真。\nALL操作符: ALL表示”与子查询返回的所有值比较”。只有当比较结果对所有值都为真时，整个表达式才为真。\n\n题目：返回其它job_id中比job_id为‘IT_PROG’部门任一工资低的员工的员工号、姓名、job_id 以及salary\nSELECT employee_id, last_name, job_id, salaryFROM employeesWHERE salary &lt; ANY    (SELECT salary        FROM employees        WHERE job_id = &#x27;IT_PROG&#x27;)AND job_id &lt;&gt; &#x27;IT_PROG&#x27;;\n\n题目：返回其它job_id中比job_id为‘IT_PROG’部门所有工资都低的员工的员工号、姓名、job_id以及salary\nSELECT employee_id, last_name, job_id, salaryFROM employeesWHERE salary &lt; ALL    (SELECT salary        FROM employees        WHERE job_id = &#x27;IT_PROG&#x27;)AND job_id &lt;&gt; &#x27;IT_PROG&#x27;;\n\n题目：查询平均工资最低的部门id\nSELECT department_idFROM employeesGROUP BY department_id HAVING AVG(salary) &lt;= ALL(        SELECT AVG(salary)        FROM employees        GROUP BY department_id);\n\n相关子查询执行流程相关子查询就是, 子查询中引用了外部表, 比如, 我们想查员工中工资大于本部门平均工资的员工, department_id &#x3D; e.department_id,\n 我们每计算一行的时候, 外部查询产生的结果集都会发生变化, 这个时候对应的子查询也需要重复计算一次, 因为它引用了外部表\nSELECT column1, column2, ...FROM &lt;table1&gt; outerWHERE column1 operator\t\t\t\t\t(SELECT column1, column2                    \tFROM &lt;table2&gt;                    \tWHERE expr1 =                     \t\t\t\touter.expr2)\n\n\n这里的outer是&lt;table1&gt; 的别名\n\n题目：查询员工中工资大于本部门平均工资的员工的last_name,salary和其department_id\n使用相关子查询\nSELECT last_name, salary, department_idFROM employees eWHERE e.salary &gt;             (SELECT AVG(salary)            FROM employees            WHERE  department_id = e.`department_id`);\n\nFROM中使用子查询\nSELECT last_name, salary, e1.department_idFROM employees e1, (SELECT department_id, AVG(salary) dept_avg_sal FROM employees GROUP BY department_id) e2WHERE e1.`department_id` = e2.department_idAND e2.dept_avg_sal &lt; e1.`salary`;\n\n\nFROM型的子查询: 子查询是作为FROM的一部分, 子查询要用()引起来, 并且要给这个子查询取别名, 把它当成一张”临时的虚拟的表”来使用\n\n在ORDER BY中使用子查询:\n题目：查询员工的id,salary,按照department_name 排序\nSELECT employee_id, salaryFROM employees eORDER BY (          SELECT department_name          FROM departments d          WHERE e.`department_id` = d.`department_id`) DESC;\n\n题目：若employees表中employee_id与job_history表中employee_id相同的数目不小于2，输出这些相同\nid的员工的employee_id,last_name和其job_id \nSELECT e.employee_id, last_name, e.job_idFROM employees e WHERE 2 &lt;= (SELECT COUNT(*) num FROM job_history j WHERE j.`employee_id` = e.`employee_id`);\n\nEXISTS 与 NOT EXISTS关键字\n关联子查询通常也会和 EXISTS 操作符一起使用, 用来检查在子查询中是否存在满足条件的行\n如果在子查询中不存在满足条件的行:\n返回FALSE\n继续在子查询中查找\n\n\n如果在子查询中存在满足条件的行:\n不在子查询中继续查找\n条件返回TRUE\n\n\nNOT EXISTS关键字表示如果不存在某种条件, 则返回TRUE, 否则返回FALSE\n\n题目：查询公司管理者的employee_id，last_name，job_id，department_id信息\n方式一:\nSELECT employee_id, last_name, job_id, department_idFROM employees e1WHERE EXISTS (SELECT *            FROM employees e2            WHERE e1.`employee_id` = e2.`manager_id`);\n\n方式二:\nSELECT e1.employee_id, e1.last_name, e1.job_id, e1.department_idFROM employees e1 JOIN employees e2WHERE e1.`manager_id` = e2.`employee_id`\n\n方式三:\nSELECT e1.employee_id, e1.last_name, e1.job_id, e1.department_idFROM employees e1 WHERE employee_id IN (                SELECT DISTINCT manager_id                FROM employees                );\n\n题目：查询departments表中，不存在于employees表中的部门的department_id和department_name \nSELECT department_id, department_nameFROM departments dWHERE NOT EXISTS (SELECT 1                    FROM employees e                    WHERE e.`department_id` = d.`department_id`);\n\n相关更新UPDATE &lt;table1&gt; alias1SET\t\tcolumn = (SELECT expression                 FROM &lt;table2&gt; &lt;alias2&gt;                 WHERE alias1.column = alias2.column)\n\n使用相关子查询一个表中的数据更新另一个表的数据\n题目：在employees中增加一个department_name字段，数据为员工对应的部门名称\n# 1)ALTER TABLE employeesADD(department_name VARCHAR2(14));# 2)UPDATE employees eSET  department_name = (SELECT department_name                        FROM departments d                        WHERE e.`department_id` = d.`department_id`);\n\n相关删除….\n思考题自连接和子查询哪个更好\n自连接方式好\n题目中可以使用子查询，也可以使用自连接。一般情况建议你使用自连接，因为在许多 DBMS 的处理过\n程中，对于自连接的处理速度要比子查询快得多。\n可以这样理解：子查询实际上是通过未知表进行查询后的条件判断，而自连接是通过已知的自身数据表\n进行条件判断，因此在大部分 DBMS 中都对自连接处理进行了优化。\n作业\n每个派生表都必须有自己的别名\n派生表(Derived table): 这是指在SQL查询中通过子查询创建的临时表。它不是数据库中实际存在的表,而是查询过程中临时生成的结果集。\n\n# 1SELECT last_name, salaryFROM employees eWHERE department_id =             (SELECT department_id              FROM employees              WHERE last_name = &#x27;Zlotkey&#x27;);\n\n# 2SELECT salary, employee_id, last_nameFROM employees eWHERE salary &gt; (            SELECT AVG(salary)            FROM employees            );\n\n# 3SELECT last_name, job_id, salaryFROM employees eWHERE salary &gt; ALL (                SELECT salary                FROM employees                WHERE job_id = &#x27;SA_MAN&#x27;);\n\n# 4SELECT employee_id, last_name FROM employees eWHERE department_id IN             (SELECT DISTINCT department_id            FROM employees            WHERE  last_name REGEXP &#x27;[u]&#x27;);\n\n# 5SELECT employee_idFROM employeesWHERE department_id = ANY(            SELECT department_id            FROM departments            WHERE location_id = 1700);\n\n# 6SELECT last_name, salary, manager_idFROM employeesWHERE manager_id IN (            SELECT DISTINCT employee_id            FROM employees            WHERE last_name = &#x27;King&#x27;);\n\n# 7SELECT last_name, salaryFROM employeesWHERE salary = (            SELECT MIN(salary)            FROM employees);\n\n# 8SELECT department_id ,department_nameFROM departmentsWHERE department_id = (        SELECT department_id         FROM employees        GROUP BY department_id        HAVING AVG(salary) &lt;= ALL                     (SELECT AVG(salary)                        FROM employees                        GROUP BY department_id)            );                # 方式2: SELECT department_id ,department_nameFROM departmentsWHERE department_id = (        SELECT department_id         FROM employees        GROUP BY department_id        HAVING AVG(salary) =                     (SELECT MIN(dept_avgsal)                        FROM (                            SELECT AVG(salary) dept_avgsal                            FROM employees                            GROUP BY department_id) avg_sal                            )            );        # 方式3:SELECT d.*FROM departments d, (        SELECT department_id, AVG(salary) avg_sal        FROM employees        GROUP BY department_id        ORDER BY avg_sal        LIMIT 0,1) dept_avg_salWHERE d.`department_id` = dept_avg_sal.department_id;\n\n# 9SELECT d.*, (SELECT AVG(salary) FROM employees e WHERE e.department_id = d.department_id) FROM departments dWHERE department_id = (        SELECT DISTINCT department_id        FROM employees e        WHERE e.`department_id` = d.`department_id`        GROUP BY department_id        HAVING AVG(e.`salary`) = (            SELECT AVG(salary) avgasl            FROM employees            GROUP BY department_id            ORDER BY avgasl            LIMIT 0,1));            # 方式2: SELECT d.*, (SELECT AVG(salary) FROM employees e WHERE e.department_id = d.department_id) FROM departments dWHERE department_id = (        SELECT department_id        FROM employees e        GROUP BY department_id        HAVING AVG(e.`salary`) = (            SELECT MIN(dept_avgsal)            FROM (                SELECT AVG(salary) dept_avgsal                FROM employees                GROUP BY department_id                )  avg_sal            )         );\n\n# 10SELECT job_idFROM employeesWHERE job_id = (        SELECT job_id        FROM employees        GROUP BY job_id        HAVING AVG(salary) = (            SELECT MAX(job_avgsal)            FROM (                SELECT AVG(salary) job_avgsal                FROM employees                GROUP BY  job_id            ) avg_sal        )    );\n\n# 11SELECT department_idFROM employeesWHERE department_id IS NOT NULLGROUP BY department_idHAVING AVG(salary) &gt; (        SELECT AVG(salary)        FROM employees);\n\n# 12SELECT department_idFROM employeesWHERE department_id IS NOT NULLGROUP BY department_idHAVING AVG(salary) &gt; (        SELECT AVG(salary)        FROM employees);\n\n# 13SELECT MIN(salary)FROM employeesGROUP BY department_idHAVING department_id = (        SELECT department_id        FROM employees        GROUP BY department_id        HAVING MAX(salary) = (                SELECT MIN(max_sal)                 FROM (                    SELECT MAX(salary) max_sal                    FROM employees                    GROUP BY department_id                ) max_sal            )        );\n\n# 14SELECT last_name, department_id, email, salaryFROM employeesWHERE employee_id IN (    SELECT manager_id    FROM employees    WHERE department_id = (        SELECT DISTINCT department_id        FROM employees        WHERE manager_id IS NOT NULL        GROUP BY department_id        HAVING department_id = (            SELECT department_id            FROM employees            GROUP BY department_id            ORDER BY AVG(salary) DESC            LIMIT 0,1        )    ));# 方式2:SELECT last_name, department_id, email, salaryFROM employees eWHERE  employee_id IN (    SELECT DISTINCT manager_id    FROM employees e, (        SELECT department_id, AVG(salary) avg_sal        FROM employees        GROUP BY department_id        ORDER BY avg_sal DESC        LIMIT 0,1        )dept_avg_sal    WHERE dept_avg_sal.department_id = e.department_id);\n\n# 18SELECT employee_id, last_name, salaryFROM employees eWHERE salary &gt; (    SELECT AVG(salary) avg_sal    FROM employees e1    WHERE e.`department_id` = e1.`department_id`    GROUP BY department_id)\n\n创建和管理表基础知识一条数据的存储过程\n创建数据库 -&gt; 确认字段 -&gt; 创建数据表  -&gt; 插入数据\n从系统架构来看 : 数据库服务器 -&gt; 数据库  -&gt; 数据表的行与列\n\n标识符命名规则\n数据库名, 表名不得超过30个字符, 变量名限制为29个\n不能有重名现象\n保证字段名和类型的一致性\n\n数据类型\n\n\n类型\n类型举例\n\n\n\n整数类型\nTINYINT, SMALLINT, MEDIUMINT, INT(或INTERGER), BIGINT\n\n\n浮点类型\nFLOAT, DOUBLE\n\n\n定点数类型\nDECIMAL\n\n\n位类型\nBIT\n\n\n日期时间类型\nYEAR, TIME, DATE, DATETIME, TIMESTAMP\n\n\n文本字符串类型\nCHAR, VARCHAR, TINYTEXT, TEXT, MEDIUMTEXT, LONGTEXT\n\n\n枚举类型\nENUM\n\n\n集合类型\nSET\n\n\n二进制字符串类型\nBINARY, VARBINARY, TINYBLOB, MEDIUMBLOB, LONGBLOB\n\n\nJSON类型\nJSON对象, JSON数组\n\n\n空间数据类型\n单值：GEOMETRY、POINT、LINESTRING、POLYGON；集合：MULTIPOINT、MULTILINESTRING、GEOMETRYCOLLECTION\n\n\n常用数据类型\n\n\n\n数据类型\n描述\n\n\n\nINT\n从-2^31 ~ 2^31-1的整数类型, 存储大小位4个字节\n\n\nCHAR(size)\n定长字符类型, 若未指定, 默认为1个字符, 最大长度为2\n\n\nVARCHAR(size)\n可变长字符数据, 根据字符串实际长度保存, 必须指定长度\n\n\nFLOAT(M,D)\n单精度, 占用4个字节, M&#x3D;整数位+小数位, D&#x3D;小数位. D&lt;&#x3D;M&lt;&#x3D;255, 0&lt;&#x3D;D&lt;&#x3D;30, 默认M+D&lt;&#x3D;6\n\n\nDOUBLE(M,D)\n双精度, 占用8个字节, D&lt;&#x3D;M&lt;&#x3D;255, 0&lt;&#x3D;D&lt;&#x3D;30, 默认M+D&lt;&#x3D;15\n\n\nDECIMAL(M,D)\n高精度小数, 占用M+2个字节, D&lt;&#x3D;M&lt;&#x3D;65, 0&lt;&#x3D;D&lt;&#x3D;30, 最大取值范围和DOUBLE相同\n\n\nDATE\n日期类型, 格式’YYYY-MM-DD’\n\n\nBLOB\n二进制形式的长文本数据, 最大可达4G\n\n\nTEXT\n长文本数据, 最大可达4G\n\n\n创建和管理数据库创建数据库# 创建数据库CREATE DATABASE 数据库名;# 创建数据库, 并指定使用的字符集CREATE DATABASE 数据库名 CHARACTER SET 字符集;# 判断数据库是否存在,如果不存在则创建数据库CREATE DATABASE IF NOT EXISTS 数据库名;\n\n\n注意: DATABASE不能改名, 一些可视化工具可以改名, 它是建立新库, 把所有的表复制到新库, 再删去原先的库\n\n使用数据库\n查看当前所有的数据库\nSHOW DATABASES;\n\n查看当前正在使用的数据库\nSELECT DATABASE():\n\n查看指定库下所有的表\nSHOW TABLES FROM 数据库名;\n\n查看数据库的创建信息\nSHOW CREATE DATABASE 数据库名;# 或者SHOW CREATE DATABASE 数据库名\\G\n\n使用&#x2F;切换数据库\nUSE 数据库名;\n\n\n操作表和数据之前需要指定数据库, 否则就要对所有对象加上”数据库名”\n\n修改数据库\n更改数据库字符集ALTER DATABASE 数据库名 CHARACTER SET 字符集; # 比如: gbk, utf8等\n\n删除数据库DROP DATABASE 数据库名;# 推荐DROP DATABASE IF EXISTS 数据库名;\n\n创建表创建方式\n创建表的前提 :\nCRAETE TABLE权限\n存储空间\n\n\n语法格式:\n\nCREATE TABLE [IF NOT EXISTS] 表名(\t字段1, 数据类型 [约束条件] [默认值],    ....    [表约束条件]);\n\n\n必须指定:\n表名\n字段名, 数据类型, 长度\n\n\n可选指定\n约束条件\n默认值\n\n\n\nCREATE TABLE IF NOT EXISTS emp(    emp_id INT,    emp_name VARCHAR(20),    salary DOUBLE,    birthday DATE);DESC emp;a\n\n\n可以将id字段设置为INT(11), 这里的11实际上是INT类型指定的显示类型, 默认为11, 创建时可以使用INT(2)指定显示宽度\n这个属性在8.x版本后不再被推荐使用, 少用\n\nCREATE TABLE IF NOT EXISTS dept(    -- int类型, 自增    deptno INT(2) AUTO_INCREMENT,    dname VARCHAR(14),    -- 主键    PRIMARY KEY (deptno));DESC dept;\n\n创建方式2\n使用AS subquery选项, 将创建表和插入数据结合起来\n指定的列和子查询种的列要一一对应\n通过列名和默认值定义列\n\nCREATE TABLE emp1 AS SELECT * FROM employees;CREATE TABLE emp2 AS SELECT * FROM employees WHERE 1=2; -- 创建的emp2是空表\n\nCREATE TABLE dept80 ASSELECT employee_id, last_name, salary*12 ANNSAL, hire_date FROM employees WHERE department_id = 80;\n\n查看数据表结构SHOW CREATE TABLE 表名\\GDESC 表名;\n\n使用SHOW CREATE TABLE语句不仅能看到表创建时的详细语句, 还可以查看存储引擎和字符编码\n修改表使用ALTER TABLE语句能做到\n\n向已有的表中添加列\n修改现有表中的列\n删除现有表中的列\n重命名现有表中的列\n\n追加一个列ALTER TABLE 表名 ADD [column] 字段名 字段类型 [FIRST|AFTER字段名] ;\n\nALTER TABLE DEPT80ADD job_id varchar(15);\t\n\n修改一个列\n修改列的数据类型, 长度, 默认值和位置\n\nALTER TABLE 表名, MODIFY [COLUMN] 字段名1 字段类型 [DEFAULT] [FIRST|AFTER 字段名2]\n\nALTER TABLE dept80MODIFY salary DOUBLE(9,2) DEFAULT 1000; \n\n\n对默认值的修改, 只影响今后对表的修改\n这种方式还能修改列的约束\n\n重命名一个列ALTER TABLE 表名CHANGE 列名 新列名 新数据类型\n\nALTER TABLE dept80CHANGE last_name dept_name VARCHAR(15);\n\n删除一个列ALTER TABLE 表名 DROP [COLUMN] 字段名\n\nALTER TABLE dept80DROP COLUMN salary;\n\n\nCOLUMN是可选项, 可以写也可以不写\n\n重命名表\n方式一 : 使用RENAME\nRENAME TABLE empTO myemp;\n\n方式二:\nALTER TABLE deptRENAME  [TO] detail_dept;\n\n删除表\n当一张数据表没有与其他任何数据表形成关联关系时, 可以将当前数据表直接删除\n\n数据和结构都被删除\n\n所有正在运行的相关事务被提交\n\n所有相关索引被删除\nDROP TABLE [IF EXISTS]  数据表1, 数据表2 ,....\n\n删除语句不能回滚\n\n\n清空表\nTRUNCATE TABLE语句\n删除表中的所有数据\n释放表的存储空间\n\n\n\nTRUNCATE TABLE detail_dept\n\n\nTRUNCATE语句不能回滚, 而使用DELETE语句删除数据, 可以回滚\n\nSET autocommit = FALSE; DELETE FROM emp2; #TRUNCATE TABLE emp2; SELECT * FROM emp2; ROLLBACK; SELECT * FROM emp2;\n\n\n阿里开发规范:\n[参考] TRUNCATE TABLE 比 DELETE 速度快, 且使用的系统和事务日志资源少, 但是TRUNCATE无事务, 且不触发 TRIGGER, 有可能造成事故, 故不建议在开发代码中使用次语句\n\n内容拓展阿里巴巴开发手册之MySQL字段命名\n[强制] 表名字段名, 必须小写字母和数字, 禁止出现数字开头, 禁止两个下划线中间只出现数字\n[强制] 禁止使用保留字\n[强制] 表必备三字段: id, gmt_create, gmt_modified\n其中id必为主键, 类型为BIGINT UNSIGNED, 单表时自增, 步长为1. gmt_create, gmt_modified 类型必须为DATETIME类型, 前者现在时表示主动式创建, 后者过去分词表示被动式更新\n\n\n[推荐] 表的命名最好是遵守 “业务名称_表的作用”\n[推荐] 库名和应用名称尽量一致\n\n如何理解清空表, 删除表等操作需谨慎MySQL删除表的时候, 不会有任何确认信息, 因此执行删除操作时应当慎重, 在删除表钱, 最好对表的数据进行备份, 这样能有利于数据的恢复, 避免造成无法挽回的后果\n在使用ALTER TABLE 进行表的基本修改操作时, 在执行操作过程之前, 也应该确保对数据进行完整的备份, 因为数据的改变时无法撤销的. \nMySQL8新特性-DDL原子化DDL操作要么成功, 要么回滚\n比如我现在要删除book1, book2两张表, 但是后一张表是不存在的, 我现在执行DROP TABLE book1, book2, MySQL5.7就会执行后报错, 但是仍然删除了book1, 而MySQL8.x就会保留book1, 因为这是一次失败的操作, 会直接回滚\n作业# 1CREATE DATABASE test02_market;SELECT DATABASE();USE test02_market;# 2CREATE TABLE customers(    c_num INT,    c_name VARCHAR(50),    c_contact VARCHAR(50),    c_city VARCHAR(50),    c_birth DATE);# 3ALTER TABLE customersMODIFY c_contact VARCHAR(50) AFTER c_birth;# 5ALTER TABLE customersCHANGE c_contact c_phone VARCHAR(50);# 6 ALTER TABLE customersADD c_gender CHAR(1) AFTER c_name;# 7ALTER TABLE customersRENAME customers_info;SHOW TABLES;DESC customers_info;\n\n数据处理之增删改插入数据方式1: VALUES的方式增加数据这种语法一次只能向表中插入一条数据, 即插入一行数据\n情况1:  为表的所有字段按默认顺序插入数据\nINSERT INTO 表名VALUES (value1, value2)\n\n值列表中需要为表的每一个字段指定值, 并且值的顺序必须和数据表中字段定义时的顺序相同\nINSERT INTO departmentsVALUES (280, &#x27;Pub&#x27;, 100, 1700);\n\nINSERT INTO departmentsVALUES (290, &#x27;Finance&#x27;, NULL, NULL);\n\n情况2 : 为表的指定字段插入数据\nINSERT INTO 表名 (column1, column2...)VALUES (value1, ....)\n\n只为表的指定字段插入数据, INSERT语句只向部分字段插入值, 其他未指定的字段会填充上默认值\n在INSERT子句中随意列出列名, 但是一旦列出, VALUES中要插入的value1,…valuen需要和column1,column2,…一一对应, 如果类型不同, 将无法插入\nINSERT INTO departments(department_id, department_name) VALUES (80, &#x27;IT&#x27;);\n\n情况3: 同时插入多条数据\n在VALUES子句上加上逗号即可\nINSERT INTO table_nameVALUES (value1 [,value2, …, valuen]), (value1 [,value2, …, valuen]),……(value1 [,value2, …, valuen]);\n\n或者\nINSERT INTO table_name(column1 [, column2, …, columnn]) VALUES (value1 [,value2, …, valuen]), (value1 [,value2, …, valuen]),……(value1 [,value2, …, valuen]);\n\nmysql&gt; INSERT INTO emp(emp_id,emp_name)-&gt; VALUES (1001,&#x27;shkstart&#x27;),-&gt; (1002,&#x27;atguigu&#x27;),-&gt; (1003,&#x27;Tom&#x27;);\n\n在使用INSERT插入多行数据的时候, MySQL会返回一些在执行单行插入的时候, 没有的额外的信息 \n\nRecords: 表名插入的记录条数\nDuplicates: 表明插入时被忽略的记录, 原因是这些记录包含了重复的主键\nWarnings: 表明有问题的数据值, 例如发生了数据类型的转换\n\n\n多行的INSERT语句在处理的过程中的 效率更高, 因为MySQL执行单条INSERT语句插入多行数据比使用多条INSERT语句快, 所以在插入多条记录时最好选择使用单挑INSERT语句的方式插入\n\n方式2: 将查询结果插入到表中INSERT INTO 表名(tar_column1, ...)SELECT (src_column1, ...)FROM 源表名[WHRER condition]\n\n\n子查询的值列表应与INSERT子句中的列名对应\n\nINSERT INTO dept80 (employee_id, hire_date, job_id)SELECT employee_id, hire_date, job_idFROM employees;\n\n更新数据 (修改数据)UPDATE table_nameSET column1=value1, column2=value2,....[WHERE condition]\n\n\n可以一次更新多条数据\n如果需要回滚数据, 需要保证在DML之前, 进行设置: SET AUTOCOMMIT &#x3D; FALSE\n使用WHERE指定需要更新的数据\n\nUPDATE employeesSET department_id = 70WHERE employee_id = 113;\n\n\n如果忽略WHERE子句, 则表中的所有数据将被更新\n\n更新中的数据完整性错误\nUPDATE employees SET department_id = 55 WHERE department_id = 110;\n\n\n外键约束冲突\n检查约束冲突\n触发器问题\n这些都是在更新数据的时候, 会导致数据完整性冲突的因素\n\n\n\n删除数据DELETE FROM &lt;table_name&gt; [WHERE &lt;condition&gt;];\n\ntable_name指定要执行删除操作的表, 如果没有WHERE子句, DELETE将删除表中的所有记录\nDELETE FROM departmentsWHERE department_name = &#x27;Finance&#x27;;\n\n\n删除中的数据完整性错误\n\nDELETE FROM departmentsWHERE\t\tdepartment_id = 60;\n\n错误代码错误代码： 1451Cannot delete or update a parent row: a foreign key constraint fails (`atguigudb`.`employees`, CONSTRAINT `emp_dept_fk`                                 FOREIGN KEY (`department_id`) REFERENCES `departments` (`department_id`))\n\n\n说明: You cannot delete a row that contains a primary key that is used as a foreign key in another table\n\n计算列某一列的值是通过别的列计算得来的, 例如a列值为1, b列值为2, 那么c列值不需要手动赋值, 可以由c&#x3D;a+b计算得来, 这样的c列就是计算列\nMySQL8.0中, CREATE TABLE和ALTER TABLE都支持计算列\nCREATE TABLE tb1(\tid INT,    a INT,    b INT,    c INT HENERATED ALWAYS AS (a + b) VIRTUAL)\n\n作业CREATE DATABASE test01_library;USE test01_library;CREATE TABLE books(    id INT,    b_name VARCHAR(50),    b_authors VARCHAR(100),    price FLOAT,    pubdate YEAR,    note VARCHAR(100),    num INT);INSERT INTO booksVALUES (1, &#x27;Tal of AAA&#x27;, &#x27;Dickes&#x27;, 23, &#x27;1995&#x27;, &#x27;novel&#x27;, 11);INSERT INTO books (id, b_name, b_authors, price, pubdate, note, num)VALUES (2, &#x27;EmmaT&#x27;, &#x27;Jane lura&#x27;, 35, &#x27;1993&#x27;, &#x27;joke&#x27;, 22);INSERT INTO booksVALUES     (3, &#x27;Stroy of Jane&#x27;, &#x27;Jane Tim&#x27;, 40, &#x27;2001&#x27;, &#x27;novel&#x27;, 0),    (4, &#x27;Lovey Day&#x27;, &#x27;George Byron&#x27;, 20 , &#x27;2005&#x27;, &#x27;novel&#x27;, 30),    (5, &#x27;Old land&#x27;, &#x27;Honore Blade&#x27;, 30, &#x27;2010&#x27;, &#x27;law&#x27;, 0),    (6, &#x27;The Battle&#x27;, &#x27;Upton Sara&#x27;, 30, &#x27;1999&#x27;, &#x27;medicine&#x27;, 40),    (7, &#x27;Rose Hood&#x27;, &#x27;Richard haggard&#x27;, 28, &#x27;2008&#x27;, &#x27;cartoon&#x27;, 28);    UPDATE booksSET price = price + 5WHERE note = &#x27;novel&#x27;;SELECT *FROM books;UPDATE booksSET price = 40, note=&#x27;drama&#x27;WHERE b_name = &#x27;EmmaT&#x27;;DELETE FROM booksWHERE num = 0;SELECT b_nameFROM booksWHERE b_name REGEXP &#x27;[a]&#x27;;SELECT COUNT(*), SUM(num)FROM booksWHERE b_name REGEXP &#x27;[a]&#x27;;SELECT *FROM booksWHERE note = &#x27;novel&#x27;ORDER BY price DESC;SELECT *FROM booksORDER BY num DESC, note ASC;SELECT COUNT(1)FROM booksGROUP BY note;SELECT SUM(num)FROM booksGROUP BY noteHAVING SUM(num) &gt; 30;SELECT *FROM booksLIMIT 5, 5;# 1SELECT SUM(num)FROM booksGROUP BY noteHAVING SUM(num) &gt;= ALL(        SELECT SUM(num)        FROM books        GROUP BY note);# 2 SELECT MAX(sum_num)FROM (SELECT SUM(num) sum_num       FROM books       GROUP BY note) sum_nums;       # 3SELECT SUM(num) sum_numFROM booksGROUP BY noteORDER BY sum_num DESCLIMIT 0,1;SELECT b_nameFROM booksWHERE  LENGTH(REPLACE(b_name, &#x27; &#x27;, &#x27;&#x27;)) &gt;= 10;SELECT b_name, note, (CASE note            WHEN &#x27;novel&#x27; THEN &#x27;小说&#x27;            WHEN &#x27;law&#x27;  THEN &#x27;法律&#x27;            WHEN &#x27;medicine&#x27; THEN &#x27;医药&#x27;            WHEN &#x27;cartoon&#x27;  THEN &#x27;卡通&#x27;            WHEN &#x27;joke&#x27; THEN &#x27;笑话&#x27;            END) type_cnFROM books;\n\nMySQL数据类型精讲整型可选属性MM -&gt; 显示宽度, 这个属性已经是不再被推荐使用的属性\nCREATE TABLE test01_int (\tx INT(M))\n\n这个属性不影响存储, 只影响显示\nUNSIGNED无符号\nCREATE TABLE test01_int (\tx INT UNSIGNED)\n\nZEROFILL0填充, 某列有ZEROFILL属性, 也会自动加上UNSIGNED这个属性\n表示显示不够M位的时候, 用0在左边填充, 超过了M位, 就不会填充了\n也就是说只有 ZEROFILL 和 M 两个属性连用的时候才有意义\n各个类型的整型的适用场所和字节数\n\n\n类型名\n字节数\n适用场景\n\n\n\nTINYINT\n1\n一般用于枚举类型, 适用于系统设置取值范围很小, 且取值固定的场景\n\n\nSMALLINT\n2\n少用, 用于小范围的数据统计, 比如工厂的固定资产库存数等\n\n\nMEDIUMINT\n3\n少用, 用于较大整数的计算，比如车站每日的客流量等。\n\n\nINT, INTEGER\n4\n用的最多, 一般不需要考虑越界问题\n\n\nBIGINT\n8\n特别大的整数才需要用到, 比如双十一的交易数, 大型门户网站的点击数….\n\n\n\n选择策略 : 优先保证稳定性 -&gt; 优先确保这个范围不会超, 其次考虑大小\n\n浮点类型\n\n\n类型\n占用字节\n\n\n\nFLOAT\n4\n\n\nDOUBLE\n8\n\n\n\n无符号的属性在浮点类型上已经要被弃用了, 因为它并不能扩大取值范围, 只会让取值范围变成正常浮点数的正数的那一半\n\nM, D属性用于指定浮点数的精度, 这种语法是非标准语法, 其他数据库不一定支持, 涉及到数据迁移, 就尽量不要这么写\n\nFLOAT(M, D) -&gt;\n\nM指明整数位 + 小数位\nD指明小数位\n(3, 2) -&gt; 整数位加上小数位一共是个3位数, 小数位是0位数 -&gt; 实际存储范围就是 (-9.99 ~ 9.99)\n\n\n会影响存储\n\n存储的时候, 整数部分超出了范围是会报错的\n小数部分超出了范围, 会进行四舍五入, 如果舍入后, 整数部分没有超出范围就不报错, 只是警告, 相反就会报错\n\n\n这个属性也不推荐使用了\n\n\n定点数底层是用字符串存储, 很精确, 可以用 &#x3D;&#x3D; 判断\n\n\n\n数据类型\n字节数\n\n\n\nDECIMAL(M,D),DEC,NUMERIC\nM+2字节\n\n\n\nDECIMAL最大取值范围与DOUBLE一致, 但是有效数据范围由M和D决定\n\n当DECIMAL类型不指定精度和标度的时候, 默认为DECIMAL(10, 0), 数据精度超出范围的时候, MySQL做出的舍入和浮点数一样\n\n\n适用范围的讨论\n浮点数更适用于数字取值范围大,  可以容忍微小误差的科学计算场景\n适用于精度有要求极高的场景 (涉及金额计算的场景)\n\n位类型\n\n\n二进制类型\n长度\n长度范围\n占用空间\n\n\n\nBIT(M)\nM\n1&lt;&#x3D;M&lt;&#x3D;64\n约为(M+7)&#x2F;8字节\n\n\n在使用SELECT语句查询的时候, 可以使用BIN(), HEC()函数, 读取出二进制数据和十六进制数据\n日期与时间类型\nYEAR 类型通常用来表示年\nDATE 类型通常用来表示年、月、日\nTIME 类型通常用来表示时、分、秒\nDATETIME 类型通常用来表示年、月、日、时、分、秒\nTIMESTAMP 类型通常用来表示带时区的年、月、日、时、分、秒\n\nYEAR以四位字符串或数字格式表示YEAR类型, 格式为YYYY, 最小值为1901, 最大值为2155\nDATE类型\n没有时间部分\n\n格式为YYYY-MM-DD, 需要三个字节的存储空间\n\n以 YYYY-MM-DD 格式或者 YYYYMMDD 格式表示的字符串日期，其最小取值为1000-01-01，最大取值为\n9999-12-03。YYYYMMDD格式会被转化为YYYY-MM-DD格式。\n\n以 YY-MM-DD 格式或者 YYMMDD 格式表示的字符串日期，此格式中，年份为两位数值或字符串满足\nYEAR类型的格式条件为：当年份取值为00到69时，会被转化为2000到2069；当年份取值为70到99\n时，会被转化为1970到1999。\n\n使用NOW()会插入系统日期\n\n\nTIME类型\n三个字节\n\n不包含日期\n\n使用NOW()会插入系统时间\n\n\n插入格式\n可以使用带有冒号的字符串，比如’ D HH:MM:SS’ 、’ HH:MM:SS ‘、’ HH:MM ‘、’ D HH:MM ‘、’ D HH ‘或’ SS ‘格式，都能被正确地插入TIME类型的字段中。其中D表示天，其最小值为0，最大值为34。如果使用带有D格式的字符串插入TIME类型的字段时，D会被转化为小时，计算格式为D*24+HH。当使用带有冒号并且不带D的字符串表示时间时，表示当天的时间，比如12:10表示12:10:00，而不是00:12:10。 -&gt; 也可以存入D, 但是实际上会发生转化\n可以使用不带有冒号的字符串或者数字，格式为’ HHMMSS ‘或者 HHMMSS 。如果插入一个不合法的字符串或者数字，MySQL在存储数据时，会将其自动转化为00:00:00进行存储。比如1210，MySQL会将最右边的两位解析成秒，表示00:12:10，而不是12:10:00。 -&gt; 不合法的时间会取其中正常的, 然后用0填充, 而且默认从右往左取正常值\n\nDATETIME\n8个字节\n\n存储的格式条件\n以 YYYY-MM-DD HH:MM:SS 格式或者 YYYYMMDDHHMMSS 格式的字符串插入DATETIME类型的字段时，最小值为1000-01-01 00:00:00，最大值为9999-12-03 23:59:59。 以YYYYMMDDHHMMSS格式的数字插入DATETIME类型的字段时，会被转化为&#96;格式。\n\n以 YY-MM-DD HH:MM:SS 格式或者 YYMMDDHHMMSS 格式的字符串插入DATETIME类型的字段时，两位数的年份规则符合YEAR类型的规则，00到69表示2000到2069；70到99表示1970到1999。\n\n使用函数 CURRENT_TIMESTAMP() 和 NOW() ，可以向DATETIME类型的字段插入系统的当前日期和时间。\n\n\nTIMESTAMP类型\n取值范围小, 包含时区信息\n4个字节\n会根据用户时区的不同, 显示不同的结果\n存储数据的时候需要对当前时间所在的时区进行转换, 查询数据的时候, 再将时间转换回当前的时区.\n\n开发中经验\n用的最多的就是DATETIME, 存储的信息最完整, 范围也大\n存注册时间, 商品发布时间等, 不建议使用DATETIEM存储, 使用时间戳, DATETIME虽然直观, 但是不便于计算\n\n文本字符类型CHAR 和 VARCHAR\n\n\n类型\n特点\n长度\n长度范围\n存储空间\n\n\n\nCAHR\n固定长度\nM\n0 &lt;&#x3D; M &lt;&#x3D; 255\nM个字节\n\n\nVARCHAR\n可变长度\nM\n0 &lt;&#x3D; M &lt;&#x3D; 65535\n(实际长度 + 1)个字节\n\n\n那种情况使用CHAR 或 VARCHAR 更好情况1 : 存储很短的信息, 这个时候, 使用CHAR, 因为 VARCHAR还要额外占用一个字节\n情况2 : 固定长度的, 比如uuid作为主键, 那使用char应该更合适\n情况3 : 十分频繁更改的列, 因为varchar每次存储需要额外的计算\n情况4 : 视引擎而定\n\nMyISAM数据存储引擎和数据列: 最好使用固定长度(CHAR), 这样使整个表静态化, 加快数据检索\nMEMORY存储引擎和数据列 : 两个都一样\nInnoDB存储引擎 : 建议使用VARCHAR, 主要影响性能的因素是数据行使用的存储量, 而char平均占用的空间多余varchar\n\nTEXT类型\n\n由于实际存储的长度不确定, MySQL不允许 TEXT 类型做主键\n\n开发中的经验TEXT文本类型，可以存比较大的文本段，搜索速度稍慢，因此如果不是特别大的内容，建议使用CHAR， VARCHAR来代替。还有TEXT类型不用加默认值，加了也没用。而且text和blob类型的数据删除后容易导致“空洞”，使得文件碎片比较多，所以频繁使用的表不建议包含TEXT类型字段，建议单独分出去，单独用一个表\nENUM类型\n\n\n类型\n长度\n长度范围\n占用的存储空间\n\n\n\nENUM\nL\n1 &lt;&#x3D; L &lt;&#x3D; 65535\n1或2个字节\n\n\n\n当ENUM类型包含1～255个成员时，需要1个字节的存储空间；\n当ENUM类型包含256～65535个成员时，需要2个字节的存储空间。\nENUM类型的成员个数的上限为65535个。\n\nCREATE TABLE test01_enum(\tseason ENUM (&#x27;春&#x27;, &#x27;夏&#x27;, &#x27;秋&#x27;, &#x27;冬&#x27;, &#x27;unknow&#x27;));\n\n# 允许按照角标的方式获取指定索引位置的枚举值 INSERT INTO test01_enum VALUES(&#x27;1&#x27;),(3);# 忽略大小写 INSERT INTO test_enum VALUES(&#x27;UNKNOW&#x27;);# 插入不存在的值的时候的报错 : Data truncated for column &#x27;season&#x27; at row 1 INSERT INTO test_enum VALUES(&#x27;ab&#x27;);# 当ENUM类型的字段没有声明为NOT NULL时，插入NULL也是有效的 INSERT INTO test_enum VALUES(NULL);\n\nSET类型\n集合类型\n\nCREATE TABLE test_set(     s SET (&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;) );\n\nINSERT INTO test_set (s) VALUES (&#x27;A&#x27;), (&#x27;A,B&#x27;); #插入重复的SET类型成员时，MySQL会自动删除重复的成员 INSERT INTO test_set (s) VALUES (&#x27;A,B,C,A&#x27;); #向SET类型的字段插入SET成员中不存在的值时，MySQL会抛出错误。 INSERT INTO test_set (s) VALUES (&#x27;A,B,C,D&#x27;); SELECT * FROM test_set;\n\n二进制字符串类型MySQL中的二进制字符串类型主要存储一些二进制数据，比如可以存储图片、音频和视频等二进制数据。\nBINARY与VARBINARY类型这两个类似于CHAR和VARCHAR的关系, 一个是固定的, 一个是变长的\n\n\n\n类型\n特点\n值的长度\n占用空间\n\n\n\nBINARY(M)\n固定长度\nM (0 &lt;&#x3D; M &lt;&#x3D; 255)\nM个字节\n\n\nVARBINARY(M)\n可变长度\nM (0 &lt;&#x3D; M &lt;&#x3D; 65535)\nM+1个字节\n\n\n\nBINARY类型如果未指定(M), 表示只能存储一个字节\nVARBINARY必须指定(M)\n\nBLOB类型\n二进制大对象, 可以容纳可变数量的数据\n和INT一样, 分有TINYBLOB, BLOB, MEDIUMBLOB, LONGBLOB四种类型\n可以用来存储一个二进制大对象, 比如图片, 音频, 视频等\n实际工作中, 往往不会在MySQL数据库中使用BLOB类型存储大对象数据, 通常会将图片, 音频, 视频文件存储到服务器的磁盘上, 在MySQL中存储访问路径\n\nTEXT和BLOB的使用注意事项\nBLOB和TEXT值, 在执行了大量的删除和更新操作后. 删除这种大值后很容易留下来数据空洞, 而后面填入数据空洞的数据的大小不同, 会出现碎片化, 建议定期对这类表 OPIMIZE TABLE进行碎片整理\n不要通过SELECT *这种方式查询这类大的数据类型, 会导致资源的大幅度浪费, 针对大文本字段进行模糊查询, MySQL提供了前缀索引\n把BLOB或TEXT列分离到单独的表中, 如果将这些数据列移动到另一张表后, 可以使原先的表中的数据列转化为固定长度的数据列格式. 这会减少主表中的碎片, 获得到固定长度数据行的性能优势. 而且还会在我们SELECT * 主表的时候, 不会通过网络传输大量的BLOB或TEXT值\n\nJSON类型将整个JSON文件的内容, 作为一个数据对象存储\nINSERT INTO test_json (js) VALUES (&#x27;&#123;&quot;name&quot;:&quot;songhk&quot;, &quot;age&quot;:18, &quot;address&quot;:&#123;&quot;province&quot;:&quot;beijing&quot;, &quot;city&quot;:&quot;beijing&quot;&#125;&#125;&#x27;);\n\n检索的时候, 需要查询某个具体的值的时候可以通过”-&gt;”, “-&gt;&gt;”符号获取\nSELECT js -&gt; &#x27;$.name&#x27; AS NAME-&gt; &quot;songhk&quot;\n\n空间类型没用的东西\n小结及选择建议\n整数 -&gt; INT\n小数 -&gt; DICIMAL\n日期和时间 -&gt; TEXT\n字符串的选择\n如果存储的数据范围超过DECIMAL范围, 建议将数据拆分为整数部分和小数部分分开存储\n存储的字符串长度几乎相等 -&gt; CHAR\nVARCHAR长度不要超过 5000, 存储长度大于此值, 定义字段类型为 TEXT, 并独立出来一张表, 用主键来对应, 避免影响其它字段索引效率\n\n\n\n13. 约束约束概述为什么需要约束\n为了保证数据的完整性, 对表数据进行的额外的条件限制\n实体完整性  -&gt; 同一张表中不能存在两条完全相同无法区分的记录\n域完整性 -&gt;年龄 0 ~ 120\n引用完整性 -&gt; 员工所在部门, 在部门表中要能找到那个部门\n用户自定义完整性 -&gt; 用户唯一, 密码不能为空等\n\n\n\n约束的创建时机\n在创建表的时候 ( CREATE TABLE )\n表创建后通过 ( ALTER TABLE) 修改规定约束\n\n约束的分类\n根据约束数据里的限制\n单列约束: 只约束一列\n多列约束: 可约束多行数据\n\n\n约束的作用范围\n列级约束: 只作用在一个列上, 跟在列的定义后面\n表级约束: 可以作用在多个列上, 不与表一起定义, 单独定义\n\n\n根据约束起的作用:\nNOT NULL 非空约束, 规定某个字段不能为空\nUNIQUE 唯一约束, 规定某个字段在整张表中式唯一的\nPRIMARY KEY主键约束 (非空且唯一)\nFOREIGN KEY 外键约束\nCHECK 检查约束\nDEFAULT 默认值约束\n\n\n\n\nMySQL不支持check约束, 但可以使用check约束, 但是没有任何效果\n\n\n查看某个表已有的约束\n# information_schema数据库名 (系统库)# table_constraints表名称 (专门存储各个表的约束)SELECT * FROM information_schema.table_constrainsWHERE table_name = &#x27;&lt;table-name&gt;&#x27;\n\n非空约束 NOT NULL添加非空约束\n建表时\n\nCREATE TABLE &lt;table-name&gt;(\t字段名 数据类型 NOT NULL)\n\n\n建表后的修改, 加上约束\n\nALTER TABLE &lt;table-name&gt;MODIFY 字段名 数据类型 NOT NULL\n\n删除约束\n设置为NULL\nALTER TABLE &lt;table-name&gt;MODIFY 字段名 数据类型 NULL# 设置为NULL说明允许为NULL\n\n去掉NOT NULL\nALTER TABLE &lt;table-name&gt;MODIFY 字段名 数据类型\n\n唯一性约束 UNIQUE特点\n约束后的列, 值没有重复\n可以时某一列的值唯一, 也可以是多个列组合的值唯一\n允许列值为空\n创建唯一约束的时候, 如果不给唯一约束命名, 就默认和列名相同\n\n复合唯一约束unique key(字段列表) #字段列表中写的是多个字段名，多个字段名用逗号分隔，表示那么是复合唯一，即多 个字段的组合是唯一的\n\n添加唯一约束\n建表时\n\nCREATE TABLE &lt;table-name&gt;(\t字段名 数据类型,    字段名 数据类型 UNIQUE,    字段名 数据类型 UNIQUE KEY);CREATE TABLE &lt;table-name&gt;(\t字段名 数据类型,    ...,    [constraint 约束名] UNIQUE KEY(字段名))\n\nCREATE TABLE USER(    id INT NOT NULL,    -- 列级约束语法    NAME VARCHAR(25), UNIQUE    PASSWORD VARCHAR(16),    -- 表级约束语法    CONSTRAINT uk_name_pwd UNIQUE(NAME, PASSWORD));\n\n\n用户名和密码的组合不能重合\n\n\n建表后指定唯一键约束\n\n# 列级约束的添加ALTER TABLE &lt;table-name&gt;MODIFY 字段名 字段类型 UNIQUE;# 表级约束的添加ALTER TABLE &lt;table-name&gt;ADD UNIQUE KEY(字段名称);# orALTER TABLE &lt;table-name&gt;ADD CONSTRAINT uk_name_ped UNIQUE(NAME, PASSWORD)\n\n\n列级的就是对一个列的修改\n表级的就是添加一个列了\n\n删除唯一约束\n添加唯一性约束的列上会自动创建唯一索引\n删除唯一性约束只能通过删除唯一索引的方式删除\n删除时需要指定唯一索引名, 唯一索引名和唯一约束名一样\n如果创建唯一约束时未指定名称, 如果是单列, 就默认和列名相同, 如果是组合列, 那就默认和()中排在第一个的列名相同, 也可以是自定义唯一性约束名\n主键的索引名都是 PRIMARY, 就算自己命名了主键约束也没用\n不要修改主键字段的值, 因为主键是数据的唯一标识, 修改了以后会破坏数据的完整性\n\nSELECT * FROM information_schema.table_constraints WHERE table_name = &#x27;&lt;table-name&gt;&#x27;# 查看有哪些约束\n\nALTER TABLE USERDROP INDEX uk_name_pwd;\n\n\n可以通过show index from 表名称; 来查看到索引\n\n主键约束 PRIMARY KEY特点\n每个表有且仅有一个主键\n主键 &lt;&#x3D;&gt; 唯一性约束 + 非空约束\n主键有列级的主键 -&gt; 在创建列的时候添加后缀, 表级主键 -&gt; 新建一列, 用于写约束\n主键有复合主键和单列主键\n复合主键\n每个属性都非空\n组合不重复\n\n\n\n\n一张表只能有一个主键\n\n创建主键约束和唯一性约束的创建模式相同\n# 列级CREATE TABLE &lt;table-name&gt;(\tid INT PEIMARY KEY)# 表级CREATE TABLE &lt;table-name&gt;(\tid INT,    CONSTRAINT pk_id PRIMARY KEY(id))CREATE TABLE &lt;table-name&gt;(\tid INT,    PRIMARY KEY(id))\n\n\n复合主键和唯一性约束相同\n\n添加主键\n同样和唯一性主键相同\n列级主键就当MODIFY一列就行\n表级主键就当ADD一列就行\n\n\n\n删除主键约束因为一张表只有一个主键, 所以不需要指定索引\nALTER TABLE &lt;table-name&gt;DROP PRIMARY KEY;\n\n自增 AUTO_INCREMENT特性\n只有键列 (主键列, 唯一键列) 后可加上AUTO_INCREMENT\n如果指定键列的值为0或NULL的时候, 就会执行自增长, 自增长的值为max(当前列) + 1, 如果指定其他值, 那么就会是其他值\n一个表最多只有一个自增长列\n自增长的列数据类型必须是整数类型\n\n创建自增长约束在键值列后添加后缀\n添加自增长约束当成一个列修改他的属性即可\nALTER TABLE &lt;table-name&gt; MODIFY\n删除自增长约束和删除NOT NULL约束一样, 直接覆盖就行\nMySQL8新特性-自增长持久化\nMySQL5.7版本, 我INSERT数据后, 假设id为主键它的值为1,2,3,4, 我删除4后, 再插入, 主键序列为1,2,3,5. 删除后重启数据库, 这个时候插入数据, 得到的序列却会是1,2,3,4\n这是因为在5.7中, 计数器的维护是在内存中, 重启后就会重置\n\n\n而在8后, 会符合预期的获得1,2,3,5, 因为自增主键的计数器持久化到重做日志\n\nFOREIGN KEY 约束特点\n分为主表和从表, 从表references主表\n从表的外键列, 必须参考主表的主键列或唯一约束键列\n创建的时候, 如果需要在创建表的时候指定外键, 得先创建主表, 从表才能在创建的时候指定外键\n如果是后续添加外键, 则不会有创建顺序上的限制\n\n\n创建时, 如果不给外键约束命名, 默认名不是列名, 而是自动产生的一个外键名\n删除的时候, 需要先删除从表中依赖的主表的数据, 才能删除主表中对应的数据\n一个表可以有多个外键\n从表的外键列与主表的被参照的列的名字可以相同或不同, 但是数据类型必须一样, 逻辑意义一致(NOT NUL等)\n删除外键约束的时候, 还需要手动删除外键索引\n\n创建外键CREATE TABLE &lt;table-name&gt;(\tid INT PRIMARY KEY,    CONSTRAINT fk_id_name FOREIGN KEY (从表的字段) REFERENCES 主表名(主表的字段))\n\n添加外键ALTER TABLE 从表名ADD[CONSTRAINT 约束名] FOREIGN KEY (从表的字段) REFERENCES 主表名(主表的字段) [on update xx][on delete xx];\n\n删除外键约束# 先查看约束名和删除外键的约束SELECT * FROM information_schema.table_constraints WHERE table_name = &quot;表名&quot;;ALTER TABLE 从表名 DROP FOREIGN KEY 外键名# 查看索引名和删除索引SHOW INDEX FROM 表名称;ALTER TABLE 表名称 DROP INDEX 索引名;\n\n约束等级\nCascade: 父表上update&#x2F;delete记录时, 同步update&#x2F;delete从表的匹配记录\nSet null: 父表上update&#x2F;delete记录时, 将子表匹配记录的列设为null, 这个时候, 从表的外键列不能为NOT NULL\nNo action: 如果子表中有匹配的记录, 则不允许对父表对应键进行update&#x2F;delete操作\nRestrict: 和No action一致\nSet default: 父表有变更的时候, 子表将外键列设置为一个默认的值, 但Innodb不能识别\n没有指定, 默认为Restrict方式\n对于外键约束, 最好采用: ON UPDATE CASCADE ON DELETE的方式\n\n开发规范\n[强制]: 不得使用外键与级联, 一切外键概念必须在应用层解决\n\nCHECK约束特点\n在5.7版本是没有用的属性\n8版本后开始有效\n\n使用CREATE TABLE &lt;table-name&gt;(\tage INT CHECK(age &gt; 20),    gender CHAR(5) check (gender IN(&#x27;男&#x27; OR &#x27;女&#x27;)))# 如果插入不合规的值, 就会报错\n\nDEFAULT约束# 用于指定默认值CREATE TABLE &lt;table-name&gt;(\t字段名 数据类型 default 默认值)\n\n面试\n为什么要在建表的时候, 加上not null default 或 defualt 0\n不想让表中出现null值\n\n\n为什么不想要null\n不好比较\n效率不高, 影响索引\n\n\n并不是每个表可以选择任意存储引擎\n外键约束不能跨引擎使用\n\n\n\n14. 视图\n视图的使用就当一张正常的虚拟表就行\n\n视图的意义\n相当于对于数据和操作的封装, \n对于数据的封装 -&gt; 使数据具有隔离性, 我们可以通过视图, 让用户只能访问到有限的, 我们想提供的数据\n对于操作的封装 -&gt; 就像函数一样, 我们把一些复杂的频繁使用的查询, 直接封装为视图, 下次需要查询的时候, 直接调用视图就能获取了\n\n\n视图在执行逻辑上, 也像一个无传参函数, 每次调用视图就是会执行视图里定义的语句, 然后给出返回, 所以视图的返回结果是会根据基表动态变化的, 因为实质上, 就是进行了查询\n\n创建视图CREATE VIEW 视图名称(字段名)AS 查询语句# 如果创建视图的时候指定了字段名, 那SELECT返回的结果的字段名, 就会按照设置字段名别名给出, # 如果没有, 就会默认按照SELECT语句中的字段名\n\n\n使用情景 : 利用视图进行格式化\n\n我们经常需要输出某个格式的内容, 我们就可以把他封装为一个视图\nCREATE VIEW emp_departASSELECT CONCAT(last_name, &#x27;(&#x27;, department_name ,&#x27;)&#x27;) AS emp_deptFROM employees e JOIN departments dWHERE e.departemnt_id = d.department_id\n\n\n我们也可以基于视图创建视图\n\nCREATE VIEW emp_dept_ysalary ASSELECT emp_dept.ename,dname,year_salary FROM emp_dept INNER JOIN emp_year_salary ON emp_dept.ename = emp_year_salary.ename;\n\n查看视图\n就和查看TABLE时一样的\n\n查看视图的属性信息\nSHOW TABLE STATUS LIKE &#x27;视图名称&#x27;\\G\n\n查看视图的详细定义信息\nSHOW CREATE VIEW 视图名称;\n\n通过视图更新数据\n在且仅在视图只是隔离了部分原表的数据的时候可以UPDATE, DELETE\n在且仅在视图包含了基表中所有被定义为非空又未指认默认值的列, 可以执行INSERT操作\n形式化的定义 : 视图中的行和底层基本表中的行之间必须存在一对一的关系, 才能执行更新操作\n\n\n通过视图来更新数据是一种不推荐的行为, 因为视图作为虚拟表, 主要是为了方便查询, 所以没必要将不属于它的职责强加\n\n修改视图\n使用CREATE OR REPLACE VIEW子句覆盖式地修改视图\nCREATE OR REPLACE VIEW &lt;view-name&gt;(字段...)ASSELECT ...\n\nALTER VIEW\nALTER VIEW 视图名称AS查询语句\n\n\n别名要和子查询中的各列一一对应\n\n删除视图\n删除只是删除视图的定义, 不会删除基表的数据\n\n语法\nDROP VIEW IF EXISTS 视图名称;\n\n作业USE atguigudb;CREATE TABLE empsASSELECT * FROM atguigudb.employees;CREATE OR REPLACE VIEW emp_v1ASSELECT last_name, salary, email, phone_numberFROM empsWHERE emps.`phone_number` REGEXP &#x27;^011&#x27;AND email REGEXP &#x27;[e]&#x27;;SELECT * FROM emp_v1;DESC emp_v1;INSERT TO emp_v1VALUES (&#x27;方&#x27;, 12000, &#x27;email&#x27;, &#x27;198&#x27;);UPDATE TABLE emp_v1SET salary = salary + 1000;DELETE FROM emp_v1WHERE emp_v1.`last_name` = &#x27;Olsen&#x27;;CREATE OR REPLACE VIEW emp_v2AS SELECT department_id, MAX(salary)FROM employeesGROUP BY department_idHAVING MAX(salary) &gt; 12000;SELECT * FROM emp_v2;SELECT DATABASE();DROP VIEW emp_v1, emp_v2;\n\n剩下部分暂不观看, 没什么用, 都是在应用层实现的内容"},{"url":"/2025/07/08/Computer_Science/Algorithm/out/production/Algorithm/%E5%91%A8%E8%B5%9B/452/","content":"Q1等积子集的划分方案给你一个整数数组 nums，其中包含的正整数 互不相同 ，另给你一个整数 target。\n请判断是否可以将 nums 分成两个 非空、互不相交 的 子集 ，并且每个元素必须  恰好 属于 一个 子集，使得这两个子集中元素的乘积都等于 target。\n如果存在这样的划分，返回 true；否则，返回 false。\n子集 是数组中元素的一个选择集合。\n示例 1：\n输入： nums &#x3D; [3,1,6,8,4], target &#x3D; 24\n输出： true\n**解释：**子集 [3, 8] 和 [1, 6, 4] 的乘积均为 24。因此，输出为 true 。\n示例 2：\n输入： nums &#x3D; [2,5,3,7], target &#x3D; 15\n输出： false\n解释 无法将 nums 划分为两个非空的互不相交子集，使得它们的乘积均为 15。因此，输出为 false。\n提示：\n\n3 &lt;= nums.length &lt;= 12\n1 &lt;= target &lt;= 1015\n1 &lt;= nums[i] &lt;= 100\nnums 中的所有元素互不相同。\n\nQ2 子矩阵的最小绝对差给你一个 m x n 的整数矩阵 grid 和一个整数 k。\n对于矩阵 grid 中的每个连续的 k x k 子矩阵，计算其中任意两个 不同值 之间的 最小绝对差 。\n返回一个大小为 (m - k + 1) x (n - k + 1) 的二维数组 ans，其中 ans[i][j] 表示以 grid 中坐标 (i, j) 为左上角的子矩阵的最小绝对差。\n注意：如果子矩阵中的所有元素都相同，则答案为 0。\n子矩阵 (x1, y1, x2, y2) 是一个由选择矩阵中所有满足 x1 &lt;= x &lt;= x2 且 y1 &lt;= y &lt;= y2 的单元格 matrix[x][y] 组成的矩阵。\n示例 1：\n输入： grid &#x3D; [[1,8],[3,-2]], k &#x3D; 2\n输出： [[2]]\n解释：\n\n只有一个可能的 k x k 子矩阵：[[1, 8], [3, -2]]。\n子矩阵中的不同值为 [1, 8, 3, -2]。\n子矩阵中的最小绝对差为 |1 - 3| = 2。因此，答案为 [[2]]。\n\n示例 2：\n输入： grid &#x3D; [[3,-1]], k &#x3D; 1\n输出： [[0,0]]\n解释：\n\n每个 k x k 子矩阵中只有一个不同的元素。\n因此，答案为 [[0, 0]]。\n\n示例 3：\n输入： grid &#x3D; [[1,-2,3],[2,3,5]], k &#x3D; 2\n输出： [[1,2]]\n解释：\n\n有两个可能的 k × k 子矩阵：\n以 (0, 0) 为起点的子矩阵：[[1, -2], [2, 3]]。\n子矩阵中的不同值为 [1, -2, 2, 3]。\n子矩阵中的最小绝对差为 |1 - 2| = 1。\n\n\n以 (0, 1) 为起点的子矩阵：[[-2, 3], [3, 5]]。\n子矩阵中的不同值为 [-2, 3, 5]。\n子矩阵中的最小绝对差为 |3 - 5| = 2。\n\n\n\n\n因此，答案为 [[1, 2]]。\n\n"}]