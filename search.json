[{"title":"分布式架构-架构演进概述","url":"/2025/07/25/Architecture/%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B%E6%A6%82%E8%BF%B0/","content":"\n参考凤凰架构: 演进的架构一大章节\n\n演进中的架构\n计算机总是务实, 某一架构的出现和兴盛往往都是在承载着某个历史使命, 衰败则是因为使命的消失或者有了更好的方案. 所以想要知道某个架构的历史使命, 我们不得不向过去看, 了解到它到底是解决了之前无法解决的什么问题, 也要向现在看它为什么能兴盛, 最后向未来看它为什么衰败, 如此才能理解这个架构的历史和使命 @fung\n\n原始分布式时代令人惊讶的是, 使用多个独立的分布式服务共同构建一个大型系统的设想和尝试, 反而是比今天的大型单体系统出现的时间更早\n在20世纪70年代末期到80年代初, 计算机硬件的运算能力的局促, 直接妨碍到了在单台计算机上信息系统软件能够达到的最大规模. 于是计算机科学家们开始探索一种多台计算机共同协作来支撑一套软件系统, 这就是原始分布式时代\n负责制定 UNIX 系统技术标准的“开放软件基金会”（Open Software Foundation，OSF，也即后来的“国际开放标准组织”）邀请了当时业界主流的计算机厂商一起参与，共同制订了名为“分布式运算环境”（Distributed Computing Environment，DCE）的分布式技术体系. \n\nUNIX 的分布式设计哲学\nSimplicity of both the interface and the implementation are more important than any other attributes of the system — including correctness, consistency, and completeness\n保持接口与实现的简单性，比系统的任何其他属性，包括准确性、一致性和完整性，都来得更加重要。\n—— Richard P. Gabriel，The Rise of ‘Worse is Better’，1991\n\nOSF尝试设计出来一种简单的, 透明的远程方法调用模式, 让程序员无需关注自己使用的方法是本地方法还是远程方法\n调用远程方法的网络环境带来了一系列的新问题\n\n远程服务在哪里(服务发现)\n有多少个(负载均衡)\n网络出现了分区, 超时或者服务出错怎么办(熔断, 隔离, 降级)\n方法的参数和返回结果如何表示 (序列化协议)\n信息如何传输 (传输协议)\n服务权限如何管理 (认证, 授权)\n如何保证通信安全 (网络安全层)\n如何令调用不同机器的服务返回相同的结果 (分布式数据一致性)\n\n尝试的结果自然是失败的, 不然我们现在看到的应用也不会是现在的以单体应用为主的模式了. 远程和本地方法在性能上的鸿沟是无法跨越的(抛弃了内联等优化), 在当时得硬件条件下如果想为用户提供可以接受的速度的远程调用服务, 不得不使用将多个方法打包到同一个方法体中等奇技淫巧, 并且开发者必须无时无刻不意识到本地和远程之间的边界. 设计为性能让步, DCE的努力”付之东流”\n不过在这个时期产出了很多后续分布式的关键技术和概念\n\n源自 NCA 的远程服务调用规范（Remote Procedure Call，RPC），当时被称为DCE&#x2F;RPC，它与后来 Sun 公司向互联网工程任务组（Internet Engineering Task Force，IETF）提交的基于通用 TCP&#x2F;IP 协议的远程服务标准ONC RPC被认为是现代 RPC 的共同鼻祖；\n源自 AFS 的分布式文件系统（Distributed File System，DFS）规范，当时被称为DCE&#x2F;DFS；源自 Kerberos 的服务认证规范；\n还有时间服务、命名与目录服务，就连现在程序中很常用的通用唯一识别符 UUID 也是在 DCE 中发明出来的。\n\n\n原始分布式时代的教训\nJust because something can be distributed doesn’t mean it should be distributed. Trying to make a distributed call act like a local call always ends in tears\n某个功能能够进行分布式，并不意味着它就应该进行分布式，强行追求透明的分布式操作，只会自寻苦果\n—— Kyle Brown，IBM Fellow，Beyond Buzzwords: A Brief History of Microservices Patterns，2016\n\n单体系统时代\n单体架构（Monolithic）\n“单体”只是表明系统中主要的过程调用都是进程内调用，不会发生进程间通信，仅此而已。\n\n单体架构是最早的架构, 也是使用得最自然的架构, 以至于相当长的一段时间里人们都没有去为单体架构专门下一个定义出来\n在剖析单体架构之前, 非常有必要理清的一个概念就是, 单体架构并不是”不如”微服务架构, 在书籍中常出现的作为微服务架构的对比对象, 来说明单体系统的不足, 实际上是大型单体系统, 对于小型系统上单体架构有自己的优势\n小型系统上, 单体架构易开发, 易部署, 易测试. 调用过程都是进程间调用, 运行效率最高\n同时在纵向上, 无论是单体还是微服务抑或是其他架构风格, 都会对代码进行纵向的分层, 这点无关架构.\n\n在横向角度上看, 单体架构同样能将系统从技术, 功能, 职责上进行模块拆分. 横向拓展上来看, 部署多个单体副本也是个常见的需求.\n单体系统的真正缺陷不在于拆分, 而是拆分后的隔离性与自治能力上的欠缺. 在隔离性上, 单体系统所有的代码都共享同一片进程空间, 错误的传播范围是全局性并且式难以隔离的. 自治能力的欠缺会导致在错误传播以后往往会对程序造成极大的破坏. 同时因为隔离性的不支持, 也带来了单体系统难以动态更新的问题. 并且很难优雅地支持异构(Java的native方法还是支持异构的, 所以还是支持的, 只是支持的形式不优雅).\n但是上面列举的问题, 都不是现今微服务取代单体系统成为潮流趋势的核心原因. 最核心的原因是, 单体系统难以支持Phoenix的特性(程序动态迭代更新, 并通过不可靠的部件构建出来一个可靠的整体服务). 单体架构风格潜在的观念是希望系统的每一个部件, 每一处代码都尽量可靠, 靠不出或少出缺陷来构建可靠系统. 单体系统靠高质量来保证的思路, 在小规模软件上还能运作良好, 但是规模越大, 交付一个可靠的单体系统就变得越来越具有挑战性. \n为了允许程序出错, 为了获得隔离, 自治的能力, 可以技术异构等目标, 是继为了性能和算力之后, 让程序再次选择分布式的理由.\nSOA(面向服务架构)时代\nSOA 架构（Service-Oriented Architecture）\n面向服务的架构是一次具体地、系统性地成功解决分布式服务主要问题的架构模式。\n\n对一个大型的单体项目进行拆分, 使每个子系统都能独立部署, 运行, 更新, 开发者尝试了很多种架构\n\n烟囱式架构, 也叫信息孤岛架构, 各个模块之间没有任何的信息交互, 严格来说这个甚至不能叫做架构, 只是各个独立的子系统部署在了一起而已\n微内核架构, 也叫插件式式架构, 在烟囱架构中, 即使是没有任何的业务往来的子系统之间也需要共享一些如人员权限, 组织等公共的主数据, 那就不妨将这些被共享的资源集中在一块, 成为一个被各个组件共同依赖的核心, 这个核心就是微内核, 具体的业务以插件的形式存在. 常用于桌面端的程序, 比如Web程序. 不过微内核架构也有它的缺陷和局限性, 微内核架构的假设是各个组件之间是相互独立的, 不可预知系统安装了哪些模块, 只是向他们提供一些公共的数据, 所有组件之间是不会有直接交互的. 我们必须找到方法既能拆分系统, 又能让子系统之间进行交互\n\n\n\n事件驱动架构, 为了能让子系统之间交互, 我们在子系统之间提供一个事件队列管道, 子系统可以从事件管道中获取到自己的想要的也就是订阅了的事件, 同时子系统也能发布事件. 和发布订阅机制比较像. 同时每个子系统之间是独立, 高度解耦合的\n\n\n在事件驱动架构之后, 软件架构发展就迎来了SOAP协议的诞生, 这个时候SOA (Service Oriented Architecture, SOA), 已经有了登上历史舞台的全部的前置条件. \n软件架构来到了SOA时代, 许多的概念, 思想都已经能在今天的微服务中找到对应的身影了, 譬如服务之间的松散耦合, 注册, 发现, 治理, 隔离, 编排等等, 这些在今天微服务中耳熟能详的名词概念. SOA针对这些问题, 甚至是软件开发这件事情本身, 都提供了更加系统性, 更加具体的探索\n\n更具体: 体现在尽管SOA本身还属于抽象的软件架构风格, 但是实际上提供一套软件设计的基础平台\n更系统: 是SOA的宏大理想, 终极目标是希望能总结出来一套自上而下的软件开发研究的方法论\n\nSOA在21世纪初10年间曾风靡一时, 最终还是偃旗息鼓, 沉寂下去. SOAP会被边缘化的本质原因: 过于严格的规范定义带来过度的复杂性. 而构建在SOAP基础之上的ESB, BPM, SCA, SDO等诸多上层建筑, 进一步加剧了这种复杂性. 过于精密的流程和理论也需要懂得复杂概念的专业人员才能驾驭, 它能实现多个异构代行系统之间的复杂集成交互, 却很难作为一种具有广泛普适性的软件架构风格来推广\n经过了30年的技术进步, 软件受架构复杂性牵制越来越大, 已经离透明二字越来越远了, 这是不是忘记了我们最开始透明和简单的初心? 微服务时代, 似乎正是带着这样的自省开始的\n微服务时代\n微服务架构（Microservices）\n微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。服务采取轻量级的通信机制和自动化的部署机制实现通信与运维。\n\n微服务并不是SOA的变体\n\nMicroservices and SOA\nThis common manifestation of SOA has led some microservice advocates to reject the SOA label entirely, although others consider microservices to be one form of SOA , perhaps service orientation done right. Either way, the fact that SOA means such different things means it’s valuable to have a term that more crisply defines this architectural style\n由于与 SOA 具有一致的表现形式，这让微服务的支持者更加迫切地拒绝再被打上 SOA 的标签，尽管有一些人坚持认为微服务就是 SOA 的一种变体形式，也许从面向服务方面这个方面来说是对的，但无论如何，SOA 与微服务都是两种不同的东西，正因如此，使用一个别的名称来简明地定义这种架构风格就显得更有必要。\n—— Martin Fowler &#x2F; James Lewis，Microservices\n\n微服务有九个核心的业务与技术特征\n\n围绕业务能力构建 （Organized around Business Capability）:  也就是康威定律, 有怎么样结构, 规模, 能力的团队, 就会产出对应的结构, 规模, 能力的产品. 比如本应该归属于一个产品内的功能被划分到了不同的团队, 必然会产生大量的跨团队的沟通协作, 跨越团队边界进行协作在管理, 工作安排, 沟通上都会有更高昂的成本, 高效的团队必然会进行改进, 当团队和产品磨合稳定以后, 团队和产品就会有一致性的结构\n分散治理（Decentralized Governance）: 谁家的孩子谁来管, 服务对应的开发团队有直接对服务运行质量负责的责任, 也应该有着不受外界干预地掌控服务各方面的权力. 实际开发中并不会有高程度的技术异构, 甚至一般来说是有主语言, 微服务更加强调的是确实有必要的技术异构时, 应该有选择不统一的权力\n通过服务来实现独立自治的组件（Componentization via Services）: 通过服务这种进程外组件, 以远程调用的形式提供服务, 虽然有着更高昂的车成本, 但是这是为组件带来隔离和自治能力的必要代价\n产品化思维 (Products not Projects): 避免把软件研发视作去完成某个功能, 而是要视作一种持续改进, 提升的过程. 微服务下, 要求开发团队中的每个人都有产品化思维, 关心整个产品的全部的可行性. DDD也是在这个时期提出的理念.\n数据去中心化 （Decentralized Data Management）:  微服务明确体长数据应该按照领域分散管理, 更新, 维护, 存储. 如果使用中心化的存储, 所有领域必须修改和映射到同一个实体身上, 这使得不同服务之间相互影响, 丧失了独立性. 尽管在分布式中要想处理好一致性问题相当困难, 但是两害相权取其轻, 有一些必要的代价是值得付出的\n强终端弱管道 (Smart Endpoint and Dumb Pipe) : 弱管道可以说是指名道姓地反对SOAP和ESB地复杂地通信机制. 认证, 事务一致性, 授权等一系列的工作, 构建在通信管道上对于一些应用程序来说是必要的, 但是对于更多的应用程序来说都是一个负担. 如果服务需要额外的通信能力, 应该在自己的Endpoint上解决, 而不是在管道上一揽子地解决\n容错性设计 (Design for Failure) : 不再虚幻地追求服务永远稳定, 而是接受服务总是会出错的现实, 要求在微服务的设计中, 有自动的机制对其依赖的服务能够进行快速的故障检测, 并在持续出错的时候进行隔离, 服务恢复的时候进行重建. 如果没有容错性的设计, 系统很容易就会因为一两个服务的崩溃所带来的雪崩效应给淹没. 可靠系统完全可能由会出错的服务组成, 这也是微服务最大的价值\n演进式设计 (Evolutionary Design) : 容灾性设计是允许服务出错, 演进式设计则是承认服务会报废淘汰, 一个设计良好的服务应该是能够报废的,  而不是期望能够得到永生. 系统中出现不可替代, 不可更改的服务, 不能说明这个服务有多重要, 恰恰相反, 是说明了系统设计上的脆弱性\n基础设施自动化 (Infrastructure Automation) : 微服务下运维的对象比起单体架构要有数量级上的增长, 使用微服务的团队更加依赖于基础设施上的自动化\n\n微服务所带来的自由是一把双刃开锋的宝剑，当软件架构者拿起这把宝剑，一刃指向 SOA 定下的复杂技术标准，将选择的权力夺回的同一时刻，另外一刃也正朝向着自己映出冷冷的寒光。微服务时代中，软件研发本身的复杂度应该说是有所降低。一个简单服务，并不见得就会同时面临分布式中所有的问题，也就没有必要背上 SOA 那百宝袋般沉重的技术包袱。需要解决什么问题，就引入什么工具；团队熟悉什么技术，就使用什么框架。此外，像 Spring Cloud 这样的胶水式的全家桶工具集，通过一致的接口、声明和配置，进一步屏蔽了源自于具体工具、框架的复杂性，降低了在不同工具、框架之间切换的成本，所以，作为一个普通的服务开发者，作为一个“螺丝钉”式的程序员，微服务架构是友善的。可是，微服务对架构者是满满的恶意，对架构能力要求已提升到史无前例的程度，笔者在这部文档的多处反复强调过，技术架构者的第一职责就是做决策权衡，有利有弊才需要决策，有取有舍才需要权衡，如果架构者本身的知识面不足以覆盖所需要决策的内容，不清楚其中利弊，恐怕也就无可避免地陷入选择困难症的困境之中。\n后微服务时代\n后微服务时代（Cloud Native）\n从软件层面独力应对微服务架构问题，发展到软、硬一体，合力应对架构问题的时代，此即为“后微服务时代”。\n\n分布式架构中出现的问题 : 注册发现, 跟踪治理, 负载均衡, 传输通信等, 这些问题从原始分布式时代就已经出现了, 只要是分布式架构就无法避免, 但是这些问题一定要软件系统来自己解决吗?\n后微服务时代就是通过容器化和虚拟化技术, 在硬件层面实现了这些服务. \n表 1-1 列出了在同一个分布式服务的问题在传统 Spring Cloud 中提供的应用层面的解决方案与在 Kubernetes 中提供的基础设施层面的解决方案，尽管因为各自出发点不同，解决问题的方法和效果都有所差异，但这无疑是提供了一条全新的、前途更加广阔的解题思路。\n表 1-1 传统 Spring Cloud 与 Kubernetes 提供的解决方案对比\n\n\n\n\nKubernetes\nSpring Cloud\n\n\n\n弹性伸缩\nAutoscaling\nN&#x2F;A\n\n\n服务发现\nKubeDNS &#x2F; CoreDNS\nSpring Cloud Eureka\n\n\n配置中心\nConfigMap &#x2F; Secret\nSpring Cloud Config\n\n\n服务网关\nIngress Controller\nSpring Cloud Zuul\n\n\n负载均衡\nLoad Balancer\nSpring Cloud Ribbon\n\n\n服务安全\nRBAC API\nSpring Cloud Security\n\n\n跟踪监控\nMetrics API &#x2F; Dashboard\nSpring Cloud Turbine\n\n\n降级熔断\nN&#x2F;A\nSpring Cloud Hystrix\n\n\n一旦虚拟化的硬件跟上了软件的灵活性, 那些与业务无关的技术问题有可能从软件层面剥离, 悄无声息解决于硬件基础设施之内, 让软件只需要关注业务&#x2F;\n但是Kurbernets并没有完美解决所有的分布式问题, 仅从功能上看k8s甚至不如之前的Spring Cloud方案. 因为有一些问题处于应用系统与基础设置的边缘, 使得很难在基础设施层上进行处理. 举个例子，微服务 A 调用了微服务 B 的两个服务，称为 B1和 B2，假设 B1表现正常但 B2出现了持续的 500 错，那在达到一定阈值之后就应该对 B2进行熔断，以避免产生雪崩效应。如果仅在基础设施层面来处理，这会遇到一个两难问题，切断 A 到 B 的网络通路则会影响到 B1的正常调用，不切断的话则持续受 B2的错误影响。基础设施是针对整个容器来管理的，粒度相对粗旷，只能到容器层面，对单个远程服务就很难有效管控\n为了解决这一类问题，虚拟化的基础设施很快完成了第二次进化，引入了今天被称为“服务网格”（Service Mesh）的“边车代理模式”（Sidecar Proxy）. 系统自动在服务容器(通常是指 Kubernetes 的 Pod) 中注入一个通信代理服务器, 以类似网络安全里中间人的方式进行流量劫持, 在应用毫无感知的情况下, 悄然接管所有的对外通信. 这个代理处理实现正常的服务间通信以外 (数据平面通信), 还接收来自控制器的指令, 以实现熔断, 认证, 度量, 监控, 均衡负载等各种附加功能. 这样便实现了既不需要在应用层面加入额外的处理代码，也提供了几乎不亚于程序代码的精细管理能力\n\n","categories":["Architecture","Distributed Systems"],"tags":["Architecture","Distributed Systems"]},{"title":"Java基础面试问题","url":"/2025/07/10/Interview/Java%20Base/","content":"Java基础a &#x3D; a + b 与 a +&#x3D; b 的区别+&#x3D; 隐式的将加操作的结果类型强制转换为持有结果的类型。如果两个整型相加，如 byte、short 或者 int，首先会将它们提升到 int 类型，然后在执行加法操作。\nbyte a = 127;byte b = 127;b = a + b; // error : cannot convert from int to byteb += a; // ok\n\n(因为 a+b 操作会将 a、b 提升为 int 类型，所以将 int 类型赋值给 byte 就会编译出错)\n为什么需要泛型？适用于多种数据类型执行相同的代码\n引入泛型，它将提供类型的约束，提供编译前的检查\n泛型方法泛型方法创建\n\n泛型方法使用\n\n泛型方法创建的时候需要使用&lt;T&gt;来声明这是一个泛型方法, 在传入的参数中需要有Class&lt;T&gt; c参数来指明传入的参数的类型, 然后在方法中通过反射newInstance方法来创建一个新的对象\n使用泛型方法的时候, 可以通过Class.forName(“全限定类名”)来获取Class类\n泛型的上限和下限？在使用泛型的时候，我们可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。\n上限\nclass Info&lt;T extends Number&gt;&#123;    // 此处泛型只能是数字类型\n\n下限\npublicstaticvoidfun(Info&lt;? super String&gt; temp)&#123;// 只能接收String或Object类型的泛型，String类的父类只有Object类System.out.print(temp +&quot;, &quot;);&#125;\n\n如何理解Java中的泛型是伪泛型？泛型中类型擦除 Java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型, 同时这里是会擦除成下限类型），就像完全没有泛型一样。\n注解元注解，元注解是用于定义注解的注解，包括@Retention、@Target、@Inherited、@Documented\n\n@Retention用于标明注解被保留的阶段\n@Target用于标明注解使用的范围\n@Inherited用于标明注解可继承\n\nJava异常类层次结构?\nThrowable\n 是 Java 语言中所有错误与异常的超类。 \n\nError 类及其子类：程序中无法处理的错误，表示运行应用程序中出现了严重的错误。\nException 程序本身可以捕获并且可以处理的异常。Exception 这种异常又分为两类：运行时异常和编译时异常。\n\n\n\n\n\n运行时异常\n\n都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。\n运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。\n\n非运行时异常 （编译异常）\n\n是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。\n可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）区别？\n可查异常（编译器要求必须处置的异常）：\n\n正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。\n除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。\n\n不可查异常(编译器不要求强制处置的异常)\n\n包括运行时异常（RuntimeException与其子类）和错误（Error）\n什么是SPI机制？SPI（Service Provider Interface），是JDK内置的一种 服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，MySQL和PostgreSQL都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是 解耦。\nSPI整体机制图如下：\n\n当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader。\nSPI机制的应用？\nSPI机制 - JDBC DriverManager\n\n在JDBC4.0之前，我们开发有连接数据库的时候，通常会用Class.forName(“com.mysql.jdbc.Driver”)这句先加载数据库相关的驱动，然后再进行获取连接等的操作。而JDBC4.0之后不需要用Class.forName(“com.mysql.jdbc.Driver”)来加载驱动，直接获取连接就可以了，现在这种方式就是使用了Java的SPI扩展机制来实现。\n\nJDBC接口定义\n\n首先在java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商来提供的。\n\nmysql实现\n\n在mysql的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。\n\npostgresql实现\n\n同样在postgresql的jar包postgresql-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是postgresql对Java的java.sql.Driver的实现。\n\n使用方法\n\n上面说了，现在使用SPI扩展来加载具体的驱动，我们在Java中写连接数据库的代码的时候，不需要再使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动了，而是直接使用如下代码：\nString url = &quot;jdbc:xxxx://xxxx:xxxx/xxxx&quot;;Connection conn = DriverManager.getConnection(url,username,password);.....","categories":["Interview","Java","JavaBase"],"tags":["Java","Interview","JavaBase"]},{"title":"Java JUC-并发编程面试问题","url":"/2025/07/11/Interview/Java%20JUC/","content":"并发编程问题\n","categories":["Interview","Java","JUC"]},{"title":"Java Colletion-集合框架面试问题","url":"/2025/07/10/Interview/Java%20Collection/","content":"&#x2F;&#x2F; TODO\n","categories":["Interview","Java","Collection"],"tags":["Java","Interview","Collection"]},{"title":"Binary Sort-二分查找","url":"/2025/07/10/Computer%20Fundamentals/Algorithm/Binary%20Search/","content":"二分查找典型特征\n原数组是有序的, 或者改变原数组顺序不影响答案\n我们要找出来一个数字在数组中的位置(标准二分查找题目)\n\n一般化特征\n我们能一次性排除解空间中的一半解\n我们要找出来解空间中的某一个解的位置\n\n解题通法-红蓝染色法我们能将数组依照单调性分成两部分, 以我们要找出target为例\nnum &gt;&#x3D; target的部分染成蓝色, num &lt; target为红色, 我们需要染色的区间是[left, right]或者(left-1, right+1)…\n\n[left, right]要染色的区间的含义就是我们现在没有染色也就是不知道其中的元素和target之间的关系\n\n循环不变量(以两端闭区间举例)\n\nleft - 1始终是红色\nright + 1始终是蓝色\n\n思考顺序\n首先确定我们怎么确定答案, 这种方式一定是要利用原数组在找到答案方面的单调性, 我们一定能一次性排除一半的解空间\n确定下来红蓝染色情况\n确定下来没有染色区间的开闭选择(一般是双开区间)\n\n典型例题及实现找到第一个大于等于target的值\n闭区间private int lower_bound(int[] nums, int target) &#123;    int left = 0;    int right = nums.length - 1;    // [left, right], left == right + 1 区间为空    // left - 1始终 &lt; target    // right + 1始终 &gt;= target    while (left &lt; right + 1) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid + 1;        else             right = mid - 1;    &#125;    return right + 1;&#125;\n\n开区间private int lower_bound(int[] nums, int target) &#123;    int left = -1;    int right = nums.length;    // (left, right), left + 1 == right 区间为空    // left 始终 &lt; target    // right 始终 &gt;= target    while (left + 1 &lt; right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid;        else             right = mid;    &#125;    return right;&#125;\n\n左开右闭private int lower_bound(int[] nums, int target) &#123;    int left = -1;    int right = nums.length - 1;    // (left, right], left == right 区间为空    // left 始终 &lt; target    // right + 1始终 &gt;= target    while (left &lt; right) &#123;        int mid = left + (right - left + 1) / 2;        if (nums[mid] &lt; target)             left = mid;        else             right = mid - 1;    &#125;    return right + 1;&#125;\n\n这里会有个额外的问题是mid向下取整, 会在left &#x3D; -1, right &#x3D; 0的时候取到-1, 所以我们需要调整成向上取整, 在left &#x3D; -1, right &#x3D; 0的时候取整到0, 就会不落到区间外面了\n左闭右开private int lower_bound(int[] nums, int target) &#123;    int left = 0;    int right = nums.length;    // [left, right), left == right 区间为空    // left - 1始终 &lt; target    // right 始终 &gt;= target    while (left &lt; right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid + 1;        else             right = mid;    &#125;    return right;&#125;\n\n题单典型题目35. 搜索插入位置\n74. 搜索二维矩阵\n34. 在排序数组中查找元素的第一个和最后一个位置\n非典型题目33. 搜索旋转排序数组\n153. 寻找旋转排序数组中的最小值\n4. 寻找两个正序数组的中位数\n参考链接灵茶山艾府-红蓝染色法\n","categories":["Computer Fundamentals","Algorithm","Binary sort"],"tags":["Computer Fundamentals","Algorithm","Binary Sort"]},{"title":"栈 (单调栈)","url":"/2025/07/30/Computer%20Fundamentals/Algorithm/Stack/","content":"栈栈核心特征 (什么时候使用栈)本质上是一种用空间换时间的优化方案, 如果我们缓存数据的方向是从左往右(从右往左), 而我们求解答案的时候是从右往左的, 计算完成以后就不需要了, 符合后进先出的特征, 使用栈结构\n比如括号匹配问题, 我们从左向右遍历和缓存数据, 然后在我们匹配到右括号的时候, 从右往左将数据弹出\n一般解法for (int i = 0; i &lt; nums.length; i++) &#123;   \t// 特殊的情况下, 也就是匹配到了需要解递归的数据的时候    // 元素出栈    while (!stack.isEmpty() &amp;&amp; condition) &#123;        int j = stack.pop();        ...    &#125;        // 一般情况下直接将元素入栈    stack.push(i);&#125;\n\n典型题目20. 有效的括号\n394. 字符串解码\n非典型题目155. 最小栈\n单调栈核心特征单调栈是栈的一种特殊的用法, 我们维护的栈是一个大小单调变化的, 它的需要弹出节点的时刻是将要入栈的元素会比栈顶元素大(小), 我们需要不断弹出元素直至到这个新加入的元素比栈顶元素小(大). 往往弹出元素的时候也就是计算答案的时候.\n常用于解决我们需要知道某个节点的左右最小值(大)的位置的题目, 比如每日温度和柱状图中的最大矩形都是很典型的题目. 在每日温度里面我们需要知道下一个更高温度出现在几天后, 柱状图的最大矩形中, 我们在计算以height[i]为高的矩形大小的时候, 需要知道i左右两边第一个小于height[i]的元素的位置\n一般解法for (int i = 0; i &lt; nums.length; i++) &#123;    while (!stack.isEmpty()            &amp;&amp; nums[i] &lt; nums[stack.peek()]) &#123;\t\tint top = stack.pop();        ans = .... // 计算ans    &#125;    stack.push(i);&#125;\n\n\n\n典型题目739. 每日温度\n84. 柱状图中最大的矩形\n","categories":["Computer Fundamentals","Algorithm","Stack"],"tags":["Computer Fundamentals","Algorithm","Stack"]},{"title":"堆","url":"/2025/08/01/Computer%20Fundamentals/Algorithm/Heap/","content":"堆核心概念\n这里并不讨论堆的实现和基本的原理, 只是讨论这个数据结构的使用场景, 解决的问题\n\n使用堆我们能获得O(logn)的时间复杂度的插入和删除元素, O(1)的时间复杂度的获取某个集合的最大(小)值\n如果一个场景需要持续获取某个变化集合的最大(小)值, 我们就能考虑使用堆, 并且一定会有出堆操作!!! 不然我们简单维护一个min或max变量就行了\n一般解法// 创建小堆Queue&lt;Integer&gt; minHeap = new PriorityQueue&lt;&gt;();// 创建大堆Queue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;&gt;((a,b) -&gt; b-a);\n\n典型例题295. 数据流的中位数\n347. 前 K 个高频元素\n215. 数组中的第K个最大元素\n","categories":["Computer Fundamentals","Algorithm","Heap"],"tags":["Computer Fundamentals","Algorithm","Heap"]},{"title":"操作系统I/O - 多路复用","url":"/2025/07/25/Computer%20Fundamentals/Operating%20System/IO-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","content":"I&#x2F;O-多路复用多路复用是解决的什么问题解决的最根本的问题是: 我们怎么让我们的服务器能并发处理更多的数量的请求\n最经典的问题就是C10K问题: 服务器怎么并发处理1w个请求\n解决这个问题我们就需要考虑到, 连接占用的资源有哪些\n\n文件描述符: Socket实际上是一个虚拟的文件, 也就对应着有相应的文件描述符, 在Linux中一个进程能打开的文件描述符的数量是有限的, 一般来说是1024(默认值)\n系统内存: 每个TCP连接在内核中都有对应的数据结构, 也就是每个连接都占用了一定的内存\n\n在这些基础上, 我们该怎么实现并发处理1w个请求呢?\n\n多进程模型?\n\n我们每成功建立一个连接就创建一个进程, 这个时候因为fork()创建的子进程中的文件描述符也是被继承过去, 让子进程来通过已连接Socket来提供服务\n但是这种方式很明显是不能解决C10K问题的, 没有哪个系统扛得住创建1W个进程, 并且进程间切换的成本很高, 性能很差\n\n多线程模型\n\n为了解决多进程模型中, 进程的体量很大并且切换成本高的问题, 我们换成多线程模型\n当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。\n使用线程池避免频繁地创建和销毁线程, 维护一个已连接Socket队列, 每建立一个连接, 就将已连接Socket添加到队列中, 然后子线程负责从队列中取出来已连接Socket进行处理\n但是同样是没有哪个操作系统能同时维护1w个线程, 也是不可行的\nI&#x2F;O 多路复用为每个请求分配一个进程&#x2F;线程不合适, 我们就只能使用一个进程来维护多个Socket, 这个就是I&#x2F;O多路复用技术\n这就像一个线程调度算法一样, 我们只有一个CPU, 但是我们通过线程调度, 提供了一种我们并发执行多个程序的视图\n我们将处理每个请求的事件耗时控制在0.1ms内, 我们1s就能同时处理1w个请求, 拉长时间来看, 就是多个请求复用了一个进程, 也被称为时分多路复用\nselect&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用, 一个进程可以通过一个系统调用函数从内核中获取多个事件, 当其中任何一个文件描述符准备好IO操作的时候, 程序会被通知\n它们是怎么获取网络事件的呢? 处理事件的时候, 先将所有的连接 (文件描述符) 传给内核, 再由内核返回产生了事件的连接, 然后在用户态处理这些连接对应的请求\nselect&#x2F;poll\n参考 小林coding-I&#x2F;O 多路复用\n\n","categories":["Computer Fundamentals","OS","IO"],"tags":["Computer Fundamentals","OS","IO"]},{"title":"操作系统I/O - 零拷贝","url":"/2025/07/25/Computer%20Fundamentals/Operating%20System/IO-%E9%9B%B6%E6%8B%B7%E8%B4%9D/","content":"I&#x2F;O的演进DMA技术在最开始的时候, 读一个文件的过程是\n\n\n用户进程调用read(), 切换到内核态, CPU向磁盘发起IO请求\n磁盘将数据放入到磁盘控制器缓冲区里面, 发送IO中断信号给CPU\nCPU将数据从磁盘数据控制器缓冲区中拷贝到 PageCache\nCPU将数据从PageCache中拷贝到用户缓冲区\nread()调用返回, 切换到用户态\n\n一共发生了两次用户态和内核态的上下文切换, 发生了两次拷贝, 并且数据的搬运也是交给CPU来操作的, 占用了大量的CPU的时间, 导致了CPU吞吐量下降\n解决方式就是引入了DMA(Direct Memory Access)直接内存访问技术, \n我们将把数据从磁盘控制器缓冲区搬运到PageCache的工作交给了DMA控制器来进行\n\n现在的读一个文件的流程变成了\n\n用户进程调用read(), 切换到内核态, 向操作系统发起IO请求, 将数据读取到自己的内存缓冲区中, 进程进入到了阻塞状态\nCPU收到操作系统发送的指令以后, 将请求发送给DMA, DMA再进一步发送给磁盘\n磁盘将数据放入到磁盘控制器缓冲区里面, 发送IO中断信号给DMA控制器, 告知缓冲区已满\nDMA收到磁盘的信号, 将磁盘缓冲区中的数据拷贝到内核缓冲区中, 此时不占用CPU, CPU可以执行其他的任务\nCPU将数据从PageCache中拷贝到用户缓冲区\nread()调用返回, 切换到用户态\n\n零拷贝我们如果要使用网络传输一个文件, 最初是怎么实现的\n我们一般要用到两个系统调用\nread(file, tmp_buf, len);write(socket, tmp_buf, len);\n\nread读取文件到buf中, write再将这个buf中的内容通过socket发送给客户端, 在这个过程中, 我们会经历四次用户态和内核态的上下文切换, 四次拷贝\n\n\n用户调用read()系统调用, 切换内核态\n将文件从磁盘控制器缓冲区DMA拷贝到内核缓冲区\n将文件从内核缓冲区CPU拷贝到用户缓冲区\n切换到用户态\n用户调用write(), 切换到内核态\n将用户缓冲区中的数据CPU拷贝到socket缓冲区中\n将socket缓冲区的数据DMA拷贝到网卡中, 发送数据\n切换回用户态\n\n我们要优化这种IO形式, 关键就在于减少内核态与用户态的上下文切换, 并减少拷贝的次数\n\n怎么减少用户态和内核态的切换, 只要执行了一次系统调用, 不可避免地会有两次切换, 所以核心思路就是减少系统调用的数量\n\n\n怎么减少拷贝的数量, 在这个文件出书的场景中, 其实用户缓冲区是完全没有必要的存在\n\nmmap + write使用mmap代替read函数\nbuf = mmap(file, len);write(sockfd, buf, len);\n\nmmap系统调用直接把内核缓冲区中的数据映射到用户空间, 这样我们就相当于不使用用户缓冲区中转数据, 减少了一次数据的拷贝\n\n现在PageCache中的数据直接通过CPU拷贝到scoket缓冲区中\n但是这种形式系统调用的次数仍然是两次, 也就是内核态和用户态的上下文切换的次数仍然是四次\nsendfile#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd. int in_fd, off_t *offset, size_t count);\n\n这个系统调用能直接将mmap + write合并, 能减少一次系统调用的次数\n并且如果网卡支持SG-DMA技术(The Scatter-Gather Direct Memory Access), 还能再减少一次数据拷贝\n\n\n通过DMA将磁盘的数据拷贝到内核缓冲区\n缓冲区描述符和数据长度传到socket缓冲区, 网卡的SG-DMA控制器直接将内核缓存中的数据拷贝到网卡的缓冲区中\n\n省去了将数据从内核缓冲区中拷贝到socket缓冲区中的过程\n这样就是零拷贝的最终形态, 只需要两次数据的拷贝, 两次内核态和用户态的上下文切换, 并且没有在内存层面的数据拷贝, 也就是这个过程全程是通过DMA来进行的, 不需要CPU参与\n大文件传输实现的特殊性PageCache我们常说的IO文件的时候的内核缓冲区, 就是PageCache(磁盘高速缓存). 在零拷贝中我们就使用了PageCache, 读文件时候, 会先将数据通过DMA控制器读到内核缓冲区中. 实际上PageCache就可以看作是磁盘和内存之间的中间层, 和CPU Cache是性质类似的东西\nPageCache有预读功能, 同时PageCache内部是一个LRU队列, 会维护热点数据. 如果我们读大文件, 就会导致LRU队列我们批量读取文件的时候的预读失效和缓存污染问题(当然Linux通过inactive_list和active_list以及升级策略很大程度上解决了这个问题). \n但是我们还是能很明显看出, 在读大文件的时候PageCache是没有什么作用的, \n\n读大文件预读功能没有什么用\n缓存最近被访问的数据, 大文件导致缓存污染\n\n相当于DMA多做了一次没有的数据拷贝\n直接I&#x2F;O我们直接绕开DMA, 并且不再拷贝到内核缓冲区中. 阻塞问题我们使用异步I&#x2F;O来解决\n\n\n用户进程调用系统调用, 发起异步I&#x2F;O读, CPU发送指令到磁盘, 这里会直接返回, 也就是不阻塞读\n然后磁盘准备好数据后发送IO中断信号, DMA将数据从磁盘控制器缓冲区拷贝到用户缓冲区\n通知用户进程读取成功了\n\n直接I&#x2F;O绕过了PageCache就无法享受到内核提供的两点优化\n\n内核的I&#x2F;O调度算法会缓存尽可能多的I&#x2F;O请求在PageCache中, 最后合并成一个更大的I&#x2F;O请求, 减少I&#x2F;O次数\n无法享受到预读机制\n\n\n参考文档:\n小林coding 9.1什么是零拷贝\n\n","categories":["Computer Fundamentals","OS","IO"],"tags":["Computer Fundamentals","OS","IO"]},{"title":"原子类-AtomicInteger类详解","url":"/2025/07/23/Java/JUC/%E5%8E%9F%E5%AD%90%E7%B1%BB-AtomicInteger/","content":"原子类-AtomicInteger类详解说实话, 也没什么好额外讲的, 整个原子类家族, 就是一族封装了一些类CAS操作的类, 提供了我们为某个变量进行原子操作的能力, 让我们可以在多线程环境下, 对某个变量进行原子操作, 而不需要加锁.\n下面简单说明一下类的结构\n核心字段private static final Unsafe U = Unsafe.getUnsafe();private static final long VALUE    = U.objectFieldOffset(AtomicInteger.class, &quot;value&quot;);private volatile int value;\n\n\nUnsafe就是提供了操作系统层面的API来执行CAS操作类\nVALUE是使用了Unsafe获取到的AtomicInteger类中的value字段的属性在类中偏移量, 用于CAS操作\nvalue就是我们这个Integer类的值, 这里的value是保证可见性的, 所以如果使用Atomic是默认保证多线程之间的可见性, 不需要额外加volatile\n\n核心方法因为比较简单, 大多数方法就是让CAS操作更易用, 所以我只列举出来核心方法, 不提供源码了\n\nget() : 获取原子类的值\nset(int newValue) : 设置原子类的值\n\n核心方法一般分成getAndSet和setAndGet两种, 前者返回的是set前的值, 后者返回的是set后的值\ngetAndSet类getAndSet(int newValue) : 获取原子类的值, 并设置为newValue\ngetAndIncrement() : 获取原子类的值, 并将其加1\ngetAndDecrement() : 获取原子类的值, 并将其减1\ngetAndAdd(int delta) : 获取原子类的值, 并将其加上delta\nsetAndGet类setAndGet(int newValue) : 设置原子类的值为newValue, 并返回newValue\nincrementAndGet() : 将原子类的值加1, 并返回加1后的值\ndecrementAndGet() : 将原子类的值减1, 并返回减1后的值\naddAndGet(int delta) : 将原子类的值加上delta, 并返回加上delta后的值\nCompare And Exchange类 (JDK9)正宗的CAS操作\npublic final int compareAndExchangeAcquire(int expectedValue, int newValue) &#123;    return U.compareAndExchangeIntAcquire(this, VALUE, expectedValue, newValue);&#125;\n\n这个CAS是有内存屏障保障不会被重排序的, 任何内存操作不会跨越该操作进行重排序\n\npublic final int compareAndExchangeAcquire(int expectedValue, int newValue) &#123;    return U.compareAndExchangeIntAcquire(this, VALUE, expectedValue, newValue);&#125;\n\n\n这个CAS只保证该操作之后的读写操作不会被重排序到该操作之前, 但该操作之前的读写操作可以被重排序到该操作之后\n\n","categories":["Java","JUC","原子类"],"tags":["Java","JUC","原子类"]},{"title":"线程池-ThreadPoolExecutor类详解","url":"/2025/07/24/Java/JUC/%E7%BA%BF%E7%A8%8B%E6%B1%A0-ThreadPoolExecutor/","content":"线程池-ThreadPoolExecutor类详解ThreadPoolExecutor的构造方法public ThreadPoolExecutor(int corePoolSize,                            int maximumPoolSize,                            long keepAliveTime,                            TimeUnit unit,                            BlockingQueue&lt;Runnable&gt; workQueue) &#123;    this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,            Executors.defaultThreadFactory(), defaultHandler);&#125;\n\ncorePoolSize: 核心线程数, 线程池中即使没有任务也要保持存活的最大线程数量\nmaximumPoolSize: 线程池中允许的最大线程数量\nkeepAliveTime: 线程池中超过核心线程数的空闲线程存活时间\nunit: keepAliveTime的时间单位\nworkQueue: 任务队列, 用于存放待执行的任务\nthreadFactory: 线程工厂, 用于创建新线程\nhandler: 拒绝策略, 当任务无法被执行时的处理策略\n\n拒绝策略JDK提供了四种默认的拒绝策略\n\nAbortPolicy: 将任务丢弃并抛出一个RejectedExecutionException异常, 默认的拒绝策略\n\npublic static class AbortPolicy implements RejectedExecutionHandler &#123;    /**     * Creates an &#123;@code AbortPolicy&#125;.     */    public AbortPolicy() &#123; &#125;    /**     * Always throws RejectedExecutionException.     *     * @param r the runnable task requested to be executed     * @param e the executor attempting to execute this task     * @throws RejectedExecutionException always     */    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        throw new RejectedExecutionException(&quot;Task &quot; + r.toString() +                                                &quot; rejected from &quot; +                                                e.toString());    &#125;&#125;\n\n\nDiscardPolicy: 将任务直接丢弃\n\npublic static class DiscardPolicy implements RejectedExecutionHandler &#123;    /**     * Creates a &#123;@code DiscardPolicy&#125;.     */    public discardpolicy() &#123; &#125;    /**     * does nothing, which has the effect of discarding task r.     *     * @param r the runnable task requested to be executed     * @param e the executor attempting to execute this task     */    public void rejectedexecution(runnable r, threadpoolexecutor e) &#123;    &#125;&#125;\n\n\nCallerRunPolicy: 直接在试图创建并执行任务的calling Thread线程执行这个任务\n\npublic static class CallerRunsPolicy implements RejectedExecutionHandler &#123;    /**     * Creates a &#123;@code CallerRunsPolicy&#125;.     */    public CallerRunsPolicy() &#123; &#125;    /**     * Executes task r in the caller&#x27;s thread, unless the executor     * has been shut down, in which case the task is discarded.     *     * @param r the runnable task requested to be executed     * @param e the executor attempting to execute this task     */    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        if (!e.isShutdown()) &#123;            r.run();        &#125;    &#125;&#125;\n\n\nDiscardOldestPolicy: 将阻塞队列的最后一个任务丢弃, 然后重新执行这个任务\n\npublic static class DiscardOldestPolicy implements RejectedExecutionHandler &#123;    /**     * Creates a &#123;@code DiscardOldestPolicy&#125; for the given executor.     */    public DiscardOldestPolicy() &#123; &#125;    /**     * Obtains and ignores the next task that the executor     * would otherwise execute, if one is immediately available,     * and then retries execution of task r, unless the executor     * is shut down, in which case task r is instead discarded.     *     * @param r the runnable task requested to be executed     * @param e the executor attempting to execute this task     */    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        if (!e.isShutdown()) &#123;            e.getQueue().poll();            e.execute(r);        &#125;    &#125;&#125;\n\n核心字段源码\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;private static final int STOP       =  1 &lt;&lt; COUNT_BITS;private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;\n\n\nctl: Control线程控制信号, 是一个原子类, 前三位是线程池的状态位, 后29位是线程池中的线程数量\n int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;方法构建ctl\nrs是RunState 线程池状态\nwc是WorkerCount 工人数量也就是线程池中的线程的数量\n\n\nint runStateOf(int c)     &#123; return c &amp; ~COUNT_MASK; &#125;: 获取线程池状态\nint workerCountOf(int c)  &#123; return c &amp; COUNT_MASK; &#125;: 获取工人数量\n\n\nCOUNT_BITS: 这个参数 &#x3D;&#x3D; 29, 是获取状态位和设置状态位需要移动的位数\nCONUT_MASK: 前29bit都是1, c &amp; COUNT_MASK来获取到wc\nRUNNING: 线程池的正常工作状态, 线程池可以接受新的任务并且会处理等待队列中的任务\nSHUTDOWN: 调用shutdown()方法的时候, 线程池进入到这个状态\n线程池不再接受新的任务\n继续执行等待队列中的已经存在的任务和正在执行的任务\n\n\nSTOP: 调用shutdownNow()方法\n不接受新的任务\n不处理队列中的任务\n尝试中断正在执行的任务\n\n\nTIDYING: 一种过渡状态, 在满足以下条件的时候进入\n所有的任务都已经终止\n工作线程的数量是0\n队列为空的时候进入到这个状态以后, 会执行 terminate()钩子方法\n\n\nTERMINATED: 线程池关闭, 所有的资源都得到释放\n\n\n任务的执行execute方法源码及解析\npublic void execute(Runnable command) &#123;    if (command == null)        throw new NullPointerException();    // 1. 如果现在的线程数量 &lt; 核心线程数量    int c = ctl.get();    if (workerCountOf(c) &lt; corePoolSize) &#123;        // 增加核心线程数量        if (addWorker(command, true))            return;        c = ctl.get();    &#125;    // 2. 现在的线程数量 &gt; 核心线程数量    // 将任务添加到等待队列中    if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;        // 双重检查, 因为进入到if块以后可能状态线程池的状态发生了变化        int recheck = ctl.get();        // 如果双重检查的时候发现线程池的状态不再是RUNNING, 移除任务        // 并执行reject回调方法        if (! isRunning(recheck) &amp;&amp; remove(command))            reject(command);        // 执行到这个位置的时候, 逻辑上核心线程已经满了, 但是是可能出现其他的线程因为某些错误死掉的情况, wc实际记录的是还存活着的线程, 这个时候我们就需要创建一个非核心线程来执行        else if (workerCountOf(recheck) == 0)            addWorker(null, false);    &#125;    // 3. 等待队列也已经满了, 尝试创建非核心队列执行任务, 如果创建失败    // 说明线程数量已经超过了最大线程数量, 或者线程池的状态不允许创建新的线程了    else if (!addWorker(command, false))        // 执行reject方法        reject(command);&#125;\n\n线程池类执行任务的顺序是\n\n先尝试将任务交给核心线程, 如果核心线程的数量 &lt; 最大核心线程数量, 创建新的核心线程执行任务\n核心线程的数量超过了最大线程, 尝试将任务添加到等待队列里面\n等待队列也已经满了, 创建一个非核心线程执行任务, 如果创建失败, 说明线程状态不是RUNNING或者线程数量已经超过了最大的数量, 这个时候执行reject方法\n\n\n原文:Proceed in 3 steps:\n\nIf fewer than corePoolSize threads are running, try tostart a new thread with the given command as its firsttask.  The call to addWorker atomically checks runState andworkerCount, and so prevents false alarms that would addthreads when it shouldn’t, by returning false.\n\nIf a task can be successfully queued, then we still needto double-check whether we should have added a thread(because existing ones died since last checking) or thatthe pool shut down since entry into this method. So werecheck state and if necessary roll back the enqueuing ifstopped, or start a new thread if there are none.\n\nIf we cannot queue task, then we try to add a newthread.  If it fails, we know we are shut down or saturatedand so reject the task.\n\n\n\naddWorker方法比较长, 分成两部分解读\n方法签名: private boolean addWorker(Runnable firstTask, boolean core)\n\ncore: 添加的线程是不是核心线程\n\n增加线程的数量, 并没有真的增加线程\n\n\nretry:for (int c = ctl.get();;) &#123;    // 如果线程池的状态至少是SHUTDOWN, 这个时候我们不能再添加新的任务    // 如果状态是STOP, 说明这个时候不能再添加任务了, return false    // 如果状态是SHUTDOWN, 但是传入的任务不是null, 也返回null, 因为SHUTSOWN状态只能从任务队列中消费任务    // 如果传入的任务是空, 但是任务队列也是空的, 这个时候没有要消费的任务了, retuen false    if (runStateAtLeast(c, SHUTDOWN)        &amp;&amp; (runStateAtLeast(c, STOP)            || firstTask != null            || workQueue.isEmpty()))        return false;    // CAS增加worker的数量    for (;;) &#123;        // 超过线程数量的限制, 不能再添加worker了        if (workerCountOf(c)            &gt;= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK))            return false;         // CAS成功增加worker的数量, 到下一步增加Worker        if (compareAndIncrementWorkerCount(c))            break retry;         c = ctl.get();  // CAS失败, 重新获取worker数量        if (runStateAtLeast(c, SHUTDOWN))            continue retry;        // CAS失败, 说明在这个for中的CAS之前worker的数量发生了变化, CAS尝试添加线程    &#125;&#125;\n\n\n\n添加Worker, 也就是真的添加工作线程\n\nWorker是一个继承了AQS, 实现了Runnable的类\nboolean workerStarted = false;boolean workerAdded = false;Worker w = null;try &#123;    w = new Worker(firstTask);    // w.thread是在构造方法中使用线程工厂创建的    // this.thread = getThreadFactory().newThread(this);    final Thread t = w.thread;    if (t != null) &#123;        final ReentrantLock mainLock = this.mainLock;        // 加锁保护HashSet的线程安全        // largestPoolSize 统计信息的安全        // 在双重检查时候, ws不会发生变化        mainLock.lock();        try &#123;            // 用于双重检查            // 如果在获取锁以前, 线程池shutdown了            int c = ctl.get();            // 状态是RUNNING, 或者状态是SHUTDOWN并且任务是空            // 前者正常情况, 后者是在创建非核心线程            if (isRunning(c) ||                (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) &#123;                // 创建线程失败                if (t.getState() != Thread.State.NEW)                    throw new IllegalThreadStateException();                // 创建成功, 将worker添加到线程池中                workers.add(w);                workerAdded = true;                int s = workers.size();                if (s &gt; largestPoolSize)                    largestPoolSize = s;            &#125;        &#125; finally &#123;            mainLock.unlock();        &#125;        // 启动worker的任务        if (workerAdded) &#123;            t.start();            workerStarted = true;        &#125;    &#125;&#125; finally &#123;    // 针对创建失败的Worker的处理    if (! workerStarted)        // 将这个worker从hashSet中移除        addWorkerFailed(w);&#125;return workerStarted;\n\nWorker类的构造方法Worker(Runnable firstTask) &#123;    setState(-1); // inhibit interrupts until runWorker    this.firstTask = firstTask;    this.thread = getThreadFactory().newThread(this);&#125;\n\nrunWorker方法Worker类的run方法实现内部是直接调用runWorker(Worker w) 方法\nfinal void runWorker(Worker w) &#123;    Thread wt = Thread.currentThread();    Runnable task = w.firstTask;    w.firstTask = null;    w.unlock();    boolean completedAbruptly = true;    try &#123;        // 工作者线程不断从队列中尝试获取Task然后执行        // 优先执行被分配的first Task        while (task != null || (task = getTask()) != null) &#123;            // 加锁确保任务执行的时候不会被shutdown中断            w.lock();            // 先检查线程池状态 &gt;= STOP, 是的话直接设置线程中断            // 再次检查, 在线程已被中断, 线程池 &gt;= STOP的时候                // 清除线程的中断标志, 然后设置线程被中断了            if ((runStateAtLeast(ctl.get(), STOP) ||                 (Thread.interrupted() &amp;&amp;                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;                !wt.isInterrupted())                wt.interrupt();            try &#123;                beforeExecute(wt, task);                try &#123;                    // 核心执行内容, 执行task                    task.run();                    afterExecute(task, null);                &#125; catch (Throwable ex) &#123;                    afterExecute(task, ex);                    throw ex;                &#125;            &#125; finally &#123;                // 扫尾工作                task = null;                w.completedTasks++;                w.unlock();            &#125;        &#125;        completedAbruptly = false;    &#125; finally &#123;        // 核心线程在RUNNIN步骤是不会走到这一步的,         // 因为会在getTask的过程中阻塞获取任务        processWorkerExit(w, completedAbruptly);    &#125;&#125;\n\ngetTask方法private Runnable getTask() &#123;    boolean timedOut = false; // Did the last poll() time out?    for (;;) &#123;        int c = ctl.get();        // 在线程池 &gt;= STOP, 等待队列是空的时候        // 工人的数量--, 并直接返回null, 这种情况是getTask失败的情况        if (runStateAtLeast(c, SHUTDOWN)            &amp;&amp; (runStateAtLeast(c, STOP) || workQueue.isEmpty())) &#123;            // workerCount--            decrementWorkerCount();            return null;        &#125;        // 运行到这里的时候, 说明运行状态是RUNNING        // 或者 == SHUTDOWN, 或者 &gt;= STOP 但是等待队列不是空        int wc = workerCountOf(c);        // 需不需要处理线程存活时间超时的情况        boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;        // 这里是用于处理当前的Worker是不是要销毁        // 如果Worker的数量超过了最大线程池的大小, 减少多余的worker        // 当前线程需要考虑超时, 并且上一次获取任务时发生了超时, 这种情况下worker也应该被回收以节省资源        if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))            // 保证不会过度销毁Worker, Worker数量至少大于1            // 或者等待队列中没有任务了, 这种情况也能销毁当前Worker            &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123;            if (compareAndDecrementWorkerCount(c))                return null;            continue;        &#125;        try &#123;            Runnable r = timed ?                // 如果是非核心线程就会获取任务就会有超时设置                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :                workQueue.take();            if (r != null)                // 成功获取到了任务                return r;            // 超时了, 在下一次循环中, 就会因为这个timeout = true            // 而导致这个非核心线程被销毁            timedOut = true;        &#125; catch (InterruptedException retry) &#123;            timedOut = false;        &#125;    &#125;&#125;\n\n\n到这里我们能简单总结下一个Worker的生命周期\n对于任何Worker, 会在runWorker方法中不断循环获取任务执行任务一旦没有获取到任务, worker就会被移除\n对于核心线程worker, 会在获取任务getTask()上一直阻塞直到获取任务对于非核心线程worker, 在getTask上只会阻塞这个worker存活时间超过这个时间, 就会在getTask的下一次循环中workerCOunt–返回null,然后结束runWorker中while循环, 然后将这个worker销毁\n\n任务的提交submit方法ThreadPoolExecutor类是继承自AbstractExecutorService的. 其中的submit方法也是在这个抽象类中实现的\npublic Future&lt;?&gt; submit(Runnable task) &#123;        if (task == null) throw new NullPointerException();        // 通过submit方法提交的Callable任务会被封装成一个FutureTask对象        // 普通的Runnable接口类, 也会被封装成FutureTask对象        RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null);        execute(ftask);        return ftask;    &#125;\n\n而execute就是我们第一个讲解的任务的执行的核心部分了\n这里线程池的设计我们能看到是使用了模板模式\n任务的关闭shutdown方法将所有的正在阻塞获取任务的空闲线程的状态变成interrupt, 来释放没有在\n怎么实现的SHUTDOWM状态的语义: \n\n线程池不再接受新的任务\n在addWorker的时候, 如果是addWorker(command, true&#x2F;false)形式都会返回false\n\n\n继续执行等待队列中的已经存在的任务和正在执行的任务\n只会通过interrupt唤醒没有在执行任务在阻塞获取Task的worker, 并且会删除这个空闲的worker\n不会影响正在执行的任务, 也不会影响在等待队列中还有任务的时候\n\n\n\n怎么从SHUTDOWN一步一步变成的TERMINATE\n\n在execute中会直接reject新的任务\nSHUTDOWN状态下并且队列为空的时候, 也就是开始出现空闲的worker的时候, 会在getTask方法返回null\n因为getTask方法返回了null, 触发了runWorker方法中的销毁worker, 并tryTerminate()\n在tryTerminate中再interrupt下一个worker, 这样渐进式将所有的worker都销毁\n\npublic void shutdown() &#123;    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try &#123;        checkShutdownAccess();        advanceRunState(SHUTDOWN);        // 将所有没有执行任务的worker打上中断状态        interruptIdleWorkers();        onShutdown(); // hook for ScheduledThreadPoolExecutor    &#125; finally &#123;        mainLock.unlock();    &#125;    tryTerminate();&#125;private void interruptIdleWorkers() &#123;    interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123;    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try &#123;        for (Worker w : workers) &#123;            Thread t = w.thread;            // 成功获取到了worker的lock,             // 而worker的lock只会在runWorker方法类里面被获取走            // 说明这个worker是一个空闲的worker            // 通过中断来唤醒阻塞的worker来去检查是不是STOP了            if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123;                try &#123;                    t.interrupt();                &#125; catch (SecurityException ignore) &#123;                &#125; finally &#123;                    w.unlock();                &#125;            &#125;            if (onlyOne)                break;        &#125;    &#125; finally &#123;        mainLock.unlock();    &#125;&#125;\n\nshutdownNow方法shutdownNow会为所有的线程都打上interrupt状态\n\nSTOP: 调用shutdownNow()方法\n不接受新的任务\n同SHUTDOWN\n\n\n不处理队列中的任务\n会将队列清空并返回\n\n\n尝试中断正在执行的任务\n如果方法尝试执行, 但是还没有执行的时候, 也就是worker刚获取到下一轮的task的时候, 会因为状态是STOP, getTask() &#x3D; null, 进入到销毁worker的过程\n\n\n\n\n\npublic List&lt;Runnable&gt; shutdownNow() &#123;    List&lt;Runnable&gt; tasks;    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try &#123;        checkShutdownAccess();        advanceRunState(STOP);        interruptWorkers();        tasks = drainQueue();    &#125; finally &#123;        mainLock.unlock();    &#125;    tryTerminate();    return tasks;&#125;private void interruptWorkers() &#123;    // assert mainLock.isHeldByCurrentThread();    for (Worker w : workers)        w.interruptIfStarted();&#125;void interruptIfStarted() &#123;    Thread t;    if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123;        try &#123;            t.interrupt();        &#125; catch (SecurityException ignore) &#123;        &#125;    &#125;&#125;","categories":["Java","JUC","线程池"],"tags":["Java","JUC","线程池"]},{"title":"MySQL Buffer","url":"/2025/07/20/MiddleWare/MySQL/MySQL%20Buffer%20Pool/","content":"Buffer Pool就像CPU Cache一样的缓存中间层, 来提高MySQL的性能, 写方面采用写回策略(修改的时候如果在缓存中, 就会直接修改缓存中的数据, 然后标记为脏页)\nBuffer Pool缓存了什么在MySQL启动的时候, 会为Buffer Pool分配一片连续的内存空间, 然后按照默认的16KB的大小分页, Buffer Pool中的页就是缓存页\nBuffer Pool中缓存了这六种信息\n\n\nundo页记录的是什么\n\n生成undo log的时候, undo log会写入到Buffer Pool中的Undo 页面\n\n查询一条记录, 就只会缓冲一条记录吗\n\n会将整个页都缓存进去\n","categories":["Middleware","MySQL"],"tags":["Middleware","MySQL"]},{"title":"MySQL 日志","url":"/2025/07/20/MiddleWare/MySQL/MySQL%20%E6%97%A5%E5%BF%97/","content":"MySQL日志\n参考文章:  小林coding-MySQL 日志\n\n执行一条update语句, 期间会发生什么\nUPDATE t_user SET name = &#x27;xiaolin&#x27; WHERE id = 1;\n\n首先是前面和查询语句相似的流程\n\n客户端先通过连接器建立连接, 连接器判断用户的身份\n查询缓存, 但是因为这是一条update语句, 所以不会走查询缓存的步骤, 相反会将对应的表的缓存给清空\n通过解析器分析update语句, 拿到update关键字, 表名等信息, 构建出来语法树, 做语法检查\n通过预处理器判断表和字段是否存在\n优化器确定执行计划, 这里因为是通过id作为where的条件, 会通过id这个主键执行查询\n将执行计划交给存储引擎执行, 找到这一行, 然后执行更新\n\n\n而日志就在最后的更新步骤出现了\n\nundo log: Innodb引擎层生成的日志, 实现了事务的原子性, 主要实现了事务回滚和MVCC\nredo log: Innodb引擎层生成的日志, 实现了事务的持久性, 主要实现了crush-safe\nbinlog: Server层生成的日志, 主要用于数据备份和主从复制\n\nundo log是怎么工作的在执行DML语句的时候, 会将回滚时需要的数据都记录到undo log中\n\ninsert语句, 将这个记录的主键值记录下来, 之后要回滚的时候, 就只需要将这个主键值的记录给删除就行了\ndelete语句, 将这个被删除的记录的内容都记录下来, 之后回滚的时候, 就再重新插入\nupdate语句, 将更新列的旧值记录下来, 之后回滚的时候, 将记录重新用旧值覆盖\n如果不是主键列, 会记录旧值, 在回滚的时候用旧值覆盖\n如果是主键列, 会记录成删除旧行再插入新行, 回滚的时候也会将新记录先删除再插入原来的记录\n\n\n\n每条记录有trx_id事务id和roll_pointer指针\n\ntrx_id: 该记录是哪个事务修改的\nroll_pointer: 该指针将一条记录的undo log串联起来, 形成一条版本链\n\n\n在事务执行失败的时候, 就回滚到这个事务执行之前的版本\n上面都是通过undo log实现的事务回滚, undo log同样用于MVCC\n对于 [读提交] 和 [可重复读] 两个执行级别来说, 它们的快照读是通过 Read View + undo log来实现的, 区别在于创建undo log的时机不一样\n\n对于读提交: 在每个select后都会生成一个Read View, 在这个隔离级别中, 不会有脏读现象, 但是如果其他事务修改了数据并且提交了, 该事务中就能读到, 也就会出现同一个select语句前后执行的结果不一样的问题\n对于可重复度: 在事务启动的时候生成一个Read View, 保证了在事务中, 不会读到其他事务修改的数据\n\n为什么需要redo logredo log是用于解决崩溃恢复问题, 也就是数据的持久化(这里包括undo log和表数据)\nredo log是物理日志, 会记录对某个数据页进行了什么修改, 比如对XXX表空间中的YYY数据页ZZZ偏移量的地方做了AAA更新\n\n为什么要写到redo log, 而不直接将数据写到磁盘中, 多此一举\n\nredo log是使用了WAL(Write-Ahaed Logging)技术, MySQL的写操作并不是立刻写到磁盘上, 而是先写日志, 然后写到磁盘上. \n如果直接将数据写入到磁盘中, 就是随机写, 而将数据写入到log文件中因为是追加写, 所以是顺序写, 磁盘的I&#x2F;O性能有10~100倍的提升\n\n产生的redo log是直接写入到磁盘中吗\n\n问出来很明显就不是了, 我们需要注意到内核的缓冲区这个存在, 我们执行write函数, 实际上是将数据写入到内核缓冲区中, 直到我们主动调用fsync()或者内核自己同步, 才会刷盘. 这是其中一方面, 另一方面是redo log本身就有一个redo log buffer, 用于缓冲log, 提高IO性能\nredo log什么时候刷盘redo log刷盘的时机主要有下面几个(注意是刷盘, 而不是写入到文件中, 前者是直接写入到磁盘中的, 后者只是将内容写入到内核缓冲区中)\n\nMySQL正常关闭的时候\nredo log buffer中的记录写入量大于redo log buffer内存空间的一半的时候\n每次事务提交的时候都将缓存在redo log buffer中的redo log直接持久化到磁盘中(这个策略通过innodb_flush_log_at_trx_commit参数控制)\n\n\ninnodb_flush_log_at_trx_commit 参数控制的是什么\n\n\n参数为0的时候: 每次事务提交会将redo log留在redo log buffer\n参数为1的时候: 每次事务提交会将redo log buffer中的redo log直接持久化到磁盘中\n参数为2的时候: 每次事务提交会将redo log buffer中的redo log写入到redo log文件中(并不是持久化到了磁盘中, 而是到了内核中的Page Cache)\n\n\n\n那么innodb_flush_log_at_trx_commit参数的值是0或者2的时候, 什么时候刷盘?\n\nInnoDB后台线程每隔一秒:\n\n参数为0的时候: 后台线程执行write()将redo log buffer中的redo log写到Page Cache中, 再执行fsync()写入到磁盘中, 所以MySQL进程的崩溃, 会导致前1s的所有事务丢失\n参数为2的时候: 区别就是只需要调用fsync(), 数据已经都在Page Cache中了, 所以MySQL进程的崩溃, 不会导致事务丢失, 只有宕机崩溃的时候, 会导致前1s的所有事务丢失\n\n\nredo文件写满了怎么办InnoDB中redo log是以重做文件日志组的形式存在的, redo log group中有两个redo log文件, 两个文件大小一致, 分别叫做 ib_logfile0和ib_logfile1\n重做文件日志组是采用循环写的模式, 从头开始写, 写到了末尾又回到了开头, InnoDB引擎会先写 ib_logfile0, 然后写ib_logfile1, 当 ib_logfile1也写满的时候, 就会重新回到logfile0的开头\nInnoDB使用write pos 表示redo log当前记录写到的位置, checkpoint 表示当前要擦除的位置, 其中要擦除的位置就是已经持久化到磁盘中脏页的位置\n\n如果write pos 追上了 checkpoint, 说明redo log已经满了, 这个时候MySQL会被阻塞, 会停下来将Buffer Pool中的脏页刷新到磁盘中, 将redo log中对应的记录标记并清除, 然后移动checkpoint, MySQL恢复正常\nredo log的格式redo log是物理日志, 记录的是对数据页的修改, redo log的格式是:\nLSN | Log Record Type | Log Record Length | Log Record Body\n\nLSN: Log Sequence Number, redo log的序列号, 用于标识redo log的顺序\nLog Record Type: redo log的类型, 比如更新数据页, 删除数据页\nLog Record Length: redo log的长度, 用于标识redo log的大小\nLog Record Body: redo log的具体内容, 包含了对数据页的修改信息Log Record Body的内容是根据Log Record Type的不同而不同的, 比如更新数据页的Log Record Body会包含更新前的数据和更新后的数据, 删除数据页的Log Record Body会包含被删除的数据\n\n为什么需要binlogbinlog是逻辑日志, 记录的是对数据的修改, binlog的主要作用是用于数据备份和主从复制\nMySQL在执行完一条更新操作以后, Server层还会生成一条binlog, 等事务提交的时候, 会将该事务执行过程中产生的binlog写入到binlog文件中\nbinlog只能用于归档, 是不具备crush-safe能力的\nredo log和binlog的区别\n适用对象不同\n\n\nbinlog是Server层实现的日志, 所有的存储引擎都能使用\nredo log是InnoDB引擎实现的日志, 只能用于InnoDB存储引擎\n\n\n文件格式不同\n\n\nbinlog有 3 种格式: STATEMENT, ROW, MIXED\nSTATEMENT: 记录每一条更新的操作的SQL语句, 这也是为什么binlog会被称作逻辑日志, 主从复制种slave端就是通过binlog中记录的SQL语句来执行更新操作的. 但是会存在动态函数的问题, 比如NOW()函数, 在主从复制中, 主库执行的NOW()函数和从库执行的NOW()函数的时间不一致, 会导致数据不一致\nROW: 记录行数据最后被修改成什么样子(这种格式的日志就不是逻辑日志了), 缺点就是如果是批量更新, 会记录每一行的修改, 可能会导致binlog文件过大\nMIXED: 结合了STATEMENT和ROW两种格式, 会根据不同的情况自动选是使用STATMENT模式还是ROW模式\n\n\n\n\n写入方式不同\n\n\nbinlog是追加写, 写满一个文件, 就创建一个新的文件继续写, 不会覆盖之前的文件, 保存的是全量的日志\nredo log是循环写, 写满一个文件, 就回到开头继续写, 只保存最近的日志\n\n\n用途不同\n\n\nbinlog主要用于数据备份和主从复制, 也可以用于数据恢复\nredo log主要用于崩溃恢复, 也可以用于数据恢复\n\n\n如果整个数据库的数据都被删除了, 能通过redo log来恢复吗\n\n不能, 只能通过binlog来恢复, redo log记录的不是全量的数据, 如果脏页被写入到了磁盘中, 就会从redo log中删除\n主从复制是怎么实现的MySQL集群的主从复制可以分成三个阶段\n\n写入binlog: 主库写binlog日志, 提交事务并更新本地存储数据\n同步binlog: 从库通过IO线程连接到主库, 从主库获取binlog日志, 写入到本地的中继日志中\n回访binlog: 从库通过SQL线程读取中继日志, 执行SQL语句, 更新本地存储数据\n\n\n详细过程是\n\n主库在收到的客户端提交事务的请求之后, 会先写入到binlog中, 然后提交事务, 更新存储引擎中的数据, 事务提交完成后, 返回给客户端”操作成功”的响应\n从库创建一个专门的IO线程, 连接主库的log dump线程, 来接收主库的binlog日志, 再把binlog信息写入到relay log中, 再返回给主库复制的复制成功的响应\n从库会创建一个用于回放binlog的线程, 去读relay log中的中继日志, 然后回放binlog更新存储引擎中数据\n\n\n从库是不是越多越好\n\n并不是, 从库越多, 主库需要创建同样多的log dump线程来处理从库连接上来的IO线程, 对主库的资源消耗较高\n\n主从复制还有哪些模型\n\n\n同步模型: MySQL主库提交事务的线程需要等待所有的从库都响应复制成功以后, 才会返回给客户端结果, 这样的形式性能和可用性都很差\n异步模型: 就是上面的模型, 缺点就是如果主库宕机, 就会出现数据的丢失\n半同步模型: 介于上面两者之间, 事务线程不用等待所有的从库返回复制成功响应, 只需要等待一部分返回复制成功响应就会返回给客户端. 通过这种形式, 保证了即使主库宕机, 也还有从库保存有最新的数据, 不会导致数据丢失\n\nbinlog什么时候刷盘在Server层, binlog有一个binlog cache, 事务提交的时候, 是先写到binlog cache中, 然后再把binlog cache写入到binlog文件中.\n一个线程中只能有一个事务正在执行, 每个线程也都携带了一个binlog cache\n\n什么时候binlog cache会被写入到binlog中\n\n在事务提交的时候, 会将binlog cache中的完整事务写入到binlog文件中, 并清空binlog cache (注意这里不是持久化, 也就是只调用了write(), 而没有调用fsync())\n\nMySQL中提供了sync_binlog参数来控制数据库binlog刷盘的频率\n\nsync_binlog &#x3D; 0的时候, 表示每次提交事务都只write, 不fsync(), 什么时候fsync交给操作系统决定\nsync_binlog &#x3D; N的时候, 表示每次提交事务的时候都只write(), 在积累了N个事务以后fsync\n\nMySQL中默认的是sync_binlog &#x3D; 0\n\n小结update语句的执行过程\n\n这里我们从优化器分析出来了成本最小的执行计划以后, 执行器按照其计划执行\n\n执行器调用存储引擎的接口, 通过主键索引树搜索id &#x3D; 1这一行的记录\n如果id &#x3D; 1这一行所在的数据也本身就在buffer pool中, 就直接返回给执行器更新\n如果不在, 就需要先将数据页从磁盘中加载到buffer pool中, 返回记录给执行器更新\n\n\n执行器拿到聚簇索引记录以后, 比较更新的记录和原记录是不是一样的\n如果是一样的, 不执行后续流程\n不一样, 将更新前的记录和更新后的记录都当作参数传给InnoDB层, 让InnoDB执行真正的更新操作\n\n\n开启事务, InnoDB更新前需要先记录相应的undo log, 因为是更新操作, 所以将旧值存入undo log, 将undo log写入buffer pool中的Undo页面, 然后将这个Undo页面记录到redo log中\nInnoDB层开始更新记录, 先更新内存中记录, 并标记成脏页, 然后将记录写入到redo log中, 这时就是更新完成了, 后台线程将内存中脏页刷盘\n开始记录该语句对应的binlog, binlog先被保存到binlog cache中, 在事务提交的时候统一将该事务运行过程中的所有binlog更新到磁盘上\n最后就是事务提交, 也就是[两阶段提交], 接下来就是讲两阶段提交\n\n为什么需要两阶段提交在主从复制的场景中, 主库MySQL宕机了, redo log负责的是主库的崩溃恢复, binlog负责的是事务能否传播到从库\n而redo log和binlog持久化到磁盘是两个独立逻辑, 那么就会出现下面的两种情况\n\n如果在redo log刷盘以后, MySQL宕机了, binlog还没有来得及刷盘. 这个时候, 崩溃恢复以后, 主库中能将Buffer Pool中的事务修改的数据恢复, 但是从库读binlog并没有执行之前的事务, 出现了主库是新值, 从库是旧值\n如果在binlog刷盘以后, MySQl宕机了, redo log没有刷盘. 就会变成主库是旧值, 从库是新值\n\n这两种情况都是出现了主从库数据不一致的问题\nMySQL给出的解决方案就是两阶段提交, 将事务提交的过程分成了两个阶段, 准备阶段和提交阶段\n两阶段提交是怎么样的为了保证binlog和redo log的一致性, MySQL使用了内部XA事务\n在客户端执行commit的时候, MySQL内部开启一个XA事务, 分两阶段完成XA事务的提交\n\n将redo log的写入拆分成了两个阶段: prepare和commit, 中间穿插binlog\n\nprepare阶段: 将XID (内部XA事务的ID) 写入到redo log, 将redo log对应的事务状态设置成prepare, 将redo log持久化到磁盘(innodb_flush_log_at_trx_commit &#x3D; 1的时候)\ncommit阶段: 将XID写入到binlog中, 然后将binlog持久化到磁盘 (sync_binlog &#x3D; 1的时候), 接着调用引擎的提交事务接口, 将redo log状态设置成 commit\n\n异常重启后的现象\n在MySQL重启以后, 会按照顺序扫描redo log文件, 碰到处于 prepare 状态的 redo log, 就会拿着redo log的XID去binlog中查看是否有该XID\n\n如果没有XID, 说明redo log完成了刷盘, 但是binlog还没有完成刷盘, 回滚事务, 因为从库会无法同步这个数据, 对于到途中的A时刻\n如果有XID, 说明redo log和binlog都完成了刷盘, 则提交事务, 对应B时刻崩溃恢复\n\n对于处于prepare阶段的redo log, 既可以提交事务, 也可以回滚事务, 这取决于是否在binlog中查找到与redo log相同的XID\n两阶的提交是以binlog写成功为事务提交成功的标志\n两阶段提交的问题\n磁盘的I&#x2F;O次数高, 每次事务提交都会有两次刷盘 (如果在两个刷盘配置都是1的情况下)\n锁竞争激烈, 多事务的场景下, 需要通过锁来保证提交的原子性(即保证binlog的写入顺序和事务提交顺序一致)\n\n组提交为了解决锁竞争激烈的问题, 引入了binlog组提交机制, 当有多个事务提交的时候, 将多个binlog刷盘操作合并成一个, 从而减少磁盘I&#x2F;O的次数\n将commit拆分成了三个阶段\n\nflush阶段: 多个事务按照进入的顺序将binlog从binlog cache写入到文件(不刷盘)\nsync阶段: 将多个事务的binlog合并一次刷盘\ncommit阶段: 各个事务按顺序做commit操作\n\n\n在每个阶段引入了锁机制以后, 锁就只针对每个队列进行保护, 不再锁住提交事务的整个过程, 可以看出来, 锁粒度减小了, 这样就使得多个阶段可以并发执行\n\n\nflush 阶段\n\nflush阶段的队列用于支撑redo log的组提交\n\nsync 阶段\n\n事务会在sync队列上等待一定时间, 以组合更多事务的binlog然后一起刷盘\nsync队列的作用是用于支持binlog的提交\n\ncommit 阶段\n\n承接sync阶段的事务, 完成最后的引擎提交\n","categories":["Middleware","MySQL"],"tags":["Middleware","MySQL"]},{"title":"MySQL 锁机制","url":"/2025/07/16/MiddleWare/MySQL/MySQl%20%E9%94%81/","content":"\n参考:\n\nhttps://relph1119.github.io/mysql-learning-notes/#/mysql/25-%E5%B7%A5%E4%BD%9C%E9%9D%A2%E8%AF%95%E8%80%81%E5%A4%A7%E9%9A%BE-%E9%94%81 \nhttps://xiaolincoding.com/mysql/lock/how_to_lock.html\n\n\nMySQL锁机制详解快照读与锁定读MySQL中读可以分作两类\n\n快照读: 也就是普通的select, 读-读场景不需要额外的机制保证并发安全, 而读-写场景通过MVCC来实现隔离级别\n锁定读: 会加锁的读, 是select ... for update或者select ... lock in share mode , 在MySQL中update, delete操作会分成两部分, 读取阶段和写入(删除)阶段, 前一阶段就属于锁定读\n\n共享锁(S)和互斥锁(X)共享锁: 如果一个事务给一个表(记录)加了S锁, 其他事务能再获取这个S锁, 但是该事务和其他事务都不能再获取这个表(记录)的X锁\n互斥锁: 独占锁, 如果有一个事务给一个表(记录)加了X锁, 其他事务不能再从这个表(记录)上获取锁了(无论XS), 同时也不能给已经上锁了的表(记录)加上X锁\n\n\n\n兼容性\n共享锁S\n互斥锁X\n\n\n\n共享锁S\n兼容\n不兼容\n\n\n互斥锁X\n不兼容\n不兼容\n\n\n类似于读-读并发安全, 所以不需要额外处理, 也就是S锁能兼容, 其他的情况都存在并发安全问题, 所以不能兼容\n表锁表级锁锁上整张表的锁, 分有X和S两种\n什么时候会加上表级锁: MySQL InnoDB引擎中因为有更细粒度的行级锁, 所以其实表级锁应用场景极其有限(没啥用)\n但是现在有个问题就是, 如果我们要对某个表加X锁或者S锁, 有个问题就是, 我们需要确保现在这个表是没有不兼容的行锁的\n\n我们要加上表级S锁的时候, 就需要保证表内没有X锁\n我们要加上表级X锁的时候, 就需要保证表内没有锁\n\n这种时候很明显我们不能遍历每行来看是不是有加锁, Innodb引入了意向锁的机制\n意向锁IS锁: 共享意向锁, IX锁: 互斥意向锁\n什么时候会加上意向锁: 现在在加锁前, 我们会现在表级上加上一个意向锁, 比如我们要加上一个互斥X锁, 我们就会先在表上加一把IX, IS同理\n在有了意向锁以后, 我们就能通过判断表上有没有持有IS和IX锁来快速判断现在我们能不能加表锁\nIS, IX是表级锁, 它们的出现仅仅是为了在之后加表级锁的时候快速判断表中是不是存在加锁的记录, IS锁和IS锁之间是兼容的,  IX和IX之间是兼容的\n\n\n\n兼容性\nX\nIX\nS\nIS\n\n\n\nX\n不兼容\n不兼容\n不兼容\n不兼容\n\n\nIX\n不兼容\n兼容 兼容的\n不兼容\n兼容 兼容的\n\n\nS\n不兼容\n不兼容\n兼容 兼容的\n兼容 兼容的\n\n\nIS\n不兼容\n兼容 兼容的\n兼容 兼容的\n兼容 兼容的\n\n\nMDL锁Meta Data Lock: 元数据锁, 是针对DDL操作的锁, 防止在存在事务还在执行的时候变更表结构\n什么时候会加上MDL: \n\n对一张表CRUD的时候, 加上MDL读锁\n修改表结构的时候, 加上MDL写锁\n\nMDL写锁的获取会阻塞MDL读锁的获取, 也就是如果有一个事务在修改表结构获取MDL写锁的时候阻塞了, 后续的CRUD操作都会被阻塞住\nMDL在事务提交后才会释放\nAUTO-INC锁是用于处理AUTO_INCREAMENT自增字段的自增的锁, 如果并发地向一张表中插入记录, 就可能会导致自增字段值重复\n有两种锁来解决并发自增问题\n\nAUTO-INC锁: 在执行插入语句的时候, 会加上一个表级的AUTO_INC锁, 然后分配自增属性的值, 在插入语句执行结束后将锁释放掉, 以此将插入时生成自增值串行化\n轻量级锁: 在执行插入语句的时候, 获取这个轻量级锁, 在生成自增属性的值以后就将锁释放掉\n\n如果我们的插入语句在执行前就知道要插入多少条数据, 就会采用轻量级锁\n\nTIP：设计InnoDB的大佬提供了一个称之为innodb_autoinc_lock_mode的系统变量来控制到底使用上述两种方式中的哪种来为AUTO_INCREMENT修饰的列进行赋值，当innodb_autoinc_lock_mode值为0时，一律采用AUTO-INC锁；当innodb_autoinc_lock_mode值为2时，一律采用轻量级锁；当innodb_autoinc_lock_mode值为1时，两种方式混着来（也就是在插入记录数量确定时采用轻量级锁，不确定时使用AUTO-INC锁）。不过当innodb_autoinc_lock_mode值为2时，可能会造成不同事务中的插入语句为AUTO_INCREMENT修饰的列生成的值是交叉的，在有主从复制的场景中是不安全的。\n\n行锁行锁在MySQL中是InnoDB独有的更加细粒度的锁\n记录锁Record Lock: 记录锁, 有S锁和X锁之分, 是针对一条记录上加的锁, 也就是对某一行加上的锁\n什么时候加锁: 在执行锁定读的时候会对遍历到的行加上, 往往是以next-key lock的组成部分的形式被加上\n间隙锁Gap Loc: 间隙锁, 有S锁和X锁, 但是没有分别, 实际上是都是S锁的行为, 多个事务可同时获取一个间隙的Gap Lock, 是对一个开区间的锁, 用于解决可重复读隔离级别下的幻读现象的\n\n在id范围(3, 5)的间隙锁以后, 其他事务就无法再插入id &#x3D;4的记录了\n什么时候加锁: 和记录锁是一样的, 执行锁定读的时候会对遍历到的行加上, 往往是以next-key lock的组成部分的形式被加上\nNext-Key LockNext-Key Lock &#x3D; Record Lock + Gap Lock, 锁定一个范围, 并且锁定记录本身\n因为Next-Key Lock是包含Record Lock的, 所以是分X锁和S锁的\n插入意向锁是在insert前会对某个记录加上锁, 用于提高插入的并发效率, 只要插入位置不同, 想插入的事务间不会相互阻塞, 只有当多个事务尝试插入相同位置时才会产生冲突\n什么时候加锁: 在执行插入操作的时候需要判断这个位置上有没有间隙锁, 如果有, 插入操作就会被阻塞, 然后生成一个插入意向锁(is_wait &#x3D; true), 在这个间隙锁被释放掉以后, 插入意向锁就会被真正获取到, 执行插入操作\n有插入意向锁（当前机制）：\ncss复制索引：[1] [4] [7] [10]事务A：INSERT 5  → 在(4,7)设置插入意向锁事务B：INSERT 6  → 在(4,7)设置插入意向锁结果：两个事务可以并发执行 ✓\n\n没有插入意向锁（假设情况）：\ncss复制索引：[1] [4] [7] [10]事务A：INSERT 5  → 在(4,7)设置间隙锁事务B：INSERT 6  → 等待事务A释放间隙锁结果：事务B被阻塞，必须等待 ✗\n","categories":["Middleware","MySQL","Lock"]},{"title":"工作流-Chain Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/1.%20Workflow-ChainWorkflow/","content":"工作流-lian’shi\n参考\n\nhttps://www.anthropic.com/engineering/building-effective-agents\n\n\n流程说明对于链式工作流, 整体的呈现效果就是用户输入userInput以后, 这个userInput在输入以后会链式的向下执行, 在每个节点携带上一个节点的回答和使用当前节点的prompt来和LLM对话\n\n填充systemPrompts数组, 在这种情况下, Chain Workflow也被称作Prompts Chain工作流\n遍历每个prompt\n将上一轮的回答和现在的prompt组成一个新的input\n对话获取response\n\n\n输出最后的response\n\n\n代码\n代码\n\npublic String chain(String userInput) &#123;    String response = usertInput;        for (String promt : systemPrompts) &#123;        String input = String.format(&quot;&#123;%s&#125;\\n &#123;%s&#125;&quot;, prompt, response);        String response = chatClient.prompt(input).call().conmtent();                if(!check(response)) &#123;            return this.errorResponse;        &#125;    &#125;    return response;&#125;\n\n\n系统prompt示例\n\n// Step 1    &quot;&quot;&quot;    Extract only the numerical values and their associated metrics from the text.    Format each as&#x27;value: metric&#x27; on a new line.    Example format:    92: customer satisfaction    45%: revenue growth&quot;&quot;&quot;,// Step 2    &quot;&quot;&quot;    Convert all numerical values to percentages where possible.    If not a percentage or points, convert to decimal (e.g., 92 points -&gt; 92%).    Keep one number per line.    Example format:    92%: customer satisfaction    45%: revenue growth&quot;&quot;&quot;,// Step 3    &quot;&quot;&quot;    Sort all lines in descending order by numerical value.    Keep the format &#x27;value: metric&#x27; on each line.    Example:    92%: customer satisfaction    87%: employee satisfaction&quot;&quot;&quot;,// Step 4    &quot;&quot;&quot;    Format the sorted data as a markdown table with columns:    | Metric | Value |    |:--|--:|    | Customer Satisfaction | 92% | &quot;&quot;&quot;\n\n\n\n使用场景此工作流非常适合于任务可以轻松明晰地分解成多个固定子步骤的场景. 用延迟换取更高的准确性\n\n原文: \nWhen to use this workflow: This workflow is ideal for situations where the task can be easily and cleanly decomposed into fixed subtasks. The main goal is to trade off latency for higher accuracy, by making each LLM call an easier task.\n\n举例说明: \n\n撰写文章大纲, 检查大纲是否符合某些标准, 然后根据大纲完成文档\n从MCP中获取应用监控数据, 提取出来关键信息, 捕捉其中的异常, 推送给管理者\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Parallelization Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/3.%20Workflow-ParallelizationWorkflow/","content":"工作流-并行工作流流程说明\n用户输入input数组对应需要并行执行一系列任务, 适用于所有的任务的prompt, 以及线程池的数量\n将每个input并行化运行LLM\n等待所有的运行完毕后返回\n\n代码public List&lt;String&gt; parallel(String prompt, List&lt;String&gt; inputs, int nWorks) &#123;    ExecutorService executor = Executors.newFixedThreadPool(nWorkers);        try &#123;        List&lt;CompletableFuture&lt;String&gt;&gt; futures = input.stream()            .map(input -&gt; CompletableFuture.supplyAsync(() 0&gt; &#123;                try&#123;                    return chatClient.prompt(prmopt + &quot;\\nInput: &quot; + input).call().content();                &#125; catch (Exception e) &#123;                    throw new RuntimeException(&quot;Failed to process input: &quot; + input, e);                &#125;            &#125;, executor))            .collect(Collectors.toList());                // 等待所有的任务结束        CompletableFuture&lt;Void&gt; allFutures = CompletableFuture.allof(        \t\t\tfutures.toArray(CompletableFuture[]::new));        allFutures.join();                return futures.stream()            .map(CompletableFuture::join)            .collec(Collectors.toList());    &#125;&#125;\n\n适用场景当拆分后的子任务可以并行化以提高速度的时候, 或者需要多个视角或尝试来获取更高置信度的结果的时候. 涉及到多方面考量的复杂任务的时候, 每个考量都由单独的LLM调用处理, LLM的表现会更好\n\n原文:\nWhen to use this workflow: Parallelization is effective when the divided subtasks can be parallelized for speed, or when multiple perspectives or attempts are needed for higher confidence results. For complex tasks with multiple considerations, LLMs generally perform better when each consideration is handled by a separate LLM call, allowing focused attention on each specific aspect.\n\n\n投票场景, 多次运行相同的任务来获得不同的输出\n切分: 将并行化的任务交给不同的LLM来执行, 比如自动评估的时候, 或者防护机制, 一个LLM处理用户的查询, 另一个模型沙宣不适当的请求和内容\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Routing Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/2.%20Workflow-RoutingWorkflow/","content":"工作流-路由工作流流程说明用户输入userInput和可行的路由Map&lt;String, Object&gt; String是对这个路由的简介, Object就是实际的路由内容\n这里以角色分配, 将不同的任务分配给不同的promt角色的使用方式举例\n\n用户输入初始的userInput和Map&lt;String, String&gt;\n根据userInput和Map的keySet让LLM决策当前任务使用的prompt角色, 给出原因和选择, 使用结构化的输出到RoutingResponse中\n使用对应的prompt角色, 输出最后的结果\n\n\n代码\nroute方法\n\npublic String route(String userInput, Map&lt;String, Object&gt; routes, String mode) &#123;    RoutingResponse routingResponse = determineRoute(input, routes.keySet);        Object select = routes.get(routingResponse.getSelect());    \tswitch (mode) &#123;        case &quot;prompts&quot;:            // 选择不同的prompt解决这个问题            return chatClient.prompt((String) select + &quot;\\nInput: &quot; + userInput).call().content();        case &quot;modelChoose&quot;:            // 选择不同的client解决这个问题            return (chatClient) select.prompt(userInput).call().content();    &#125;&#125;\n\n\ndetermineRoute方法\n\nprivate String determineRoute(String input, Iterable&lt;String&gt; availableRoutes) &#123;\tString selectorPrompt = String.format(&quot;&quot;&quot;                Analyze the input and select the most appropriate support team from these options: %s                First explain your reasoning, then provide your selection in this JSON format:                \\\\&#123;                    &quot;reasoning&quot;: &quot;Brief explanation of why this ticket should be routed to a specific team.                                Consider key terms, user intent, and urgency level.&quot;,                    &quot;selection&quot;: &quot;The chosen team name&quot;                \\\\&#125;                Input: %s&quot;&quot;&quot;, availableRoutes, input);                                              RoutingResponse routingResponse = chatClient.prompt(selectorPrompt).call().entity(RoutingResponse.class);    return routingResponse.selection();&#125;\n\n适用场景适合处理存在不同的分类, 分别处理的复杂任务\n\n原文:\nWhen to use this workflow: Routing works well for complex tasks where there are distinct categories that are better handled separately, and where classification can be handled accurately, either by an LLM or a more traditional classification model&#x2F;algorithm.\n\n\n将简单&#x2F;常见问题路由到较小的模型（如 Claude 3.5 Haiku），将困难&#x2F;不寻常的问题路由到功能更强大的模型（如 Claude 3.5 Sonnet），以优化成本和速度。\n将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具中。\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Evaluator-optimizer","url":"/2025/07/19/Project/AI%20Agentic%20System/5.%20%20Workflow-Evaluator-optimizer.md/","content":"工作流-评估优化器流程说明在评估-优化器中, 一个LLM调用生成响应, 另一个在循环中提供评估和反馈\n\n用户输入task\nLLM生成第一轮的回复\n对LLM的回复生成评估\n检查评估的结果是不是PASS, 如果是, 直接返回最终结果\n\n\n将所有的历史memory都添加到上下文中, 以及将回复评估添加到上下文中\n进行下一次循环\n\n代码\nloop\n\nprivate RefinedResponse loop(String task, String context, List&lt;String&gt; memory,                             List&lt;Generation&gt; chainOfThought) &#123;    Generation generation = generate(task, context);    memory.add(generation.response());    chainOfThought.add(generation);    EvaluationResponse evaluationResponse = evalute(generation.response(), task);    if (evaluationResponse.evaluation().equals(EvaluationResponse.Evaluation.PASS)) &#123;        // Solution is accepted!        return new RefinedResponse(generation.response(), chainOfThought);    &#125;    // Accumulated new context including the last and the previous attempts and    // feedbacks.    StringBuilder newContext = new StringBuilder();    newContext.append(&quot;Previous attempts:&quot;);    for (String m : memory) &#123;        newContext.append(&quot;\\n- &quot;).append(m);    &#125;    newContext.append(&quot;\\nFeedback: &quot;).append(evaluationResponse.feedback());    return loop(task, newContext.toString(), memory, chainOfThought);&#125;\n\n\ngenerate\n\nprivate Generation generate(String task, String context) &#123;    Generation generationResponse = chatClient.prompt()        .user(u -&gt; u.text(&quot;&#123;prompt&#125;\\n&#123;context&#125;\\nTask: &#123;task&#125;&quot;)              .param(&quot;prompt&quot;, this.generatorPrompt)              .param(&quot;context&quot;, context)              .param(&quot;task&quot;, task))        .call()        .entity(Generation.class);    System.out.println(String.format(&quot;\\n=== GENERATOR OUTPUT ===\\nTHOUGHTS: %s\\n\\nRESPONSE:\\n %s\\n&quot;,                                     generationResponse.thoughts(), generationResponse.response()));    return generationResponse;&#125;\n\n\nevalute\n\nprivate EvaluationResponse evalute(String content, String task) &#123;    EvaluationResponse evaluationResponse = chatClient.prompt()        .user(u -&gt; u.text(&quot;&#123;prompt&#125;\\nOriginal task: &#123;task&#125;\\nContent to evaluate: &#123;content&#125;&quot;)              .param(&quot;prompt&quot;, this.evaluatorPrompt)              .param(&quot;task&quot;, task)              .param(&quot;content&quot;, content))        .call()        .entity(EvaluationResponse.class);    System.out.println(String.format(&quot;\\n=== EVALUATOR OUTPUT ===\\nEVALUATION: %s\\n\\nFEEDBACK: %s\\n&quot;,                                     evaluationResponse.evaluation(), evaluationResponse.feedback()));    return evaluationResponse;&#125;\n\n\n\n\nGenerator prompt\n\n&quot;&quot;&quot;Your goal is to complete the task based on the input. If there are feedbackfrom your previous generations, you should reflect on them to improve your solution.CRITICAL: Your response must be a SINGLE LINE of valid JSON with NO LINE BREAKS except those explicitly escaped with \\\\n.Here is the exact format to follow, including all quotes and braces:&#123;&quot;thoughts&quot;:&quot;Brief description here&quot;,&quot;response&quot;:&quot;public class Example &#123;\\\\n    // Code here\\\\n&#125;&quot;&#125;Rules for the response field:1. ALL line breaks must use \\\\n2. ALL quotes must use \\\\&quot;3. ALL backslashes must be doubled: \\\\4. NO actual line breaks or formatting - everything on one line5. NO tabs or special characters6. Java code must be complete and properly escapedExample of properly formatted response:&#123;&quot;thoughts&quot;:&quot;Implementing counter&quot;,&quot;response&quot;:&quot;public class Counter &#123;\\\\n    private int count;\\\\n    public Counter() &#123;\\\\n        count = 0;\\\\n    &#125;\\\\n    public void increment() &#123;\\\\n        count++;\\\\n    &#125;\\\\n&#125;&quot;&#125;Follow this format EXACTLY - your response must be valid JSON on a single line.&quot;&quot;&quot;\n\n\nEvaluator prompt\n\n&quot;&quot;&quot;Evaluate this code implementation for correctness, time complexity, and best practices.Ensure the code have proper javadoc documentation.Respond with EXACTLY this JSON format on a single line:&#123;&quot;evaluation&quot;:&quot;PASS, NEEDS_IMPROVEMENT, or FAIL&quot;, &quot;feedback&quot;:&quot;Your feedback here&quot;&#125;The evaluation field must be one of: &quot;PASS&quot;, &quot;NEEDS_IMPROVEMENT&quot;, &quot;FAIL&quot;Use &quot;PASS&quot; only if all criteria are met with no improvements needed.&quot;&quot;&quot;\n\n适用场景在有清晰的评估标准, 并且迭代改进提供可衡量的价值. 良好契合的两个标志是\n\n当人类清晰地表达反馈时, LLM的答案可以得到显著的改进\nLLM能表达这种反馈\n\n\n原文:\nWhen to use this workflow: This workflow is particularly effective when we have clear evaluation criteria, and when iterative refinement provides measurable value. The two signs of good fit are, first, that LLM responses can be demonstrably improved when a human articulates their feedback; and second, that the LLM can provide such feedback. This is analogous to the iterative writing process a human writer might go through when producing a polished document.\n\n\n复杂的搜索任务需要多轮搜索和分析才能收集全面的信息, 评估人员是否需要进一步搜索\n生成代码的自优化\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Orchestrator-workers","url":"/2025/07/18/Project/AI%20Agentic%20System/4.%20Workflow-Orchestrator-workers/","content":"工作流-编排器-工人工作流流程说明这个工作流可以看作是ParallelizationWorkflow的自动分配任务版本\n中央LLM动态分解任务, 并将其委派给工作者LLM, 并综合结果\n\n用户输入任务描述input\n将用户的任务和编排器prompt输入给LLM用于划分任务\n将划分后的任务集合和工人prompt输入给LLM用于执行划分后的任务\n返回所有的执行结果\n\n代码\n执行代码, process\n\npublic FinalResponse process(String taskDescription) &#123;    // 获取编排器的编排结果    OrchestratorResponse orchestratorResponse = this.chatClient.prompt()        .user(u -&gt; u.text(this.orchestratorPrompt))        \t\t\t.param(&quot;task&quot;, taskDescription)        .call()        .entity(OrchestratorResponse.class);        // 执行每个任务    List&lt;String&gt; workerResponse = orchestratorResponse.tasks().stram().map(task -&gt; this.chatClient.prompt()     .user(u -&gt; u.text(this.workerPrompt)          .param(&quot;original_task&quot;, taskDescription)          .param(&quot;task_type&quot;, task.type())          .param(&quot;task_description&quot;, task.description())      ))      .call()      .content().toList();        return new FinalResponse(orchestratorResponse.analysis(), workerResponse);&#125;\n\n\n\n\norchestrator prompt\n\n&quot;&quot;&quot;Analyze this task and break it down into 2-3 distinct approaches:Task: &#123;task&#125;Return your response in this JSON format:\\\\&#123;&quot;analysis&quot;: &quot;Explain your understanding of the task and which variations would be valuable.Focus on how each approach serves different aspects of the task.&quot;,&quot;tasks&quot;: [\\\\&#123;&quot;type&quot;: &quot;formal&quot;,&quot;description&quot;: &quot;Write a precise, technical version that emphasizes specifications&quot;\\\\&#125;,\\\\&#123;&quot;type&quot;: &quot;conversational&quot;,&quot;description&quot;: &quot;Write an engaging, friendly version that connects with readers&quot;\\\\&#125;]\\\\&#125;&quot;&quot;\n\n\nworker\n\n&quot;&quot;&quot;Generate content based on:Task: &#123;original_task&#125;Style: &#123;task_type&#125;Guidelines: &#123;task_description&#125;&quot;&quot;&quot;\n\n适用场景非常适合无法预测所需子任务的复杂任务, 在拓扑结构上和并行化类似, 和并行化的关键区别是在于灵活性-子任务不需要预先定义, 而是由编排器根据具体的输入确定\n\n原文:\nWhen to use this workflow: This workflow is well-suited for complex tasks where you can’t predict the subtasks needed (in coding, for example, the number of files that need to be changed and the nature of the change in each file likely depend on the task). Whereas it’s topographically similar, the key difference from parallelization is its flexibility—subtasks aren’t pre-defined, but determined by the orchestrator based on the specific input.\n\n\n每次对多个文件进行复杂更改的编码产品\n搜索任务涉及从多个来源搜集和分析信息以获取可能相关的信息\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"Spring AI 测试文件","url":"/2025/07/10/Spring/Spring%20AI/Spring%20AI-test/","content":"Spring AI 测试文件\n","categories":["Spring","Spring AI"],"tags":["Spring AI"]}]