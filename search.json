[{"title":"分布式架构-架构演进概述","url":"/2025/07/25/Architecture/%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B%E6%A6%82%E8%BF%B0/","content":"\n参考凤凰架构: 演进的架构一大章节\n\n单体应用单体应用并不是分布式应用的下位替代, 不需要进程间通信, 更简单的编码和管理都是其相较于分布式应用的优点\n那么为什么要构建分布式应用?\n最核心的特性应该是运行时更新, 也就是不停机更新: 分布式架构以集群的形式部署, 能在部分应用实例错误的情况下, 仍然保持整体服务的可用性, 在分布式架构中热更新是件很自然的事情, 我们停掉一定比例的应用, 然后将他们进行更新, 然后确保没有问题以后, 我们再更新其他部分, 实现了不停机更新\n隔离各个单体应用, 减少错误的传播范围, 增加开发效率: 随着软件规模的扩大, 制约软件拓展的开始变成人, 开发团队往往是以少数专家和多数普通开发的形式组成, 错误率较高. 这样的组成形式下, 如果是单体应用, 我们会面临某一个开发的错误会导致整个服务错误, 错误传播范围广, 并且没有很好的隔离手段. 分布式就是一个解决方案, 各个单体应用之间相对隔离, 能有效缩小错误的传播范围只会局限于这个单体应用\n\n","categories":["Architecture","Distributed Systems"],"tags":["Architecture","Distributed Systems"]},{"title":"Java基础面试问题","url":"/2025/07/10/Interview/Java%20Base/","content":"Java基础a &#x3D; a + b 与 a +&#x3D; b 的区别+&#x3D; 隐式的将加操作的结果类型强制转换为持有结果的类型。如果两个整型相加，如 byte、short 或者 int，首先会将它们提升到 int 类型，然后在执行加法操作。\nbyte a = 127;byte b = 127;b = a + b; // error : cannot convert from int to byteb += a; // ok\n\n(因为 a+b 操作会将 a、b 提升为 int 类型，所以将 int 类型赋值给 byte 就会编译出错)\n为什么需要泛型？适用于多种数据类型执行相同的代码\n引入泛型，它将提供类型的约束，提供编译前的检查\n泛型方法泛型方法创建\n\n泛型方法使用\n\n泛型方法创建的时候需要使用&lt;T&gt;来声明这是一个泛型方法, 在传入的参数中需要有Class&lt;T&gt; c参数来指明传入的参数的类型, 然后在方法中通过反射newInstance方法来创建一个新的对象\n使用泛型方法的时候, 可以通过Class.forName(“全限定类名”)来获取Class类\n泛型的上限和下限？在使用泛型的时候，我们可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。\n上限\nclass Info&lt;T extends Number&gt;&#123;    // 此处泛型只能是数字类型\n\n下限\npublicstaticvoidfun(Info&lt;? super String&gt; temp)&#123;// 只能接收String或Object类型的泛型，String类的父类只有Object类System.out.print(temp +&quot;, &quot;);&#125;\n\n如何理解Java中的泛型是伪泛型？泛型中类型擦除 Java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型, 同时这里是会擦除成下限类型），就像完全没有泛型一样。\n注解元注解，元注解是用于定义注解的注解，包括@Retention、@Target、@Inherited、@Documented\n\n@Retention用于标明注解被保留的阶段\n@Target用于标明注解使用的范围\n@Inherited用于标明注解可继承\n\nJava异常类层次结构?\nThrowable\n 是 Java 语言中所有错误与异常的超类。 \n\nError 类及其子类：程序中无法处理的错误，表示运行应用程序中出现了严重的错误。\nException 程序本身可以捕获并且可以处理的异常。Exception 这种异常又分为两类：运行时异常和编译时异常。\n\n\n\n\n\n运行时异常\n\n都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。\n运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。\n\n非运行时异常 （编译异常）\n\n是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。\n可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）区别？\n可查异常（编译器要求必须处置的异常）：\n\n正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。\n除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。\n\n不可查异常(编译器不要求强制处置的异常)\n\n包括运行时异常（RuntimeException与其子类）和错误（Error）\n什么是SPI机制？SPI（Service Provider Interface），是JDK内置的一种 服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，MySQL和PostgreSQL都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是 解耦。\nSPI整体机制图如下：\n\n当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader。\nSPI机制的应用？\nSPI机制 - JDBC DriverManager\n\n在JDBC4.0之前，我们开发有连接数据库的时候，通常会用Class.forName(“com.mysql.jdbc.Driver”)这句先加载数据库相关的驱动，然后再进行获取连接等的操作。而JDBC4.0之后不需要用Class.forName(“com.mysql.jdbc.Driver”)来加载驱动，直接获取连接就可以了，现在这种方式就是使用了Java的SPI扩展机制来实现。\n\nJDBC接口定义\n\n首先在java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商来提供的。\n\nmysql实现\n\n在mysql的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。\n\npostgresql实现\n\n同样在postgresql的jar包postgresql-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是postgresql对Java的java.sql.Driver的实现。\n\n使用方法\n\n上面说了，现在使用SPI扩展来加载具体的驱动，我们在Java中写连接数据库的代码的时候，不需要再使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动了，而是直接使用如下代码：\nString url = &quot;jdbc:xxxx://xxxx:xxxx/xxxx&quot;;Connection conn = DriverManager.getConnection(url,username,password);.....","categories":["Interview","Java","JavaBase"],"tags":["Java","Interview","JavaBase"]},{"title":"Java Colletion-集合框架面试问题","url":"/2025/07/10/Interview/Java%20Collection/","content":"&#x2F;&#x2F; TODO\n","categories":["Interview","Java","Collection"],"tags":["Java","Interview","Collection"]},{"title":"原子类-AtomicInteger类详解","url":"/2025/07/23/Java/JUC/%E5%8E%9F%E5%AD%90%E7%B1%BB-AtomicInteger/","content":"原子类-AtomicInteger类详解说实话, 也没什么好额外讲的, 整个原子类家族, 就是一族封装了一些类CAS操作的类, 提供了我们为某个变量进行原子操作的能力, 让我们可以在多线程环境下, 对某个变量进行原子操作, 而不需要加锁.\n下面简单说明一下类的结构\n核心字段private static final Unsafe U = Unsafe.getUnsafe();private static final long VALUE    = U.objectFieldOffset(AtomicInteger.class, &quot;value&quot;);private volatile int value;\n\n\nUnsafe就是提供了操作系统层面的API来执行CAS操作类\nVALUE是使用了Unsafe获取到的AtomicInteger类中的value字段的属性在类中偏移量, 用于CAS操作\nvalue就是我们这个Integer类的值, 这里的value是保证可见性的, 所以如果使用Atomic是默认保证多线程之间的可见性, 不需要额外加volatile\n\n核心方法因为比较简单, 大多数方法就是让CAS操作更易用, 所以我只列举出来核心方法, 不提供源码了\n\nget() : 获取原子类的值\nset(int newValue) : 设置原子类的值\n\n核心方法一般分成getAndSet和setAndGet两种, 前者返回的是set前的值, 后者返回的是set后的值\ngetAndSet类getAndSet(int newValue) : 获取原子类的值, 并设置为newValue\ngetAndIncrement() : 获取原子类的值, 并将其加1\ngetAndDecrement() : 获取原子类的值, 并将其减1\ngetAndAdd(int delta) : 获取原子类的值, 并将其加上delta\nsetAndGet类setAndGet(int newValue) : 设置原子类的值为newValue, 并返回newValue\nincrementAndGet() : 将原子类的值加1, 并返回加1后的值\ndecrementAndGet() : 将原子类的值减1, 并返回减1后的值\naddAndGet(int delta) : 将原子类的值加上delta, 并返回加上delta后的值\nCompare And Exchange类 (JDK9)正宗的CAS操作\npublic final int compareAndExchangeAcquire(int expectedValue, int newValue) &#123;    return U.compareAndExchangeIntAcquire(this, VALUE, expectedValue, newValue);&#125;\n\n这个CAS是有内存屏障保障不会被重排序的, 任何内存操作不会跨越该操作进行重排序\n\npublic final int compareAndExchangeAcquire(int expectedValue, int newValue) &#123;    return U.compareAndExchangeIntAcquire(this, VALUE, expectedValue, newValue);&#125;\n\n\n这个CAS只保证该操作之后的读写操作不会被重排序到该操作之前, 但该操作之前的读写操作可以被重排序到该操作之后\n\n","categories":["Java","JUC","原子类"],"tags":["Java","JUC","原子类"]},{"title":"Java JUC-并发编程面试问题","url":"/2025/07/11/Interview/Java%20JUC/","content":"并发编程问题\n","categories":["Interview","Java","JUC"]},{"title":"线程池-ThreadPoolExecutor类详解","url":"/2025/07/24/Java/JUC/%E7%BA%BF%E7%A8%8B%E6%B1%A0-ThreadPoolExecutor/","content":"线程池-ThreadPoolExecutor类详解ThreadPoolExecutor的构造方法public ThreadPoolExecutor(int corePoolSize,                            int maximumPoolSize,                            long keepAliveTime,                            TimeUnit unit,                            BlockingQueue&lt;Runnable&gt; workQueue) &#123;    this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,            Executors.defaultThreadFactory(), defaultHandler);&#125;\n\ncorePoolSize: 核心线程数, 线程池中即使没有任务也要保持存活的最大线程数量\nmaximumPoolSize: 线程池中允许的最大线程数量\nkeepAliveTime: 线程池中超过核心线程数的空闲线程存活时间\nunit: keepAliveTime的时间单位\nworkQueue: 任务队列, 用于存放待执行的任务\nthreadFactory: 线程工厂, 用于创建新线程\nhandler: 拒绝策略, 当任务无法被执行时的处理策略\n\n拒绝策略JDK提供了四种默认的拒绝策略\n\nAbortPolicy: 将任务丢弃并抛出一个RejectedExecutionException异常, 默认的拒绝策略\n\npublic static class AbortPolicy implements RejectedExecutionHandler &#123;    /**     * Creates an &#123;@code AbortPolicy&#125;.     */    public AbortPolicy() &#123; &#125;    /**     * Always throws RejectedExecutionException.     *     * @param r the runnable task requested to be executed     * @param e the executor attempting to execute this task     * @throws RejectedExecutionException always     */    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        throw new RejectedExecutionException(&quot;Task &quot; + r.toString() +                                                &quot; rejected from &quot; +                                                e.toString());    &#125;&#125;\n\n\nDiscardPolicy: 将任务直接丢弃\n\npublic static class DiscardPolicy implements RejectedExecutionHandler &#123;    /**     * Creates a &#123;@code DiscardPolicy&#125;.     */    public discardpolicy() &#123; &#125;    /**     * does nothing, which has the effect of discarding task r.     *     * @param r the runnable task requested to be executed     * @param e the executor attempting to execute this task     */    public void rejectedexecution(runnable r, threadpoolexecutor e) &#123;    &#125;&#125;\n\n\nCallerRunPolicy: 直接在试图创建并执行任务的calling Thread线程执行这个任务\n\npublic static class CallerRunsPolicy implements RejectedExecutionHandler &#123;    /**     * Creates a &#123;@code CallerRunsPolicy&#125;.     */    public CallerRunsPolicy() &#123; &#125;    /**     * Executes task r in the caller&#x27;s thread, unless the executor     * has been shut down, in which case the task is discarded.     *     * @param r the runnable task requested to be executed     * @param e the executor attempting to execute this task     */    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        if (!e.isShutdown()) &#123;            r.run();        &#125;    &#125;&#125;\n\n\nDiscardOldestPolicy: 将阻塞队列的最后一个任务丢弃, 然后重新执行这个任务\n\npublic static class DiscardOldestPolicy implements RejectedExecutionHandler &#123;    /**     * Creates a &#123;@code DiscardOldestPolicy&#125; for the given executor.     */    public DiscardOldestPolicy() &#123; &#125;    /**     * Obtains and ignores the next task that the executor     * would otherwise execute, if one is immediately available,     * and then retries execution of task r, unless the executor     * is shut down, in which case task r is instead discarded.     *     * @param r the runnable task requested to be executed     * @param e the executor attempting to execute this task     */    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        if (!e.isShutdown()) &#123;            e.getQueue().poll();            e.execute(r);        &#125;    &#125;&#125;\n\n核心字段源码\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;private static final int STOP       =  1 &lt;&lt; COUNT_BITS;private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;\n\n\nctl: Control线程控制信号, 是一个原子类, 前三位是线程池的状态位, 后29位是线程池中的线程数量\n int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;方法构建ctl\nrs是RunState 线程池状态\nwc是WorkerCount 工人数量也就是线程池中的线程的数量\n\n\nint runStateOf(int c)     &#123; return c &amp; ~COUNT_MASK; &#125;: 获取线程池状态\nint workerCountOf(int c)  &#123; return c &amp; COUNT_MASK; &#125;: 获取工人数量\n\n\nCOUNT_BITS: 这个参数 &#x3D;&#x3D; 29, 是获取状态位和设置状态位需要移动的位数\nCONUT_MASK: 前29bit都是1, c &amp; COUNT_MASK来获取到wc\nRUNNING: 线程池的正常工作状态, 线程池可以接受新的任务并且会处理等待队列中的任务\nSHUTDOWM: 调用shutdown()方法的时候, 线程池进入到这个状态\n线程池不再接受新的任务\n继续执行等待队列中的已经存在的任务和正在执行的任务\n\n\nSTOP: 调用shutdownNow()方法\n不接受新的任务\n不处理队列中的任务\n尝试中断正在执行的任务\n\n\nTIDYING: 一种过渡状态, 在满足以下条件的时候进入\n所有的任务都已经终止\n工作线程的数量是0\n队列为空的时候进入到这个状态以后, 会执行 terminate()钩子方法\n\n\nTERMINATED: 线程池关闭, 所有的资源都得到释放\n\n\n任务的执行execute方法源码及解析\npublic void execute(Runnable command) &#123;    if (command == null)        throw new NullPointerException();    // 1. 如果现在的线程数量 &lt; 核心线程数量    int c = ctl.get();    if (workerCountOf(c) &lt; corePoolSize) &#123;        // 增加核心线程数量        if (addWorker(command, true))            return;        c = ctl.get();    &#125;    // 2. 现在的线程数量 &gt; 核心线程数量    // 将任务添加到等待队列中    if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;        // 双重检查, 因为进入到if块以后可能状态线程池的状态发生了变化        int recheck = ctl.get();        // 如果双重检查的时候发现线程池的状态不再是RUNNING, 移除任务        // 并执行reject回调方法        if (! isRunning(recheck) &amp;&amp; remove(command))            reject(command);        // 执行到这个位置的时候, 逻辑上核心线程已经满了, 但是是可能出现其他的线程因为某些错误死掉的情况, wc实际记录的是还存活着的线程, 这个时候我们就需要创建一个非核心线程来执行        else if (workerCountOf(recheck) == 0)            addWorker(null, false);    &#125;    // 3. 等待队列也已经满了, 尝试创建非核心队列执行任务, 如果创建失败    // 说明线程数量已经超过了最大线程数量, 或者线程池的状态不允许创建新的线程了    else if (!addWorker(command, false))        // 执行reject方法        reject(command);&#125;\n\n线程池类执行任务的顺序是\n\n先尝试将任务交给核心线程, 如果核心线程的数量 &lt; 最大核心线程数量, 创建新的核心线程执行任务\n核心线程的数量超过了最大线程, 尝试将任务添加到等待队列里面\n等待队列也已经满了, 创建一个非核心线程执行任务, 如果创建失败, 说明线程状态不是RUNNING或者线程数量已经超过了最大的数量, 这个时候执行reject方法\n\n\n原文:Proceed in 3 steps:\n\nIf fewer than corePoolSize threads are running, try tostart a new thread with the given command as its firsttask.  The call to addWorker atomically checks runState andworkerCount, and so prevents false alarms that would addthreads when it shouldn’t, by returning false.\n\nIf a task can be successfully queued, then we still needto double-check whether we should have added a thread(because existing ones died since last checking) or thatthe pool shut down since entry into this method. So werecheck state and if necessary roll back the enqueuing ifstopped, or start a new thread if there are none.\n\nIf we cannot queue task, then we try to add a newthread.  If it fails, we know we are shut down or saturatedand so reject the task.\n\n\n\naddWorker方法比较长, 分成两部分解读\n方法签名: private boolean addWorker(Runnable firstTask, boolean core)\n\ncore: 添加的线程是不是核心线程\n\n增加线程的数量, 并没有真的增加线程\n\n\nretry:for (int c = ctl.get();;) &#123;    // 如果线程池的状态至少是SHUTDOWN, 这个时候我们不能再添加新的任务    // 如果状态是STOP, 说明这个时候不能再添加任务了, return false    // 如果状态是SHUTDOWN, 但是传入的任务不是null, 也返回null, 因为SHUTSOWN状态只能从任务队列中消费任务    // 如果传入的任务是空, 但是任务队列也是空的, 这个时候没有要消费的任务了, retuen false    if (runStateAtLeast(c, SHUTDOWN)        &amp;&amp; (runStateAtLeast(c, STOP)            || firstTask != null            || workQueue.isEmpty()))        return false;    // CAS增加worker的数量    for (;;) &#123;        // 超过线程数量的限制, 不能再添加worker了        if (workerCountOf(c)            &gt;= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK))            return false;         // CAS成功增加worker的数量, 到下一步增加Worker        if (compareAndIncrementWorkerCount(c))            break retry;         c = ctl.get();  // CAS失败, 重新获取worker数量        if (runStateAtLeast(c, SHUTDOWN))            continue retry;        // CAS失败, 说明在这个for中的CAS之前worker的数量发生了变化, CAS尝试添加线程    &#125;&#125;\n\n\n\n添加Worker, 也就是真的添加工作线程\n\nWorker是一个继承了AQS, 实现了Runnable的类\nboolean workerStarted = false;boolean workerAdded = false;Worker w = null;try &#123;    w = new Worker(firstTask);    // w.thread是在构造方法中使用线程工厂创建的    // this.thread = getThreadFactory().newThread(this);    final Thread t = w.thread;    if (t != null) &#123;        final ReentrantLock mainLock = this.mainLock;        // 加锁保护HashSet的线程安全        // largestPoolSize 统计信息的安全        // 在双重检查时候, ws不会发生变化        mainLock.lock();        try &#123;            // 用于双重检查            // 如果在获取锁以前, 线程池shutdown了            int c = ctl.get();            // 状态是RUNNING, 或者状态是SHUTDOWN并且任务是空            // 前者正常情况, 后者是在创建非核心线程            if (isRunning(c) ||                (runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) &#123;                // 创建线程失败                if (t.getState() != Thread.State.NEW)                    throw new IllegalThreadStateException();                // 创建成功, 将worker添加到线程池中                workers.add(w);                workerAdded = true;                int s = workers.size();                if (s &gt; largestPoolSize)                    largestPoolSize = s;            &#125;        &#125; finally &#123;            mainLock.unlock();        &#125;        // 启动worker的任务        if (workerAdded) &#123;            t.start();            workerStarted = true;        &#125;    &#125;&#125; finally &#123;    // 针对创建失败的Worker的处理    if (! workerStarted)        // 将这个worker从hashSet中移除        addWorkerFailed(w);&#125;return workerStarted;\n\nWorker类的构造方法Worker(Runnable firstTask) &#123;    setState(-1); // inhibit interrupts until runWorker    this.firstTask = firstTask;    this.thread = getThreadFactory().newThread(this);&#125;\n\nrunWorker方法Worker类的run方法实现内部是直接调用runWorker(Worker w) 方法\nfinal void runWorker(Worker w) &#123;    Thread wt = Thread.currentThread();    Runnable task = w.firstTask;    w.firstTask = null;    w.unlock();    boolean completedAbruptly = true;    try &#123;        // 工作者线程不断从队列中尝试获取Task然后执行        // 优先执行被分配的first Task        while (task != null || (task = getTask()) != null) &#123;            // 加锁确保任务执行的时候不会被shutdown中断            w.lock();            // 先检查线程池状态 &gt;= STOP, 是的话直接设置线程中断            // 再次检查, 在线程已被中断, 线程池 &gt;= STOP的时候                // 清除线程的中断标志, 然后设置线程被中断了            if ((runStateAtLeast(ctl.get(), STOP) ||                 (Thread.interrupted() &amp;&amp;                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;                !wt.isInterrupted())                wt.interrupt();            try &#123;                beforeExecute(wt, task);                try &#123;                    // 核心执行内容, 执行task                    task.run();                    afterExecute(task, null);                &#125; catch (Throwable ex) &#123;                    afterExecute(task, ex);                    throw ex;                &#125;            &#125; finally &#123;                // 扫尾工作                task = null;                w.completedTasks++;                w.unlock();            &#125;        &#125;        completedAbruptly = false;    &#125; finally &#123;        // 核心线程在RUNNIN步骤是不会走到这一步的,         // 因为会在getTask的过程中阻塞获取任务        processWorkerExit(w, completedAbruptly);    &#125;&#125;\n\ngetTask方法private Runnable getTask() &#123;    boolean timedOut = false; // Did the last poll() time out?    for (;;) &#123;        int c = ctl.get();        // 在线程池 &gt;= STOP, 等待队列是空的时候        // 工人的数量--, 并直接返回null, 这种情况是getTask失败的情况        if (runStateAtLeast(c, SHUTDOWN)            &amp;&amp; (runStateAtLeast(c, STOP) || workQueue.isEmpty())) &#123;            // workerCount--            decrementWorkerCount();            return null;        &#125;        // 运行到这里的时候, 说明运行状态是RUNNING        // 或者 == SHUTDOWN, 或者 &gt;= STOP 但是等待队列不是空        int wc = workerCountOf(c);        // 需不需要处理线程存活时间超时的情况        boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;        // 这里是用于处理当前的Worker是不是要销毁        // 如果Worker的数量超过了最大线程池的大小, 减少多余的worker        // 当前线程需要考虑超时, 并且上一次获取任务时发生了超时, 这种情况下worker也应该被回收以节省资源        if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))            // 保证不会过度销毁Worker, Worker数量至少大于1            // 或者等待队列中没有任务了, 这种情况也能销毁当前Worker            &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123;            if (compareAndDecrementWorkerCount(c))                return null;            continue;        &#125;        try &#123;            Runnable r = timed ?                // 如果是非核心线程就会获取任务就会有超时设置                workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :                workQueue.take();            if (r != null)                // 成功获取到了任务                return r;            // 超时了, 在下一次循环中, 就会因为这个timeout = true            // 而导致这个非核心线程被销毁            timedOut = true;        &#125; catch (InterruptedException retry) &#123;            timedOut = false;        &#125;    &#125;&#125;\n\n\n到这里我们能简单总结下一个Worker的生命周期\n对于任何Worker, 会在runWorker方法中不断循环获取任务执行任务一旦没有获取到任务, worker就会被移除\n对于核心线程worker, 会在获取任务getTask()上一直阻塞直到获取任务对于非核心线程worker, 在getTask上只会阻塞这个worker存活时间超过这个时间, 就会在getTask的下一次循环中workerCOunt–返回null,然后结束runWorker中while循环, 然后将这个worker销毁\n\n任务的提交submit方法ThreadPoolExecutor类是继承自AbstractExecutorService的. 其中的submit方法也是在这个抽象类中实现的\npublic Future&lt;?&gt; submit(Runnable task) &#123;        if (task == null) throw new NullPointerException();        // 通过submit方法提交的Callable任务会被封装成一个FutureTask对象        // 普通的Runnable接口类, 也会被封装成FutureTask对象        RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null);        execute(ftask);        return ftask;    &#125;\n\n而execute就是我们第一个讲解的任务的执行的核心部分了\n这里线程池的设计我们能看到是使用了模板模式\n任务的关闭shutdown方法将所有的正在阻塞获取任务的空闲线程的状态变成interrupt, 来释放没有在\n怎么实现的SHUTDOWM状态的语义: \n\n线程池不再接受新的任务\n在addWorker的时候, 如果是addWorker(command, true&#x2F;false)形式都会返回false\n\n\n继续执行等待队列中的已经存在的任务和正在执行的任务\n只会通过interrupt唤醒没有在执行任务在阻塞获取Task的worker, 并且会删除这个空闲的worker\n不会影响正在执行的任务, 也不会影响在等待队列中还有任务的时候\n\n\n\n怎么从SHUTDOWN一步一步变成的TERMINATE\n\n在execute中会直接reject新的任务\nSHUTDOWN状态下并且队列为空的时候, 也就是开始出现空闲的worker的时候, 会在getTask方法返回null\n因为getTask方法返回了null, 触发了runWorker方法中的销毁worker, 并tryTerminate()\n在tryTerminate中再interrupt下一个worker, 这样渐进式将所有的worker都销毁\n\npublic void shutdown() &#123;    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try &#123;        checkShutdownAccess();        advanceRunState(SHUTDOWN);        // 将所有没有执行任务的worker打上中断状态        interruptIdleWorkers();        onShutdown(); // hook for ScheduledThreadPoolExecutor    &#125; finally &#123;        mainLock.unlock();    &#125;    tryTerminate();&#125;private void interruptIdleWorkers() &#123;    interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123;    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try &#123;        for (Worker w : workers) &#123;            Thread t = w.thread;            // 成功获取到了worker的lock,             // 而worker的lock只会在runWorker方法类里面被获取走            // 说明这个worker是一个空闲的worker            // 通过中断来唤醒阻塞的worker来去检查是不是STOP了            if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123;                try &#123;                    t.interrupt();                &#125; catch (SecurityException ignore) &#123;                &#125; finally &#123;                    w.unlock();                &#125;            &#125;            if (onlyOne)                break;        &#125;    &#125; finally &#123;        mainLock.unlock();    &#125;&#125;\n\nshutdownNow方法shutdownNow会为所有的线程都打上interrupt状态\n\nSTOP: 调用shutdownNow()方法\n不接受新的任务\n同SHUTDOWN\n\n\n不处理队列中的任务\n会将队列清空并返回\n\n\n尝试中断正在执行的任务\n如果方法尝试执行, 但是还没有执行的时候, 也就是worker刚获取到下一轮的task的时候, 会因为状态是STOP, getTask() &#x3D; null, 进入到销毁worker的过程\n\n\n\n\n\npublic List&lt;Runnable&gt; shutdownNow() &#123;    List&lt;Runnable&gt; tasks;    final ReentrantLock mainLock = this.mainLock;    mainLock.lock();    try &#123;        checkShutdownAccess();        advanceRunState(STOP);        interruptWorkers();        tasks = drainQueue();    &#125; finally &#123;        mainLock.unlock();    &#125;    tryTerminate();    return tasks;&#125;private void interruptWorkers() &#123;    // assert mainLock.isHeldByCurrentThread();    for (Worker w : workers)        w.interruptIfStarted();&#125;void interruptIfStarted() &#123;    Thread t;    if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123;        try &#123;            t.interrupt();        &#125; catch (SecurityException ignore) &#123;        &#125;    &#125;&#125;","categories":["Java","JUC","线程池"],"tags":["Java","JUC","线程池"]},{"title":"MySQL Buffer","url":"/2025/07/20/MiddleWare/MySQL/MySQL%20Buffer%20Pool/","content":"Buffer Pool就像CPU Cache一样的缓存中间层, 来提高MySQL的性能, 写方面采用写回策略(修改的时候如果在缓存中, 就会直接修改缓存中的数据, 然后标记为脏页)\nBuffer Pool缓存了什么在MySQL启动的时候, 会为Buffer Pool分配一片连续的内存空间, 然后按照默认的16KB的大小分页, Buffer Pool中的页就是缓存页\nBuffer Pool中缓存了这六种信息\n\n\nundo页记录的是什么\n\n生成undo log的时候, undo log会写入到Buffer Pool中的Undo 页面\n\n查询一条记录, 就只会缓冲一条记录吗\n\n会将整个页都缓存进去\n","categories":["Middleware","MySQL"],"tags":["Middleware","MySQL"]},{"title":"MySQL 日志","url":"/2025/07/20/MiddleWare/MySQL/MySQL%20%E6%97%A5%E5%BF%97/","content":"MySQL日志\n参考文章:  小林coding-MySQL 日志\n\n执行一条update语句, 期间会发生什么\nUPDATE t_user SET name = &#x27;xiaolin&#x27; WHERE id = 1;\n\n首先是前面和查询语句相似的流程\n\n客户端先通过连接器建立连接, 连接器判断用户的身份\n查询缓存, 但是因为这是一条update语句, 所以不会走查询缓存的步骤, 相反会将对应的表的缓存给清空\n通过解析器分析update语句, 拿到update关键字, 表名等信息, 构建出来语法树, 做语法检查\n通过预处理器判断表和字段是否存在\n优化器确定执行计划, 这里因为是通过id作为where的条件, 会通过id这个主键执行查询\n将执行计划交给存储引擎执行, 找到这一行, 然后执行更新\n\n\n而日志就在最后的更新步骤出现了\n\nundo log: Innodb引擎层生成的日志, 实现了事务的原子性, 主要实现了事务回滚和MVCC\nredo log: Innodb引擎层生成的日志, 实现了事务的持久性, 主要实现了crush-safe\nbinlog: Server层生成的日志, 主要用于数据备份和主从复制\n\nundo log是怎么工作的在执行DML语句的时候, 会将回滚时需要的数据都记录到undo log中\n\ninsert语句, 将这个记录的主键值记录下来, 之后要回滚的时候, 就只需要将这个主键值的记录给删除就行了\ndelete语句, 将这个被删除的记录的内容都记录下来, 之后回滚的时候, 就再重新插入\nupdate语句, 将更新列的旧值记录下来, 之后回滚的时候, 将记录重新用旧值覆盖\n如果不是主键列, 会记录旧值, 在回滚的时候用旧值覆盖\n如果是主键列, 会记录成删除旧行再插入新行, 回滚的时候也会将新记录先删除再插入原来的记录\n\n\n\n每条记录有trx_id事务id和roll_pointer指针\n\ntrx_id: 该记录是哪个事务修改的\nroll_pointer: 该指针将一条记录的undo log串联起来, 形成一条版本链\n\n\n在事务执行失败的时候, 就回滚到这个事务执行之前的版本\n上面都是通过undo log实现的事务回滚, undo log同样用于MVCC\n对于 [读提交] 和 [可重复读] 两个执行级别来说, 它们的快照读是通过 Read View + undo log来实现的, 区别在于创建undo log的时机不一样\n\n对于读提交: 在每个select后都会生成一个Read View, 在这个隔离级别中, 不会有脏读现象, 但是如果其他事务修改了数据并且提交了, 该事务中就能读到, 也就会出现同一个select语句前后执行的结果不一样的问题\n对于可重复度: 在事务启动的时候生成一个Read View, 保证了在事务中, 不会读到其他事务修改的数据\n\n为什么需要redo logredo log是用于解决崩溃恢复问题, 也就是数据的持久化(这里包括undo log和表数据)\nredo log是物理日志, 会记录对某个数据页进行了什么修改, 比如对XXX表空间中的YYY数据页ZZZ偏移量的地方做了AAA更新\n\n为什么要写到redo log, 而不直接将数据写到磁盘中, 多此一举\n\nredo log是使用了WAL(Write-Ahaed Logging)技术, MySQL的写操作并不是立刻写到磁盘上, 而是先写日志, 然后写到磁盘上. \n如果直接将数据写入到磁盘中, 就是随机写, 而将数据写入到log文件中因为是追加写, 所以是顺序写, 磁盘的I&#x2F;O性能有10~100倍的提升\n\n产生的redo log是直接写入到磁盘中吗\n\n问出来很明显就不是了, 我们需要注意到内核的缓冲区这个存在, 我们执行write函数, 实际上是将数据写入到内核缓冲区中, 直到我们主动调用fsync()或者内核自己同步, 才会刷盘. 这是其中一方面, 另一方面是redo log本身就有一个redo log buffer, 用于缓冲log, 提高IO性能\nredo log什么时候刷盘redo log刷盘的时机主要有下面几个(注意是刷盘, 而不是写入到文件中, 前者是直接写入到磁盘中的, 后者只是将内容写入到内核缓冲区中)\n\nMySQL正常关闭的时候\nredo log buffer中的记录写入量大于redo log buffer内存空间的一半的时候\n每次事务提交的时候都将缓存在redo log buffer中的redo log直接持久化到磁盘中(这个策略通过innodb_flush_log_at_trx_commit参数控制)\n\n\ninnodb_flush_log_at_trx_commit 参数控制的是什么\n\n\n参数为0的时候: 每次事务提交会将redo log留在redo log buffer\n参数为1的时候: 每次事务提交会将redo log buffer中的redo log直接持久化到磁盘中\n参数为2的时候: 每次事务提交会将redo log buffer中的redo log写入到redo log文件中(并不是持久化到了磁盘中, 而是到了内核中的Page Cache)\n\n\n\n那么innodb_flush_log_at_trx_commit参数的值是0或者2的时候, 什么时候刷盘?\n\nInnoDB后台线程每隔一秒:\n\n参数为0的时候: 后台线程执行write()将redo log buffer中的redo log写到Page Cache中, 再执行fsync()写入到磁盘中, 所以MySQL进程的崩溃, 会导致前1s的所有事务丢失\n参数为2的时候: 区别就是只需要调用fsync(), 数据已经都在Page Cache中了, 所以MySQL进程的崩溃, 不会导致事务丢失, 只有宕机崩溃的时候, 会导致前1s的所有事务丢失\n\n\nredo文件写满了怎么办InnoDB中redo log是以重做文件日志组的形式存在的, redo log group中有两个redo log文件, 两个文件大小一致, 分别叫做 ib_logfile0和ib_logfile1\n重做文件日志组是采用循环写的模式, 从头开始写, 写到了末尾又回到了开头, InnoDB引擎会先写 ib_logfile0, 然后写ib_logfile1, 当 ib_logfile1也写满的时候, 就会重新回到logfile0的开头\nInnoDB使用write pos 表示redo log当前记录写到的位置, checkpoint 表示当前要擦除的位置, 其中要擦除的位置就是已经持久化到磁盘中脏页的位置\n\n如果write pos 追上了 checkpoint, 说明redo log已经满了, 这个时候MySQL会被阻塞, 会停下来将Buffer Pool中的脏页刷新到磁盘中, 将redo log中对应的记录标记并清除, 然后移动checkpoint, MySQL恢复正常\nredo log的格式redo log是物理日志, 记录的是对数据页的修改, redo log的格式是:\nLSN | Log Record Type | Log Record Length | Log Record Body\n\nLSN: Log Sequence Number, redo log的序列号, 用于标识redo log的顺序\nLog Record Type: redo log的类型, 比如更新数据页, 删除数据页\nLog Record Length: redo log的长度, 用于标识redo log的大小\nLog Record Body: redo log的具体内容, 包含了对数据页的修改信息Log Record Body的内容是根据Log Record Type的不同而不同的, 比如更新数据页的Log Record Body会包含更新前的数据和更新后的数据, 删除数据页的Log Record Body会包含被删除的数据\n\n为什么需要binlogbinlog是逻辑日志, 记录的是对数据的修改, binlog的主要作用是用于数据备份和主从复制\nMySQL在执行完一条更新操作以后, Server层还会生成一条binlog, 等事务提交的时候, 会将该事务执行过程中产生的binlog写入到binlog文件中\nbinlog只能用于归档, 是不具备crush-safe能力的\nredo log和binlog的区别\n适用对象不同\n\n\nbinlog是Server层实现的日志, 所有的存储引擎都能使用\nredo log是InnoDB引擎实现的日志, 只能用于InnoDB存储引擎\n\n\n文件格式不同\n\n\nbinlog有 3 种格式: STATEMENT, ROW, MIXED\nSTATEMENT: 记录每一条更新的操作的SQL语句, 这也是为什么binlog会被称作逻辑日志, 主从复制种slave端就是通过binlog中记录的SQL语句来执行更新操作的. 但是会存在动态函数的问题, 比如NOW()函数, 在主从复制中, 主库执行的NOW()函数和从库执行的NOW()函数的时间不一致, 会导致数据不一致\nROW: 记录行数据最后被修改成什么样子(这种格式的日志就不是逻辑日志了), 缺点就是如果是批量更新, 会记录每一行的修改, 可能会导致binlog文件过大\nMIXED: 结合了STATEMENT和ROW两种格式, 会根据不同的情况自动选是使用STATMENT模式还是ROW模式\n\n\n\n\n写入方式不同\n\n\nbinlog是追加写, 写满一个文件, 就创建一个新的文件继续写, 不会覆盖之前的文件, 保存的是全量的日志\nredo log是循环写, 写满一个文件, 就回到开头继续写, 只保存最近的日志\n\n\n用途不同\n\n\nbinlog主要用于数据备份和主从复制, 也可以用于数据恢复\nredo log主要用于崩溃恢复, 也可以用于数据恢复\n\n\n如果整个数据库的数据都被删除了, 能通过redo log来恢复吗\n\n不能, 只能通过binlog来恢复, redo log记录的不是全量的数据, 如果脏页被写入到了磁盘中, 就会从redo log中删除\n主从复制是怎么实现的MySQL集群的主从复制可以分成三个阶段\n\n写入binlog: 主库写binlog日志, 提交事务并更新本地存储数据\n同步binlog: 从库通过IO线程连接到主库, 从主库获取binlog日志, 写入到本地的中继日志中\n回访binlog: 从库通过SQL线程读取中继日志, 执行SQL语句, 更新本地存储数据\n\n\n详细过程是\n\n主库在收到的客户端提交事务的请求之后, 会先写入到binlog中, 然后提交事务, 更新存储引擎中的数据, 事务提交完成后, 返回给客户端”操作成功”的响应\n从库创建一个专门的IO线程, 连接主库的log dump线程, 来接收主库的binlog日志, 再把binlog信息写入到relay log中, 再返回给主库复制的复制成功的响应\n从库会创建一个用于回放binlog的线程, 去读relay log中的中继日志, 然后回放binlog更新存储引擎中数据\n\n\n从库是不是越多越好\n\n并不是, 从库越多, 主库需要创建同样多的log dump线程来处理从库连接上来的IO线程, 对主库的资源消耗较高\n\n主从复制还有哪些模型\n\n\n同步模型: MySQL主库提交事务的线程需要等待所有的从库都响应复制成功以后, 才会返回给客户端结果, 这样的形式性能和可用性都很差\n异步模型: 就是上面的模型, 缺点就是如果主库宕机, 就会出现数据的丢失\n半同步模型: 介于上面两者之间, 事务线程不用等待所有的从库返回复制成功响应, 只需要等待一部分返回复制成功响应就会返回给客户端. 通过这种形式, 保证了即使主库宕机, 也还有从库保存有最新的数据, 不会导致数据丢失\n\nbinlog什么时候刷盘在Server层, binlog有一个binlog cache, 事务提交的时候, 是先写到binlog cache中, 然后再把binlog cache写入到binlog文件中.\n一个线程中只能有一个事务正在执行, 每个线程也都携带了一个binlog cache\n\n什么时候binlog cache会被写入到binlog中\n\n在事务提交的时候, 会将binlog cache中的完整事务写入到binlog文件中, 并清空binlog cache (注意这里不是持久化, 也就是只调用了write(), 而没有调用fsync())\n\nMySQL中提供了sync_binlog参数来控制数据库binlog刷盘的频率\n\nsync_binlog &#x3D; 0的时候, 表示每次提交事务都只write, 不fsync(), 什么时候fsync交给操作系统决定\nsync_binlog &#x3D; N的时候, 表示每次提交事务的时候都只write(), 在积累了N个事务以后fsync\n\nMySQL中默认的是sync_binlog &#x3D; 0\n\n小结update语句的执行过程\n\n这里我们从优化器分析出来了成本最小的执行计划以后, 执行器按照其计划执行\n\n执行器调用存储引擎的接口, 通过主键索引树搜索id &#x3D; 1这一行的记录\n如果id &#x3D; 1这一行所在的数据也本身就在buffer pool中, 就直接返回给执行器更新\n如果不在, 就需要先将数据页从磁盘中加载到buffer pool中, 返回记录给执行器更新\n\n\n执行器拿到聚簇索引记录以后, 比较更新的记录和原记录是不是一样的\n如果是一样的, 不执行后续流程\n不一样, 将更新前的记录和更新后的记录都当作参数传给InnoDB层, 让InnoDB执行真正的更新操作\n\n\n开启事务, InnoDB更新前需要先记录相应的undo log, 因为是更新操作, 所以将旧值存入undo log, 将undo log写入buffer pool中的Undo页面, 然后将这个Undo页面记录到redo log中\nInnoDB层开始更新记录, 先更新内存中记录, 并标记成脏页, 然后将记录写入到redo log中, 这时就是更新完成了, 后台线程将内存中脏页刷盘\n开始记录该语句对应的binlog, binlog先被保存到binlog cache中, 在事务提交的时候统一将该事务运行过程中的所有binlog更新到磁盘上\n最后就是事务提交, 也就是[两阶段提交], 接下来就是讲两阶段提交\n\n为什么需要两阶段提交在主从复制的场景中, 主库MySQL宕机了, redo log负责的是主库的崩溃恢复, binlog负责的是事务能否传播到从库\n而redo log和binlog持久化到磁盘是两个独立逻辑, 那么就会出现下面的两种情况\n\n如果在redo log刷盘以后, MySQL宕机了, binlog还没有来得及刷盘. 这个时候, 崩溃恢复以后, 主库中能将Buffer Pool中的事务修改的数据恢复, 但是从库读binlog并没有执行之前的事务, 出现了主库是新值, 从库是旧值\n如果在binlog刷盘以后, MySQl宕机了, redo log没有刷盘. 就会变成主库是旧值, 从库是新值\n\n这两种情况都是出现了主从库数据不一致的问题\nMySQL给出的解决方案就是两阶段提交, 将事务提交的过程分成了两个阶段, 准备阶段和提交阶段\n两阶段提交是怎么样的为了保证binlog和redo log的一致性, MySQL使用了内部XA事务\n在客户端执行commit的时候, MySQL内部开启一个XA事务, 分两阶段完成XA事务的提交\n\n将redo log的写入拆分成了两个阶段: prepare和commit, 中间穿插binlog\n\nprepare阶段: 将XID (内部XA事务的ID) 写入到redo log, 将redo log对应的事务状态设置成prepare, 将redo log持久化到磁盘(innodb_flush_log_at_trx_commit &#x3D; 1的时候)\ncommit阶段: 将XID写入到binlog中, 然后将binlog持久化到磁盘 (sync_binlog &#x3D; 1的时候), 接着调用引擎的提交事务接口, 将redo log状态设置成 commit\n\n异常重启后的现象\n在MySQL重启以后, 会按照顺序扫描redo log文件, 碰到处于 prepare 状态的 redo log, 就会拿着redo log的XID去binlog中查看是否有该XID\n\n如果没有XID, 说明redo log完成了刷盘, 但是binlog还没有完成刷盘, 回滚事务, 因为从库会无法同步这个数据, 对于到途中的A时刻\n如果有XID, 说明redo log和binlog都完成了刷盘, 则提交事务, 对应B时刻崩溃恢复\n\n对于处于prepare阶段的redo log, 既可以提交事务, 也可以回滚事务, 这取决于是否在binlog中查找到与redo log相同的XID\n两阶的提交是以binlog写成功为事务提交成功的标志\n两阶段提交的问题\n磁盘的I&#x2F;O次数高, 每次事务提交都会有两次刷盘 (如果在两个刷盘配置都是1的情况下)\n锁竞争激烈, 多事务的场景下, 需要通过锁来保证提交的原子性(即保证binlog的写入顺序和事务提交顺序一致)\n\n组提交为了解决锁竞争激烈的问题, 引入了binlog组提交机制, 当有多个事务提交的时候, 将多个binlog刷盘操作合并成一个, 从而减少磁盘I&#x2F;O的次数\n将commit拆分成了三个阶段\n\nflush阶段: 多个事务按照进入的顺序将binlog从binlog cache写入到文件(不刷盘)\nsync阶段: 将多个事务的binlog合并一次刷盘\ncommit阶段: 各个事务按顺序做commit操作\n\n\n在每个阶段引入了锁机制以后, 锁就只针对每个队列进行保护, 不再锁住提交事务的整个过程, 可以看出来, 锁粒度减小了, 这样就使得多个阶段可以并发执行\n\n\nflush 阶段\n\nflush阶段的队列用于支撑redo log的组提交\n\nsync 阶段\n\n事务会在sync队列上等待一定时间, 以组合更多事务的binlog然后一起刷盘\nsync队列的作用是用于支持binlog的提交\n\ncommit 阶段\n\n承接sync阶段的事务, 完成最后的引擎提交\n","categories":["Middleware","MySQL"],"tags":["Middleware","MySQL"]},{"title":"MySQL 锁机制","url":"/2025/07/16/MiddleWare/MySQL/MySQl%20%E9%94%81/","content":"\n参考:\n\nhttps://relph1119.github.io/mysql-learning-notes/#/mysql/25-%E5%B7%A5%E4%BD%9C%E9%9D%A2%E8%AF%95%E8%80%81%E5%A4%A7%E9%9A%BE-%E9%94%81 \nhttps://xiaolincoding.com/mysql/lock/how_to_lock.html\n\n\nMySQL锁机制详解快照读与锁定读MySQL中读可以分作两类\n\n快照读: 也就是普通的select, 读-读场景不需要额外的机制保证并发安全, 而读-写场景通过MVCC来实现隔离级别\n锁定读: 会加锁的读, 是select ... for update或者select ... lock in share mode , 在MySQL中update, delete操作会分成两部分, 读取阶段和写入(删除)阶段, 前一阶段就属于锁定读\n\n共享锁(S)和互斥锁(X)共享锁: 如果一个事务给一个表(记录)加了S锁, 其他事务能再获取这个S锁, 但是该事务和其他事务都不能再获取这个表(记录)的X锁\n互斥锁: 独占锁, 如果有一个事务给一个表(记录)加了X锁, 其他事务不能再从这个表(记录)上获取锁了(无论XS), 同时也不能给已经上锁了的表(记录)加上X锁\n\n\n\n兼容性\n共享锁S\n互斥锁X\n\n\n\n共享锁S\n兼容\n不兼容\n\n\n互斥锁X\n不兼容\n不兼容\n\n\n类似于读-读并发安全, 所以不需要额外处理, 也就是S锁能兼容, 其他的情况都存在并发安全问题, 所以不能兼容\n表锁表级锁锁上整张表的锁, 分有X和S两种\n什么时候会加上表级锁: MySQL InnoDB引擎中因为有更细粒度的行级锁, 所以其实表级锁应用场景极其有限(没啥用)\n但是现在有个问题就是, 如果我们要对某个表加X锁或者S锁, 有个问题就是, 我们需要确保现在这个表是没有不兼容的行锁的\n\n我们要加上表级S锁的时候, 就需要保证表内没有X锁\n我们要加上表级X锁的时候, 就需要保证表内没有锁\n\n这种时候很明显我们不能遍历每行来看是不是有加锁, Innodb引入了意向锁的机制\n意向锁IS锁: 共享意向锁, IX锁: 互斥意向锁\n什么时候会加上意向锁: 现在在加锁前, 我们会现在表级上加上一个意向锁, 比如我们要加上一个互斥X锁, 我们就会先在表上加一把IX, IS同理\n在有了意向锁以后, 我们就能通过判断表上有没有持有IS和IX锁来快速判断现在我们能不能加表锁\nIS, IX是表级锁, 它们的出现仅仅是为了在之后加表级锁的时候快速判断表中是不是存在加锁的记录, IS锁和IS锁之间是兼容的,  IX和IX之间是兼容的\n\n\n\n兼容性\nX\nIX\nS\nIS\n\n\n\nX\n不兼容\n不兼容\n不兼容\n不兼容\n\n\nIX\n不兼容\n兼容 兼容的\n不兼容\n兼容 兼容的\n\n\nS\n不兼容\n不兼容\n兼容 兼容的\n兼容 兼容的\n\n\nIS\n不兼容\n兼容 兼容的\n兼容 兼容的\n兼容 兼容的\n\n\nMDL锁Meta Data Lock: 元数据锁, 是针对DDL操作的锁, 防止在存在事务还在执行的时候变更表结构\n什么时候会加上MDL: \n\n对一张表CRUD的时候, 加上MDL读锁\n修改表结构的时候, 加上MDL写锁\n\nMDL写锁的获取会阻塞MDL读锁的获取, 也就是如果有一个事务在修改表结构获取MDL写锁的时候阻塞了, 后续的CRUD操作都会被阻塞住\nMDL在事务提交后才会释放\nAUTO-INC锁是用于处理AUTO_INCREAMENT自增字段的自增的锁, 如果并发地向一张表中插入记录, 就可能会导致自增字段值重复\n有两种锁来解决并发自增问题\n\nAUTO-INC锁: 在执行插入语句的时候, 会加上一个表级的AUTO_INC锁, 然后分配自增属性的值, 在插入语句执行结束后将锁释放掉, 以此将插入时生成自增值串行化\n轻量级锁: 在执行插入语句的时候, 获取这个轻量级锁, 在生成自增属性的值以后就将锁释放掉\n\n如果我们的插入语句在执行前就知道要插入多少条数据, 就会采用轻量级锁\n\nTIP：设计InnoDB的大佬提供了一个称之为innodb_autoinc_lock_mode的系统变量来控制到底使用上述两种方式中的哪种来为AUTO_INCREMENT修饰的列进行赋值，当innodb_autoinc_lock_mode值为0时，一律采用AUTO-INC锁；当innodb_autoinc_lock_mode值为2时，一律采用轻量级锁；当innodb_autoinc_lock_mode值为1时，两种方式混着来（也就是在插入记录数量确定时采用轻量级锁，不确定时使用AUTO-INC锁）。不过当innodb_autoinc_lock_mode值为2时，可能会造成不同事务中的插入语句为AUTO_INCREMENT修饰的列生成的值是交叉的，在有主从复制的场景中是不安全的。\n\n行锁行锁在MySQL中是InnoDB独有的更加细粒度的锁\n记录锁Record Lock: 记录锁, 有S锁和X锁之分, 是针对一条记录上加的锁, 也就是对某一行加上的锁\n什么时候加锁: 在执行锁定读的时候会对遍历到的行加上, 往往是以next-key lock的组成部分的形式被加上\n间隙锁Gap Loc: 间隙锁, 有S锁和X锁, 但是没有分别, 实际上是都是S锁的行为, 多个事务可同时获取一个间隙的Gap Lock, 是对一个开区间的锁, 用于解决可重复读隔离级别下的幻读现象的\n\n在id范围(3, 5)的间隙锁以后, 其他事务就无法再插入id &#x3D;4的记录了\n什么时候加锁: 和记录锁是一样的, 执行锁定读的时候会对遍历到的行加上, 往往是以next-key lock的组成部分的形式被加上\nNext-Key LockNext-Key Lock &#x3D; Record Lock + Gap Lock, 锁定一个范围, 并且锁定记录本身\n因为Next-Key Lock是包含Record Lock的, 所以是分X锁和S锁的\n插入意向锁是在insert前会对某个记录加上锁, 用于提高插入的并发效率, 只要插入位置不同, 想插入的事务间不会相互阻塞, 只有当多个事务尝试插入相同位置时才会产生冲突\n什么时候加锁: 在执行插入操作的时候需要判断这个位置上有没有间隙锁, 如果有, 插入操作就会被阻塞, 然后生成一个插入意向锁(is_wait &#x3D; true), 在这个间隙锁被释放掉以后, 插入意向锁就会被真正获取到, 执行插入操作\n有插入意向锁（当前机制）：\ncss复制索引：[1] [4] [7] [10]事务A：INSERT 5  → 在(4,7)设置插入意向锁事务B：INSERT 6  → 在(4,7)设置插入意向锁结果：两个事务可以并发执行 ✓\n\n没有插入意向锁（假设情况）：\ncss复制索引：[1] [4] [7] [10]事务A：INSERT 5  → 在(4,7)设置间隙锁事务B：INSERT 6  → 等待事务A释放间隙锁结果：事务B被阻塞，必须等待 ✗\n","categories":["Middleware","MySQL","Lock"]},{"title":"工作流-Chain Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/1.%20Workflow-ChainWorkflow/","content":"工作流-lian’shi\n参考\n\nhttps://www.anthropic.com/engineering/building-effective-agents\n\n\n流程说明对于链式工作流, 整体的呈现效果就是用户输入userInput以后, 这个userInput在输入以后会链式的向下执行, 在每个节点携带上一个节点的回答和使用当前节点的prompt来和LLM对话\n\n填充systemPrompts数组, 在这种情况下, Chain Workflow也被称作Prompts Chain工作流\n遍历每个prompt\n将上一轮的回答和现在的prompt组成一个新的input\n对话获取response\n\n\n输出最后的response\n\n\n代码\n代码\n\npublic String chain(String userInput) &#123;    String response = usertInput;        for (String promt : systemPrompts) &#123;        String input = String.format(&quot;&#123;%s&#125;\\n &#123;%s&#125;&quot;, prompt, response);        String response = chatClient.prompt(input).call().conmtent();                if(!check(response)) &#123;            return this.errorResponse;        &#125;    &#125;    return response;&#125;\n\n\n系统prompt示例\n\n// Step 1    &quot;&quot;&quot;    Extract only the numerical values and their associated metrics from the text.    Format each as&#x27;value: metric&#x27; on a new line.    Example format:    92: customer satisfaction    45%: revenue growth&quot;&quot;&quot;,// Step 2    &quot;&quot;&quot;    Convert all numerical values to percentages where possible.    If not a percentage or points, convert to decimal (e.g., 92 points -&gt; 92%).    Keep one number per line.    Example format:    92%: customer satisfaction    45%: revenue growth&quot;&quot;&quot;,// Step 3    &quot;&quot;&quot;    Sort all lines in descending order by numerical value.    Keep the format &#x27;value: metric&#x27; on each line.    Example:    92%: customer satisfaction    87%: employee satisfaction&quot;&quot;&quot;,// Step 4    &quot;&quot;&quot;    Format the sorted data as a markdown table with columns:    | Metric | Value |    |:--|--:|    | Customer Satisfaction | 92% | &quot;&quot;&quot;\n\n\n\n使用场景此工作流非常适合于任务可以轻松明晰地分解成多个固定子步骤的场景. 用延迟换取更高的准确性\n\n原文: \nWhen to use this workflow: This workflow is ideal for situations where the task can be easily and cleanly decomposed into fixed subtasks. The main goal is to trade off latency for higher accuracy, by making each LLM call an easier task.\n\n举例说明: \n\n撰写文章大纲, 检查大纲是否符合某些标准, 然后根据大纲完成文档\n从MCP中获取应用监控数据, 提取出来关键信息, 捕捉其中的异常, 推送给管理者\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Parallelization Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/3.%20Workflow-ParallelizationWorkflow/","content":"工作流-并行工作流流程说明\n用户输入input数组对应需要并行执行一系列任务, 适用于所有的任务的prompt, 以及线程池的数量\n将每个input并行化运行LLM\n等待所有的运行完毕后返回\n\n代码public List&lt;String&gt; parallel(String prompt, List&lt;String&gt; inputs, int nWorks) &#123;    ExecutorService executor = Executors.newFixedThreadPool(nWorkers);        try &#123;        List&lt;CompletableFuture&lt;String&gt;&gt; futures = input.stream()            .map(input -&gt; CompletableFuture.supplyAsync(() 0&gt; &#123;                try&#123;                    return chatClient.prompt(prmopt + &quot;\\nInput: &quot; + input).call().content();                &#125; catch (Exception e) &#123;                    throw new RuntimeException(&quot;Failed to process input: &quot; + input, e);                &#125;            &#125;, executor))            .collect(Collectors.toList());                // 等待所有的任务结束        CompletableFuture&lt;Void&gt; allFutures = CompletableFuture.allof(        \t\t\tfutures.toArray(CompletableFuture[]::new));        allFutures.join();                return futures.stream()            .map(CompletableFuture::join)            .collec(Collectors.toList());    &#125;&#125;\n\n适用场景当拆分后的子任务可以并行化以提高速度的时候, 或者需要多个视角或尝试来获取更高置信度的结果的时候. 涉及到多方面考量的复杂任务的时候, 每个考量都由单独的LLM调用处理, LLM的表现会更好\n\n原文:\nWhen to use this workflow: Parallelization is effective when the divided subtasks can be parallelized for speed, or when multiple perspectives or attempts are needed for higher confidence results. For complex tasks with multiple considerations, LLMs generally perform better when each consideration is handled by a separate LLM call, allowing focused attention on each specific aspect.\n\n\n投票场景, 多次运行相同的任务来获得不同的输出\n切分: 将并行化的任务交给不同的LLM来执行, 比如自动评估的时候, 或者防护机制, 一个LLM处理用户的查询, 另一个模型沙宣不适当的请求和内容\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Evaluator-optimizer","url":"/2025/07/19/Project/AI%20Agentic%20System/5.%20%20Workflow-Evaluator-optimizer.md/","content":"工作流-评估优化器流程说明在评估-优化器中, 一个LLM调用生成响应, 另一个在循环中提供评估和反馈\n\n用户输入task\nLLM生成第一轮的回复\n对LLM的回复生成评估\n检查评估的结果是不是PASS, 如果是, 直接返回最终结果\n\n\n将所有的历史memory都添加到上下文中, 以及将回复评估添加到上下文中\n进行下一次循环\n\n代码\nloop\n\nprivate RefinedResponse loop(String task, String context, List&lt;String&gt; memory,                             List&lt;Generation&gt; chainOfThought) &#123;    Generation generation = generate(task, context);    memory.add(generation.response());    chainOfThought.add(generation);    EvaluationResponse evaluationResponse = evalute(generation.response(), task);    if (evaluationResponse.evaluation().equals(EvaluationResponse.Evaluation.PASS)) &#123;        // Solution is accepted!        return new RefinedResponse(generation.response(), chainOfThought);    &#125;    // Accumulated new context including the last and the previous attempts and    // feedbacks.    StringBuilder newContext = new StringBuilder();    newContext.append(&quot;Previous attempts:&quot;);    for (String m : memory) &#123;        newContext.append(&quot;\\n- &quot;).append(m);    &#125;    newContext.append(&quot;\\nFeedback: &quot;).append(evaluationResponse.feedback());    return loop(task, newContext.toString(), memory, chainOfThought);&#125;\n\n\ngenerate\n\nprivate Generation generate(String task, String context) &#123;    Generation generationResponse = chatClient.prompt()        .user(u -&gt; u.text(&quot;&#123;prompt&#125;\\n&#123;context&#125;\\nTask: &#123;task&#125;&quot;)              .param(&quot;prompt&quot;, this.generatorPrompt)              .param(&quot;context&quot;, context)              .param(&quot;task&quot;, task))        .call()        .entity(Generation.class);    System.out.println(String.format(&quot;\\n=== GENERATOR OUTPUT ===\\nTHOUGHTS: %s\\n\\nRESPONSE:\\n %s\\n&quot;,                                     generationResponse.thoughts(), generationResponse.response()));    return generationResponse;&#125;\n\n\nevalute\n\nprivate EvaluationResponse evalute(String content, String task) &#123;    EvaluationResponse evaluationResponse = chatClient.prompt()        .user(u -&gt; u.text(&quot;&#123;prompt&#125;\\nOriginal task: &#123;task&#125;\\nContent to evaluate: &#123;content&#125;&quot;)              .param(&quot;prompt&quot;, this.evaluatorPrompt)              .param(&quot;task&quot;, task)              .param(&quot;content&quot;, content))        .call()        .entity(EvaluationResponse.class);    System.out.println(String.format(&quot;\\n=== EVALUATOR OUTPUT ===\\nEVALUATION: %s\\n\\nFEEDBACK: %s\\n&quot;,                                     evaluationResponse.evaluation(), evaluationResponse.feedback()));    return evaluationResponse;&#125;\n\n\n\n\nGenerator prompt\n\n&quot;&quot;&quot;Your goal is to complete the task based on the input. If there are feedbackfrom your previous generations, you should reflect on them to improve your solution.CRITICAL: Your response must be a SINGLE LINE of valid JSON with NO LINE BREAKS except those explicitly escaped with \\\\n.Here is the exact format to follow, including all quotes and braces:&#123;&quot;thoughts&quot;:&quot;Brief description here&quot;,&quot;response&quot;:&quot;public class Example &#123;\\\\n    // Code here\\\\n&#125;&quot;&#125;Rules for the response field:1. ALL line breaks must use \\\\n2. ALL quotes must use \\\\&quot;3. ALL backslashes must be doubled: \\\\4. NO actual line breaks or formatting - everything on one line5. NO tabs or special characters6. Java code must be complete and properly escapedExample of properly formatted response:&#123;&quot;thoughts&quot;:&quot;Implementing counter&quot;,&quot;response&quot;:&quot;public class Counter &#123;\\\\n    private int count;\\\\n    public Counter() &#123;\\\\n        count = 0;\\\\n    &#125;\\\\n    public void increment() &#123;\\\\n        count++;\\\\n    &#125;\\\\n&#125;&quot;&#125;Follow this format EXACTLY - your response must be valid JSON on a single line.&quot;&quot;&quot;\n\n\nEvaluator prompt\n\n&quot;&quot;&quot;Evaluate this code implementation for correctness, time complexity, and best practices.Ensure the code have proper javadoc documentation.Respond with EXACTLY this JSON format on a single line:&#123;&quot;evaluation&quot;:&quot;PASS, NEEDS_IMPROVEMENT, or FAIL&quot;, &quot;feedback&quot;:&quot;Your feedback here&quot;&#125;The evaluation field must be one of: &quot;PASS&quot;, &quot;NEEDS_IMPROVEMENT&quot;, &quot;FAIL&quot;Use &quot;PASS&quot; only if all criteria are met with no improvements needed.&quot;&quot;&quot;\n\n适用场景在有清晰的评估标准, 并且迭代改进提供可衡量的价值. 良好契合的两个标志是\n\n当人类清晰地表达反馈时, LLM的答案可以得到显著的改进\nLLM能表达这种反馈\n\n\n原文:\nWhen to use this workflow: This workflow is particularly effective when we have clear evaluation criteria, and when iterative refinement provides measurable value. The two signs of good fit are, first, that LLM responses can be demonstrably improved when a human articulates their feedback; and second, that the LLM can provide such feedback. This is analogous to the iterative writing process a human writer might go through when producing a polished document.\n\n\n复杂的搜索任务需要多轮搜索和分析才能收集全面的信息, 评估人员是否需要进一步搜索\n生成代码的自优化\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"工作流-Routing Workflow","url":"/2025/07/18/Project/AI%20Agentic%20System/2.%20Workflow-RoutingWorkflow/","content":"工作流-路由工作流流程说明用户输入userInput和可行的路由Map&lt;String, Object&gt; String是对这个路由的简介, Object就是实际的路由内容\n这里以角色分配, 将不同的任务分配给不同的promt角色的使用方式举例\n\n用户输入初始的userInput和Map&lt;String, String&gt;\n根据userInput和Map的keySet让LLM决策当前任务使用的prompt角色, 给出原因和选择, 使用结构化的输出到RoutingResponse中\n使用对应的prompt角色, 输出最后的结果\n\n\n代码\nroute方法\n\npublic String route(String userInput, Map&lt;String, Object&gt; routes, String mode) &#123;    RoutingResponse routingResponse = determineRoute(input, routes.keySet);        Object select = routes.get(routingResponse.getSelect());    \tswitch (mode) &#123;        case &quot;prompts&quot;:            // 选择不同的prompt解决这个问题            return chatClient.prompt((String) select + &quot;\\nInput: &quot; + userInput).call().content();        case &quot;modelChoose&quot;:            // 选择不同的client解决这个问题            return (chatClient) select.prompt(userInput).call().content();    &#125;&#125;\n\n\ndetermineRoute方法\n\nprivate String determineRoute(String input, Iterable&lt;String&gt; availableRoutes) &#123;\tString selectorPrompt = String.format(&quot;&quot;&quot;                Analyze the input and select the most appropriate support team from these options: %s                First explain your reasoning, then provide your selection in this JSON format:                \\\\&#123;                    &quot;reasoning&quot;: &quot;Brief explanation of why this ticket should be routed to a specific team.                                Consider key terms, user intent, and urgency level.&quot;,                    &quot;selection&quot;: &quot;The chosen team name&quot;                \\\\&#125;                Input: %s&quot;&quot;&quot;, availableRoutes, input);                                              RoutingResponse routingResponse = chatClient.prompt(selectorPrompt).call().entity(RoutingResponse.class);    return routingResponse.selection();&#125;\n\n适用场景适合处理存在不同的分类, 分别处理的复杂任务\n\n原文:\nWhen to use this workflow: Routing works well for complex tasks where there are distinct categories that are better handled separately, and where classification can be handled accurately, either by an LLM or a more traditional classification model&#x2F;algorithm.\n\n\n将简单&#x2F;常见问题路由到较小的模型（如 Claude 3.5 Haiku），将困难&#x2F;不寻常的问题路由到功能更强大的模型（如 Claude 3.5 Sonnet），以优化成本和速度。\n将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具中。\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"Spring AI 测试文件","url":"/2025/07/10/Spring/Spring%20AI/Spring%20AI-test/","content":"Spring AI 测试文件\n","categories":["Spring","Spring AI"],"tags":["Spring AI"]},{"title":"工作流-Orchestrator-workers","url":"/2025/07/18/Project/AI%20Agentic%20System/4.%20Workflow-Orchestrator-workers/","content":"工作流-编排器-工人工作流流程说明这个工作流可以看作是ParallelizationWorkflow的自动分配任务版本\n中央LLM动态分解任务, 并将其委派给工作者LLM, 并综合结果\n\n用户输入任务描述input\n将用户的任务和编排器prompt输入给LLM用于划分任务\n将划分后的任务集合和工人prompt输入给LLM用于执行划分后的任务\n返回所有的执行结果\n\n代码\n执行代码, process\n\npublic FinalResponse process(String taskDescription) &#123;    // 获取编排器的编排结果    OrchestratorResponse orchestratorResponse = this.chatClient.prompt()        .user(u -&gt; u.text(this.orchestratorPrompt))        \t\t\t.param(&quot;task&quot;, taskDescription)        .call()        .entity(OrchestratorResponse.class);        // 执行每个任务    List&lt;String&gt; workerResponse = orchestratorResponse.tasks().stram().map(task -&gt; this.chatClient.prompt()     .user(u -&gt; u.text(this.workerPrompt)          .param(&quot;original_task&quot;, taskDescription)          .param(&quot;task_type&quot;, task.type())          .param(&quot;task_description&quot;, task.description())      ))      .call()      .content().toList();        return new FinalResponse(orchestratorResponse.analysis(), workerResponse);&#125;\n\n\n\n\norchestrator prompt\n\n&quot;&quot;&quot;Analyze this task and break it down into 2-3 distinct approaches:Task: &#123;task&#125;Return your response in this JSON format:\\\\&#123;&quot;analysis&quot;: &quot;Explain your understanding of the task and which variations would be valuable.Focus on how each approach serves different aspects of the task.&quot;,&quot;tasks&quot;: [\\\\&#123;&quot;type&quot;: &quot;formal&quot;,&quot;description&quot;: &quot;Write a precise, technical version that emphasizes specifications&quot;\\\\&#125;,\\\\&#123;&quot;type&quot;: &quot;conversational&quot;,&quot;description&quot;: &quot;Write an engaging, friendly version that connects with readers&quot;\\\\&#125;]\\\\&#125;&quot;&quot;\n\n\nworker\n\n&quot;&quot;&quot;Generate content based on:Task: &#123;original_task&#125;Style: &#123;task_type&#125;Guidelines: &#123;task_description&#125;&quot;&quot;&quot;\n\n适用场景非常适合无法预测所需子任务的复杂任务, 在拓扑结构上和并行化类似, 和并行化的关键区别是在于灵活性-子任务不需要预先定义, 而是由编排器根据具体的输入确定\n\n原文:\nWhen to use this workflow: This workflow is well-suited for complex tasks where you can’t predict the subtasks needed (in coding, for example, the number of files that need to be changed and the nature of the change in each file likely depend on the task). Whereas it’s topographically similar, the key difference from parallelization is its flexibility—subtasks aren’t pre-defined, but determined by the orchestrator based on the specific input.\n\n\n每次对多个文件进行复杂更改的编码产品\n搜索任务涉及从多个来源搜集和分析信息以获取可能相关的信息\n\n","categories":["Project","AI Agentic System","Workflow"],"tags":["Project","AI Agentic System","Workflow"]},{"title":"操作系统I/O - 零拷贝","url":"/2025/07/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/Operating%20System/IO-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","content":"","categories":["Compuiter Fundamentals","OS","IO"],"tags":["Compuiter Fundamentals","OS","IO"]},{"title":"操作系统I/O - 零拷贝","url":"/2025/07/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/Operating%20System/IO-%E9%9B%B6%E6%8B%B7%E8%B4%9D/","content":"I&#x2F;O的演进DMA技术在最开始的时候, 读一个文件的过程是\n\n\n用户进程调用read(), 切换到内核态, CPU向磁盘发起IO请求\n磁盘将数据放入到磁盘控制器缓冲区里面, 发送IO中断信号给CPU\nCPU将数据从磁盘数据控制器缓冲区中拷贝到 PageCache\nCPU将数据从PageCache中拷贝到用户缓冲区\nread()调用返回, 切换到用户态\n\n一共发生了两次用户态和内核态的上下文切换, 发生了两次拷贝, 并且数据的搬运也是交给CPU来操作的, 占用了大量的CPU的时间, 导致了CPU吞吐量下降\n解决方式就是引入了DMA(Direct Memory Access)直接内存访问技术, \n我们将把数据从磁盘控制器缓冲区搬运到PageCache的工作交给了DMA控制器来进行\n\n现在的读一个文件的流程变成了\n\n用户进程调用read(), 切换到内核态, 向操作系统发起IO请求, 将数据读取到自己的内存缓冲区中, 进程进入到了阻塞状态\nCPU收到操作系统发送的指令以后, 将请求发送给DMA, DMA再进一步发送给磁盘\n磁盘将数据放入到磁盘控制器缓冲区里面, 发送IO中断信号给DMA控制器, 告知缓冲区已满\nDMA收到磁盘的信号, 将磁盘缓冲区中的数据拷贝到内核缓冲区中, 此时不占用CPU, CPU可以执行其他的任务\nCPU将数据从PageCache中拷贝到用户缓冲区\nread()调用返回, 切换到用户态\n\n零拷贝我们如果要使用网络传输一个文件, 最初是怎么实现的\n我们一般要用到两个系统调用\nread(file, tmp_buf, len);write(socket, tmp_buf, len);\n\nread读取文件到buf中, write再将这个buf中的内容通过socket发送给客户端, 在这个过程中, 我们会经历四次用户态和内核态的上下文切换, 四次拷贝\n\n\n用户调用read()系统调用, 切换内核态\n将文件从磁盘控制器缓冲区DMA拷贝到内核缓冲区\n将文件从内核缓冲区CPU拷贝到用户缓冲区\n切换到用户态\n用户调用write(), 切换到内核态\n将用户缓冲区中的数据CPU拷贝到socket缓冲区中\n将socket缓冲区的数据DMA拷贝到网卡中, 发送数据\n切换回用户态\n\n我们要优化这种IO形式, 关键就在于减少内核态与用户态的上下文切换, 并减少拷贝的次数\n\n怎么减少用户态和内核态的切换, 只要执行了一次系统调用, 不可避免地会有两次切换, 所以核心思路就是减少系统调用的数量\n\n\n怎么减少拷贝的数量, 在这个文件出书的场景中, 其实用户缓冲区是完全没有必要的存在\n\nmmap + write使用mmap代替read函数\nbuf = mmap(file, len);write(sockfd, buf, len);\n\nmmap系统调用直接把内核缓冲区中的数据映射到用户空间, 这样我们就相当于不使用用户缓冲区中转数据, 减少了一次数据的拷贝\n\n现在PageCache中的数据直接通过CPU拷贝到scoket缓冲区中\n但是这种形式系统调用的次数仍然是两次, 也就是内核态和用户态的上下文切换的次数仍然是四次\nsendfile#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd. int in_fd, off_t *offset, size_t count);\n\n这个系统调用能直接将mmap + write合并, 能减少一次系统调用的次数\n并且如果网卡支持SG-DMA技术(The Scatter-Gather Direct Memory Access), 还能再减少一次数据拷贝\n\n\n通过DMA将磁盘的数据拷贝到内核缓冲区\n缓冲区描述符和数据长度传到socket缓冲区, 网卡的SG-DMA控制器直接将内核缓存中的数据拷贝到网卡的缓冲区中\n\n省去了将数据从内核缓冲区中拷贝到socket缓冲区中的过程\n这样就是零拷贝的最终形态, 只需要两次数据的拷贝, 两次内核态和用户态的上下文切换, 并且没有在内存层面的数据拷贝, 也就是这个过程全程是通过DMA来进行的, 不需要CPU参与\n大文件传输实现的特殊性PageCache我们常说的IO文件的时候的内核缓冲区, 就是PageCache(磁盘高速缓存). 在零拷贝中我们就使用了PageCache, 读文件时候, 会先将数据通过DMA控制器读到内核缓冲区中. 实际上PageCache就可以看作是磁盘和内存之间的中间层, 和CPU Cache是性质类似的东西\nPageCache有预读功能, 同时PageCache内部是一个LRU队列, 会维护热点数据. 如果我们读大文件, 就会导致LRU队列我们批量读取文件的时候的预读失效和缓存污染问题(当然Linux通过inactive_list和active_list以及升级策略很大程度上解决了这个问题). \n但是我们还是能很明显看出, 在读大文件的时候PageCache是没有什么作用的, \n\n读大文件预读功能没有什么用\n缓存最近被访问的数据, 大文件导致缓存污染\n\n相当于DMA多做了一次没有的数据拷贝\n直接I&#x2F;O我们直接绕开DMA, 并且不再拷贝到内核缓冲区中. 阻塞问题我们使用异步I&#x2F;O来解决\n\n\n用户进程调用系统调用, 发起异步I&#x2F;O读, CPU发送指令到磁盘, 这里会直接返回, 也就是不阻塞读\n然后磁盘准备好数据后发送IO中断信号, DMA将数据从磁盘控制器缓冲区拷贝到用户缓冲区\n通知用户进程读取成功了\n\n直接I&#x2F;O绕过了PageCache就无法享受到内核提供的两点优化\n\n内核的I&#x2F;O调度算法会缓存尽可能多的I&#x2F;O请求在PageCache中, 最后合并成一个更大的I&#x2F;O请求, 减少I&#x2F;O次数\n无法享受到预读机制\n\n\n参考文档:\n小林coding 9.1什么是零拷贝\n\n","categories":["Compuiter Fundamentals","OS","IO"],"tags":["Compuiter Fundamentals","OS","IO"]},{"title":"Binary Sort-二分查找","url":"/2025/07/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/Algorithm/Binary%20Search/","content":"二分查找典型特征\n原数组是有序的, 或者改变原数组顺序不影响答案\n我们要找出来一个数字在数组中的位置(标准二分查找题目)\n\n一般化特征\n我们能一次性排除解空间中的一半解\n我们要找出来解空间中的某一个解的位置\n\n解题通法-红蓝染色法我们能将数组依照单调性分成两部分, 以我们要找出target为例\nnum &gt;&#x3D; target的部分染成蓝色, num &lt; target为红色, 我们需要染色的区间是[left, right]或者(left-1, right+1)…\n\n[left, right]要染色的区间的含义就是我们现在没有染色也就是不知道其中的元素和target之间的关系\n\n循环不变量(以两端闭区间举例)\n\nleft - 1始终是红色\nright + 1始终是蓝色\n\n思考顺序\n首先确定我们怎么确定答案, 这种方式一定是要利用原数组在找到答案方面的单调性, 我们一定能一次性排除一半的解空间\n确定下来红蓝染色情况\n确定下来没有染色区间的开闭选择(一般是双开区间)\n\n典型例题及实现找到第一个大于等于target的值\n闭区间private int lower_bound(int[] nums, int target) &#123;    int left = 0;    int right = nums.length - 1;    // [left, right], left == right + 1 区间为空    // left - 1始终 &lt; target    // right + 1始终 &gt;= target    while (left &lt; right + 1) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid + 1;        else             right = mid - 1;    &#125;    return right + 1;&#125;\n\n开区间private int lower_bound(int[] nums, int target) &#123;    int left = -1;    int right = nums.length;    // (left, right), left + 1 == right 区间为空    // left 始终 &lt; target    // right 始终 &gt;= target    while (left + 1 &lt; right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid;        else             right = mid;    &#125;    return right;&#125;\n\n左开右闭private int lower_bound(int[] nums, int target) &#123;    int left = -1;    int right = nums.length - 1;    // (left, right], left == right 区间为空    // left 始终 &lt; target    // right + 1始终 &gt;= target    while (left &lt; right) &#123;        int mid = left + (right - left + 1) / 2;        if (nums[mid] &lt; target)             left = mid;        else             right = mid - 1;    &#125;    return right + 1;&#125;\n\n这里会有个额外的问题是mid向下取整, 会在left &#x3D; -1, right &#x3D; 0的时候取到-1, 所以我们需要调整成向上取整, 在left &#x3D; -1, right &#x3D; 0的时候取整到0, 就会不落到区间外面了\n左闭右开private int lower_bound(int[] nums, int target) &#123;    int left = 0;    int right = nums.length;    // [left, right), left == right 区间为空    // left - 1始终 &lt; target    // right 始终 &gt;= target    while (left &lt; right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target)             left = mid + 1;        else             right = mid;    &#125;    return right;&#125;\n\n题单典型题目35. 搜索插入位置\n74. 搜索二维矩阵\n34. 在排序数组中查找元素的第一个和最后一个位置\n非典型题目33. 搜索旋转排序数组\n153. 寻找旋转排序数组中的最小值\n参考链接灵茶山艾府-红蓝染色法\n","categories":["Algorithm","Binary sort"],"tags":["Algorithm","Binary Sort"]}]